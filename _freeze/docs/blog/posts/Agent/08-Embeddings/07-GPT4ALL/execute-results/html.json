{
  "hash": "fc6f40abea188950bb7e6eb54e7e8fc6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"GPT4All\"\nsubtitle: 임베딩\ndescription: |\n  텍스트를 벡터로 변환하는 다양한 임베딩 모델을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n[GPT4All](https://gpt4all.io/index.html)은 무료로 사용할 수 있는 로컬 실행 기반의 개인정보 보호를 고려한 챗봇입니다.\n\nGPU나 인터넷 연결이 필요하지 않으며, GPT4All Falcon, Wizard 등 인기 있는 모델과 자체 모델을 제공합니다.\n\n이 노트북에서는 LangChain과 함께 [GPT4All embeddings](https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All)를 사용하는 방법을 설명합니다.\n\n::: {#4efe19b2 .cell execution_count=1}\n``` {.python .cell-code}\n# API KEY를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API KEY 정보로드\nload_dotenv()\n```\n:::\n\n\n::: {#6e20bdcc .cell execution_count=2}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH08-Embeddings\")\n```\n:::\n\n\n## GPT4All의 Python 바인딩 설치\n\nGPT4All의 Python 바인딩을 설치하려면 다음 명령을 실행하세요\n\n::: {#23621ea9 .cell execution_count=3}\n``` {.python .cell-code}\n# 설치\n# !pip install -qU  gpt4all > /dev/null\n```\n:::\n\n\n- `GPT4AllEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.\n\n`GPT4AllEmbeddings`는 GPT4All 모델을 사용하여 텍스트 데이터를 벡터로 임베딩하는 기능을 제공하는 클래스입니다. 이 클래스는 LangChain 프레임워크의 임베딩 인터페이스를 구현하여, LangChain의 다양한 기능과 함께 사용할 수 있습니다.\n\n::: {#1f2d85a7 .cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain_community.embeddings import GPT4AllEmbeddings\n```\n:::\n\n\nGPT4All은 CPU에 최적화된 대조 학습 문장 변환기를 사용하여 임의 길이의 텍스트 문서에 대한 고품질 임베딩 생성을 지원합니다. 이러한 임베딩은 OpenAI를 사용하는 많은 작업에서 품질이 비슷합니다.\n\n`GPT4AllEmbeddings` 클래스의 인스턴스를 생성합니다.\n\n- `GPT4AllEmbeddings`는 GPT4All 모델을 사용하여 텍스트 데이터를 벡터로 변환하는 임베딩 모델입니다.\n- 이 코드에서는 `gpt4all_embd` 변수에 `GPT4AllEmbeddings` 인스턴스를 할당합니다.\n- 이후 `gpt4all_embd`를 사용하여 텍스트 데이터를 벡터로 변환할 수 있습니다.\n\n::: {#34345e78 .cell execution_count=5}\n``` {.python .cell-code}\ngpt4all_embd = GPT4AllEmbeddings()  # GPT4All 임베딩 객체를 생성합니다.\n```\n:::\n\n\n::: {#dd3dc10d .cell execution_count=6}\n``` {.python .cell-code}\ngpt4all_embd = GPT4AllEmbeddings()  # GPT4All 임베딩 객체를 생성합니다.\n```\n:::\n\n\n- `text` 변수에 \"임베딩 테스트를 하기 위한 샘플 문장입니다.\" 라는 문자열을 할당합니다.\n\n::: {#9dfad986 .cell execution_count=7}\n``` {.python .cell-code}\ntext = (\n    \"임베딩 테스트를 하기 위한 샘플 문장입니다.\"  # 테스트용 문서 텍스트를 정의합니다.\n)\n```\n:::\n\n\n## Embed the Textual Data\n\n텍스트 데이터를 임베딩하는 과정은 다음과 같습니다.\n\n먼저, 텍스트 데이터를 토큰화하여 숫자 형태로 변환합니다.\n\n이때, 사전 학습된 토크나이저(tokenizer)를 활용하여 텍스트를 토큰 단위로 분리하고, 각 토큰을 고유한 정수로 매핑합니다.\n\n다음으로, 토큰화된 데이터를 임베딩 레이어에 입력하여 고차원의 밀집 벡터(dense vector) 형태로 변환합니다.\n\n이 과정에서 각 토큰은 해당 토큰의 의미와 문맥을 포착하는 실수 값들의 벡터로 표현됩니다.\n\n마지막으로, 임베딩된 벡터는 다양한 자연어 처리 작업에 활용될 수 있습니다.\n\n예를 들어, 문서 분류, 감성 분석, 기계 번역 등의 작업에서 입력 데이터로 사용되어 모델의 성능을 향상시킬 수 있습니다.\n\n이러한 텍스트 데이터 임베딩 과정은 자연어 처리 분야에서 매우 중요한 역할을 하며, 대량의 텍스트 데이터를 효과적으로 처리하고 분석하는 데 필수적입니다.\n\n`gpt4all_embd` 객체의 `embed_query` 메서드를 사용하여 주어진 텍스트(`text`)를 임베딩합니다.\n\n- `text` 변수에 임베딩할 텍스트가 저장되어 있습니다.\n- `gpt4all_embd` 객체는 GPT4All 모델을 사용하여 텍스트 임베딩을 수행하는 객체입니다.\n- `embed_query` 메서드는 주어진 텍스트를 벡터 형태로 변환하여 반환합니다.\n- 임베딩 결과는 `query_result` 변수에 저장됩니다.\n\n::: {#28b5d827 .cell execution_count=8}\n``` {.python .cell-code}\nquery_result = gpt4all_embd.embed_query(\n    text\n)  # 주어진 텍스트에 대한 쿼리 임베딩을 생성합니다.\n```\n:::\n\n\nembed_documents 함수를 사용하면 여러 개의 텍스트 조각을 임베딩할 수 있습니다.\n\n또한 이러한 임베딩을 Nomic의 Atlas(https://docs.nomic.ai/index.html)와 매핑하여 데이터의 시각적 표현을 확인할 수 있습니다.\n\n임베딩된 차원의 크기를 확인합니다.\n\n::: {#6ec36026 .cell execution_count=9}\n``` {.python .cell-code}\n# 임베딩된 차원의 크기를 확인합니다.\nlen(query_result)\n```\n:::\n\n\n`gpt4all_embd` 객체의 `embed_documents` 메서드를 사용하여 `text` 문서를 임베딩합니다.\n\n- `text` 문서를 리스트로 감싸서 `embed_documents` 메서드의 인자로 전달합니다.\n- `embed_documents` 메서드는 문서의 임베딩 벡터를 계산하여 반환합니다.\n- 반환된 임베딩 벡터는 `doc_result` 변수에 저장됩니다.\n\n::: {#e6647c12 .cell execution_count=10}\n``` {.python .cell-code}\n# 주어진 텍스트를 임베딩하여 문서 벡터를 생성합니다.\ndoc_result = gpt4all_embd.embed_documents([text])\n```\n:::\n\n\n::: {#61fc8722 .cell execution_count=11}\n``` {.python .cell-code}\n# 임베딩된 차원의 크기를 확인합니다.\nlen(doc_result[0])\n```\n:::\n\n\n",
    "supporting": [
      "07-GPT4ALL_files"
    ],
    "filters": [],
    "includes": {}
  }
}