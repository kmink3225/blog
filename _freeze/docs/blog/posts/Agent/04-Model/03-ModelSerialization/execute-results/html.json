{
  "hash": "445553e051e2f34b54b085f3fb4113a5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Model Serialization\"\nsubtitle: 모델 직렬화 및 저장/로딩 방법\ndescription: |\n  LangChain 모델의 직렬화(Serialization) 개념과 방법을 다룬다.\n  모델을 저장 가능한 형식으로 변환하여 재사용, 배포, 버전 관리를 용이하게 하는 방법을 설명한다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 02/03/2025\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n### 직렬화(Serialization) 란?\n\n1. **정의:**\n   - 모델을 저장 가능한 형식으로 변환하는 과정\n\n2. **목적:**\n   - 모델 재사용 (재훈련 없이)\n   - 모델 배포 및 공유 용이\n   - 계산 리소스 절약\n\n3. **장점:**\n   - 빠른 모델 로딩\n   - 버전 관리 가능\n   - 다양한 환경에서 사용 가능\n\n모델 직렬화는 AI 개발 및 배포 과정에서 중요한 단계로, 효율적인 모델 관리와 재사용을 가능하게 합니다.\n\n`is_lc_serializable` 클래스 메서드로 실행하여 LangChain 클래스가 직렬화 가능한지 확인할 수 있습니다.\n\n::: {#7842ec5f .cell execution_count=1}\n``` {.python .cell-code}\n# API KEY를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API KEY 정보로드\nload_dotenv()\n```\n:::\n\n\n::: {#49442ac4 .cell execution_count=2}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH04-Models\")\n```\n:::\n\n\n::: {#2909bbfe .cell execution_count=3}\n``` {.python .cell-code}\nimport os\nfrom langchain_openai import ChatOpenAI\nfrom langchain.prompts import PromptTemplate\n\n# 프롬프트 템플릿을 사용하여 질문을 생성합니다.\nprompt = PromptTemplate.from_template(\"{fruit}의 색상이 무엇입니까?\")\n```\n:::\n\n\n클래스(class) 에 대하여 직렬화 가능 여부를 확인합니다.\n\n::: {#c58fa651 .cell execution_count=4}\n``` {.python .cell-code}\n# 직렬화가 가능한지 체크합니다.\nprint(f\"ChatOpenAI: {ChatOpenAI.is_lc_serializable()}\")\n```\n:::\n\n\nllm 객체에 대하여 직렬화 가능 여부를 확인합니다.\n\n::: {#7c2381b3 .cell execution_count=5}\n``` {.python .cell-code}\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n\n# 직렬화가 가능한지 체크합니다.\nprint(f\"ChatOpenAI: {llm.is_lc_serializable()}\")\n```\n:::\n\n\n::: {#38b3f81a .cell execution_count=6}\n``` {.python .cell-code}\n# 체인을 생성합니다.\nchain = prompt | llm\n\n# 직렬화가 가능한지 체크합니다.\nchain.is_lc_serializable()\n```\n:::\n\n\n## 체인(Chain) 직렬화(dumps, dumpd)\n\n### 개요\n\n체인 직렬화는 직렬화 가능한 모든 객체를 딕셔너리 또는 JSON 문자열로 변환하는 과정을 의미합니다.\n\n### 직렬화 방법\n\n객체의 속성 및 데이터를 키-값 쌍으로 저장하여 딕셔너리 형태로 변환합니다.\n\n이러한 직렬화 방식은 객체를 쉽게 저장하고 전송할 수 있게 하며, 다양한 환경에서 객체를 재구성할 수 있도록 합니다.\n\n**참고**\n- `dumps`: 객체를 JSON 문자열로 직렬화\n- `dumpd`: 객체를 딕셔너리로 직렬화\n\n::: {#4ba91c29 .cell execution_count=7}\n``` {.python .cell-code}\nfrom langchain_core.load import dumpd, dumps\n\ndumpd_chain = dumpd(chain)\ndumpd_chain\n```\n:::\n\n\n::: {#34a0be8f .cell execution_count=8}\n``` {.python .cell-code}\n# 직렬화된 체인의 타입을 확인합니다.\ntype(dumpd_chain)\n```\n:::\n\n\n이번에는 `dumps` 함수를 사용하여 직렬화된 체인을 확인해보겠습니다.\n\n::: {#5fa96b3a .cell execution_count=9}\n``` {.python .cell-code}\n# dumps 함수를 사용하여 직렬화된 체인을 확인합니다.\ndumps_chain = dumps(chain)\ndumps_chain\n```\n:::\n\n\n::: {#46ab0a3e .cell execution_count=10}\n``` {.python .cell-code}\n# 직렬화된 체인의 타입을 확인합니다.\ntype(dumps_chain)\n```\n:::\n\n\n## Pickle 파일\n\n### 개요\n\nPickle 파일은 Python 객체를 바이너리 형태로 직렬화하는 포맷입니다.\n\n### 특징\n\n1. **형식:**\n   - Python 객체를 바이너리 형태로 직렬화하는 포맷\n\n2. **특징:**\n   - Python 전용 (다른 언어와 호환 불가)\n   - 대부분의 Python 데이터 타입 지원 (리스트, 딕셔너리, 클래스 등)\n   - 객체의 상태와 구조를 그대로 보존\n\n3. **장점:**\n   - 효율적인 저장 및 전송\n   - 복잡한 객체 구조 유지\n   - 빠른 직렬화/역직렬화 속도\n\n4. **단점:**\n   - 보안 위험 (신뢰할 수 없는 데이터 역직렬화 시 주의 필요)\n   - 사람이 읽을 수 없는 바이너리 형식\n\n### 주요 용도\n\n1. 객체 캐싱\n2. 머신러닝 모델 저장\n3. 프로그램 상태 저장 및 복원\n\n### 사용법\n\n- `pickle.dump()`: 객체를 파일에 저장\n- `pickle.load()`: 파일에서 객체 로드\n\npickle 파일로 저장합니다.\n\n::: {#99ee0ca2 .cell execution_count=11}\n``` {.python .cell-code}\nimport pickle\n\n# fuit_chain.pkl 파일로 직렬화된 체인을 저장합니다.\nwith open(\"fruit_chain.pkl\", \"wb\") as f:\n    pickle.dump(dumpd_chain, f)\n```\n:::\n\n\nJSON 형식으로 마찬가지로 저장할 수 있습니다.\n\n::: {#b5713f0c .cell execution_count=12}\n``` {.python .cell-code}\nimport json\n\nwith open(\"fruit_chain.json\", \"w\") as fp:\n    json.dump(dumpd_chain, fp)\n```\n:::\n\n\n## load: 저장한 모델 불러오기\n\n먼저, 이전에 저장한 `pickle` 형식의 파일을 로드합니다.\n\n::: {#b24b92f1 .cell execution_count=13}\n``` {.python .cell-code}\nimport pickle\n\n# pickle 파일을 로드합니다.\nwith open(\"fruit_chain.pkl\", \"rb\") as f:\n    loaded_chain = pickle.load(f)\n```\n:::\n\n\n로드한 json 파일을 `load` 메서드를 사용하여 로드합니다.\n\n::: {#ce878600 .cell execution_count=14}\n``` {.python .cell-code}\nfrom langchain_core.load import load\n\n# 체인을 로드합니다.\nchain_from_file = load(loaded_chain)\n\n# 체인을 실행합니다.\nprint(chain_from_file.invoke({\"fruit\": \"사과\"}))\n```\n:::\n\n\n::: {#51f61e09 .cell execution_count=15}\n``` {.python .cell-code}\nfrom langchain_core.load import load, loads\n\nload_chain = load(\n    loaded_chain, secrets_map={\"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"]}\n)\n\n# 불러온 체인이 정상 동작하는지 확인합니다.\nload_chain.invoke({\"fruit\": \"사과\"})\n```\n:::\n\n\n::: {#05abf080 .cell execution_count=16}\n``` {.python .cell-code}\nwith open(\"fruit_chain.json\", \"r\") as fp:\n    loaded_from_json_chain = json.load(fp)\n    loads_chain = load(loaded_from_json_chain)\n```\n:::\n\n\n::: {#02f7dffb .cell execution_count=17}\n``` {.python .cell-code}\n# 불러온 체인이 정상 동작하는지 확인합니다.\nloads_chain.invoke({\"fruit\": \"사과\"})\n```\n:::\n\n\n",
    "supporting": [
      "03-ModelSerialization_files"
    ],
    "filters": [],
    "includes": {}
  }
}