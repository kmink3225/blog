{
  "hash": "805be09cc2a3c5a022ee29996dea9b08",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Azure OpenAI LLM\"\nsubtitle: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ìƒì„± ë° í”„ë¡¬í”„íŠ¸ ìµœì í™”\ndescription: |\n  Azure OpenAI LLMì„ í™œìš©í•œ RAG ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶• ë° í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë°©ë²•ì„ ë‹¤ë£¬ë‹¤.\ncategories:\n  - AI\n  - RAG\n  - Azure\nauthor: Kwangmin Kim\ndate: 11/07/2025\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n## Azure OpenAI LLMì´ë€?\n\nAzure OpenAI ServiceëŠ” OpenAIì˜ ê°•ë ¥í•œ ì–¸ì–´ ëª¨ë¸ì„ Azure í´ë¼ìš°ë“œì—ì„œ ì œê³µí•˜ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì„œë¹„ìŠ¤ë‹¤.\n\n**RAG ì‹œìŠ¤í…œì—ì„œì˜ ì—­í• :**\n- ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©\n- ìì—°ì–´ ë‹µë³€ ìƒì„±\n- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ë¡ \n- í•œêµ­ì–´ ì§€ì›\n\n**ì—”í„°í”„ë¼ì´ì¦ˆ ì¥ì :**\n- 99.9% SLA ë³´ì¥\n- ë°ì´í„° ì£¼ê¶Œ (í•œêµ­ ë¦¬ì „)\n- Private Endpoint ì§€ì›\n- RBAC ê¸°ë°˜ ì ‘ê·¼ ì œì–´\n\n## Azure OpenAI ëª¨ë¸\n\n### GPT-4 Turbo (ê¶Œì¥)\n\n**ì¶œì‹œ**: 2024ë…„ 4ì›”\n\n**ì‚¬ì–‘:**\n- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: 128K í† í°\n- ì¶œë ¥ í† í°: 4,096\n- ê°€ê²©: $10 / 1M ì…ë ¥ í† í°, $30 / 1M ì¶œë ¥ í† í°\n\n**íŠ¹ì§•:**\n- **ìµœê³  ì„±ëŠ¥** (ë³µì¡í•œ ì¶”ë¡ )\n- JSON ëª¨ë“œ ì§€ì›\n- í•¨ìˆ˜ í˜¸ì¶œ\n- ë¹„ì „ (ì´ë¯¸ì§€ ì´í•´)\n\n**RAG ê¶Œì¥**: âœ… ë†’ì€ ì •í™•ë„ í•„ìš” ì‹œ\n\n### GPT-4o (ìµœì‹ )\n\n**ì¶œì‹œ**: 2024ë…„ 5ì›”\n\n**ì‚¬ì–‘:**\n- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: 128K í† í°\n- ì¶œë ¥ í† í°: 4,096\n- ê°€ê²©: $5 / 1M ì…ë ¥ í† í°, $15 / 1M ì¶œë ¥ í† í° (GPT-4 ëŒ€ë¹„ **50% ì €ë ´**)\n\n**íŠ¹ì§•:**\n- GPT-4 ìˆ˜ì¤€ ì„±ëŠ¥\n- **2ë°° ë¹ ë¥¸ ì†ë„**\n- ë©€í‹°ëª¨ë‹¬ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤)\n- í–¥ìƒëœ í•œêµ­ì–´ ì§€ì›\n\n**RAG ê¶Œì¥**: âœ… **ìµœì„ ì˜ ì„ íƒ** (ì„±ëŠ¥ + ë¹„ìš©)\n\n### GPT-3.5 Turbo\n\n**ì‚¬ì–‘:**\n- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°: 16K í† í°\n- ê°€ê²©: $0.50 / 1M ì…ë ¥ í† í°, $1.50 / 1M ì¶œë ¥ í† í°\n\n**íŠ¹ì§•:**\n- ë¹ ë¥¸ ì‘ë‹µ ì†ë„\n- ë‚®ì€ ë¹„ìš©\n- ê°„ë‹¨í•œ ì§ˆë¬¸ì— ì í•©\n\n**RAG ê¶Œì¥**: ë‹¨ìˆœ FAQ ë˜ëŠ” ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½\n\n### ëª¨ë¸ ë¹„êµ\n\n| ëª¨ë¸ | ì»¨í…ìŠ¤íŠ¸ | ì…ë ¥ ê°€ê²© | ì¶œë ¥ ê°€ê²© | ì„±ëŠ¥ | ì†ë„ | RAG ê¶Œì¥ |\n|------|---------|----------|----------|------|------|---------|\n| **GPT-4o** | 128K | $5/1M | $15/1M | â­â­â­â­â­ | âš¡âš¡âš¡ | âœ… **ìµœê³ ** |\n| GPT-4 Turbo | 128K | $10/1M | $30/1M | â­â­â­â­â­ | âš¡âš¡ | ê³ ì •ë°€ë„ |\n| GPT-3.5 Turbo | 16K | $0.50/1M | $1.50/1M | â­â­â­ | âš¡âš¡âš¡ | ê°œë°œìš© |\n\n## í™˜ê²½ ì„¤ì •\n\n### Azure OpenAI ë¦¬ì†ŒìŠ¤ ìƒì„±\n\n```bash\n# Azure OpenAI ë¦¬ì†ŒìŠ¤ ìƒì„±\naz cognitiveservices account create \\\n    --name openai-rag-prod \\\n    --resource-group rg-rag-prod \\\n    --kind OpenAI \\\n    --sku S0 \\\n    --location eastus\n\n# í‚¤ ì¡°íšŒ\naz cognitiveservices account keys list \\\n    --name openai-rag-prod \\\n    --resource-group rg-rag-prod\n```\n\n### ëª¨ë¸ ë°°í¬\n\nAzure OpenAI Studioì—ì„œ:\n1. \"ë°°í¬\" â†’ \"+ ë°°í¬ ë§Œë“¤ê¸°\"\n2. ëª¨ë¸ ì„ íƒ: **gpt-4o**\n3. ë°°í¬ ì´ë¦„: `gpt-4o`\n4. TPM: 80K (ë¶„ë‹¹ í† í° ì œí•œ)\n\n### í™˜ê²½ ë³€ìˆ˜\n\n`.env` íŒŒì¼:\n```\nAZURE_OPENAI_ENDPOINT=https://openai-rag-prod.openai.azure.com/\nAZURE_OPENAI_API_KEY=your-key-here\nAZURE_OPENAI_DEPLOYMENT=gpt-4o\nAZURE_OPENAI_API_VERSION=2024-02-01\n```\n\n## ê¸°ë³¸ ì‚¬ìš©ë²•\n\n### AzureChatOpenAI ì´ˆê¸°í™”\n\n::: {#113811c8 .cell execution_count=1}\n``` {.python .cell-code}\nfrom langchain_openai import AzureChatOpenAI\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\nllm = AzureChatOpenAI(\n    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    temperature=0,  # ê²°ì •ì  ì¶œë ¥\n    max_tokens=1000  # ìµœëŒ€ ì¶œë ¥ ê¸¸ì´\n)\n\n# í…ŒìŠ¤íŠ¸\nresponse = llm.invoke(\"Azure OpenAIë€ ë¬´ì—‡ì¸ê°€?\")\nprint(response.content)\n```\n:::\n\n\n### ë©”ì‹œì§€ í˜•ì‹\n\n::: {#5066355e .cell execution_count=2}\n``` {.python .cell-code}\nfrom langchain_core.messages import HumanMessage, SystemMessage\n\nmessages = [\n    SystemMessage(content=\"ë‹¹ì‹ ì€ Azure ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\"),\n    HumanMessage(content=\"Azure AI Searchë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\")\n]\n\nresponse = llm.invoke(messages)\nprint(response.content)\n```\n:::\n\n\n## RAG í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§\n\n### ê¸°ë³¸ RAG í”„ë¡¬í”„íŠ¸\n\n::: {#5a2c20da .cell execution_count=3}\n``` {.python .cell-code}\nfrom langchain_core.prompts import ChatPromptTemplate\n\nbasic_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}\n\në‹µë³€:\"\"\"\n)\n```\n:::\n\n\n### í•œêµ­ì–´ ìµœì í™” í”„ë¡¬í”„íŠ¸\n\n::: {#d9e74b2b .cell execution_count=4}\n``` {.python .cell-code}\nkorean_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\nì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n\n## ì§€ì¹¨:\n1. ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”\n2. í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ \"ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤\"ë¼ê³  ë‹µí•˜ì„¸ìš”\n3. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”\n4. ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”\n\n## ì»¨í…ìŠ¤íŠ¸:\n{context}\n\n## ì§ˆë¬¸:\n{question}\n\n## ë‹µë³€:\"\"\"\n)\n```\n:::\n\n\n### êµ¬ì¡°í™”ëœ ë‹µë³€ í”„ë¡¬í”„íŠ¸\n\n::: {#9c80c7eb .cell execution_count=5}\n``` {.python .cell-code}\nstructured_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}\n\në‹µë³€ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:\n\n**ìš”ì•½:** (í•œ ë¬¸ì¥ ìš”ì•½)\n\n**ìƒì„¸ ì„¤ëª…:**\n- í•µì‹¬ í¬ì¸íŠ¸ 1\n- í•µì‹¬ í¬ì¸íŠ¸ 2\n- í•µì‹¬ í¬ì¸íŠ¸ 3\n\n**ì¶œì²˜:** (ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì¸ìš©)\n\në‹µë³€:\"\"\"\n)\n```\n:::\n\n\n### Few-Shot í”„ë¡¬í”„íŠ¸\n\n::: {#5a0a82cf .cell execution_count=6}\n``` {.python .cell-code}\nfew_shot_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ë‹¤ìŒ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n\nì˜ˆì‹œ 1:\nì§ˆë¬¸: Azure Blob Storageë€?\në‹µë³€: Azure Blob StorageëŠ” Microsoftì˜ í´ë¼ìš°ë“œ ê°ì²´ ìŠ¤í† ë¦¬ì§€ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. \nëŒ€ëŸ‰ì˜ ë¹„êµ¬ì¡°í™” ë°ì´í„°ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìœ¼ë©°, Hot/Cool/Archive í‹°ì–´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\nì˜ˆì‹œ 2:\nì§ˆë¬¸: Document Intelligenceì˜ ìš©ë„ëŠ”?\në‹µë³€: Document IntelligenceëŠ” OCR ë° ë¬¸ì„œ ë¶„ì„ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.\nPDF, ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸, í‘œ, ë ˆì´ì•„ì›ƒì„ ì¶”ì¶œí•˜ì—¬ RAG ì‹œìŠ¤í…œì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\nì´ì œ ì‹¤ì œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”:\n\nì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}\n\në‹µë³€:\"\"\"\n)\n```\n:::\n\n\n## ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬\n\n### ì»¨í…ìŠ¤íŠ¸ ì••ì¶•\n\n::: {#de0fb2ec .cell execution_count=7}\n``` {.python .cell-code}\ndef compress_context(docs, max_tokens=3000):\n    \"\"\"ì»¨í…ìŠ¤íŠ¸ë¥¼ í† í° ì œí•œ ë‚´ë¡œ ì••ì¶•\"\"\"\n    import tiktoken\n    \n    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n    \n    compressed = []\n    total_tokens = 0\n    \n    for doc in docs:\n        tokens = encoding.encode(doc.page_content)\n        doc_tokens = len(tokens)\n        \n        if total_tokens + doc_tokens <= max_tokens:\n            compressed.append(doc.page_content)\n            total_tokens += doc_tokens\n        else:\n            # ë‚¨ì€ ê³µê°„ì— ë§ì¶° ìë¥´ê¸°\n            remaining = max_tokens - total_tokens\n            truncated = encoding.decode(tokens[:remaining])\n            compressed.append(truncated + \"...\")\n            break\n    \n    return \"\\n\\n\".join(compressed)\n\n# ì‚¬ìš©\n# context = compress_context(retrieved_docs, max_tokens=3000)\n```\n:::\n\n\n### ì»¨í…ìŠ¤íŠ¸ ì¬ì •ë ¬\n\n::: {#e8eade09 .cell execution_count=8}\n``` {.python .cell-code}\nfrom langchain.document_transformers import LongContextReorder\n\ndef reorder_context(docs):\n    \"\"\"ì¤‘ìš”í•œ ë¬¸ì„œë¥¼ ì–‘ ëì— ë°°ì¹˜\"\"\"\n    reorderer = LongContextReorder()\n    reordered = reorderer.transform_documents(docs)\n    return reordered\n\n# ì‚¬ìš©: ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ë¬¸ì„œê°€ ê°€ì¥ ì¤‘ìš”\n# reordered_docs = reorder_context(retrieved_docs)\n```\n:::\n\n\n## ê³ ê¸‰ RAG íŒ¨í„´\n\n### Chain-of-Thought (CoT)\n\n::: {#cab60d2e .cell execution_count=9}\n``` {.python .cell-code}\ncot_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹¨ê³„ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}\n\në‹¨ê³„ë³„ ì¶”ë¡ :\n1. ë¨¼ì € ì§ˆë¬¸ì˜ í•µì‹¬ì„ íŒŒì•…í•©ë‹ˆë‹¤\n2. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤\n3. ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ì„ êµ¬ì„±í•©ë‹ˆë‹¤\n\në‹µë³€:\"\"\"\n)\n```\n:::\n\n\n### Self-Ask\n\n::: {#dec292e1 .cell execution_count=10}\n``` {.python .cell-code}\nself_ask_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ í•˜ìœ„ ì§ˆë¬¸ì„ ë¨¼ì € ìƒì„±í•˜ê³  ë‹µë³€í•˜ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}\n\ní•˜ìœ„ ì§ˆë¬¸ 1: [ì§ˆë¬¸]\në‹µë³€ 1: [ë‹µë³€]\n\ní•˜ìœ„ ì§ˆë¬¸ 2: [ì§ˆë¬¸]\në‹µë³€ 2: [ë‹µë³€]\n\nìµœì¢… ë‹µë³€: [ì¢…í•© ë‹µë³€]\"\"\"\n)\n```\n:::\n\n\n### ì¸ìš© í¬í•¨ ë‹µë³€\n\n::: {#4537f702 .cell execution_count=11}\n``` {.python .cell-code}\ncitation_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ê³ , ì¸ìš© ì¶œì²˜ë¥¼ í‘œì‹œí•˜ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}\n\në‹µë³€ í˜•ì‹:\në‹µë³€ ë‚´ìš© [ì¶œì²˜: ë¬¸ì„œëª… ë˜ëŠ” í˜ì´ì§€]\n\në‹µë³€:\"\"\"\n)\n```\n:::\n\n\n## ìŠ¤íŠ¸ë¦¬ë°\n\n### ì‹¤ì‹œê°„ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°\n\n::: {#7c0a9c19 .cell execution_count=12}\n``` {.python .cell-code}\n# ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”\nstreaming_llm = AzureChatOpenAI(\n    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    streaming=True,\n    temperature=0\n)\n\n# ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰\nfor chunk in streaming_llm.stream(\"Azure AI Searchë€?\"):\n    print(chunk.content, end=\"\", flush=True)\n```\n:::\n\n\n### RAG ì²´ì¸ ìŠ¤íŠ¸ë¦¬ë°\n\n::: {#5456d352 .cell execution_count=13}\n``` {.python .cell-code}\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\n\n# ìŠ¤íŠ¸ë¦¬ë° RAG ì²´ì¸\nstreaming_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | korean_prompt\n    | streaming_llm\n    | StrOutputParser()\n)\n\n# ì‹¤í–‰\nprint(\"ë‹µë³€: \", end=\"\")\nfor chunk in streaming_chain.stream(\"Azure AI Searchì˜ ì¥ì ì€?\"):\n    print(chunk, end=\"\", flush=True)\nprint()\n```\n:::\n\n\n## JSON ëª¨ë“œ\n\n### êµ¬ì¡°í™”ëœ ì¶œë ¥\n\n::: {#0e2d52e2 .cell execution_count=14}\n``` {.python .cell-code}\njson_llm = AzureChatOpenAI(\n    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    temperature=0,\n    model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n)\n\njson_prompt = ChatPromptTemplate.from_template(\n    \"\"\"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸:\n{context}\n\nì§ˆë¬¸: {question}\n\nJSON í˜•ì‹:\n{{\n  \"answer\": \"ë‹µë³€ ë‚´ìš©\",\n  \"confidence\": \"high/medium/low\",\n  \"sources\": [\"ì¶œì²˜1\", \"ì¶œì²˜2\"]\n}}\n\nJSON ì‘ë‹µ:\"\"\"\n)\n\n# ì‚¬ìš©\nresponse = json_llm.invoke(\n    json_prompt.invoke({\n        \"context\": \"Azure AI SearchëŠ” ë²¡í„° ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.\",\n        \"question\": \"Azure AI Searchì˜ ì£¼ìš” ê¸°ëŠ¥ì€?\"\n    })\n)\n\nimport json\nresult = json.loads(response.content)\nprint(f\"ë‹µë³€: {result['answer']}\")\nprint(f\"ì‹ ë¢°ë„: {result['confidence']}\")\n```\n:::\n\n\n## í•¨ìˆ˜ í˜¸ì¶œ\n\n### ë„êµ¬ ì •ì˜\n\n::: {#5af25f05 .cell execution_count=15}\n``` {.python .cell-code}\nfrom langchain_core.tools import tool\n\n@tool\ndef search_documents(query: str) -> str:\n    \"\"\"ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬\"\"\"\n    # ì‹¤ì œë¡œëŠ” retriever ì‚¬ìš©\n    return f\"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.\"\n\n@tool\ndef get_metadata(doc_id: str) -> dict:\n    \"\"\"ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë„êµ¬\"\"\"\n    return {\"id\": doc_id, \"title\": \"ìƒ˜í”Œ ë¬¸ì„œ\", \"date\": \"2025-01-01\"}\n\ntools = [search_documents, get_metadata]\n```\n:::\n\n\n### í•¨ìˆ˜ í˜¸ì¶œ LLM\n\n::: {#bedaa5a5 .cell execution_count=16}\n``` {.python .cell-code}\n# ë„êµ¬ ë°”ì¸ë”©\nllm_with_tools = llm.bind_tools(tools)\n\n# ì‹¤í–‰\nresponse = llm_with_tools.invoke(\"Azure AI Search ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ì¤˜\")\n\n# ë„êµ¬ í˜¸ì¶œ í™•ì¸\nif response.tool_calls:\n    for tool_call in response.tool_calls:\n        print(f\"ë„êµ¬: {tool_call['name']}\")\n        print(f\"ì¸ì: {tool_call['args']}\")\n```\n:::\n\n\n## í† í° ìµœì í™”\n\n### í† í° ê³„ì‚°\n\n::: {#e7f40464 .cell execution_count=17}\n``` {.python .cell-code}\nimport tiktoken\n\ndef count_tokens(text, model=\"gpt-4\"):\n    \"\"\"í† í° ìˆ˜ ê³„ì‚°\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    return len(encoding.encode(text))\n\n# í”„ë¡¬í”„íŠ¸ í† í° í™•ì¸\nprompt_text = korean_prompt.invoke({\n    \"context\": \"ìƒ˜í”Œ ì»¨í…ìŠ¤íŠ¸\",\n    \"question\": \"ìƒ˜í”Œ ì§ˆë¬¸\"\n}).to_string()\n\ntokens = count_tokens(prompt_text)\nprint(f\"í”„ë¡¬í”„íŠ¸ í† í°: {tokens}\")\n```\n:::\n\n\n### ë¹„ìš© ì¶”ì •\n\n::: {#c3953696 .cell execution_count=18}\n``` {.python .cell-code}\ndef estimate_cost(input_tokens, output_tokens, model=\"gpt-4o\"):\n    \"\"\"ë¹„ìš© ì¶”ì • (USD)\"\"\"\n    prices = {\n        \"gpt-4o\": {\"input\": 5.0, \"output\": 15.0},  # per 1M tokens\n        \"gpt-4-turbo\": {\"input\": 10.0, \"output\": 30.0},\n        \"gpt-3.5-turbo\": {\"input\": 0.5, \"output\": 1.5}\n    }\n    \n    price = prices.get(model, prices[\"gpt-4o\"])\n    \n    input_cost = (input_tokens / 1_000_000) * price[\"input\"]\n    output_cost = (output_tokens / 1_000_000) * price[\"output\"]\n    \n    return input_cost + output_cost\n\n# ì˜ˆì‹œ: 1000ê°œ ì§ˆë¬¸ (ê° 3000 ì…ë ¥, 500 ì¶œë ¥ í† í°)\ntotal_cost = estimate_cost(3000 * 1000, 500 * 1000, \"gpt-4o\")\nprint(f\"ì˜ˆìƒ ë¹„ìš©: ${total_cost:.2f}\")\n```\n:::\n\n\n## ì½œë°±ì„ í†µí•œ ëª¨ë‹ˆí„°ë§\n\n::: {#5c59d0dd .cell execution_count=19}\n``` {.python .cell-code}\nfrom langchain.callbacks import StdOutCallbackHandler\n\n# ì½œë°± í•¸ë“¤ëŸ¬\ncallback = StdOutCallbackHandler()\n\n# LLM í˜¸ì¶œ ì‹œ ì½œë°± ì „ë‹¬\nresponse = llm.invoke(\n    \"Azure AI Searchë€?\",\n    config={\"callbacks\": [callback]}\n)\n\n# í† í° ì‚¬ìš©ëŸ‰ í™•ì¸\nprint(f\"í† í° ì‚¬ìš©ëŸ‰: {response.response_metadata.get('token_usage')}\")\n```\n:::\n\n\n## ì˜¤ë¥˜ ì²˜ë¦¬\n\n### ì¬ì‹œë„ ë¡œì§\n\n::: {#ccf102e1 .cell execution_count=20}\n``` {.python .cell-code}\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\n@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=4, max=10)\n)\ndef invoke_llm_with_retry(messages):\n    \"\"\"ì¬ì‹œë„ ê°€ëŠ¥í•œ LLM í˜¸ì¶œ\"\"\"\n    return llm.invoke(messages)\n\n# ì‚¬ìš©\ntry:\n    response = invoke_llm_with_retry(\"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\")\n    print(response.content)\nexcept Exception as e:\n    print(f\"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n```\n:::\n\n\n### Rate Limit ì²˜ë¦¬\n\n::: {#2cd0b7ec .cell execution_count=21}\n``` {.python .cell-code}\nimport time\n\ndef invoke_with_rate_limit(query, requests_per_minute=60):\n    \"\"\"Rate limitì„ ê³ ë ¤í•œ í˜¸ì¶œ\"\"\"\n    sleep_time = 60 / requests_per_minute\n    \n    response = llm.invoke(query)\n    time.sleep(sleep_time)\n    \n    return response\n```\n:::\n\n\n## ì°¸ê³  ìë£Œ\n\n### ê³µì‹ ë¬¸ì„œ\n- [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/)\n- [GPT-4o ëª¨ë¸](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4o-and-gpt-4-turbo)\n- [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering)\n\n### LangChain\n- [AzureChatOpenAI](https://python.langchain.com/docs/integrations/chat/azure_chat_openai)\n\n## ë‹¤ìŒ ë‹¨ê³„\n\nAzure OpenAI LLM ìµœì í™”ê°€ ì™„ë£Œë˜ì—ˆë‹¤ë©´, ì´ì œ ì„œë²„ë¦¬ìŠ¤ ë°°í¬ë¥¼ ì¤€ë¹„í•˜ì:\n\nğŸ‘‰ [07-Azure-Functions-Apps.qmd](./07-Azure-Functions-Apps.qmd) - Azure Functionsë¥¼ í™œìš©í•œ ì„œë²„ë¦¬ìŠ¤ RAG ë°°í¬\n\n",
    "supporting": [
      "06-Azure-OpenAI-LLM_files"
    ],
    "filters": [],
    "includes": {}
  }
}