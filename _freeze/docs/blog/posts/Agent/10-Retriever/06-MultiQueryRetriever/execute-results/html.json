{
  "hash": "46558a78c195cbd42e4da55930d6e23f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"MultiQueryRetriever\"\nsubtitle: \"다중 쿼리 생성을 통한 RAG 검색 성능 향상\"\ndescription: |\n  사용자의 단일 쿼리를 여러 관점의 다양한 쿼리로 확장하여 검색 결과를 풍부하게 만드는 MultiQueryRetriever의 원리와 구현 방법을 다룬다.\n  거리 기반 벡터 검색의 한계를 극복하고 더 포괄적인 검색 결과를 얻는 전략을 학습한다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\n  - Retriever\nauthor: Kwangmin Kim\ndate: 05/07/2024\nformat: \n  html:\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: false\nexecute:\n    eval: false\n---\n\n# MultiQueryRetriever 개요\n\n## 핵심 개념\n\n**MultiQueryRetriever**는 LLM이 사용자의 단일 쿼리를 기반으로 여러 개의 다양한 쿼리를 자동 생성하여 검색 성능을 향상시키는 고급 검색 기법이다.\n\n### 기본 원리: \"하나로 질문하고, 여러 관점으로 검색한다\"\n\n1. **쿼리 확장**: 사용자의 원본 질문을 LLM을 통해 여러 관점의 질문들로 변환\n2. **다중 검색**: 생성된 각 쿼리로 독립적인 검색 수행\n3. **결과 합성**: 모든 검색 결과를 합집합하여 포괄적인 문서 집합 구성\n\n## 왜 필요한가?\n\n### 사용자의 쿼리 한계\n\n**게으른 사용자 문제**\n\n대부분의 사용자는 상세하고 구체적인 질문을 작성하지 않는다. 이로 인해:\n- LLM 입력 데이터가 불충분해짐\n- 검색 결과의 품질과 범위가 제한됨\n- 사용자가 원하는 정보를 놓칠 가능성 증가\n\n**비논리적 질문 문제**\n\n사람마다 논리적 개성이 강하기 때문에 다음과 같은 문제가 발생한다:\n- 논리적 비약이 포함된 질문\n- 구체성이 부족한 모호한 표현\n- 비유기적이고 정돈되지 않은 문장 구조\n- 질문자만 이해하고 타인은 이해하기 어려운 표현\n\n### 거리 기반 벡터 검색의 한계\n\n#### 임베딩 공간의 제약\n\n거리 기반 벡터 데이터베이스 검색은 고차원 공간에서 쿼리 임베딩과 문서 임베딩 간의 '거리'를 기준으로 유사한 문서를 찾는다. 하지만 다음과 같은 한계가 있다:\n\n#### 쿼리의 세부적인 차이가 검색 결과에 큰 영향을 미치는 이유\n\n벡터 공간에서의 거리 계산은 매우 민감하게 작동한다:\n\n- **고차원 공간의 차원 저주**: 768차원(BERT) 또는 1536차원(OpenAI) 공간에서 작은 변화도 거리에 큰 영향\n- **단어 순서와 표현의 미묘한 차이**: \"어떻게 사용하나요?\" vs \"사용법이 무엇인가요?\"는 의미상 동일하지만 벡터 공간에서는 다른 위치\n- **동의어와 유의어 처리의 한계**: \"방법\"과 \"방식\", \"사용법\"과 \"활용법\"이 벡터 공간에서 멀리 떨어져 위치할 수 있음\n\n**구체적인 예시:**\n```\n쿼리 A: \"OpenAI API 사용방법\"     → 벡터 위치 [0.1, 0.8, -0.3, ...]\n쿼리 B: \"OpenAI API 활용법\"      → 벡터 위치 [0.2, 0.7, -0.1, ...]\n쿼리 C: \"OpenAI API를 어떻게 써요?\" → 벡터 위치 [0.5, 0.4, 0.2, ...]\n\n동일한 의도의 질문이지만 벡터 공간에서 서로 다른 위치에 배치되어\n완전히 다른 문서들이 검색될 수 있음\n```\n\n#### 거리 계산의 한계\n\n- **코사인 유사도의 함정**: 벡터의 방향성만 고려하여 의미의 강도나 맥락적 뉘앙스 손실\n- **임베딩 모델의 편향**: 학습 데이터의 특성에 따라 특정 표현 방식에 치우친 결과\n- **문맥 길이의 영향**: 짧은 쿼리와 긴 쿼리가 동일한 공간에서 비교되어 부정확한 유사도 계산\n- 임베딩이 데이터의 의미를 완전히 포착하지 못할 수 있음\n- 단일 관점의 검색으로 인한 정보 누락 가능성\n- 수동 프롬프트 엔지니어링의 번거로움\n\n## MultiQueryRetriever의 해결책\n\n### 자동 쿼리 확장\n\nMultiQueryRetriever는 LLM(Language Learning Model)을 활용하여 주어진 사용자 입력 쿼리에 대해 다양한 관점에서 여러 쿼리를 자동으로 생성한다. 이를 통해 프롬프트 튜닝 과정을 자동화한다.\n\n### 포괄적 검색 결과\n\n각각의 생성된 쿼리에 대해 관련 문서 집합을 검색하고, 모든 쿼리를 아우르는 고유한 문서들의 **합집합**을 추출하여 잠재적으로 관련된 더 큰 문서 집합을 얻는다.\n\n### 논리적 재구성 효과\n\n사용자의 비정돈된 질문을 MultiQuery를 통해 논리정연하고 완전한 형식의 문장 및 문단으로 **paraphrasing**하는 효과가 있다. 이러한 paraphrased text들은 LLM이 이해하기 적합한 형태로 나오기 때문에 답변 성능에 긍정적인 효과를 기대할 수 있다.\n\n### 어휘 선택의 민감성 문제\n\n**사용자의 무의식적 어휘 선택**\n\n대부분의 사용자는 질문을 작성할 때 어휘 선택(vocabulary choice)을 세심하게 고려하지 않는다. 하지만 벡터 임베딩에서는 각 단어가 고유한 의미 공간을 차지하므로, 유사한 의미의 단어들도 상당한 거리 차이를 보이는 벡터를 생성한다.\n\n**동의어 간 벡터 거리의 문제**\n\n동일하거나 유사한 개념을 표현하는 단어들이 임베딩 공간에서 예상보다 멀리 떨어져 배치되는 현상:\n\n```\n한국어 예시:\n- \"이용\" → 벡터 A [0.2, 0.8, -0.1, ...]\n- \"사용\" → 벡터 B [0.1, 0.6, 0.3, ...]  \n- \"활용\" → 벡터 C [0.4, 0.2, -0.2, ...]\n\n영어 예시:\n- \"use\" → 벡터 D [0.3, 0.7, 0.1, ...]\n- \"utilize\" → 벡터 E [0.1, 0.4, -0.3, ...]\n- \"exploit\" → 벡터 F [-0.2, 0.5, 0.4, ...]\n- \"take advantage of\" → 벡터 G [0.6, -0.1, 0.2, ...]\n```\n\n**실제 검색 영향 사례**\n\n```\n사용자 질문 A: \"OpenAI API를 이용하는 방법\"\n사용자 질문 B: \"OpenAI API를 사용하는 방법\"  \n사용자 질문 C: \"OpenAI API를 활용하는 방법\"\n\n→ 동일한 의도이지만 완전히 다른 검색 결과를 얻을 수 있음\n→ 특정 단어로 작성된 문서만 검색되고 나머지는 누락될 위험\n```\n\n**언어적 뉘앙스의 벡터화 한계**\n\n- **격식의 정도**: \"사용\"(일반적) vs \"이용\"(격식) vs \"활용\"(적극적)\n- **맥락적 의미**: \"exploit\"(부정적 뉘앙스) vs \"utilize\"(중립적) vs \"use\"(일반적)\n- **언어 혼재**: 한국어-영어 혼용 시 더욱 복잡한 벡터 공간 형성\n\n이러한 어휘 선택의 민감성으로 인해 사용자가 선택한 특정 단어에 따라 검색 품질이 크게 좌우되는 문제가 발생한다.\n\n### 검색 한계 극복\n\n여러 관점에서 동일한 질문을 생성함으로써, MultiQueryRetriever는 거리 기반 검색의 제한을 일정 부분 극복하고, 더욱 풍부한 검색 결과를 제공할 수 있다.\n\n\n# 환경 설정\n\n## API 키 및 추적 설정\n\n::: {#27031050 .cell execution_count=2}\n``` {.python .cell-code}\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n```\n:::\n\n\n::: {#1273e8e2 .cell execution_count=3}\n``` {.python .cell-code}\n# LangSmith 추적을 설정한다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력한다.\nlogging.langsmith(\"CH10-Retriever\")\n```\n:::\n\n\n::: {#6a41268c .cell execution_count=4}\n``` {.python .cell-code}\n# 샘플 벡터DB 구축\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\n\n# 블로그 포스트 (Parent Document)  로드\nloader = WebBaseLoader(\n    \"https://teddylee777.github.io/openai/openai-assistant-tutorial/\", encoding=\"utf-8\"\n)\n\n# 문서 분할\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\ndocs = loader.load_and_split(text_splitter)\n\n# 임베딩 정의\nopenai_embedding = OpenAIEmbeddings()\n\n# 벡터DB 생성\ndb = FAISS.from_documents(docs, openai_embedding)\n\n# retriever 생성\nretriever = db.as_retriever()\n\n# 문서 검색\nquery = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\nrelevant_docs = retriever.invoke(query)\n\n# 검색된 문서의 개수 출력\nlen(relevant_docs)\n```\n:::\n\n\n```\nUSER_AGENT environment variable not set, consider setting it to identify your requests.\n4\n```\n\n검색된 결과 중 1개 문서의 내용을 출력한다.\n\n::: {#7e615e95 .cell execution_count=5}\n``` {.python .cell-code}\n# 1번 문서를 출력합니다.\nprint(relevant_docs[1].page_content)\n```\n:::\n\n\n```\n가장 강력한 도구로서, Assistant에게 사용자 정의 함수를 지정할 수 있습니다. 이는 Chat Completions API에서의 함수 호출과 매우 유사합니다.\n\n\nFunction calling(함수 호출) 도구를 사용하면 Assistant 에게 사용자 정의 함수 를 설명하여 호출해야 하는 함수를 인자와 함께 지능적으로 반환하도록 할 수 있습니다.\n\n\nAssistant API는 실행 중에 함수를 호출할 때 실행을 일시 중지하며, 함수 호출 결과를 다시 제공하여 Run 실행을 계속할 수 있습니다. (이는 사용자 피드백을 받아 재게할 수 있는 의미이기도 합니다. 아래 튜토리얼에서 상세히 다룹니다).\n```\n\n# MultiQueryRetriever 사용법\n\n## 기본 사용법\n\n`MultiQueryRetriever`에 사용할 LLM을 지정하고 질의 생성에 사용하면, retriever가 나머지 작업을 처리한다.\n\n### MultiQueryRetriever 생성\n\n::: {#511c0a0c .cell execution_count=6}\n``` {.python .cell-code}\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\nfrom langchain_openai import ChatOpenAI\n\n\n# ChatOpenAI 언어 모델을 초기화한다. temperature는 0으로 설정한다.\nllm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n\nmultiquery_retriever = MultiQueryRetriever.from_llm(  # MultiQueryRetriever를 언어 모델을 사용하여 초기화한다.\n    # 벡터 데이터베이스의 retriever와 언어 모델을 전달한다.\n    retriever=db.as_retriever(),\n    llm=llm,\n)\n```\n:::\n\n\n아래는 다중 쿼리를 생성하는 중간 과정을 디버깅하기 위하여 실행하는 코드이다.\n\n먼저 `\"langchain.retrievers.multi_query\"` 로거를 가져온다. 이는 `logging.getLogger()` 함수를 사용하여 수행된다. 그 다음, 이 로거의 로그 레벨을 `INFO`로 설정하여, `INFO` 레벨 이상의 로그 메시지만 출력되도록 할 수 있다. \n\n::: {#5d94e998 .cell execution_count=7}\n``` {.python .cell-code}\n# 쿼리에 대한 로깅 설정\nimport logging\n\nlogging.basicConfig()\nlogging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n```\n:::\n\n\n### MultiQueryRetriever 실행 및 결과 분석\n\n이 코드는 `multiquery_retriever` 객체의 `invoke` 메서드를 사용하여 주어진 `question`과 관련된 문서를 검색한다. 검색된 문서들은 `unique_docs`라는 변수에 저장되며, 이 변수의 길이를 확인함으로써 검색된 관련 문서의 총 개수를 알 수 있다. 이 과정을 통해 사용자의 질문에 대한 관련 정보를 효과적으로 찾아내고 그 양을 파악할 수 있다.\n\n::: {#405707c4 .cell execution_count=8}\n``` {.python .cell-code}\n# 질문을 정의한다.\nquestion = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n# 문서 검색\nrelevant_docs = multiquery_retriever.invoke(question)\n\n# 검색된 고유한 문서의 개수를 반환합니다.\nprint(\n    f\"===============\\n검색된 문서 개수: {len(relevant_docs)}\",\n    end=\"\\n===============\\n\",\n)\n\n# 검색된 문서의 내용을 출력합니다.\nprint(relevant_docs[0].page_content)\n```\n:::\n\n\n```\nINFO:langchain.retrievers.multi_query:Generated queries: ['OpenAI Assistant API에서 Functions 기능을 사용하는 방법에 대해 설명해 주세요.  ', 'OpenAI Assistant API의 Functions를 활용하는 방법은 무엇인가요?  ', 'OpenAI Assistant API의 Functions 사용에 대한 가이드를 제공해 주실 수 있나요?']\n\n```\n\n* 질문 쿼리가 3개로 늘어남\n\n```\n===============\n검색된 문서 개수: 5\n===============\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval, Functions 를 활용하는 방법에 대해 다룹니다. 이와 더불어 파일을 업로드 하는 내용과 사용자의 피드백을 제출하는 내용도 튜토리얼 말미에 포함하고 있습니다.\n\n\n\n주요내용\n```\n\n* 단일 쿼리 질문에서는 검색된 문서 개수가 4개\n* 추가된 질문 쿼리를 합하여 검색된 문서 개수가 5개 (1개가 더 늘어남)\n\n## 고급 기법: LCEL Chain 활용 방법\n\n### 사용자 정의 프롬프트로 커스터마이징\n\n기본 MultiQueryRetriever 대신 LCEL(LangChain Expression Language) Chain을 활용하여 더욱 세밀한 제어가 가능한 커스텀 리트리버를 만들 수 있다.\n\n**주요 특징:**\n- 사용자 정의 프롬프트 정의 가능\n- 생성될 쿼리 개수 조정 가능 (예: 5개)\n- 생성된 쿼리를 `\"\\n\"` 구분자로 구분하여 반환\n- 사용자 정의 Chain과 함께 사용 가능\n\n### LCEL Chain 구현\n\n::: {#c1f7d3c7 .cell execution_count=9}\n``` {.python .cell-code}\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\n# 프롬프트 템플릿을 정의한다.(5개의 질문을 생성하도록 프롬프트를 작성하였다)\nprompt = PromptTemplate.from_template(\n    \"\"\"You are an AI language model assistant. \nYour task is to generate five different versions of the given user question to retrieve relevant documents from a vector database. \nBy generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. \nYour response should be a list of values separated by new lines, eg: `foo\\nbar\\nbaz\\n`\n\n#ORIGINAL QUESTION: \n{question}\n\n#Answer in Korean:\n\"\"\"\n)\n\n# 언어 모델 인스턴스를 생성한다.\nllm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n\n# LLMChain을 생성한다.\ncustom_multiquery_chain = (\n    {\"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()\n)\n\n# 질문을 정의한다.\nquestion = \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n\n# 체인을 실행하여 생성된 다중 쿼리를 확인한다.\nmulti_queries = custom_multiquery_chain.invoke(question)\n# 결과를 확인한다.(5개 질문 생성)\nmulti_queries\n```\n:::\n\n\n```\n'OpenAI Assistant API의 Functions 기능을 사용하는 방법을 설명해 주세요.  \\nOpenAI Assistant API에서 Functions를 활용하는 방법이 궁금합니다.  \\nOpenAI Assistant API의 Functions를 어떻게 사용할 수 있는지 알려주세요.  \\nFunctions를 사용하여 OpenAI Assistant API를 활용하는 방법에 대해 설명해 주세요.  \\nOpenAI Assistant API의 Functions 사용법에 대한 자세한 정보를 제공해 주세요.  '\n```\n\n### 출력 포맷 및 고려사항\n\n**중요한 프롬프트 지시사항:**\n```\nYour response should be a list of values separated by new lines, eg: `foo\\nbar\\nbaz\\n`\n```\n\n**이 지시사항이 중요한 이유:**\n- **파싱 용이성**: 나중에 list 형식으로 파싱이 용이하게 출력이 되도록 하기 위해서다.\n- **강력한 구분자**: 리스트 형식으로 스플릿을 구현할 때 명확한 구분자(new line)를 인식시켜야 오류가 발생하지 않는다.\n- **시스템 안정성**: 일관된 출력 형식으로 후속 처리의 안정성을 보장한다.\n\n### Custom Chain을 MultiQueryRetriever에 적용\n\n이전에 생성한 Chain을 `MultiQueryRetriever`에 전달하여 검색을 수행할 수 있다.\n\n::: {#f866f5ac .cell execution_count=10}\n``` {.python .cell-code}\nmultiquery_retriever = MultiQueryRetriever.from_llm(\n    llm=custom_multiquery_chain, retriever=db.as_retriever()\n)\n```\n:::\n\n\n`MultiQueryRetriever`를 사용하여 문서를 검색하고 결과를 확인한다.\n\n::: {#f638425d .cell execution_count=11}\n``` {.python .cell-code}\n# 결과\nrelevant_docs = multiquery_retriever.invoke(question)\n\n# 검색된 고유한 문서의 개수를 반환한다.\nprint(\n    f\"===============\\n검색된 문서 개수: {len(relevant_docs)}\",\n    end=\"\\n===============\\n\",\n)\n\n# 검색된 문서의 내용을 출력한다.\nprint(relevant_docs[0].page_content)\n```\n:::\n\n\n```\nINFO:langchain.retrievers.multi_query:Generated queries: ['OpenAI Assistant API의 Functions 사용법에 대해 설명해 주세요.  ', 'OpenAI Assistant API에서 Functions를 어떻게 활용할 수 있나요?  ', 'OpenAI Assistant API의 Functions 기능에 대한 정보를 제공해 주세요.  ', 'Functions를 사용하여 OpenAI Assistant API를 어떻게 사용할 수 있는지 알려주세요.  ', 'OpenAI Assistant API의 Functions 사용법에 대한 자세한 내용을 알고 싶습니다.']\n```\n\n```\n===============\n검색된 문서 개수: 5\n===============\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval, Functions 를 활용하는 방법에 대해 다룹니다. 이와 더불어 파일을 업로드 하는 내용과 사용자의 피드백을 제출하는 내용도 튜토리얼 말미에 포함하고 있습니다.\n===============\n```\n\n# 성능 분석 및 효과\n\n## 실험 결과 비교\n\n### 단일 쿼리 vs 다중 쿼리 비교\n\n| 방식 | 생성된 쿼리 수 | 검색된 문서 수 | 장점 | 단점 |\n|:-----|:-------------|:-------------|:-----|:-----|\n| **단일 쿼리** | 1개 | 4개 | 빠른 처리, 간단한 구조 | 제한된 검색 범위 |\n| **기본 MultiQuery** | 3개 | 5개 | 자동 쿼리 확장 | 제한된 커스터마이징 |\n| **Custom MultiQuery** | 5개 | 5개 | 높은 커스터마이징, 더 다양한 관점 | 복잡한 설정 |\n\n### 주요 개선 효과\n\n**1. 검색 범위 확장**\n- 단일 쿼리: 4개 문서 → 다중 쿼리: 5개 문서 (25% 증가)\n- 더 포괄적인 정보 수집 가능\n\n**2. 쿼리 다양성 향상**\n```\n원본: \"OpenAI Assistant API의 Functions 사용법에 대해 알려주세요.\"\n\n생성된 다양한 관점:\n1. \"기능을 사용하는 방법을 설명해 주세요\"\n2. \"Functions를 활용하는 방법이 궁금합니다\"  \n3. \"Functions를 어떻게 사용할 수 있는지 알려주세요\"\n4. \"Functions를 사용하여 API를 활용하는 방법\"\n5. \"Functions 사용법에 대한 자세한 정보\"\n```\n\n**3. 검색 품질 개선**\n- 다양한 표현 방식으로 누락될 수 있는 관련 문서까지 포괄\n- 사용자 의도를 더 정확하게 해석하여 검색\n\n## 실무 적용 가이드\n\n### 언제 사용할까?\n\n**✅ MultiQueryRetriever 사용 권장 상황**\n1. **복잡하거나 모호한 쿼리**: 사용자 질문이 불명확하거나 여러 해석이 가능한 경우\n2. **포괄적 검색이 필요**: 관련된 모든 정보를 놓치지 않고 수집해야 하는 경우  \n3. **다양한 표현의 문서**: 동일한 개념이 여러 방식으로 표현된 문서들이 있는 경우\n4. **사용자 경험 개선**: 사용자가 정확한 키워드를 모르는 상황에서도 좋은 결과를 제공해야 하는 경우\n\n**❌ 일반 Retriever 사용 권장 상황**\n1. **명확하고 구체적인 쿼리**: 이미 정확한 키워드나 구문이 포함된 경우\n2. **빠른 응답이 중요**: 실시간 응답이 중요하고 약간의 정확도 손실을 감수할 수 있는 경우\n3. **제한된 리소스**: LLM API 호출 비용을 최소화해야 하는 경우\n4. **단순한 FAQ**: 간단한 질문-답변 시스템에서 과도한 기능일 수 있는 경우\n\n### 최적화 전략\n\n**1. 쿼리 생성 수 조정**\n```python\n# 간단한 질문: 3개\n# 복잡한 질문: 5-7개\n# 매우 복잡한 분석: 10개까지\n\nprompt = PromptTemplate.from_template(\n    \"\"\"Generate {num_queries} different versions of the question:\n    {question}\"\"\"\n)\n```\n\n**2. 도메인별 프롬프트 최적화**\n```python\n# 기술 문서용\ntech_prompt = \"\"\"Generate technical variations focusing on:\n- Implementation details\n- API usage patterns  \n- Code examples\n- Troubleshooting scenarios\"\"\"\n\n# 비즈니스 문서용  \nbusiness_prompt = \"\"\"Generate business-oriented variations focusing on:\n- Use cases and applications\n- Benefits and advantages\n- Cost and ROI considerations\n- Best practices\"\"\"\n```\n\n**3. 성능 모니터링**\n```python\n# 검색 결과 품질 추적\ndef evaluate_retrieval_quality(original_query, generated_queries, results):\n    return {\n        'query_diversity': calculate_diversity(generated_queries),\n        'result_coverage': len(set(results)),\n        'relevance_score': calculate_relevance(original_query, results)\n    }\n```\n\n## 핵심 요약\n\n### MultiQueryRetriever의 핵심 가치\n\n**\"하나로 질문하고, 여러 관점으로 검색한다\"**\n\n1. **자동 쿼리 확장**: 사용자의 단일 질문을 다양한 관점의 여러 질문으로 자동 변환\n2. **검색 범위 확대**: 단일 쿼리로는 놓칠 수 있는 관련 문서들까지 포괄적으로 수집\n3. **사용자 경험 향상**: 불완전하거나 모호한 질문도 의도를 파악하여 적절한 답변 제공\n4. **유연한 커스터마이징**: LCEL Chain을 통해 도메인별, 용도별 최적화 가능\n\n### 주요 장점\n\n1. **검색 정확도 향상**: 다양한 관점에서의 접근으로 누락 정보 최소화\n2. **사용성 개선**: 사용자가 정확한 키워드를 몰라도 좋은 결과 제공  \n3. **자동화**: 프롬프트 엔지니어링 과정을 LLM이 자동으로 수행\n4. **확장성**: 기존 Retriever 위에 간단히 추가하여 성능 향상 가능\n\n### 실무 적용 포인트\n\n- **적정 쿼리 수**: 3-5개 (복잡도에 따라 조정)\n- **비용 대비 효과**: LLM 호출 비용 증가 vs 검색 품질 향상의 트레이드오프 고려\n- **도메인 특화**: 업계별, 용도별 프롬프트 템플릿 개발로 효과 극대화\n- **성능 모니터링**: 검색 결과의 다양성과 관련성을 지속적으로 평가\n\nMultiQueryRetriever는 RAG 시스템의 검색 단계를 크게 개선할 수 있는 강력한 도구이다. 특히 사용자의 질문이 불명확하거나 포괄적인 정보 수집이 필요한 상황에서 그 가치를 발휘한다.\n\n",
    "supporting": [
      "06-MultiQueryRetriever_files"
    ],
    "filters": [],
    "includes": {}
  }
}