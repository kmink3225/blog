{
  "hash": "f70bd728559325f8f357185fc76d6d0f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Ensemble Retriever `Convex Combination(CC)` 추가\"\nsubtitle: 검색기\ndescription: |\n  문서 검색을 위한 다양한 Retriever 패턴과 최적화 기법을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n[written by@teddynote](https://github.com/teddylee777/langchain-teddynote)\n\n- 참고글: [AutoRAG 가 게재한 알고리즘 방식의 차이 설명](https://velog.io/@autorag/%EB%9E%AD%EC%B2%B4%EC%9D%B8%EC%9D%98-Ensemble-Retriever-%EC%9D%B4%EA%B2%8C-%EB%8C%80%EC%B2%B4-%EB%AD%90%EC%A7%80)\n\n\n아래의 주석을 풀고 패키지를 업데이트 후 진행합니다.\n\n::: {#ffc6a001 .cell execution_count=1}\n``` {.python .cell-code}\n# 업데이트 후 진행\n# !pip install -qU langchain-teddynote\n```\n:::\n\n\n::: {#33549bda .cell execution_count=2}\n``` {.python .cell-code}\nfrom dotenv import load_dotenv\n\nload_dotenv()\n```\n:::\n\n\n## 실험을 위한 사전 셋업\n\n::: {#385aabd0 .cell execution_count=3}\n``` {.python .cell-code}\nfrom langchain.retrievers import EnsembleRetriever as OriginalEnsembleRetriever\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import PDFPlumberLoader\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_teddynote.retrievers import KiwiBM25Retriever\n\n# 문서 로드(Load Documents)\nloader = PDFPlumberLoader(\"data/디지털정부혁신 추진계획.pdf\")\n\n# 문서 분할(Split Documents): 테스트를 위하여 작은 Chunk Size로 설정\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\nsplit_documents = loader.load_and_split(text_splitter)\n\n# 임베딩(Embedding) 생성\nembeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n\n# FaissRetriever 생성\nfaiss = FAISS.from_documents(\n    documents=split_documents, embedding=embeddings\n).as_retriever(search_kwargs={\"k\": 5})\n\n# KiwiBM25Retriever 생성(한글 형태소 분석기 + BM25 알고리즘)\nbm25 = KiwiBM25Retriever.from_documents(documents=split_documents, embedding=embeddings)\nbm25.k = 5\n\n# LangChain 버전의 EnsembleRetriever\noriginal_ensemble_retriever = OriginalEnsembleRetriever(retrievers=[faiss, bm25])\n```\n:::\n\n\nCC 방식과 RRF 방식의 EnsembleRetriever 생성\n\n::: {#2d3f9b3d .cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain_teddynote.retrievers import (\n    EnsembleRetriever,\n    EnsembleMethod,\n)\n\n# RRF 방식의 EnsembleRetriever (기본값으로 RRF 가 설정되어 있음)\nrrf_ensemble_retriever = EnsembleRetriever(\n    retrievers=[faiss, bm25], method=EnsembleMethod.RRF\n)\n\n# CC 방식의 EnsembleRetriever\ncc_ensemble_retriever = EnsembleRetriever(\n    retrievers=[faiss, bm25], method=EnsembleMethod.CC  # method 지정: CC\n)\n```\n:::\n\n\n## 검색 결과 비교\n\n::: {#7148a193 .cell execution_count=5}\n``` {.python .cell-code}\ndef pretty_print(query):\n    for i, (original_doc, cc_doc, rrf_doc) in enumerate(\n        zip(\n            original_ensemble_retriever.invoke(query),\n            cc_ensemble_retriever.invoke(query),\n            rrf_ensemble_retriever.invoke(query),\n        )\n    ):\n        print(f\"[{i}] [Original] Q: {query}\", end=\"\\n\\n\")\n        print(original_doc.page_content)\n        print(\"-\" * 100)\n        print(f\"[{i}] [RRF] Q: {query}\", end=\"\\n\\n\")\n        print(rrf_doc.page_content)\n        print(\"-\" * 100)\n        print(f\"[{i}] [CC] Q: {query}\", end=\"\\n\\n\")\n        print(cc_doc.page_content)\n        print(\"=\" * 100, end=\"\\n\\n\")\n```\n:::\n\n\n- 검색 결과에 `\"Original\"` 과 `\"RRF\"` 는 차이가 없어야 합니다. (LangChain 그대로 구현)\n- 검색 결과에 `\"CC\"` 는 `\"RRF\"` 와 차이가 있을 수 있습니다.\n\n`RRF` 와 `CC` 방식의 검색 결과 비교하여 문서에 적합한 방식을 차용하시길 바랍니다.\n\n::: {#f202cac0 .cell execution_count=6}\n``` {.python .cell-code}\n# 검색 결과 비교\npretty_print(\"디지털 트랜스포메이션이란 무엇인가요?\")\n```\n:::\n\n\n",
    "supporting": [
      "11-CC-EnsembleRetriever_files"
    ],
    "filters": [],
    "includes": {}
  }
}