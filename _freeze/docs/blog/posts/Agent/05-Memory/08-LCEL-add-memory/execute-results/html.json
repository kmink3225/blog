{
  "hash": "524ad8be2a03b6ba9b6dba37ac46f774",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"LCEL (대화내용 기억하기): 메모리 추가\"\nsubtitle: 대화 메모리\ndescription: |\n  대화 컨텍스트를 관리하는 다양한 메모리 시스템을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n임의의 체인에 메모리를 추가하는 방법을 보여줍니다. 현재 메모리 클래스를 사용할 수 있지만 수동으로 연결해야 합니다\n\n::: {#8d107e4d .cell execution_count=1}\n``` {.python .cell-code}\nfrom dotenv import load_dotenv\n\nload_dotenv()\n```\n:::\n\n\n::: {#2685d4ed .cell execution_count=2}\n``` {.python .cell-code}\nfrom operator import itemgetter\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\nfrom langchain_openai import ChatOpenAI\n\n\n# ChatOpenAI 모델을 초기화합니다.\nmodel = ChatOpenAI()\n\n# 대화형 프롬프트를 생성합니다. 이 프롬프트는 시스템 메시지, 이전 대화 내역, 그리고 사용자 입력을 포함합니다.\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"You are a helpful chatbot\"),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)\n```\n:::\n\n\n대화내용을 저장할 메모리인 `ConversationBufferMemory` 생성하고 `return_messages` 매개변수를 `True`로 설정하여, 생성된 인스턴스가 메시지를 반환하도록 합니다.\n\n- `memory_key` 설정: 추후 Chain 의 `prompt` 안에 대입될 key 입니다. 변경하여 사용할 수 있습니다.\n\n::: {#6a727ada .cell execution_count=3}\n``` {.python .cell-code}\n# 대화 버퍼 메모리를 생성하고, 메시지 반환 기능을 활성화합니다.\nmemory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n```\n:::\n\n\n저장된 대화기록을 확인합니다. 아직 저장하지 않았으므로, 대화기록은 비어 있습니다.\n\n::: {#ea5d43f1 .cell execution_count=4}\n``` {.python .cell-code}\nmemory.load_memory_variables({})  # 메모리 변수를 빈 딕셔너리로 초기화합니다.\n```\n:::\n\n\n`RunnablePassthrough.assign`을 사용하여 `chat_history` 변수에 `memory.load_memory_variables` 함수의 결과를 할당하고, 이 결과에서 `chat_history` 키에 해당하는 값을 추출합니다.\n\n::: {#c4e14e65 .cell execution_count=5}\n``` {.python .cell-code}\nrunnable = RunnablePassthrough.assign(\n    chat_history=RunnableLambda(memory.load_memory_variables)\n    | itemgetter(\"chat_history\")  # memory_key 와 동일하게 입력합니다.\n)\n```\n:::\n\n\n::: {#bdc09858 .cell execution_count=6}\n``` {.python .cell-code}\nrunnable.invoke({\"input\": \"hi\"})\n```\n:::\n\n\n::: {#2ec80a8d .cell execution_count=7}\n``` {.python .cell-code}\nrunnable.invoke({\"input\": \"hi\"})\n```\n:::\n\n\n::: {#c08e1c88 .cell execution_count=8}\n``` {.python .cell-code}\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"You are a helpful chatbot\"),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)\n```\n:::\n\n\n`runnable` 에 첫 번째 대화를 시작합니다.\n\n- `input`: 사용자 입력 대화가 전달됩니다.\n- `chat_history`: 대화 기록이 전달됩니다.\n\n::: {#b80339fa .cell execution_count=9}\n``` {.python .cell-code}\nrunnable.invoke({\"input\": \"hi!\"})\n```\n:::\n\n\n::: {#4f6eff6b .cell execution_count=10}\n``` {.python .cell-code}\nchain = runnable | prompt | model\n```\n:::\n\n\n첫 번째 대화를 진행합니다.\n\n::: {#621237c1 .cell execution_count=11}\n``` {.python .cell-code}\n# chain 객체의 invoke 메서드를 사용하여 입력에 대한 응답을 생성합니다.\nresponse = chain.invoke({\"input\": \"만나서 반갑습니다. 제 이름은 테디입니다.\"})\nprint(response.content)  # 생성된 응답을 출력합니다.\n```\n:::\n\n\n::: {#0ccb4aeb .cell execution_count=12}\n``` {.python .cell-code}\nmemory.load_memory_variables({})\n```\n:::\n\n\n`memory.save_context` 함수는 입력 데이터(`inputs`)와 응답 내용(`response.content`)을 메모리에 저장하는 역할을 합니다. 이는 AI 모델의 학습 과정에서 현재 상태를 기록하거나, 사용자의 요청과 시스템의 응답을 추적하는 데 사용될 수 있습니다.\n\n::: {#b6956bd8 .cell execution_count=13}\n``` {.python .cell-code}\n# 입력된 데이터와 응답 내용을 메모리에 저장합니다.\nmemory.save_context(\n    {\"human\": \"만나서 반갑습니다. 제 이름은 테디입니다.\"}, {\"ai\": response.content}\n)\n\n# 저장된 대화기록을 출력합니다.\nmemory.load_memory_variables({})\n```\n:::\n\n\n이름을 기억하고 있는지 추가 질의합니다.\n\n::: {#d86e7f3f .cell execution_count=14}\n``` {.python .cell-code}\n# 이름을 기억하고 있는지 추가 질의합니다.\nresponse = chain.invoke({\"input\": \"제 이름이 무엇이었는지 기억하세요?\"})\n# 답변을 출력합니다.\nprint(response.content)\n```\n:::\n\n\n## 커스텀 ConversationChain 구현 예시\n\n::: {#81a95e0b .cell execution_count=15}\n``` {.python .cell-code}\nfrom operator import itemgetter\nfrom langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough, Runnable\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\n\n# ChatOpenAI 모델을 초기화합니다.\nllm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n\n# 대화형 프롬프트를 생성합니다. 이 프롬프트는 시스템 메시지, 이전 대화 내역, 그리고 사용자 입력을 포함합니다.\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"You are a helpful chatbot\"),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)\n\n# 대화 버퍼 메모리를 생성하고, 메시지 반환 기능을 활성화합니다.\nmemory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n```\n:::\n\n\n::: {#0b5d0d5b .cell execution_count=16}\n``` {.python .cell-code}\nclass MyConversationChain(Runnable):\n\n    def __init__(self, llm, prompt, memory, input_key=\"input\"):\n\n        self.prompt = prompt\n        self.memory = memory\n        self.input_key = input_key\n\n        self.chain = (\n            RunnablePassthrough.assign(\n                chat_history=RunnableLambda(self.memory.load_memory_variables)\n                | itemgetter(memory.memory_key)  # memory_key 와 동일하게 입력합니다.\n            )\n            | prompt\n            | llm\n            | StrOutputParser()\n        )\n\n    def invoke(self, query, configs=None, **kwargs):\n        answer = self.chain.invoke({self.input_key: query})\n        self.memory.save_context(inputs={\"human\": query}, outputs={\"ai\": answer})\n        return answer\n```\n:::\n\n\n::: {#ca4cd81e .cell execution_count=17}\n``` {.python .cell-code}\n# ChatOpenAI 모델을 초기화합니다.\nllm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n\n# 대화형 프롬프트를 생성합니다. 이 프롬프트는 시스템 메시지, 이전 대화 내역, 그리고 사용자 입력을 포함합니다.\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", \"You are a helpful chatbot\"),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{input}\"),\n    ]\n)\n\n# 대화 버퍼 메모리를 생성하고, 메시지 반환 기능을 활성화합니다.\nmemory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n\n# 요약 메모리로 교체할 경우\n# memory = ConversationSummaryMemory(\n#     llm=llm, return_messages=True, memory_key=\"chat_history\"\n# )\n\nconversation_chain = MyConversationChain(llm, prompt, memory)\n```\n:::\n\n\n::: {#f90a5f3d .cell execution_count=18}\n``` {.python .cell-code}\nconversation_chain.invoke(\"안녕하세요? 만나서 반갑습니다. 제 이름은 테디 입니다.\")\n```\n:::\n\n\n::: {#9042725a .cell execution_count=19}\n``` {.python .cell-code}\nconversation_chain.invoke(\"제 이름이 뭐라고요?\")\n```\n:::\n\n\n::: {#935893c6 .cell execution_count=20}\n``` {.python .cell-code}\nconversation_chain.invoke(\"앞으로는 영어로만 답변해주세요 알겠어요?\")\n```\n:::\n\n\n::: {#cacde7fa .cell execution_count=21}\n``` {.python .cell-code}\nconversation_chain.invoke(\"제 이름을 다시 한 번 말해주세요\")\n```\n:::\n\n\n::: {#5fbfd895 .cell execution_count=22}\n``` {.python .cell-code}\nconversation_chain.memory.load_memory_variables({})[\"chat_history\"]\n```\n:::\n\n\n",
    "supporting": [
      "08-LCEL-add-memory_files"
    ],
    "filters": [],
    "includes": {}
  }
}