{
  "hash": "f1d736682d269cd91846a1ea11293fc3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"이전 대화를 기억하는 Chain 생성방법\"\nsubtitle: RAG 시스템\ndescription: |\n  검색 증강 생성(RAG) 시스템의 구축과 고급 기법을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n이 내용을 이해하기 위한 사전 지식\n- `RunnableWithMessageHistory`: [https://wikidocs.net/235581](https://wikidocs.net/235581)\n\n::: {#af442226 .cell execution_count=1}\n``` {.python .cell-code}\n# API KEY를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API KEY 정보로드\nload_dotenv()\n```\n:::\n\n\n::: {#cb797260 .cell execution_count=2}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH12-RAG\")\n```\n:::\n\n\n## 1. 일반 Chain 에 대화기록 추가\n\n::: {#5a858bd8 .cell execution_count=3}\n``` {.python .cell-code}\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.chat_history import BaseChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\n\n\n# 프롬프트 정의\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"당신은 Question-Answering 챗봇입니다. 주어진 질문에 대한 답변을 제공해주세요.\",\n        ),\n        # 대화기록용 key 인 chat_history 는 가급적 변경 없이 사용하세요!\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"#Question:\\n{question}\"),  # 사용자 입력을 변수로 사용\n    ]\n)\n\n# llm 생성\nllm = ChatOpenAI()\n\n# 일반 Chain 생성\nchain = prompt | llm | StrOutputParser()\n```\n:::\n\n\n대화를 기록하는 체인 생성(`chain_with_history`)\n\n::: {#e2ce154f .cell execution_count=4}\n``` {.python .cell-code}\n# 세션 기록을 저장할 딕셔너리\nstore = {}\n\n\n# 세션 ID를 기반으로 세션 기록을 가져오는 함수\ndef get_session_history(session_ids):\n    print(f\"[대화 세션ID]: {session_ids}\")\n    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n        store[session_ids] = ChatMessageHistory()\n    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n\n\nchain_with_history = RunnableWithMessageHistory(\n    chain,\n    get_session_history,  # 세션 기록을 가져오는 함수\n    input_messages_key=\"question\",  # 사용자의 질문이 템플릿 변수에 들어갈 key\n    history_messages_key=\"chat_history\",  # 기록 메시지의 키\n)\n```\n:::\n\n\n첫 번째 질문 실행\n\n::: {#9694ea0b .cell execution_count=5}\n``` {.python .cell-code}\nchain_with_history.invoke(\n    # 질문 입력\n    {\"question\": \"나의 이름은 테디입니다.\"},\n    # 세션 ID 기준으로 대화를 기록합니다.\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n```\n:::\n\n\n이어서 질문 실행\n\n::: {#4c17127c .cell execution_count=6}\n``` {.python .cell-code}\nchain_with_history.invoke(\n    # 질문 입력\n    {\"question\": \"내 이름이 뭐라고?\"},\n    # 세션 ID 기준으로 대화를 기록합니다.\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n```\n:::\n\n\n## 2. RAG + RunnableWithMessageHistory\n\n먼저 일반 RAG Chain 을 생성합니다. 단, 6단계의 prompt 에 `{chat_history}` 를 꼭 추가합니다.\n\n::: {#342519eb .cell execution_count=7}\n``` {.python .cell-code}\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import PDFPlumberLoader\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\nfrom operator import itemgetter\n\n# 단계 1: 문서 로드(Load Documents)\nloader = PDFPlumberLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\ndocs = loader.load()\n\n# 단계 2: 문서 분할(Split Documents)\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\nsplit_documents = text_splitter.split_documents(docs)\n\n# 단계 3: 임베딩(Embedding) 생성\nembeddings = OpenAIEmbeddings()\n\n# 단계 4: DB 생성(Create DB) 및 저장\n# 벡터스토어를 생성합니다.\nvectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n\n# 단계 5: 검색기(Retriever) 생성\n# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\nretriever = vectorstore.as_retriever()\n\n# 단계 6: 프롬프트 생성(Create Prompt)\n# 프롬프트를 생성합니다.\nprompt = PromptTemplate.from_template(\n    \"\"\"You are an assistant for question-answering tasks. \nUse the following pieces of retrieved context to answer the question. \nIf you don't know the answer, just say that you don't know. \nAnswer in Korean.\n\n#Previous Chat History:\n{chat_history}\n\n#Question: \n{question} \n\n#Context: \n{context} \n\n#Answer:\"\"\"\n)\n\n# 단계 7: 언어모델(LLM) 생성\n# 모델(LLM) 을 생성합니다.\nllm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n\n# 단계 8: 체인(Chain) 생성\nchain = (\n    {\n        \"context\": itemgetter(\"question\") | retriever,\n        \"question\": itemgetter(\"question\"),\n        \"chat_history\": itemgetter(\"chat_history\"),\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n```\n:::\n\n\n대화를 저장할 함수 정의\n\n::: {#0ace7364 .cell execution_count=8}\n``` {.python .cell-code}\n# 세션 기록을 저장할 딕셔너리\nstore = {}\n\n\n# 세션 ID를 기반으로 세션 기록을 가져오는 함수\ndef get_session_history(session_ids):\n    print(f\"[대화 세션ID]: {session_ids}\")\n    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n        store[session_ids] = ChatMessageHistory()\n    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n\n\n# 대화를 기록하는 RAG 체인 생성\nrag_with_history = RunnableWithMessageHistory(\n    chain,\n    get_session_history,  # 세션 기록을 가져오는 함수\n    input_messages_key=\"question\",  # 사용자의 질문이 템플릿 변수에 들어갈 key\n    history_messages_key=\"chat_history\",  # 기록 메시지의 키\n)\n```\n:::\n\n\n첫 번째 질문 실행\n\n::: {#1d214bf8 .cell execution_count=9}\n``` {.python .cell-code}\nrag_with_history.invoke(\n    # 질문 입력\n    {\"question\": \"삼성전자가 만든 생성형 AI 이름은?\"},\n    # 세션 ID 기준으로 대화를 기록합니다.\n    config={\"configurable\": {\"session_id\": \"rag123\"}},\n)\n```\n:::\n\n\n이어진 질문 실행\n\n::: {#c8db85cb .cell execution_count=10}\n``` {.python .cell-code}\nrag_with_history.invoke(\n    # 질문 입력\n    {\"question\": \"이전 답변을 영어로 번역해주세요.\"},\n    # 세션 ID 기준으로 대화를 기록합니다.\n    config={\"configurable\": {\"session_id\": \"rag123\"}},\n)\n```\n:::\n\n\n",
    "supporting": [
      "03-Conversation-With-History_files"
    ],
    "filters": [],
    "includes": {}
  }
}