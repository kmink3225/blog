{
  "hash": "bf926139ca55ea5b708501663e3cc82b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 다양한 LLM을 활용한 도구 호출 에이전트\nsubtitle: OpenAI 외 다양한 LLM으로 에이전트 구현\ndescription: |\n  Anthropic, Google Gemini, Together.ai, Ollama, Mistral 등 다양한 LLM을 활용한 에이전트 구현을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\n  - Agent\nauthor: Kwangmin Kim\ndate: 07/18/2025\nformat:\n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: false\n---\n\nOpenAI 외에도 `Anthropic`, `Google Gemini`, `Together.ai`, `Ollama`, `Mistral`과 같은 더 광범위한 공급자 구현을 지원합니다.\n\n이번 챕터에서는 다양한 LLM 을 사용하여 도구 호출 에이전트를 생성하고 실행하는 방법을 살펴보겠습니다.\n\n**참고 링크**\n\n- [LangChain 공식 도큐먼트](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/)\n\n::: {#02f16aa5 .cell execution_count=1}\n``` {.python .cell-code}\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n```\n:::\n\n\n::: {#f5994eb0 .cell execution_count=2}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install -qU langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH15-Agents\")\n```\n:::\n\n\n::: {#4c2df871 .cell execution_count=3}\n``` {.python .cell-code}\nfrom langchain.tools import tool\nfrom typing import List, Dict\nfrom langchain_teddynote.tools import GoogleNews\n\n\n# 도구 정의\n@tool\ndef search_news(query: str) -> List[Dict[str, str]]:\n    \"\"\"Search Google News by input keyword\"\"\"\n    news_tool = GoogleNews()\n    return news_tool.search_by_keyword(query, k=5)\n\n\nprint(f\"도구 이름: {search_news.name}\")\nprint(f\"도구 설명: {search_news.description}\")\n```\n:::\n\n\n::: {#453d87a0 .cell execution_count=4}\n``` {.python .cell-code}\n# tools 정의\ntools = [search_news]\n```\n:::\n\n\n## Agent 용 프롬프트 생성\n\n- `chat_history` : 이전 대화 내용을 저장하는 변수 (멀티턴을 지원하지 않는다면, 생략 가능합니다.)\n- `agent_scratchpad` : 에이전트가 임시로 저장하는 변수\n- `input` : 사용자의 입력\n\n::: {#b51be7b2 .cell execution_count=5}\n``` {.python .cell-code}\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.agents import create_tool_calling_agent\n\n# 프롬프트 생성\n# 프롬프트는 에이전트에게 모델이 수행할 작업을 설명하는 텍스트를 제공합니다. (도구의 이름과 역할을 입력)\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a helpful assistant. \"\n            \"Make sure to use the `search_news` tool for searching keyword related news.\",\n        ),\n        (\"placeholder\", \"{chat_history}\"),\n        (\"human\", \"{input}\"),\n        (\"placeholder\", \"{agent_scratchpad}\"),\n    ]\n)\n```\n:::\n\n\n## Tool Calling 을 지원하는 다양한 LLM 목록\n\n실습 진행을 위해서는 아래 내용을 설정해야 합니다.\n\n**Anthropic**\n\n- [Anthropic API 키 발급 관련](https://console.anthropic.com/settings/keys)\n- `.env` 파일 내 `ANTHROPIC_API_KEY` 에 발급받은 키를 설정하세요\n\n**Gemini**\n\n- [Gemini API 키 발급 관련](https://aistudio.google.com/app/apikey?hl=ko)\n- `.env` 파일 내 `GOOGLE_API_KEY` 에 발급받은 키를 설정하세요\n\n**Together AI**\n\n- [Together AI API 키 발급 관련](https://api.together.ai/)\n- `.env` 파일 내 `TOGETHER_API_KEY` 에 발급받은 키를 설정하세요\n\n**Ollama**\n\n- [Ollama Tool Calling 지원 모델 리스트](https://ollama.com/search?c=tools)\n- [이번 실습에 사용할 llama3.1 모델](https://ollama.com/library/llama3.1)\n- 터미널 창에 `ollama pull llama3.1` 명령어를 입력하여 모델을 다운로드 받습니다.\n- 이전에 Ollama 를 사용하지 않았다면, [Ollama](https://wikidocs.net/233805) 를 참고해 주세요.\n\nlangchain-ollama 설치를 한 뒤 진행해 주세요.\n\n::: {#6a5c4e5c .cell execution_count=6}\n``` {.python .cell-code}\n# !pip install -qU langchain-ollama==0.1.3\n```\n:::\n\n\n::: {#55109fb9 .cell execution_count=7}\n``` {.python .cell-code}\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_openai import ChatOpenAI\nfrom langchain_ollama import ChatOllama\nimport os\n\n# GPT-4o-mini\ngpt = ChatOpenAI(model=\"gpt-4o-mini\")\n\n# Claude-3-5-sonnet\nclaude = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n\n# Gemini-1.5-pro-latest\ngemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n\n# Llama-3.1-70B-Instruct-Turbo\nllama = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n)\n\n# Llama-3.1\nollama = ChatOllama(model=\"llama3.1\", temperature=0)\n\n# Qwen2.5 7B (한글 성능 괜찮은 편)\nqwen = ChatOllama(\n    model=\"qwen2.5:latest\",\n)\n```\n:::\n\n\nLLM 기반으로 Agent 를 생성합니다.\n\n::: {#dcd6f66a .cell execution_count=8}\n``` {.python .cell-code}\nfrom langchain.agents import create_tool_calling_agent\n\n# Agent 생성\ngpt_agent = create_tool_calling_agent(gpt, tools, prompt)\nclaude_agent = create_tool_calling_agent(claude, tools, prompt)\ngemini_agent = create_tool_calling_agent(gemini, tools, prompt)\nllama_agent = create_tool_calling_agent(llama, tools, prompt)\nollama_agent = create_tool_calling_agent(ollama, tools, prompt)\nqwen_agent = create_tool_calling_agent(qwen, tools, prompt)\n```\n:::\n\n\n## AgentExecutor 생성 후 실행 및 결과 확인\n\n::: {#ffa16a0d .cell execution_count=9}\n``` {.python .cell-code}\nfrom langchain.agents import AgentExecutor\n\n# gpt_agent 실행\nagent_executor = AgentExecutor(\n    agent=gpt_agent,\n    tools=tools,\n    verbose=True,\n    handle_parsing_errors=True,\n)\n\nresult = agent_executor.invoke({\"input\": \"AI 투자와 관련된 뉴스를 검색해 주세요.\"})\n\nprint(\"Agent 실행 결과:\")\nprint(result[\"output\"])\n```\n:::\n\n\n다양한 llm을 사용하여 에이전트를 실행합니다.\n\n다음은 입력받은 llm을 사용하여 Agent 를 생성하고 실행하여 결과를 출력하는 함수입니다.\n\n::: {#cff2cf1e .cell execution_count=10}\n``` {.python .cell-code}\ndef execute_agent(llm, tools, input_text, label):\n    agent = create_tool_calling_agent(llm, tools, prompt)\n    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n    result = executor.invoke({\"input\": input_text})\n    print(f\"[{label}] 결과입니다.\")\n    if isinstance(result[\"output\"], list) and len(result[\"output\"]) > 0:\n        for item in result[\"output\"]:\n            if \"text\" in item:\n                print(item[\"text\"])\n    elif isinstance(result[\"output\"], str):\n        print(result[\"output\"])\n    else:\n        print(result[\"output\"])\n```\n:::\n\n\n각 llm 별로 에이전트를 생성하고 실행하여 결과를 출력합니다.\n\n::: {#e20a6c8d .cell execution_count=11}\n``` {.python .cell-code}\nquery = (\n    \"AI 투자와 관련된 뉴스를 검색하고, 결과를 Instagram 게시글 형식으로 작성해 주세요.\"\n)\n```\n:::\n\n\n::: {#385458b9 .cell execution_count=12}\n``` {.python .cell-code}\n# gpt\nexecute_agent(gpt, tools, query, \"gpt\")\n```\n:::\n\n\n::: {#caf75589 .cell execution_count=13}\n``` {.python .cell-code}\n# claude\nexecute_agent(claude, tools, query, \"claude\")\n```\n:::\n\n\n::: {#10d3dfdf .cell execution_count=14}\n``` {.python .cell-code}\n# gemini\nexecute_agent(gemini, tools, query, \"gemini\")\n```\n:::\n\n\n::: {#5354f97b .cell execution_count=15}\n``` {.python .cell-code}\n# llama3.1 70B (Together.ai)\nexecute_agent(\n    llama,\n    tools,\n    \"Search AI related news and write it in Instagram post format\",\n    \"llama3.1 70B\",\n)\n```\n:::\n\n\n::: {#4975fd3c .cell execution_count=16}\n``` {.python .cell-code}\n# llama3.1 8B (ollama)\nexecute_agent(ollama, tools, query, \"llama3.1(Ollama)\")\n```\n:::\n\n\n::: {#06f57e03 .cell execution_count=17}\n``` {.python .cell-code}\n# qwen2.5 7B (ollama)\nquery = \"AI 투자와 관련된 뉴스를 검색하고, 결과를 Instagram 게시글 형식으로 작성해 주세요. 한글로 답변하세요!\"\n\nexecute_agent(qwen, tools, query, \"qwen2.5(Ollama)\")\n```\n:::\n\n\n",
    "supporting": [
      "04-Agent-More-LLMs_files"
    ],
    "filters": [],
    "includes": {}
  }
}