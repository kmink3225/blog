{
  "hash": "3d15a8501d3dde0d9b4e282bd707188b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Agentic RAG\"\nsubtitle: 에이전트를 활용한 검색 증강 생성\ndescription: |\n  문서 검색 도구와 웹 검색 도구를 활용하여 최신 정보를 검색하고 답변을 생성하는 Agentic RAG를 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\n  - Agent\nauthor: Kwangmin Kim\ndate: 07/20/2025\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n이번 챕터에서는 문서 검색을 통해 최신 정보에 접근하여 검색 결과를 가지고 답변을 생성하는 에이전트를 만들어 보겠습니다.\n\n질문에 따라 문서를 검색하여 답변하거나, 인터넷 검색 도구를 활용하여 답변하는 에이전트를 만들어 보겠습니다.\n\n**참고**\n\n- RAG 를 수행하되, Agent 를 활용하여 RAG 를 수행한다면 이를 **Agentic RAG** 라고 부릅니다.\n\n## 도구(Tools)\n\nAgent 가 활용할 도구를 정의하여 Agent 가 추론(reasoning)을 수행할 때 활용하도록 만들 수 있습니다.\n\nTavily Search 는 그 중 대표적인 **검색 도구** 입니다. 검색을 통해 최신 정보에 접근하여 검색 결과를 가지고 답변을 생성할 수 있습니다. 도구는 이처럼 검색 도구 뿐만아니라 Python 코드를 실행할 수 있는 도구, 직접 정의한 함수를 실행하는 도구 등 다양한 종류와 방법론을 제공합니다.\n\n\n### 웹 검색도구: Tavily Search\n\nLangChain에는 Tavily 검색 엔진을 도구로 쉽게 사용할 수 있는 내장 도구가 있습니다.\n\nTavily Search 를 사용하기 위해서는 API KEY를 발급 받아야 합니다.\n\n- [Tavily Search API 발급받기](https://app.tavily.com/sign-in)\n\n발급 받은 API KEY 를 다음과 같이 환경변수에 등록 합니다.\n\n`.env` 파일에 다음과 같이 등록합니다.\n\n- `TAVILY_API_KEY=발급 받은 Tavily API KEY 입력`\n\n::: {#d36fbac0 .cell execution_count=1}\n``` {.python .cell-code}\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n```\n:::\n\n\n::: {#c16f1320 .cell execution_count=2}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install -qU langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH15-Agentic-RAG\")\n```\n:::\n\n\n::: {#701e4fd8 .cell execution_count=3}\n``` {.python .cell-code}\n# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\nfrom langchain_community.tools.tavily_search import TavilySearchResults\n\n# TavilySearchResults 클래스의 인스턴스를 생성합니다\n# k=6은 검색 결과를 6개까지 가져오겠다는 의미입니다\nsearch = TavilySearchResults(k=6)\n```\n:::\n\n\n`search.invoke` 함수는 주어진 문자열에 대한 검색을 실행합니다.\n\n`invoke()` 함수에 검색하고 싶은 검색어를 넣어 검색을 수행합니다.\n\n::: {#90b82957 .cell execution_count=4}\n``` {.python .cell-code}\n# 검색 결과를 가져옵니다.\nsearch.invoke(\"판교 카카오 프렌즈샵 아지트점의 전화번호는 무엇인가요?\")\n```\n:::\n\n\n### 문서 기반 문서 검색 도구: Retriever\n\n우리의 데이터에 대해 조회를 수행할 retriever도 생성합니다.\n\n**실습에 활용한 문서**\n\n소프트웨어정책연구소(SPRi) - 2023년 12월호\n\n- 저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n- 링크: https://spri.kr/posts/view/23669\n- 파일명: `SPRI_AI_Brief_2023년12월호_F.pdf`\n\n_실습을 위해 다운로드 받은 파일을 `data` 폴더로 복사해 주시기 바랍니다_\n\n이 코드는 웹 기반 문서 로더, 문서 분할기, 벡터 저장소, 그리고 OpenAI 임베딩을 사용하여 문서 검색 시스템을 구축합니다.\n\n여기서는 PDF 문서를 `FAISS` DB 에 저장하고 조회하는 retriever 를 생성합니다.\n\n::: {#f072f6f3 .cell execution_count=5}\n``` {.python .cell-code}\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain.document_loaders import PyPDFLoader\n\n# PDF 파일 로드. 파일의 경로 입력\nloader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n\n# 텍스트 분할기를 사용하여 문서를 분할합니다.\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n\n# 문서를 로드하고 분할합니다.\nsplit_docs = loader.load_and_split(text_splitter)\n\n# VectorStore를 생성합니다.\nvector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n\n# Retriever를 생성합니다.\nretriever = vector.as_retriever()\n```\n:::\n\n\n이 함수는 `retriever` 객체의 `invoke()` 를 사용하여 사용자의 질문에 대한 가장 **관련성 높은 문서** 를 찾는 데 사용됩니다.\n\n::: {#1878024d .cell execution_count=6}\n``` {.python .cell-code}\n# 문서에서 관련성 높은 문서를 가져옵니다.\nretriever.invoke(\"삼성전자가 개발한 생성형 AI 관련 내용을 문서에서 찾아줘\")\n```\n:::\n\n\n이제 우리가 검색을 수행할 인덱스를 채웠으므로, 이를 에이전트가 제대로 사용할 수 있는 도구로 쉽게 변환할 수 있습니다.\n\n`create_retriever_tool` 함수로 `retriever` 를 도구로 변환합니다.\n\n::: {#09a74939 .cell execution_count=7}\n``` {.python .cell-code}\nfrom langchain.tools.retriever import create_retriever_tool\n\nretriever_tool = create_retriever_tool(\n    retriever,\n    name=\"pdf_search\",  # 도구의 이름을 입력합니다.\n    description=\"use this tool to search information from the PDF document\",  # 도구에 대한 설명을 자세히 기입해야 합니다!!\n)\n```\n:::\n\n\n### Agent 가 사용할 도구 목록 정의\n\n이제 두 가지를 모두 만들었으므로, Agent 가 사용할 도구 목록을 만들 수 있습니다.\n\n`tools` 리스트는 `search`와 `retriever_tool`을 포함합니다. \n\n::: {#713e699f .cell execution_count=8}\n``` {.python .cell-code}\n# tools 리스트에 search와 retriever_tool을 추가합니다.\ntools = [search, retriever_tool]\n```\n:::\n\n\n## Agent 생성\n\n이제 도구를 정의했으니 에이전트를 생성할 수 있습니다. \n\n먼저, Agent 가 활용할 LLM을 정의하고, Agent 가 참고할 Prompt 를 정의합니다.\n\n**참고**\n- 멀티턴 대화를 지원하지 않는다면 \"chat_history\" 를 제거해도 좋습니다.\n\n::: {#70174879 .cell execution_count=9}\n``` {.python .cell-code}\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\n\n# LLM 정의\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n\n# Prompt 정의\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a helpful assistant. \"\n            \"Make sure to use the `pdf_search` tool for searching information from the PDF document. \"\n            \"If you can't find the information from the PDF document, use the `search` tool for searching information from the web.\",\n        ),\n        (\"placeholder\", \"{chat_history}\"),\n        (\"human\", \"{input}\"),\n        (\"placeholder\", \"{agent_scratchpad}\"),\n    ]\n)\n```\n:::\n\n\n다음으로는 Tool Calling Agent 를 생성합니다.\n\n::: {#726fc37b .cell execution_count=10}\n``` {.python .cell-code}\nfrom langchain.agents import create_tool_calling_agent\n\n# tool calling agent 생성\nagent = create_tool_calling_agent(llm, tools, prompt)\n```\n:::\n\n\n마지막으로, 생성한 `agent` 를 실행하는 `AgentExecutor` 를 생성합니다.\n\n**참고**\n\n- `verbose=False` 로 설정하여 중간 단계 출력을 생략하였습니다.\n\n::: {#91b4ff8a .cell execution_count=11}\n``` {.python .cell-code}\nfrom langchain.agents import AgentExecutor\n\n# AgentExecutor 생성\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n```\n:::\n\n\n## 에이전트 실행하기\n\n이제 몇 가지 질의에 대해 에이전트를 실행할 수 있습니다!\n\n현재 이러한 모든 질의는 **상태(Stateless) 가 없는** 질의입니다(이전 상호작용을 기억하지 않습니다).\n\n`agent_executor` 객체의 `invoke` 메소드는 딕셔너리 형태의 인자를 받아 처리합니다. 이 예제에서는 `input` 키에 `hi!` 값을 할당한 딕셔너리를 인자로 전달하고 있습니다. 이는 일반적으로 AI 에이전트, 함수 실행기, 또는 명령 처리기 등의 객체에서 입력을 처리하기 위해 사용됩니다.\n\n::: {#c52dc071 .cell execution_count=12}\n``` {.python .cell-code}\nfrom langchain_teddynote.messages import AgentStreamParser\n\n# 각 단계별 출력을 위한 파서 생성\nagent_stream_parser = AgentStreamParser()\n```\n:::\n\n\n::: {#8bae2eed .cell execution_count=13}\n``` {.python .cell-code}\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresult = agent_executor.stream(\n    {\"input\": \"2024년 프로야구 플레이오프 진출한 5개 팀을 검색하여 알려주세요.\"}\n)\n\nfor step in result:\n    # 중간 단계를 parser 를 사용하여 단계별로 출력\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n`agent_executor` 객체의 `invoke` 메소드를 사용하여, 질문을 입력으로 제공합니다.\n\n::: {#dd007434 .cell execution_count=14}\n``` {.python .cell-code}\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresult = agent_executor.stream(\n    {\"input\": \"삼성전자가 자체 개발한 생성형 AI 관련된 정보를 문서에서 찾아주세요.\"}\n)\n\nfor step in result:\n    # 중간 단계를 parser 를 사용하여 단계별로 출력\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n## 이전 대화내용 기억하는 Agent\n\n이전의 대화내용을 기억하기 위해서는 `RunnableWithMessageHistory` 를 사용하여 `AgentExecutor` 를 감싸줍니다.\n\n`RunnableWithMessageHistory` 에 대한 자세한 내용은 아래 링크를 참고해 주세요.\n\n**참고**\n- [RunnableWithMessageHistory](https://wikidocs.net/254682)\n\n::: {#dca38ddf .cell execution_count=15}\n``` {.python .cell-code}\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\n\n# session_id 를 저장할 딕셔너리 생성\nstore = {}\n\n\n# session_id 를 기반으로 세션 기록을 가져오는 함수\ndef get_session_history(session_ids):\n    if session_ids not in store:  # session_id 가 store에 없는 경우\n        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n        store[session_ids] = ChatMessageHistory()\n    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n\n\n# 채팅 메시지 기록이 추가된 에이전트를 생성합니다.\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    # 대화 session_id\n    get_session_history,\n    # 프롬프트의 질문이 입력되는 key: \"input\"\n    input_messages_key=\"input\",\n    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n    history_messages_key=\"chat_history\",\n)\n```\n:::\n\n\n::: {#51f33b8c .cell execution_count=16}\n``` {.python .cell-code}\n# 질의에 대한 답변을 스트리밍으로 출력 요청\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"삼성전자가 개발한 생성형 AI 관련된 정보를 문서에서 찾아주세요.\"},\n    # session_id 설정\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\n# 출력 확인\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n::: {#595fdb74 .cell execution_count=17}\n``` {.python .cell-code}\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"이전의 답변을 영어로 번역해 주세요.\"},\n    # session_id 설정\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\n# 출력 확인\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n## Agent 템플릿\n\n다음은 전체 템플릿 코드 입니다.\n\n::: {#6a504680 .cell execution_count=18}\n``` {.python .cell-code}\n# 필요한 모듈 import\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_community.tools.tavily_search import TavilySearchResults\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.chat_message_histories import ChatMessageHistory\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_openai import OpenAIEmbeddings, ChatOpenAI\nfrom langchain.document_loaders import PyMuPDFLoader\nfrom langchain.tools.retriever import create_retriever_tool\nfrom langchain.agents import create_tool_calling_agent, AgentExecutor\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_teddynote.messages import AgentStreamParser\n\n########## 1. 도구를 정의합니다 ##########\n\n### 1-1. Search 도구 ###\n# TavilySearchResults 클래스의 인스턴스를 생성합니다\n# k=6은 검색 결과를 6개까지 가져오겠다는 의미입니다\nsearch = TavilySearchResults(k=6)\n\n### 1-2. PDF 문서 검색 도구 (Retriever) ###\n# PDF 파일 로드. 파일의 경로 입력\nloader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n\n# 텍스트 분할기를 사용하여 문서를 분할합니다.\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n\n# 문서를 로드하고 분할합니다.\nsplit_docs = loader.load_and_split(text_splitter)\n\n# VectorStore를 생성합니다.\nvector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n\n# Retriever를 생성합니다.\nretriever = vector.as_retriever()\n\nretriever_tool = create_retriever_tool(\n    retriever,\n    name=\"pdf_search\",  # 도구의 이름을 입력합니다.\n    description=\"use this tool to search information from the PDF document\",  # 도구에 대한 설명을 자세히 기입해야 합니다!!\n)\n\n### 1-3. tools 리스트에 도구 목록을 추가합니다 ###\n# tools 리스트에 search와 retriever_tool을 추가합니다.\ntools = [search, retriever_tool]\n\n########## 2. LLM 을 정의합니다 ##########\n# LLM 모델을 생성합니다.\nllm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n\n########## 3. Prompt 를 정의합니다 ##########\n\n# Prompt 를 정의합니다 - 이 부분을 수정할 수 있습니다!\n# Prompt 정의\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"system\",\n            \"You are a helpful assistant. \"\n            \"Make sure to use the `pdf_search` tool for searching information from the PDF document. \"\n            \"If you can't find the information from the PDF document, use the `search` tool for searching information from the web.\",\n        ),\n        (\"placeholder\", \"{chat_history}\"),\n        (\"human\", \"{input}\"),\n        (\"placeholder\", \"{agent_scratchpad}\"),\n    ]\n)\n\n########## 4. Agent 를 정의합니다 ##########\n\n# 에이전트를 생성합니다.\n# llm, tools, prompt를 인자로 사용합니다.\nagent = create_tool_calling_agent(llm, tools, prompt)\n\n########## 5. AgentExecutor 를 정의합니다 ##########\n\n# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n\n########## 6. 채팅 기록을 수행하는 메모리를 추가합니다. ##########\n\n# session_id 를 저장할 딕셔너리 생성\nstore = {}\n\n\n# session_id 를 기반으로 세션 기록을 가져오는 함수\ndef get_session_history(session_ids):\n    if session_ids not in store:  # session_id 가 store에 없는 경우\n        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n        store[session_ids] = ChatMessageHistory()\n    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n\n\n# 채팅 메시지 기록이 추가된 에이전트를 생성합니다.\nagent_with_chat_history = RunnableWithMessageHistory(\n    agent_executor,\n    # 대화 session_id\n    get_session_history,\n    # 프롬프트의 질문이 입력되는 key: \"input\"\n    input_messages_key=\"input\",\n    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n    history_messages_key=\"chat_history\",\n)\n\n########## 7. Agent 파서를 정의합니다. ##########\nagent_stream_parser = AgentStreamParser()\n```\n:::\n\n\n::: {#fd888818 .cell execution_count=19}\n``` {.python .cell-code}\n########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n\n# 질의에 대한 답변을 출력합니다.\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"구글이 앤스로픽에 투자한 금액을 문서에서 찾아줘\"},\n    # 세션 ID를 설정합니다.\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n::: {#68bd6d7c .cell execution_count=20}\n``` {.python .cell-code}\n########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n\n# 질의에 대한 답변을 출력합니다.\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"이전의 답변을 영어로 번역해 주세요\"},\n    # 세션 ID를 설정합니다.\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n    config={\"configurable\": {\"session_id\": \"abc123\"}},\n)\n\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n::: {#aaa2f93c .cell execution_count=21}\n``` {.python .cell-code}\n########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n\n# 질의에 대한 답변을 출력합니다.\nresponse = agent_with_chat_history.stream(\n    {\n        \"input\": \"2024년 프로야구 플레이오프 진출 5개팀을 검색해서 알려주세요. 한글로 답변하세요\"\n    },\n    # 세션 ID를 설정합니다.\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n    config={\"configurable\": {\"session_id\": \"abc456\"}},\n)\n\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n::: {#b25c5707 .cell execution_count=22}\n``` {.python .cell-code}\n########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n\n# 질의에 대한 답변을 출력합니다.\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"이전의 답변을 SNS 게시글 형태로 100자 내외로 작성하세요.\"},\n    # 세션 ID를 설정합니다.\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n    config={\"configurable\": {\"session_id\": \"abc456\"}},\n)\n\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n::: {#28efded1 .cell execution_count=23}\n``` {.python .cell-code}\n########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n\n# 질의에 대한 답변을 출력합니다.\nresponse = agent_with_chat_history.stream(\n    {\"input\": \"이전의 답변에 한국 시리즈 일정을 추가하세요.\"},\n    # 세션 ID를 설정합니다.\n    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n    config={\"configurable\": {\"session_id\": \"abc456\"}},\n)\n\nfor step in response:\n    agent_stream_parser.process_agent_steps(step)\n```\n:::\n\n\n",
    "supporting": [
      "06-Agentic-RAG_files"
    ],
    "filters": [],
    "includes": {}
  }
}