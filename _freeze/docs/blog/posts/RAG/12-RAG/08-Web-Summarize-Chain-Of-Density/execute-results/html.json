{
  "hash": "b0a3e60ab638ac2b2bbcfa29983c236c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Web Summarize Chain Of Density\"\nsubtitle: RAG 시스템\ndescription: |\n  검색 증강 생성(RAG) 시스템의 구축과 고급 기법을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n::: {#09b143a8 .cell execution_count=1}\n``` {.python .cell-code}\n# API 키를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API 키 정보 로드\nload_dotenv()\n```\n:::\n\n\nChain of Density: https://arxiv.org/pdf/2309.04269.pdf\n\n::: {#046f91e6 .cell execution_count=2}\n``` {.python .cell-code}\nimport time\nimport textwrap\n\nfrom langchain import hub\nfrom langchain_openai import ChatOpenAI\nfrom langchain.output_parsers.json import SimpleJsonOutputParser\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.schema.runnable import RunnablePassthrough\n\n# Load some data to summarize\nloader = WebBaseLoader(\"https://teddylee777.github.io/data-science/optuna/\")\ndocs = loader.load()\ncontent = docs[0].page_content\n\n# Get this prompt template\nprompt = hub.pull(\"lawwu/chain_of_density\")\n\n# The chat model output is a JSON list of dicts, with SimpleJsonOutputParser\n# we can convert it o a dict, and it suppors streaming.\njson_parser = SimpleJsonOutputParser()\n```\n:::\n\n\n::: {#904875a5 .cell execution_count=3}\n``` {.python .cell-code}\nchain = (\n    {\"ARTICLE\": RunnablePassthrough()}\n    | prompt\n    | ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0.1)\n    | json_parser\n)\n```\n:::\n\n\n::: {#1a68b403 .cell execution_count=4}\n``` {.python .cell-code}\nchain.invoke(content)\n```\n:::\n\n\n::: {#247f16e1 .cell execution_count=5}\n``` {.python .cell-code}\nfrom langchain import hub\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser, JsonOutputParser\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.callbacks.base import BaseCallbackHandler\nimport json\n\n\n# Load some data to summarize\nloader = WebBaseLoader(\n    \"https://www.aitimes.com/news/articleView.html?idxno=131777\")\ndocs = loader.load()\ncontent = docs[0].page_content\n# Load the prompt\n# prompt = hub.pull(\"langchain-ai/chain-of-density:4f55305e\")\n\n\nclass StreamCallback(BaseCallbackHandler):\n    def on_llm_new_token(self, token, **kwargs):\n        print(token, end=\"\", flush=True)\n\n\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"Article: {ARTICLE}\nYou will generate increasingly concise, entity-dense summaries of the above article. \n\nRepeat the following 2 steps 5 times. \n\nStep 1. Identify 1-3 informative entities (\";\" delimited) from the article which are missing from the previously generated summary. \nStep 2. Write a new, denser summary of identical length which covers every entity and detail from the previous summary plus the missing entities. \n\nA missing entity is:\n- relevant to the main story, \n- specific yet concise (50 words or fewer), \n- novel (not in the previous summary), \n- faithful (present in the article), \n- anywhere (can be located anywhere in the article).\n\nGuidelines:\n\n- The first summary should be long (8-10 sentences, ~200 words) yet highly non-specific, containing little information beyond the entities marked as missing. Use overly verbose language and fillers (e.g., \"this article discusses\") to reach ~200 words.\n- Make every word count: rewrite the previous summary to improve flow and make space for additional entities.\n- Make space with fusion, compression, and removal of uninformative phrases like \"the article discusses\".\n- The summaries should become highly dense and concise yet self-contained, i.e., easily understood without the article. \n- Missing entities can appear anywhere in the new summary.\n- Never drop entities from the previous summary. If space cannot be made, add fewer new entities. \n\nRemember, use the exact same number of words for each summary.\nAnswer in JSON. The JSON should be a list (length 5) of dictionaries whose keys are \"Missing_Entities\" and \"Denser_Summary\".\nUse only KOREAN language to reply.\"\"\"\n)\n\n\n# Create the chain, including\nchain = (\n    prompt\n    | ChatOpenAI(\n        temperature=0,\n        model=\"gpt-4-turbo-preview\",\n        streaming=True,\n        callbacks=[StreamCallback()],\n    )\n    | JsonOutputParser()\n    | (lambda x: x[-1][\"Denser_Summary\"])\n)\n\n# Invoke the chain\nresult = chain.invoke({\"ARTICLE\": content})\nprint(result)\n```\n:::\n\n\n",
    "supporting": [
      "08-Web-Summarize-Chain-Of-Density_files"
    ],
    "filters": [],
    "includes": {}
  }
}