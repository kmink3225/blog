{
  "hash": "f2902a0914cb06b83b940380e9c36400",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Azure OpenAI Embeddings\"\nsubtitle: ë¬¸ì„œ ì„ë² ë”© ìƒì„±\ndescription: |\n  Azure OpenAI Serviceë¥¼ í™œìš©í•œ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ë°©ë²•ì„ ë‹¤ë£¬ë‹¤.\ncategories:\n  - AI\n  - RAG\n  - Azure\n  - Embeddings\nauthor: Kwangmin Kim\ndate: 01/04/2025\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n## Azure OpenAI Embeddingsë€?\n\nAzure OpenAI EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì„œë¹„ìŠ¤ë‹¤. RAG ì‹œìŠ¤í…œì—ì„œ ë¬¸ì„œë¥¼ ìˆ«ì ë²¡í„°ë¡œ í‘œí˜„í•˜ì—¬ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.\n\n**RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ì—­í• :**\n- ë¬¸ì„œ ì²­í¬ â†’ ë²¡í„° ë³€í™˜\n- ì‚¬ìš©ì ì§ˆì˜ â†’ ë²¡í„° ë³€í™˜\n- ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚° â†’ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n\n**ì™œ ì„ë² ë”©ì´ í•„ìš”í•œê°€?**\n- í‚¤ì›Œë“œ ë§¤ì¹­ì˜ í•œê³„ ê·¹ë³µ (ì˜ˆ: \"ìë™ì°¨\" vs \"ìŠ¹ìš©ì°¨\")\n- ì˜ë¯¸ì  ìœ ì‚¬ì„± ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)\n- ë‹¤êµ­ì–´ ì§€ì› (ë™ì¼ ì˜ë¯¸ ê³µê°„ì— ë§¤í•‘)\n\n## Azure OpenAI Embeddings ëª¨ë¸\n\nAzure OpenAIëŠ” 3ê°€ì§€ ì£¼ìš” ì„ë² ë”© ëª¨ë¸ì„ ì œê³µí•œë‹¤:\n\n### 1. text-embedding-ada-002 (ë ˆê±°ì‹œ)\n**ì¶œì‹œ**: 2022ë…„ 12ì›”\n\n**ì‚¬ì–‘:**\n- ì°¨ì›: 1536 (ê³ ì •)\n- ìµœëŒ€ í† í°: 8,191\n- ê°€ê²©: $0.10 / 1M í† í°\n\n**íŠ¹ì§•:**\n- ë²”ìš© ì„ë² ë”© ëª¨ë¸\n- ì•ˆì •ì ì´ê³  ê²€ì¦ëœ ì„±ëŠ¥\n- ì‹ ê·œ í”„ë¡œì íŠ¸ëŠ” text-embedding-3 ê¶Œì¥\n\n### 2. text-embedding-3-small (ê¶Œì¥)\n**ì¶œì‹œ**: 2024ë…„ 1ì›”\n\n**ì‚¬ì–‘:**\n- ì°¨ì›: 512 ë˜ëŠ” 1536 (ì„ íƒ ê°€ëŠ¥)\n- ìµœëŒ€ í† í°: 8,191\n- ê°€ê²©: $0.02 / 1M í† í° (ada-002 ëŒ€ë¹„ **5ë°° ì €ë ´**)\n\n**íŠ¹ì§•:**\n- ì„±ëŠ¥ì€ ada-002ì™€ ìœ ì‚¬\n- **ë¹„ìš© íš¨ìœ¨ì ** (ê°€ê²© 1/5)\n- ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„\n\n**RAG ì‹œìŠ¤í…œ ê¶Œì¥**: âœ… **ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ìµœì„ ì˜ ì„ íƒ**\n\n### 3. text-embedding-3-large (ê³ ì„±ëŠ¥)\n**ì¶œì‹œ**: 2024ë…„ 1ì›”\n\n**ì‚¬ì–‘:**\n- ì°¨ì›: 256 ~ 3072 (ì„ íƒ ê°€ëŠ¥)\n- ìµœëŒ€ í† í°: 8,191\n- ê°€ê²©: $0.13 / 1M í† í°\n\n**íŠ¹ì§•:**\n- **ìµœê³  ì„±ëŠ¥** (MTEB ë²¤ì¹˜ë§ˆí¬ 1ìœ„ê¶Œ)\n- ë‹¤êµ­ì–´ ì§€ì› ê°•í™”\n- ë³µì¡í•œ ë„ë©”ì¸ì— ì í•©\n\n**RAG ì‹œìŠ¤í…œ ê¶Œì¥**: ë†’ì€ ì •í™•ë„ê°€ ì¤‘ìš”í•œ ê²½ìš°\n\n### ëª¨ë¸ ë¹„êµ\n\n| í•­ëª© | ada-002 | text-embedding-3-small | text-embedding-3-large |\n|------|---------|------------------------|------------------------|\n| **ì°¨ì›** | 1536 | 512/1536 | 256~3072 |\n| **ê°€ê²©** | $0.10/1M | $0.02/1M | $0.13/1M |\n| **ì„±ëŠ¥** | ê¸°ì¤€ | ìœ ì‚¬ | **ìµœê³ ** |\n| **ì†ë„** | ë³´í†µ | **ë¹ ë¦„** | ë³´í†µ |\n| **ê¶Œì¥** | ë ˆê±°ì‹œ | âœ… ë²”ìš© | ê³ ì •ë°€ë„ í•„ìš” ì‹œ |\n\n## Azure OpenAI ë¦¬ì†ŒìŠ¤ ìƒì„±\n\n### Azure Portalì—ì„œ ìƒì„±\n\n**1. Azure OpenAI ë¦¬ì†ŒìŠ¤ ë§Œë“¤ê¸°:**\n- [portal.azure.com](https://portal.azure.com) â†’ \"ë¦¬ì†ŒìŠ¤ ë§Œë“¤ê¸°\"\n- \"Azure OpenAI\" ê²€ìƒ‰ ë° ì„ íƒ\n- **ì‹ ì²­ ì–‘ì‹ ì‘ì„± í•„ìš”** (ì²˜ìŒ ì‚¬ìš© ì‹œ)\n\n**2. ê¸°ë³¸ ì„¤ì •:**\n- **êµ¬ë…**: ì‚¬ìš©í•  êµ¬ë… ì„ íƒ\n- **ë¦¬ì†ŒìŠ¤ ê·¸ë£¹**: `rg-rag-prod`\n- **ì§€ì—­**: East US (GPT-4 ì§€ì›) ë˜ëŠ” Sweden Central\n  - âš ï¸ **Korea Centralì€ í˜„ì¬ ì¼ë¶€ ëª¨ë¸ ë¯¸ì§€ì›**\n- **ì´ë¦„**: `openai-rag-prod`\n- **ê°€ê²© ì±…ì • ê³„ì¸µ**: Standard S0\n\n**3. ë„¤íŠ¸ì›Œí‚¹:**\n- ëª¨ë“  ë„¤íŠ¸ì›Œí¬ (ê°œë°œ) ë˜ëŠ” ì„ íƒëœ ë„¤íŠ¸ì›Œí¬ (í”„ë¡œë•ì…˜)\n\n**4. ê²€í†  + ë§Œë“¤ê¸°** â†’ ìƒì„± ì™„ë£Œ\n\n### ëª¨ë¸ ë°°í¬\n\nAzure OpenAIì—ì„œëŠ” ë¦¬ì†ŒìŠ¤ ìƒì„± í›„ **ëª¨ë¸ì„ ë°°í¬**í•´ì•¼ í•œë‹¤.\n\n**1. Azure OpenAI Studio ì ‘ì†:**\n- ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ â†’ \"Azure OpenAI Studioë¡œ ì´ë™\"\n\n**2. ë°°í¬ ë§Œë“¤ê¸°:**\n- \"ë°°í¬\" ë©”ë‰´ â†’ \"+ ë°°í¬ ë§Œë“¤ê¸°\"\n- **ëª¨ë¸ ì„ íƒ**: text-embedding-3-small\n- **ë°°í¬ ì´ë¦„**: `text-embedding-3-small` (ë˜ëŠ” ì›í•˜ëŠ” ì´ë¦„)\n- **ëª¨ë¸ ë²„ì „**: ìµœì‹  ë²„ì „\n- **TPM (ë¶„ë‹¹ í† í°)**: 120K (ê¸°ë³¸ê°’)\n\n**3. ì—”ë“œí¬ì¸íŠ¸ ë° í‚¤ í™•ì¸:**\n- ë¦¬ì†ŒìŠ¤ â†’ \"í‚¤ ë° ì—”ë“œí¬ì¸íŠ¸\"\n- **KEY 1**, **ì—”ë“œí¬ì¸íŠ¸** ë³µì‚¬\n\n### Azure CLIë¡œ ìƒì„±\n\n```bash\n# Azure OpenAI ë¦¬ì†ŒìŠ¤ ìƒì„±\naz cognitiveservices account create \\\n    --name openai-rag-prod \\\n    --resource-group rg-rag-prod \\\n    --kind OpenAI \\\n    --sku S0 \\\n    --location eastus \\\n    --yes\n\n# í‚¤ ë° ì—”ë“œí¬ì¸íŠ¸ ì¡°íšŒ\naz cognitiveservices account keys list \\\n    --name openai-rag-prod \\\n    --resource-group rg-rag-prod\n\naz cognitiveservices account show \\\n    --name openai-rag-prod \\\n    --resource-group rg-rag-prod \\\n    --query properties.endpoint\n```\n\n## í™˜ê²½ ì„¤ì •\n\n### Python SDK ì„¤ì¹˜\n\n```bash\npip install openai\npip install langchain-openai\npip install python-dotenv\npip install tiktoken  # í† í° ê³„ì‚°ìš©\n```\n\n### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n\n`.env` íŒŒì¼:\n```\nAZURE_OPENAI_ENDPOINT=https://openai-rag-prod.openai.azure.com/\nAZURE_OPENAI_API_KEY=your-key-here\nAZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small\nAZURE_OPENAI_API_VERSION=2024-02-01\n```\n\n## ê¸°ë³¸ ì‚¬ìš©ë²•\n\n### ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©\n\n::: {#24f9a157 .cell execution_count=1}\n``` {.python .cell-code}\nfrom openai import AzureOpenAI\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\n# Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±\nclient = AzureOpenAI(\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n)\n\n# í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±\ntext = \"Azure OpenAIëŠ” Microsoftì˜ ê´€ë¦¬í˜• OpenAI ì„œë¹„ìŠ¤ë‹¤.\"\nresponse = client.embeddings.create(\n    input=text,\n    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n)\n\n# ì„ë² ë”© ë²¡í„° ì¶”ì¶œ\nembedding = response.data[0].embedding\n\nprint(f\"ì„ë² ë”© ì°¨ì›: {len(embedding)}\")\nprint(f\"ì²« 10ê°œ ê°’: {embedding[:10]}\")\n```\n:::\n\n\n### ë°°ì¹˜ ì„ë² ë”© ìƒì„±\n\n::: {#fc1d1113 .cell execution_count=2}\n``` {.python .cell-code}\n# ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë™ì‹œ ì„ë² ë”©\ntexts = [\n    \"AzureëŠ” Microsoftì˜ í´ë¼ìš°ë“œ í”Œë«í¼ì´ë‹¤.\",\n    \"RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ì´ë‹¤.\",\n    \"ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤.\"\n]\n\nresponse = client.embeddings.create(\n    input=texts,\n    model=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n)\n\n# ëª¨ë“  ì„ë² ë”© ì¶”ì¶œ\nembeddings = [data.embedding for data in response.data]\n\nprint(f\"ìƒì„±ëœ ì„ë² ë”© ìˆ˜: {len(embeddings)}\")\nprint(f\"ê° ì„ë² ë”© ì°¨ì›: {len(embeddings[0])}\")\n```\n:::\n\n\n## LangChain í†µí•©\n\n### AzureOpenAIEmbeddings ì‚¬ìš©\n\n::: {#96a4c734 .cell execution_count=3}\n``` {.python .cell-code}\nfrom langchain_openai import AzureOpenAIEmbeddings\n\n# LangChain ì„ë² ë”© í´ë˜ìŠ¤ ìƒì„±\nembeddings = AzureOpenAIEmbeddings(\n    azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n)\n\n# ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©\ntext = \"LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ë‹¤.\"\nembedding = embeddings.embed_query(text)\n\nprint(f\"ì„ë² ë”© ì°¨ì›: {len(embedding)}\")\nprint(f\"ì²« 5ê°œ ê°’: {embedding[:5]}\")\n```\n:::\n\n\n### ë¬¸ì„œ ëª©ë¡ ì„ë² ë”©\n\n::: {#8dc75060 .cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain_core.documents import Document\n\n# ë¬¸ì„œ ëª©ë¡ ìƒì„±\ndocuments = [\n    Document(page_content=\"Azure AI SearchëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë‹¤.\", metadata={\"source\": \"doc1\"}),\n    Document(page_content=\"Document IntelligenceëŠ” OCR ì„œë¹„ìŠ¤ë‹¤.\", metadata={\"source\": \"doc2\"}),\n    Document(page_content=\"Blob StorageëŠ” íŒŒì¼ ì €ì¥ì†Œë‹¤.\", metadata={\"source\": \"doc3\"})\n]\n\n# ë¬¸ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ì—¬ ì„ë² ë”©\ntexts = [doc.page_content for doc in documents]\ndoc_embeddings = embeddings.embed_documents(texts)\n\nprint(f\"ì„ë² ë”©ëœ ë¬¸ì„œ ìˆ˜: {len(doc_embeddings)}\")\nprint(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ì„ë² ë”© ì°¨ì›: {len(doc_embeddings[0])}\")\n```\n:::\n\n\n## ë¬¸ì„œ ì²­í¬ ì„ë² ë”©\n\nRAG ì‹œìŠ¤í…œì—ì„œëŠ” ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• í•œ í›„ ê° ì²­í¬ë¥¼ ì„ë² ë”©í•œë‹¤.\n\n### ì „ì²´ íŒŒì´í”„ë¼ì¸\n\n::: {#5165d66b .cell execution_count=5}\n``` {.python .cell-code}\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.document_loaders import TextLoader\n\n# 1. ë¬¸ì„œ ë¡œë”©\nloader = TextLoader(\"sample_document.txt\", encoding=\"utf-8\")\ndocuments = loader.load()\n\n# 2. í…ìŠ¤íŠ¸ ë¶„í• \ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=200,\n    length_function=len,\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n)\nchunks = text_splitter.split_documents(documents)\n\nprint(f\"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}\")\n\n# 3. ê° ì²­í¬ ì„ë² ë”©\nchunk_texts = [chunk.page_content for chunk in chunks]\nchunk_embeddings = embeddings.embed_documents(chunk_texts)\n\nprint(f\"ì„ë² ë”© ì™„ë£Œ: {len(chunk_embeddings)}ê°œ ì²­í¬\")\n```\n:::\n\n\n### ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥\n\n::: {#590b403d .cell execution_count=6}\n``` {.python .cell-code}\n# ì„ë² ë”©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥\nembedded_chunks = []\nfor chunk, embedding in zip(chunks, chunk_embeddings):\n    embedded_chunks.append({\n        \"text\": chunk.page_content,\n        \"embedding\": embedding,\n        \"metadata\": {\n            **chunk.metadata,\n            \"chunk_size\": len(chunk.page_content),\n            \"embedding_model\": \"text-embedding-3-small\"\n        }\n    })\n\nprint(f\"ì²« ë²ˆì§¸ ì²­í¬ ë©”íƒ€ë°ì´í„°: {embedded_chunks[0]['metadata']}\")\n```\n:::\n\n\n## ìœ ì‚¬ë„ ê³„ì‚°\n\n### ì½”ì‚¬ì¸ ìœ ì‚¬ë„\n\n::: {#24c64b14 .cell execution_count=7}\n``` {.python .cell-code}\nimport numpy as np\n\ndef cosine_similarity(vec1, vec2):\n    \"\"\"ë‘ ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n\n# ì˜ˆì‹œ: ì§ˆì˜ì™€ ë¬¸ì„œ ìœ ì‚¬ë„ ê³„ì‚°\nquery = \"Azureì˜ AI ì„œë¹„ìŠ¤ëŠ” ë¬´ì—‡ì¸ê°€?\"\ndoc1 = \"Azure AI SearchëŠ” ê²€ìƒ‰ ì„œë¹„ìŠ¤ë‹¤.\"\ndoc2 = \"Blob StorageëŠ” íŒŒì¼ ì €ì¥ì†Œë‹¤.\"\n\n# ì„ë² ë”© ìƒì„±\nquery_embedding = embeddings.embed_query(query)\ndoc1_embedding = embeddings.embed_query(doc1)\ndoc2_embedding = embeddings.embed_query(doc2)\n\n# ìœ ì‚¬ë„ ê³„ì‚°\nsimilarity1 = cosine_similarity(query_embedding, doc1_embedding)\nsimilarity2 = cosine_similarity(query_embedding, doc2_embedding)\n\nprint(f\"ì§ˆì˜ vs ë¬¸ì„œ1 ìœ ì‚¬ë„: {similarity1:.4f}\")\nprint(f\"ì§ˆì˜ vs ë¬¸ì„œ2 ìœ ì‚¬ë„: {similarity2:.4f}\")\n```\n:::\n\n\n### ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°\n\n::: {#9e390912 .cell execution_count=8}\n``` {.python .cell-code}\ndef find_most_similar(query_embedding, doc_embeddings, top_k=3):\n    \"\"\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°\"\"\"\n    similarities = []\n    for idx, doc_emb in enumerate(doc_embeddings):\n        sim = cosine_similarity(query_embedding, doc_emb)\n        similarities.append((idx, sim))\n    \n    # ìœ ì‚¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬\n    similarities.sort(key=lambda x: x[1], reverse=True)\n    return similarities[:top_k]\n\n# ì‚¬ìš© ì˜ˆì‹œ\nquery = \"RAG ì‹œìŠ¤í…œ êµ¬ì¶• ë°©ë²•\"\nquery_emb = embeddings.embed_query(query)\n\n# ìƒìœ„ 3ê°œ ìœ ì‚¬ ë¬¸ì„œ ì°¾ê¸°\ntop_docs = find_most_similar(query_emb, chunk_embeddings, top_k=3)\n\nprint(\"ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ:\")\nfor idx, similarity in top_docs:\n    print(f\"ì²­í¬ {idx}: {similarity:.4f}\")\n    print(f\"ë‚´ìš©: {chunks[idx].page_content[:100]}...\\n\")\n```\n:::\n\n\n## ì°¨ì› ì¶•ì†Œ (Matryoshka Embeddings)\n\ntext-embedding-3 ëª¨ë¸ì€ ì°¨ì› ì¶•ì†Œë¥¼ ì§€ì›í•œë‹¤.\n\n### ì¶•ì†Œ ì°¨ì›ìœ¼ë¡œ ì„ë² ë”© ìƒì„±\n\n::: {#58299aff .cell execution_count=9}\n``` {.python .cell-code}\n# 512 ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ (ê¸°ë³¸ 1536)\nresponse = client.embeddings.create(\n    input=\"Azure OpenAI ì„ë² ë”© í…ŒìŠ¤íŠ¸\",\n    model=\"text-embedding-3-small\",\n    dimensions=512  # 1536 â†’ 512\n)\n\nembedding_512 = response.data[0].embedding\nprint(f\"ì¶•ì†Œëœ ì°¨ì›: {len(embedding_512)}\")\n```\n:::\n\n\n### ì°¨ì› ì¶•ì†Œ í›„ ìœ ì‚¬ë„ ë¹„êµ\n\n::: {#f4d215db .cell execution_count=10}\n``` {.python .cell-code}\n# ì „ì²´ ì°¨ì› (1536) vs ì¶•ì†Œ ì°¨ì› (512) ë¹„êµ\ntext1 = \"AzureëŠ” í´ë¼ìš°ë“œ í”Œë«í¼ì´ë‹¤.\"\ntext2 = \"Microsoftì˜ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ë‹¤.\"\ntext3 = \"Pythonì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë‹¤.\"\n\n# 1536 ì°¨ì›\nresp_full = client.embeddings.create(\n    input=[text1, text2, text3],\n    model=\"text-embedding-3-small\"\n)\nemb_full = [d.embedding for d in resp_full.data]\n\n# 512 ì°¨ì›\nresp_reduced = client.embeddings.create(\n    input=[text1, text2, text3],\n    model=\"text-embedding-3-small\",\n    dimensions=512\n)\nemb_reduced = [d.embedding for d in resp_reduced.data]\n\n# ìœ ì‚¬ë„ ë¹„êµ\nsim_full_12 = cosine_similarity(emb_full[0], emb_full[1])\nsim_reduced_12 = cosine_similarity(emb_reduced[0], emb_reduced[1])\n\nprint(f\"1536 ì°¨ì›: text1-text2 ìœ ì‚¬ë„ = {sim_full_12:.4f}\")\nprint(f\"512 ì°¨ì›: text1-text2 ìœ ì‚¬ë„ = {sim_reduced_12:.4f}\")\nprint(f\"ì°¨ì´: {abs(sim_full_12 - sim_reduced_12):.4f}\")\n```\n:::\n\n\n**ì°¨ì› ì¶•ì†Œ ì¥ì :**\n- ì €ì¥ ê³µê°„ ì ˆì•½ (512 ì°¨ì›: 1/3 í¬ê¸°)\n- ë¹ ë¥¸ ê²€ìƒ‰ ì†ë„\n- ìœ ì‚¬ë„ ì •í™•ë„ ì•½ê°„ ê°ì†Œ (ë³´í†µ 5% ì´ë‚´)\n\n## ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”\n\n### ëŒ€ëŸ‰ ë¬¸ì„œ ì„ë² ë”©\n\n::: {#e43d1ba7 .cell execution_count=11}\n``` {.python .cell-code}\ndef embed_documents_batch(texts, batch_size=100):\n    \"\"\"ë°°ì¹˜ ë‹¨ìœ„ë¡œ ëŒ€ëŸ‰ ë¬¸ì„œ ì„ë² ë”©\"\"\"\n    all_embeddings = []\n    \n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i+batch_size]\n        print(f\"ë°°ì¹˜ {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘...\")\n        \n        # ë°°ì¹˜ ì„ë² ë”©\n        batch_embeddings = embeddings.embed_documents(batch)\n        all_embeddings.extend(batch_embeddings)\n    \n    return all_embeddings\n\n# ì‚¬ìš© ì˜ˆì‹œ (1000ê°œ ë¬¸ì„œ)\n# large_texts = [f\"ë¬¸ì„œ {i} ë‚´ìš©...\" for i in range(1000)]\n# embeddings_result = embed_documents_batch(large_texts, batch_size=100)\n```\n:::\n\n\n### ë³‘ë ¬ ì²˜ë¦¬\n\n::: {#5117d808 .cell execution_count=12}\n``` {.python .cell-code}\nfrom concurrent.futures import ThreadPoolExecutor\nimport time\n\ndef embed_chunk(texts_chunk):\n    \"\"\"ì²­í¬ ë‹¨ìœ„ ì„ë² ë”© (ë³‘ë ¬ ì‹¤í–‰ìš©)\"\"\"\n    return embeddings.embed_documents(texts_chunk)\n\ndef embed_parallel(texts, num_workers=4, chunk_size=25):\n    \"\"\"ë³‘ë ¬ë¡œ ì„ë² ë”© ìƒì„±\"\"\"\n    # ì²­í¬ë¡œ ë¶„í• \n    chunks = [texts[i:i+chunk_size] for i in range(0, len(texts), chunk_size)]\n    \n    # ë³‘ë ¬ ì‹¤í–‰\n    start_time = time.time()\n    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n        results = list(executor.map(embed_chunk, chunks))\n    \n    # ê²°ê³¼ ë³‘í•©\n    all_embeddings = [emb for chunk_result in results for emb in chunk_result]\n    \n    duration = time.time() - start_time\n    print(f\"ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {len(all_embeddings)}ê°œ ì„ë² ë”©, {duration:.2f}ì´ˆ\")\n    \n    return all_embeddings\n\n# ì‚¬ìš© ì˜ˆì‹œ\n# texts_sample = [f\"ìƒ˜í”Œ í…ìŠ¤íŠ¸ {i}\" for i in range(100)]\n# parallel_embeddings = embed_parallel(texts_sample, num_workers=4, chunk_size=25)\n```\n:::\n\n\n## ìºì‹± ì „ëµ\n\në™ì¼í•œ í…ìŠ¤íŠ¸ëŠ” ì¬ê³„ì‚°í•˜ì§€ ì•Šë„ë¡ ìºì‹±í•œë‹¤.\n\n### ê°„ë‹¨í•œ ìºì‹±\n\n::: {#80d608e9 .cell execution_count=13}\n``` {.python .cell-code}\nimport hashlib\nimport json\n\nclass EmbeddingCache:\n    def __init__(self, cache_file=\".embedding_cache.json\"):\n        self.cache_file = cache_file\n        self.cache = self._load_cache()\n    \n    def _load_cache(self):\n        \"\"\"ìºì‹œ íŒŒì¼ ë¡œë“œ\"\"\"\n        try:\n            with open(self.cache_file, \"r\") as f:\n                return json.load(f)\n        except FileNotFoundError:\n            return {}\n    \n    def _save_cache(self):\n        \"\"\"ìºì‹œ íŒŒì¼ ì €ì¥\"\"\"\n        with open(self.cache_file, \"w\") as f:\n            json.dump(self.cache, f)\n    \n    def _get_hash(self, text):\n        \"\"\"í…ìŠ¤íŠ¸ í•´ì‹œ ìƒì„±\"\"\"\n        return hashlib.md5(text.encode()).hexdigest()\n    \n    def get_embedding(self, text, embeddings_func):\n        \"\"\"ìºì‹œëœ ì„ë² ë”© ë°˜í™˜ ë˜ëŠ” ìƒì„±\"\"\"\n        text_hash = self._get_hash(text)\n        \n        # ìºì‹œ í™•ì¸\n        if text_hash in self.cache:\n            print(f\"ìºì‹œ íˆíŠ¸: {text[:50]}...\")\n            return self.cache[text_hash]\n        \n        # ì„ë² ë”© ìƒì„±\n        print(f\"ìºì‹œ ë¯¸ìŠ¤: {text[:50]}...\")\n        embedding = embeddings_func(text)\n        \n        # ìºì‹œ ì €ì¥\n        self.cache[text_hash] = embedding\n        self._save_cache()\n        \n        return embedding\n\n# ì‚¬ìš© ì˜ˆì‹œ\ncache = EmbeddingCache()\n\ntext = \"Azure OpenAI ì„œë¹„ìŠ¤\"\nemb1 = cache.get_embedding(text, embeddings.embed_query)  # ìºì‹œ ë¯¸ìŠ¤\nemb2 = cache.get_embedding(text, embeddings.embed_query)  # ìºì‹œ íˆíŠ¸ (ì¦‰ì‹œ ë°˜í™˜)\n```\n:::\n\n\n### LangChain CacheBackedEmbeddings\n\n::: {#2df7a1b9 .cell execution_count=14}\n``` {.python .cell-code}\nfrom langchain.embeddings import CacheBackedEmbeddings\nfrom langchain.storage import LocalFileStore\n\n# ë¡œì»¬ íŒŒì¼ ìºì‹œ ìŠ¤í† ì–´\nstore = LocalFileStore(\"./.embedding_cache/\")\n\n# ìºì‹œê°€ ì ìš©ëœ ì„ë² ë”©\ncached_embedder = CacheBackedEmbeddings.from_bytes_store(\n    underlying_embeddings=embeddings,\n    document_embedding_cache=store,\n    namespace=\"azure-openai-embeddings\"\n)\n\n# ì‚¬ìš© (ìë™ ìºì‹±)\ntexts = [\"Azure AI\", \"OpenAI Service\", \"Azure AI\"]  # \"Azure AI\" ì¤‘ë³µ\nembeddings_result = cached_embedder.embed_documents(texts)\n# ë‘ ë²ˆì§¸ \"Azure AI\"ëŠ” ìºì‹œì—ì„œ ì¦‰ì‹œ ë°˜í™˜\n```\n:::\n\n\n## í† í° ê³„ì‚° ë° ë¹„ìš© ì¶”ì •\n\n### í† í° ìˆ˜ ê³„ì‚°\n\n::: {#10cfed46 .cell execution_count=15}\n``` {.python .cell-code}\nimport tiktoken\n\ndef count_tokens(text, model=\"cl100k_base\"):\n    \"\"\"í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ê³„ì‚°\"\"\"\n    encoding = tiktoken.get_encoding(model)\n    return len(encoding.encode(text))\n\n# ì˜ˆì‹œ\ntext = \"Azure OpenAI EmbeddingsëŠ” í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ì„œë¹„ìŠ¤ë‹¤.\"\ntoken_count = count_tokens(text)\n\nprint(f\"í…ìŠ¤íŠ¸: {text}\")\nprint(f\"í† í° ìˆ˜: {token_count}\")\n```\n:::\n\n\n### ë¹„ìš© ì¶”ì •\n\n::: {#0d3371a9 .cell execution_count=16}\n``` {.python .cell-code}\ndef estimate_cost(token_count, model=\"text-embedding-3-small\"):\n    \"\"\"ì„ë² ë”© ë¹„ìš© ì¶”ì •\"\"\"\n    prices = {\n        \"text-embedding-ada-002\": 0.0001,  # $0.10 / 1M tokens\n        \"text-embedding-3-small\": 0.00002,  # $0.02 / 1M tokens\n        \"text-embedding-3-large\": 0.00013   # $0.13 / 1M tokens\n    }\n    \n    price_per_token = prices.get(model, 0)\n    cost = token_count * price_per_token\n    \n    return cost\n\n# ì˜ˆì‹œ: 10,000ê°œ ë¬¸ì„œ (ê° 500 í† í°)\ntotal_tokens = 10000 * 500\ncost_small = estimate_cost(total_tokens, \"text-embedding-3-small\")\ncost_large = estimate_cost(total_tokens, \"text-embedding-3-large\")\n\nprint(f\"ì´ í† í°: {total_tokens:,}\")\nprint(f\"text-embedding-3-small ë¹„ìš©: ${cost_small:.2f}\")\nprint(f\"text-embedding-3-large ë¹„ìš©: ${cost_large:.2f}\")\n```\n:::\n\n\n## Azure AI Search ì—°ë™\n\nì„ë² ë”© ìƒì„± í›„ Azure AI Searchì— ì €ì¥í•œë‹¤.\n\n::: {#3f1dc3be .cell execution_count=17}\n``` {.python .cell-code}\nfrom langchain_community.vectorstores.azuresearch import AzureSearch\n\n# Azure Search VectorStore ì´ˆê¸°í™”\nvector_store = AzureSearch(\n    azure_search_endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n    azure_search_key=os.getenv(\"AZURE_SEARCH_API_KEY\"),\n    index_name=\"rag-embeddings\",\n    embedding_function=embeddings.embed_query\n)\n\n# ë¬¸ì„œ ì¶”ê°€ (ìë™ ì„ë² ë”©)\nfrom langchain_core.documents import Document\n\ndocuments = [\n    Document(page_content=\"AzureëŠ” Microsoftì˜ í´ë¼ìš°ë“œ í”Œë«í¼ì´ë‹¤.\", metadata={\"source\": \"doc1\"}),\n    Document(page_content=\"RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ì´ë‹¤.\", metadata={\"source\": \"doc2\"}),\n    Document(page_content=\"ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤.\", metadata={\"source\": \"doc3\"})\n]\n\n# ë¬¸ì„œ ì¶”ê°€ (ì„ë² ë”© ìë™ ìƒì„± ë° ì—…ë¡œë“œ)\nvector_store.add_documents(documents)\nprint(f\"{len(documents)}ê°œ ë¬¸ì„œê°€ Azure AI Searchì— ì¶”ê°€ë˜ì—ˆë‹¤.\")\n```\n:::\n\n\n## ëª¨ë‹ˆí„°ë§\n\n### ì„ë² ë”© í’ˆì§ˆ í™•ì¸\n\n::: {#f62b2536 .cell execution_count=18}\n``` {.python .cell-code}\ndef check_embedding_quality(embeddings_list):\n    \"\"\"ì„ë² ë”© í’ˆì§ˆ ë©”íŠ¸ë¦­\"\"\"\n    if not embeddings_list:\n        return None\n    \n    # ë²¡í„° ê¸¸ì´ (L2 norm)\n    norms = [np.linalg.norm(emb) for emb in embeddings_list]\n    \n    # ì°¨ì›ë³„ í†µê³„\n    embeddings_array = np.array(embeddings_list)\n    \n    metrics = {\n        \"count\": len(embeddings_list),\n        \"dimensions\": len(embeddings_list[0]),\n        \"norm_mean\": np.mean(norms),\n        \"norm_std\": np.std(norms),\n        \"value_mean\": np.mean(embeddings_array),\n        \"value_std\": np.std(embeddings_array)\n    }\n    \n    return metrics\n\n# ì‚¬ìš© ì˜ˆì‹œ\nsample_texts = [\"Azure\", \"OpenAI\", \"RAG\", \"Embeddings\"]\nsample_embeddings = embeddings.embed_documents(sample_texts)\n\nquality = check_embedding_quality(sample_embeddings)\nprint(\"ì„ë² ë”© í’ˆì§ˆ ë©”íŠ¸ë¦­:\")\nfor key, value in quality.items():\n    print(f\"- {key}: {value}\")\n```\n:::\n\n\n## ë¬¸ì œ í•´ê²°\n\n### ì¼ë°˜ì ì¸ ì˜¤ë¥˜\n\n**1. RateLimitError: ìš”ì²­ ì œí•œ ì´ˆê³¼**\n```python\n# í•´ê²°: ì¬ì‹œë„ ë¡œì§ êµ¬í˜„\nfrom tenacity import retry, stop_after_attempt, wait_exponential\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\ndef embed_with_retry(text):\n    return embeddings.embed_query(text)\n\n# ì‚¬ìš©\nresult = embed_with_retry(\"í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\")\n```\n\n**2. InvalidRequestError: í† í° ì´ˆê³¼**\n```python\n# í•´ê²°: í…ìŠ¤íŠ¸ ìë¥´ê¸° (ìµœëŒ€ 8,191 í† í°)\ndef truncate_text(text, max_tokens=8000):\n    encoding = tiktoken.get_encoding(\"cl100k_base\")\n    tokens = encoding.encode(text)\n    \n    if len(tokens) > max_tokens:\n        tokens = tokens[:max_tokens]\n        text = encoding.decode(tokens)\n    \n    return text\n\nlong_text = \"...\" * 10000\nsafe_text = truncate_text(long_text)\nembedding = embeddings.embed_query(safe_text)\n```\n\n## ì°¸ê³  ìë£Œ\n\n### ê³µì‹ ë¬¸ì„œ\n- [Azure OpenAI Embeddings](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/understand-embeddings)\n- [text-embedding-3 ëª¨ë¸](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#embeddings-models)\n- [Python SDK ì°¸ì¡°](https://learn.microsoft.com/en-us/python/api/overview/azure/openai-readme)\n\n### ë²¤ì¹˜ë§ˆí¬\n- [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) - ì„ë² ë”© ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n\n## ë‹¤ìŒ ë‹¨ê³„\n\nì„ë² ë”© ìƒì„±ì´ ì™„ë£Œë˜ì—ˆë‹¤ë©´, ì´ì œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì:\n\nğŸ‘‰ [04-Azure-AI-Search-Integration.qmd](./04-Azure-AI-Search-Integration.qmd) - Azure AI Searchì™€ RAG ì‹œìŠ¤í…œ í†µí•©\n\n",
    "supporting": [
      "03-Azure-OpenAI-Embeddings_files"
    ],
    "filters": [],
    "includes": {}
  }
}