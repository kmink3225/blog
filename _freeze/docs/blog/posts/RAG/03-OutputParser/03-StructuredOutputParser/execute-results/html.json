{
  "hash": "692725f0a9ba692be325f187439afe3c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"StructuredOutputParser\"\nsubtitle: 출력 파싱\ndescription: |\n  LLM 출력을 구조화된 데이터로 변환하는 다양한 파서를 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\nStructuredOutputParser는 LLM에 대한 답변을 `dict` 형식으로 구성하고, key/value 쌍으로 여러 필드를 반환하고자 할 때 유용하게 사용할 수 있습니다. \n\n## 장점\nPydantic/JSON 파서가 더 강력하다는 평가를 받지만, StructuredOutputParser는 로컬 모델과 같은 덜 강력한 모델에서도 유용합니다. 이는 GPT나 Claude 모델보다 인텔리전스가 낮은(즉, parameter 수가 적은) 모델에서 특히 효과적입니다. \n\n## 참고 사항\n로컬 모델의 경우 `Pydantic` 파서가 동작하지 않는 상황이 빈번하게 발생할 수 있습니다. 이러한 경우, 대안으로 StructuredOutputParser를 사용하는 것이 좋은 해결책이 될 수 있습니다.\n\n::: {#5b1f02f5 .cell execution_count=1}\n``` {.python .cell-code}\nfrom dotenv import load_dotenv\n\nload_dotenv()\n```\n:::\n\n\n::: {#d2e64033 .cell execution_count=2}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH03-OutputParser\")\n```\n:::\n\n\n::: {#7b265b37 .cell execution_count=3}\n``` {.python .cell-code}\nfrom langchain.output_parsers import ResponseSchema, StructuredOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n```\n:::\n\n\n- `ResponseSchema` 클래스를 사용하여 사용자의 질문에 대한 답변과 사용된 소스(웹사이트)에 대한 설명을 포함하는 응답 스키마를 정의합니다.\n- `StructuredOutputParser`를 `response_schemas`를 사용하여 초기화하여, 정의된 응답 스키마에 따라 출력을 구조화합니다.\n\n::: {#15c0be25 .cell execution_count=4}\n``` {.python .cell-code}\n# 사용자의 질문에 대한 답변\nresponse_schemas = [\n    ResponseSchema(name=\"answer\", description=\"사용자의 질문에 대한 답변\"),\n    ResponseSchema(\n        name=\"source\",\n        description=\"사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.\",\n    ),\n]\n# 응답 스키마를 기반으로 한 구조화된 출력 파서 초기화\noutput_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n```\n:::\n\n\n이제 응답이 어떻게 포맷되어야 하는지에 대한 지시사항이 포함된 문자열을 받게 되며(schemas), 정의된 스키마를 프롬프트에 삽입합니다.\n\n::: {#75c7df41 .cell execution_count=5}\n``` {.python .cell-code}\n# 출력 형식 지시사항을 파싱합니다.\nformat_instructions = output_parser.get_format_instructions()\nprompt = PromptTemplate(\n    # 사용자의 질문에 최대한 답변하도록 템플릿을 설정합니다.\n    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n    # 입력 변수로 'question'을 사용합니다.\n    input_variables=[\"question\"],\n    # 부분 변수로 'format_instructions'을 사용합니다.\n    partial_variables={\"format_instructions\": format_instructions},\n)\n```\n:::\n\n\n::: {#f51d815c .cell execution_count=6}\n``` {.python .cell-code}\nmodel = ChatOpenAI(temperature=0)  # ChatOpenAI 모델 초기화\nchain = prompt | model | output_parser  # 프롬프트, 모델, 출력 파서를 연결\n```\n:::\n\n\n::: {#8c396b83 .cell execution_count=7}\n``` {.python .cell-code}\n# 대한민국의 수도가 무엇인지 질문합니다.\nchain.invoke({\"question\": \"대한민국의 수도는 어디인가요?\"})\n```\n:::\n\n\n`chain.stream` 메소드를 사용하여 \"세종대왕의 업적은 무엇인가요?\" 라는 질문에 대한 스트림 응답을 받습니다.\n\n::: {#1b42787f .cell execution_count=8}\n``` {.python .cell-code}\nfor s in chain.stream({\"question\": \"세종대왕의 업적은 무엇인가요?\"}):\n    # 스트리밍 출력\n    print(s)\n```\n:::\n\n\n",
    "supporting": [
      "03-StructuredOutputParser_files"
    ],
    "filters": [],
    "includes": {}
  }
}