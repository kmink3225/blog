{
  "hash": "fe1557746e65b8fc68f5b40ba6a31560",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Llama-cpp\"\nsubtitle: 임베딩\ndescription: |\n  텍스트를 벡터로 변환하는 다양한 임베딩 모델을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\n이 노트북은 LangChain 내에서 Llama-cpp 임베딩을 사용하는 방법에 대해 설명합니다.\n\n\nllama-cpp-python 패키지를 최신 버전으로 업그레이드하는 pip 명령어입니다.\n\n::: {#30d791d3 .cell execution_count=1}\n``` {.python .cell-code}\n# API KEY를 환경변수로 관리하기 위한 설정 파일\nfrom dotenv import load_dotenv\n\n# API KEY 정보로드\nload_dotenv()\n```\n:::\n\n\n::: {#26210142 .cell execution_count=2}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH08-Embeddings\")\n```\n:::\n\n\n::: {#c7348f3f .cell execution_count=3}\n``` {.python .cell-code}\n# 설치\n# !pip install -qU llama-cpp-python\n```\n:::\n\n\n- `LlamaCppEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.\n\n`LlamaCppEmbeddings`는 LLaMA 모델을 사용하여 텍스트 임베딩을 생성하는 클래스입니다. 이 클래스는 LangChain 커뮤니티에서 제공하는 확장 기능 중 하나로, C++로 구현된 LLaMA 모델을 활용하여 빠르고 효율적인 임베딩 생성을 지원합니다.\n\n::: {#6c3d2215 .cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain_community.embeddings import LlamaCppEmbeddings\n```\n:::\n\n\n- `LlamaCppEmbeddings` 클래스를 사용하여 임베딩 모델을 초기화합니다.\n- `model_path` 매개변수를 통해 사전 학습된 LLaMA 모델 파일(\"ggml-model-q4_0.bin\")의 경로를 지정합니다.\n\n::: {#c07ecc79 .cell execution_count=5}\n``` {.python .cell-code}\n# LlamaCpp 임베딩 모델을 초기화하고, 모델 경로를 지정합니다.\nllama = LlamaCppEmbeddings(model_path=\"/path/to/model/ggml-model-q4_0.bin\")\n```\n:::\n\n\n- `text` 변수에 \"This is a test document.\"라는 문자열을 할당합니다.\n\n::: {#7d07c157 .cell execution_count=6}\n``` {.python .cell-code}\ntext = \"This is a test document.\"  # 테스트용 문서 텍스트를 정의합니다.\n```\n:::\n\n\n`llama.embed_query(text)`는 입력된 텍스트를 임베딩 벡터로 변환하는 함수입니다.\n\n- `text` 매개변수로 전달된 텍스트를 임베딩 모델에 입력하여 벡터 표현을 생성합니다.\n- 생성된 임베딩 벡터는 `query_result` 변수에 저장됩니다.\n\n이 함수는 텍스트를 벡터 공간에 매핑하여 의미적 유사성을 계산하거나 검색에 활용할 수 있는 벡터 표현을 얻는 데 사용됩니다.\n\n::: {#54b80f64 .cell execution_count=7}\n``` {.python .cell-code}\n# 텍스트를 임베딩하여 쿼리 결과를 생성합니다.\nquery_result = llama.embed_query(text)\n```\n:::\n\n\n`llama.embed_documents([text])` 함수를 호출하여 `text` 문서를 임베딩합니다.\n\n- `text` 문서를 리스트 형태로 `embed_documents` 함수에 전달합니다.\n- `llama` 객체의 `embed_documents` 함수는 문서를 벡터 표현으로 변환합니다.\n- 변환된 벡터 표현은 `doc_result` 변수에 저장됩니다.\n\n::: {#9138dada .cell execution_count=8}\n``` {.python .cell-code}\n# 텍스트를 임베딩하여 문서 결과를 생성합니다.\ndoc_result = llama.embed_documents([text])\n```\n:::\n\n\n",
    "supporting": [
      "06-llamacpp_files"
    ],
    "filters": [],
    "includes": {}
  }
}