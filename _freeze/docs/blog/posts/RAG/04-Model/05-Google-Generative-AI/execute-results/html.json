{
  "hash": "85d29d8600c5a1e5eb066e1fa970fc2d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Google Generative AI (Gemini)\"\nsubtitle: Google Gemini 모델 활용 가이드\ndescription: |\n  Google AI의 Gemini 및 Gemini-Vision 모델을 LangChain에서 활용하는 방법을 다룬다.\n  langchain-google-genai 패키지를 통한 Google 생성 모델 연동 방법을 설명한다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\nGoogle AI의 `gemini`와 `gemini-vision` 모델뿐만 아니라 다른 생성 모델에 접근하려면 [langchain-google-genai](https://pypi.org/project/langchain-google-genai/) 통합 패키지의 `ChatGoogleGenerativeAI` 클래스를 사용하면 됩니다.\n\n::: {#59728d64 .cell execution_count=1}\n``` {.python .cell-code}\n# !pip install -qU langchain-google-genai\n```\n:::\n\n\n### API KEY 발급받기\n\n- [링크](https://makersuite.google.com/app/apikey?hl=ko) 에서 API KEY를 발급받아주세요.\n- 사용자의 Google API 키를 환경 변수 `GOOGLE_API_KEY`로 설정합니다.\n\n::: {#1a066ac4 .cell execution_count=2}\n``` {.python .cell-code}\nfrom dotenv import load_dotenv\n\nload_dotenv()\n```\n:::\n\n\n::: {#e2a7bfb1 .cell execution_count=3}\n``` {.python .cell-code}\n# LangSmith 추적을 설정합니다. https://smith.langchain.com\n# !pip install langchain-teddynote\nfrom langchain_teddynote import logging\nfrom langchain_teddynote.messages import stream_response\n\n# 프로젝트 이름을 입력합니다.\nlogging.langsmith(\"CH04-Models\")\n```\n:::\n\n\nlangchain_google_genai 패키지에서 ChatGoogleGenerativeAI 클래스를 가져옵니다.\n\n- ChatGoogleGenerativeAI 클래스는 Google의 Generative AI 모델을 사용하여 대화형 AI 시스템을 구현하는 데 사용됩니다.\n- 이 클래스를 통해 사용자는 Google의 대화형 AI 모델과 상호 작용할 수 있습니다.\n- 모델과의 대화는 채팅 형식으로 이루어지며, 사용자의 입력에 따라 모델이 적절한 응답을 생성합니다.\n- ChatGoogleGenerativeAI 클래스는 LangChain 프레임워크와 통합되어 있어, 다른 LangChain 컴포넌트와 함께 사용할 수 있습니다.\n\n지원되는 모델 정보: https://ai.google.dev/gemini-api/docs/models/gemini?hl=ko\n\n::: {#72b3dad6 .cell execution_count=4}\n``` {.python .cell-code}\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# ChatGoogleGenerativeAI 언어 모델을 초기화합니다.\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n\n# 프롬프트를 전달하여 결과를 생성합니다.\nanswer = llm.stream(\"자연어처리에 대해서 간략히 설명해 줘\")\n\n# 결과를 출력합니다.\nstream_response(answer)\n```\n:::\n\n\n::: {#6d33be9b .cell execution_count=5}\n``` {.python .cell-code}\nfrom langchain_core.prompts import PromptTemplate\n\n# ChatGoogleGenerativeAI 언어 모델을 초기화합니다.\nmodel = ChatGoogleGenerativeAI(\n    model=\"gemini-1.5-flash-latest\",  # 사용할 모델을 지정합니다.\n)\n\n# 프롬프트를 생성합니다.\nprompt = PromptTemplate.from_template(\n    \"예/아니오 질문에 대답하세요. {question}는 과일입니까?\"\n)\n\n# 체인을 생성합니다.\nchain = prompt | model\n\n# 결과를 출력합니다.\nstream_response(chain.stream({\"question\": \"사과\"}))\n```\n:::\n\n\n## Safety Settings\n\nGemini 모델에는 기본 안전 설정(Satety Settings) 이 있지만, 이를 재정의할 수 있습니다.\n\n만약 모델로부터 많은 \"Safety Warnings\"를 받고 있다면, 모델의 `safety_settings` 속성을 조정해 볼 수 있습니다.\n\nGoogle의 [Safety Setting Types](https://ai.google.dev/api/python/google/generativeai/types/SafetySettingDict) 문서에서는 사용 가능한 카테고리와 임계값에 대한 열거형 정보를 제공합니다.\n\n이 문서에는 콘텐츠 필터링 및 안전 설정과 관련된 다양한 카테고리와 해당 임계값이 정의되어 있어, 개발자들이 생성형 AI 모델을 활용할 때 적절한 안전 설정을 선택하고 적용하는 데 도움을 줍니다.\n\n이를 통해 개발자들은 모델이 생성하는 콘텐츠의 안전성과 적절성을 보장하고, 사용자에게 유해하거나 부적절한 내용이 노출되는 것을 방지할 수 있습니다.\n\n::: {#81b84b6f .cell execution_count=6}\n``` {.python .cell-code}\nfrom langchain_google_genai import (\n    ChatGoogleGenerativeAI,\n    HarmBlockThreshold,\n    HarmCategory,\n)\n\nllm = ChatGoogleGenerativeAI(\n    # 사용할 모델을 \"gemini-pro\"로 지정합니다.\n    model=\"gemini-1.5-pro-latest\",\n    safety_settings={\n        # 위험한 콘텐츠에 대한 차단 임계값을 설정합니다.\n        # 이 경우 위험한 콘텐츠를 차단하지 않도록 설정되어 있습니다. (그럼에도 기본적인 차단이 있을 수 있습니다.)\n        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n    },\n)\n```\n:::\n\n\n## Batch 단위 실행\n\n::: {#ed510a86 .cell execution_count=7}\n``` {.python .cell-code}\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nllm = ChatGoogleGenerativeAI(\n    # 사용할 모델을 \"gemini-pro\"로 지정합니다.\n    model=\"gemini-1.5-pro-latest\",\n)\n\nresults = llm.batch(\n    [\n        \"대한민국의 수도는?\",\n        \"대한민국의 주요 관광지 5곳을 나열하세요\",\n    ]\n)\n\nfor res in results:\n    # 각 결과의 내용을 출력합니다.\n    print(res.content)\n```\n:::\n\n\n## Multimodal 모델\n\n`langchain-teddynote` 에서 구현한 멀티모달 모델에 `gemini-1.5-pro` 모델을 활용하여 이미지를 텍스트로 변환 가능합니다.\n\n::: {#9f7def13 .cell execution_count=8}\n``` {.python .cell-code}\nfrom langchain_teddynote.models import MultiModal\nfrom langchain_teddynote.messages import stream_response\n\n# 객체 생성\ngemini = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n\nsystem_prompt = (\n    \"당신은 시인입니다. 당신의 임무는 주어진 이미지를 가지고 시를 작성하는 것입니다.\"\n)\n\nuser_prompt = \"다음의 이미지에 대한 시를 작성해주세요.\"\n\n# 멀티모달 객체 생성\nmultimodal_gemini = MultiModal(\n    llm, system_prompt=system_prompt, user_prompt=user_prompt\n)\n```\n:::\n\n\n::: {#8a85a842 .cell execution_count=9}\n``` {.python .cell-code}\n# 샘플 이미지 경로(파일의 경로, URL 등)를 지정합니다.\nIMAGE_URL = \"images/jeju-beach.jpg\"\n\n# 이미지 파일로 부터 질의\nanswer = multimodal_gemini.stream(IMAGE_URL)\n\n# 스트리밍 방식으로 각 토큰을 출력합니다. (실시간 출력)\nstream_response(answer)\n```\n:::\n\n\n",
    "supporting": [
      "05-Google-Generative-AI_files"
    ],
    "filters": [],
    "includes": {}
  }
}