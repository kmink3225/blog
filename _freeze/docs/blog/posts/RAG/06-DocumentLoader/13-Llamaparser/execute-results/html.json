{
  "hash": "1a5c7cb66028b68efd569f9cd1ecb8e8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"LlamaParser\"\nsubtitle: 문서 로더\ndescription: |\n  다양한 형식의 문서를 LangChain으로 로드하는 방법을 다룬다.\ncategories:\n  - AI\n  - RAG\n  - LangChain\nauthor: Kwangmin Kim\ndate: 12/31/2024\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\nexecute:\n    eval: false\n---\n\nLlamaParse는 LlamaIndex에서 개발한 문서 파싱 서비스로, 대규모 언어 모델(LLM)을 위해 특별히 설계되었습니다. 주요 특징은 다음과 같습니다:\n\n- PDF, Word, PowerPoint, Excel 등 다양한 문서 형식 지원\n- 자연어 지시를 통한 맞춤형 출력 형식 제공\n- 복잡한 표와 이미지 추출 기능\n- JSON 모드 지원\n- 외국어 지원\n\nLlamaParse는 독립형 API로 제공되며, LlamaCloud 플랫폼의 일부로도 사용 가능합니다. 이 서비스는 문서를 파싱하고 정제하여 검색 증강 생성(RAG) 등 LLM 기반 애플리케이션의 성능을 향상시키는 것을 목표로 합니다.\n\n사용자는 무료로 하루 1,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보할 수 있습니다. LlamaParse는 현재 공개 베타 버전으로 제공되고 있으며, 지속적으로 기능이 확장되고 있습니다.\n\n- 링크: https://cloud.llamaindex.ai\n\n**API 키 설정**\n- API 키를 발급 후 `.env` 파일에 `LLAMA_CLOUD_API_KEY` 에 설정합니다.\n\n::: {#5d66f873 .cell execution_count=1}\n``` {.python .cell-code}\n# 설치\n# !pip install llama-index-core llama-parse llama-index-readers-file python-dotenv\n```\n:::\n\n\n::: {#48a3cc33 .cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport nest_asyncio\nfrom dotenv import load_dotenv\n\nload_dotenv()\nnest_asyncio.apply()\n```\n:::\n\n\n기본 파서 적용\n\n::: {#bf71405a .cell execution_count=3}\n``` {.python .cell-code}\nfrom llama_parse import LlamaParse\nfrom llama_index.core import SimpleDirectoryReader\n\n# 파서 설정\nparser = LlamaParse(\n    result_type=\"markdown\",  # \"markdown\"과 \"text\" 사용 가능\n    num_workers=8,  # worker 수 (기본값: 4)\n    verbose=True,\n    language=\"ko\",\n)\n\n# SimpleDirectoryReader를 사용하여 파일 파싱\nfile_extractor = {\".pdf\": parser}\n\n# LlamaParse로 파일 파싱\ndocuments = SimpleDirectoryReader(\n    input_files=[\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n    file_extractor=file_extractor,\n).load_data()\n```\n:::\n\n\n::: {#c03ed9c0 .cell execution_count=4}\n``` {.python .cell-code}\n# 페이지 수 확인\nlen(documents)\n```\n:::\n\n\n::: {#7e157796 .cell execution_count=5}\n``` {.python .cell-code}\ndocuments[0]\n```\n:::\n\n\nLlamaIndex -> LangChain Document 로 변환\n\n::: {#691e1901 .cell execution_count=6}\n``` {.python .cell-code}\n# 랭체인 도큐먼트로 변환\ndocs = [doc.to_langchain_format() for doc in documents]\n```\n:::\n\n\n::: {#f0d5a052 .cell execution_count=7}\n``` {.python .cell-code}\nprint(docs[5].page_content)\n```\n:::\n\n\n::: {#b11cb212 .cell execution_count=8}\n``` {.python .cell-code}\n# metadata 출력\ndocs[0].metadata\n```\n:::\n\n\n## MultiModal Model 로 파싱\n\n**주요 파라미터**\n\n- `use_vendor_multimodal_model`: 멀티모달 모델 사용 여부를 지정합니다. `True`로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.\n\n- `vendor_multimodal_model_name`: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 \"openai-gpt4o\"를 사용하고 있습니다.\n\n- `vendor_multimodal_api_key`: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.\n\n- `result_type`: 파싱 결과의 형식을 지정합니다. \"markdown\"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.\n\n- `language`: 파싱할 문서의 언어를 지정합니다. \"ko\"로 설정되어 한국어로 처리됩니다.\n\n- `skip_diagonal_text`: 대각선 텍스트를 건너뛸지 여부를 결정합니다.\n\n- `page_separator`: 페이지 구분자를 지정할 수 있습니다.\n\n::: {#2c18af35 .cell execution_count=9}\n``` {.python .cell-code}\ndocuments = LlamaParse(\n    use_vendor_multimodal_model=True,\n    vendor_multimodal_model_name=\"openai-gpt4o\",\n    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n    result_type=\"markdown\",\n    language=\"ko\",\n    # skip_diagonal_text=True,\n    # page_separator=\"\\n=================\\n\"\n)\n```\n:::\n\n\n::: {#e547f036 .cell execution_count=10}\n``` {.python .cell-code}\n# parsing 된 결과\nparsed_docs = documents.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n```\n:::\n\n\n::: {#662a6e85 .cell execution_count=11}\n``` {.python .cell-code}\n# langchain 도큐먼트로 변환\ndocs = [doc.to_langchain_format() for doc in parsed_docs]\n```\n:::\n\n\n::: {#6be23130 .cell execution_count=12}\n``` {.python .cell-code}\nprint(docs[18].page_content)\n```\n:::\n\n\n아래와 같이 사용자 정의 인스트럭션을 지정하는 것도 가능합니다.\n\n::: {#9c07c65c .cell execution_count=13}\n``` {.python .cell-code}\n# parsing instruction 을 지정합니다.\nparsing_instruction = (\n    \"You are parsing a brief of AI Report. Please extract tables in markdown format.\"\n)\n\n# LlamaParse 설정\nparser = LlamaParse(\n    use_vendor_multimodal_model=True,\n    vendor_multimodal_model_name=\"openai-gpt4o\",\n    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n    result_type=\"markdown\",\n    language=\"ko\",\n    parsing_instruction=parsing_instruction,\n)\n\n# parsing 된 결과\nparsed_docs = parser.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n\n# langchain 도큐먼트로 변환\ndocs = [doc.to_langchain_format() for doc in parsed_docs]\n```\n:::\n\n\n::: {#f7493544 .cell execution_count=14}\n``` {.python .cell-code}\n# markdown 형식으로 추출된 테이블 확인\nprint(docs[-2].page_content)\n```\n:::\n\n\n",
    "supporting": [
      "13-Llamaparser_files"
    ],
    "filters": [],
    "includes": {}
  }
}