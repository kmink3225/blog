<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko" xml:lang="ko"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kwangmin Kim">
<meta name="description" content="OpenAI, Anthropic (Claude), Perplexity, Together AI, Cohere, Upstage 등 주요 Large Language Model (LLM) 제공사의 특징과 파이썬 기반 연동 코드 예시를 포함하는 모델 활용 가이드.">

<title>다양한 LLM 모델 활용 및 비교 – Kwangmin Kim</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete-preset-algolia.umd.js"></script>
<meta name="quarto:offset" content="../../../../../">
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "algolia": {
    "application-id": "DUOR1DRC9D",
    "search-only-api-key": "f264da5dea684ffb9e9b4a574af3ed61",
    "index-name": "prod_QUARTO",
    "analytics-events": true,
    "show-logo": true,
    "libDir": "site_libs"
  },
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "검색"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.5.1/dist/algoliasearch-lite.umd.js"></script>


<script type="text/javascript">
var ALGOLIA_INSIGHTS_SRC = "https://cdn.jsdelivr.net/npm/search-insights/dist/search-insights.iife.min.js";
!function(e,a,t,n,s,i,c){e.AlgoliaAnalyticsObject=s,e[s]=e[s]||function(){
(e[s].queue=e[s].queue||[]).push(arguments)},i=a.createElement(t),c=a.getElementsByTagName(t)[0],
i.async=1,i.src=n,c.parentNode.insertBefore(i,c)
}(window,document,"script",ALGOLIA_INSIGHTS_SRC,"aa");
</script>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@algolia/autocomplete-plugin-algolia-insights">

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6W0EKFMWBN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-6W0EKFMWBN', { 'anonymize_ip': true});
</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: black;
      }

      .quarto-title-block .quarto-title-banner {
        color: black;
background: #EDF3F9;
      }
</style>
<style>
.custom-footer { 
  text-align: center; 
  font-size: 0.8em; 
  color: #666; 
  margin-top: 2rem; 
}
</style>


<link rel="stylesheet" href="../../../../../styles.css">
<meta property="og:title" content="다양한 LLM 모델 활용 및 비교 – Kwangmin Kim">
<meta property="og:description" content="다양한 LLM 제공자와 모델 활용법을 다룬다.">
<meta property="og:site_name" content="Kwangmin Kim">
<meta name="twitter:title" content="다양한 LLM 모델 활용 및 비교 – Kwangmin Kim">
<meta name="twitter:description" content="다양한 LLM 제공자와 모델 활용법을 다룬다.">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../.././images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">Kwangmin Kim</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="검색"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../about.html"> 
<span class="menu-text">Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kmink3225"> <i class="bi bi-github" role="img" aria-label="Github">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/kwangmin-kim-a5241b200/"> <i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="다크 모드 전환"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">다양한 LLM 모델 활용 및 비교</h1>
            <p class="subtitle lead">OpenAI, Anthropic, Perplexity 등 주요 LLM 플랫폼 및 모델 상세 분석</p>
                  <div>
        <div class="description">
          <p>OpenAI, Anthropic (Claude), Perplexity, Together AI, Cohere, Upstage 등 주요 Large Language Model (LLM) 제공사의 특징과 파이썬 기반 연동 코드 예시를 포함하는 모델 활용 가이드.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">RAG</div>
                <div class="quarto-category">LangChain</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      <div>
      <div class="quarto-title-meta-heading">저자</div>
      <div class="quarto-title-meta-contents">
               <p>Kwangmin Kim </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">공개</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2025년 03월 15일</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#llm-model" id="toc-llm-model" class="nav-link active" data-scroll-target="#llm-model"><span class="header-section-number">1</span> LLM Model</a></li>
  <li><a href="#다양한-llm-모델-활용" id="toc-다양한-llm-모델-활용" class="nav-link" data-scroll-target="#다양한-llm-모델-활용"><span class="header-section-number">2</span> 다양한 LLM 모델 활용</a>
  <ul class="collapse">
  <li><a href="#openai" id="toc-openai" class="nav-link" data-scroll-target="#openai"><span class="header-section-number">2.1</span> OpenAI</a>
  <ul class="collapse">
  <li><a href="#개요" id="toc-개요" class="nav-link" data-scroll-target="#개요"><span class="header-section-number">2.1.1</span> 개요</a></li>
  <li><a href="#옵션-상세-설명" id="toc-옵션-상세-설명" class="nav-link" data-scroll-target="#옵션-상세-설명"><span class="header-section-number">2.1.2</span> 옵션 상세 설명</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#anthropic" id="toc-anthropic" class="nav-link" data-scroll-target="#anthropic"><span class="header-section-number">3</span> Anthropic</a>
  <ul class="collapse">
  <li><a href="#claude" id="toc-claude" class="nav-link" data-scroll-target="#claude"><span class="header-section-number">3.1</span> Claude</a></li>
  </ul></li>
  <li><a href="#perplexity" id="toc-perplexity" class="nav-link" data-scroll-target="#perplexity"><span class="header-section-number">4</span> Perplexity</a>
  <ul class="collapse">
  <li><a href="#perplexity-pro-정확한-특징" id="toc-perplexity-pro-정확한-특징" class="nav-link" data-scroll-target="#perplexity-pro-정확한-특징"><span class="header-section-number">4.1</span> Perplexity Pro 정확한 특징</a></li>
  <li><a href="#perplexity-api-사용-방법" id="toc-perplexity-api-사용-방법" class="nav-link" data-scroll-target="#perplexity-api-사용-방법"><span class="header-section-number">4.2</span> Perplexity API 사용 방법</a></li>
  <li><a href="#지원-모델" id="toc-지원-모델" class="nav-link" data-scroll-target="#지원-모델"><span class="header-section-number">4.3</span> 지원 모델</a></li>
  <li><a href="#chatperplexity-매개변수" id="toc-chatperplexity-매개변수" class="nav-link" data-scroll-target="#chatperplexity-매개변수"><span class="header-section-number">4.4</span> ChatPerplexity 매개변수</a></li>
  <li><a href="#together-ai" id="toc-together-ai" class="nav-link" data-scroll-target="#together-ai"><span class="header-section-number">4.5</span> Together AI</a>
  <ul class="collapse">
  <li><a href="#주요-제품과-특징" id="toc-주요-제품과-특징" class="nav-link" data-scroll-target="#주요-제품과-특징"><span class="header-section-number">4.5.1</span> 주요 제품과 특징</a></li>
  <li><a href="#기술적-특징" id="toc-기술적-특징" class="nav-link" data-scroll-target="#기술적-특징"><span class="header-section-number">4.5.2</span> 기술적 특징</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#cohere" id="toc-cohere" class="nav-link" data-scroll-target="#cohere"><span class="header-section-number">5</span> Cohere</a>
  <ul class="collapse">
  <li><a href="#cohere-개요" id="toc-cohere-개요" class="nav-link" data-scroll-target="#cohere-개요"><span class="header-section-number">5.1</span> Cohere 개요</a></li>
  <li><a href="#주요-제품" id="toc-주요-제품" class="nav-link" data-scroll-target="#주요-제품"><span class="header-section-number">5.2</span> 주요 제품</a>
  <ul class="collapse">
  <li><a href="#command-r" id="toc-command-r" class="nav-link" data-scroll-target="#command-r"><span class="header-section-number">5.2.1</span> Command R+</a></li>
  <li><a href="#aya" id="toc-aya" class="nav-link" data-scroll-target="#aya"><span class="header-section-number">5.2.2</span> Aya</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#upstage" id="toc-upstage" class="nav-link" data-scroll-target="#upstage"><span class="header-section-number">6</span> Upstage</a>
  <ul class="collapse">
  <li><a href="#주요-제품-및-기술" id="toc-주요-제품-및-기술" class="nav-link" data-scroll-target="#주요-제품-및-기술"><span class="header-section-number">6.1</span> 주요 제품 및 기술</a>
  <ul class="collapse">
  <li><a href="#solar-llm" id="toc-solar-llm" class="nav-link" data-scroll-target="#solar-llm"><span class="header-section-number">6.1.1</span> Solar LLM</a></li>
  <li><a href="#document-ai-pack" id="toc-document-ai-pack" class="nav-link" data-scroll-target="#document-ai-pack"><span class="header-section-number">6.1.2</span> Document AI Pack</a></li>
  <li><a href="#askup-seargest" id="toc-askup-seargest" class="nav-link" data-scroll-target="#askup-seargest"><span class="header-section-number">6.1.3</span> AskUp Seargest</a></li>
  </ul></li>
  <li><a href="#api-키-발급" id="toc-api-키-발급" class="nav-link" data-scroll-target="#api-키-발급"><span class="header-section-number">6.2</span> API 키 발급</a></li>
  <li><a href="#xionic" id="toc-xionic" class="nav-link" data-scroll-target="#xionic"><span class="header-section-number">6.3</span> Xionic</a>
  <ul class="collapse">
  <li><a href="#주요-제품-1" id="toc-주요-제품-1" class="nav-link" data-scroll-target="#주요-제품-1"><span class="header-section-number">6.3.1</span> 주요 제품</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#logickor" id="toc-logickor" class="nav-link" data-scroll-target="#logickor"><span class="header-section-number">7</span> LogicKor</a>
  <ul class="collapse">
  <li><a href="#목적" id="toc-목적" class="nav-link" data-scroll-target="#목적"><span class="header-section-number">7.1</span> 목적</a></li>
  <li><a href="#평가-영역" id="toc-평가-영역" class="nav-link" data-scroll-target="#평가-영역"><span class="header-section-number">7.2</span> 평가 영역</a></li>
  <li><a href="#주요-특징-2" id="toc-주요-특징-2" class="nav-link" data-scroll-target="#주요-특징-2"><span class="header-section-number">7.3</span> 주요 특징</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">





<section id="llm-model" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> LLM Model</h1>
<ul>
<li>모델 혹은 LLM(Large Language Model) 단계는 이전 프롬프트 단계에서 구성된 입력을 기반으로 대규모 언어 모델을 활용하여 응답을 생성하는 과정</li>
<li>RAG 시스템의 핵심적인 부분: 언어 모델의 능력을 최대한 활용하여 사용자의 질문에 대해 정확하고 자연스러운 답변을 생성</li>
<li>LLM의 필요성
<ul>
<li>사용자 의도 이해: LLM은 다양한 언어의 구조와 의미를 깊이 이해하고 있으며, 이를 바탕으로 복잡한 질문에 답할 수 있다.</li>
<li>자연어 이해(NLU)와 자연어 생성(NLG) 능력이 결합되어, 보다 자연스럽고 유익한 응답을 제공</li>
</ul></li>
<li>문맥적 적응성
<ul>
<li>LLM은 주어진 문맥을 고려하여 응답을 생성</li>
<li>이는 사용자의 질문에 더욱 정확하게 대응</li>
<li>사전학습된 지식외 사용자가 제공한 정보에 기반한 답변을 문맥을 참고하여 답변</li>
</ul></li>
<li>LLM의 중요성
<ul>
<li>LLM 단계는 사용자의 질문에 대한 답변의 질과 자연스러움을 결정짓는 핵심 요소</li>
<li>이 단계에서 LLM은 지금까지의 모든 데이터와 정보를 종합하여 사용자의 질문에 최적화된 답변을 생성</li>
<li>LLM의 성능은 RAG 시스템의 전체적인 성능과 사용자 만족도에 직접적으로 영향</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># 단계 7: 언어모델(LLM) 생성</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co"># OpenAI 의 GPT-4o 모델 을 생성합니다.</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>llm <span class="op">=</span> ChatOpenAI(model_name<span class="op">=</span><span class="st">"gpt-4o"</span>)</span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co"># Anthropic 의 Claude 모델 을 생성합니다.</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">from</span> langchain_anthropic <span class="im">import</span> ChatAnthropic</span>
<span id="cb1-7"><a href="#cb1-7"></a>llm <span class="op">=</span> ChatAnthropic(model<span class="op">=</span><span class="st">"claude-3-sonnet-20240229"</span>)</span>
<span id="cb1-8"><a href="#cb1-8"></a></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co"># LangChain이 지원하는 Ollama(로컬) 모델을 사용합니다.</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="im">from</span> langchain_community.chat_models <span class="im">import</span> ChatOllama</span>
<span id="cb1-11"><a href="#cb1-11"></a>llm <span class="op">=</span> ChatOllama(model<span class="op">=</span><span class="st">"llama3:8b"</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="다양한-llm-모델-활용" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 다양한 LLM 모델 활용</h1>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># API KEY를 환경변수로 관리하기 위한 설정 파일</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># API KEY 정보로드</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>load_dotenv()</span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co"># LangSmith 추적을 설정합니다. https://smith.langchain.com</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co"># !pip install langchain-teddynote</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="im">from</span> langchain_teddynote <span class="im">import</span> logging</span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="im">from</span> langchain_teddynote.messages <span class="im">import</span> stream_response</span>
<span id="cb2-11"><a href="#cb2-11"></a></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="co"># 프로젝트 이름을 입력합니다.</span></span>
<span id="cb2-13"><a href="#cb2-13"></a>logging.langsmith(<span class="st">"CH04-Models"</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="openai" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="openai"><span class="header-section-number">2.1</span> OpenAI</h2>
<section id="개요" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="개요"><span class="header-section-number">2.1.1</span> 개요</h3>
<ul>
<li>OpenAI는 채팅 전용 Large Language Model (LLM)을 제공</li>
<li>이 모델을 생성할 때 다양한 옵션을 지정할 수 있으며, 이러한 옵션들은 모델의 동작 방식에 영향</li>
</ul>
</section>
<section id="옵션-상세-설명" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="옵션-상세-설명"><span class="header-section-number">2.1.2</span> 옵션 상세 설명</h3>
<p><code>temperature</code></p>
<ul>
<li>샘플링 온도를 설정하는 옵션: 값은 0과 2 사이에서 선택, 높은 값(예: 0.8)은 출력을 더 무작위하게 만들고, 낮은 값(예: 0.2)은 출력을 더 집중되고 결정론적으로 만든다</li>
</ul>
<p><code>max_tokens</code></p>
<ul>
<li>채팅 완성에서 생성할 토큰의 최대 개수를 지정: 이 옵션은 모델이 한 번에 생성할 수 있는 텍스트의 길이를 제어</li>
</ul>
<p><code>model_name</code></p>
<ul>
<li>적용 가능한 모델을 선택하는 옵션: 더 자세한 정보는 <a href="https://platform.openai.com/docs/models">OpenAI 모델 문서</a>에서 확인</li>
</ul>
<p><strong>모델 스펙</strong></p>
<ul>
<li>링크: https://platform.openai.com/docs/models</li>
</ul>
<table class="caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 10%">
<col style="width: 16%">
<col style="width: 11%">
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Input (1M)</th>
<th>Cached Input (1M)</th>
<th>Output (1M)</th>
<th>Context Window</th>
<th>Max Output Tokens</th>
<th>Knowledge Cutoff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>gpt-4.1</td>
<td>$2.00</td>
<td>$0.50</td>
<td>$8.00</td>
<td>1,047,576</td>
<td>32,768</td>
<td>Jun 01, 2024</td>
</tr>
<tr class="even">
<td>gpt-4.1-mini</td>
<td>$0.40</td>
<td>$0.10</td>
<td>$1.60</td>
<td>1,047,576</td>
<td>32,768</td>
<td>Jun 01, 2024</td>
</tr>
<tr class="odd">
<td>gpt-4.1-nano</td>
<td>$0.10</td>
<td>$0.025</td>
<td>$0.40</td>
<td>1,047,576</td>
<td>32,768</td>
<td>Jun 01, 2024</td>
</tr>
<tr class="even">
<td>gpt-4o</td>
<td>$2.50</td>
<td>$1.25</td>
<td>$10.00</td>
<td>128,000</td>
<td>16,384</td>
<td>Oct 01, 2023</td>
</tr>
<tr class="odd">
<td>gpt-4o-mini</td>
<td>$0.15</td>
<td>$0.075</td>
<td>$0.60</td>
<td>128,000</td>
<td>16,384</td>
<td>Oct 01, 2023</td>
</tr>
<tr class="even">
<td>o1</td>
<td>$15.00</td>
<td>$7.50</td>
<td>$60.00</td>
<td>128,000</td>
<td>65,536</td>
<td>Oct 01, 2023</td>
</tr>
<tr class="odd">
<td>o1-mini</td>
<td>$1.10</td>
<td>$0.55</td>
<td>$4.40</td>
<td>128,000</td>
<td>65,536</td>
<td>Oct 01, 2023</td>
</tr>
<tr class="even">
<td>o1-pro</td>
<td>$150.00</td>
<td>–</td>
<td>$600.00</td>
<td>128,000</td>
<td>65,536</td>
<td>Oct 01, 2023</td>
</tr>
<tr class="odd">
<td>o3-mini</td>
<td>$1.10</td>
<td>$0.55</td>
<td>$4.40</td>
<td>200,000</td>
<td>100,000</td>
<td>Oct 01, 2023</td>
</tr>
<tr class="even">
<td>gpt-4.5-preview</td>
<td>$75.00</td>
<td>$37.50</td>
<td>$150.00</td>
<td>–</td>
<td>–</td>
<td>–</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="im">from</span> langchain_openai <span class="im">import</span> ChatOpenAI</span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-3"><a href="#cb3-3"></a><span class="co"># ChatOpenAI 객체를 생성합니다.</span></span>
<span id="cb3-4"><a href="#cb3-4"></a>gpt <span class="op">=</span> ChatOpenAI(</span>
<span id="cb3-5"><a href="#cb3-5"></a>    temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb3-6"><a href="#cb3-6"></a>    model_name<span class="op">=</span><span class="st">"gpt-4.1-mini"</span>,  <span class="co"># 모델명</span></span>
<span id="cb3-7"><a href="#cb3-7"></a>)</span>
<span id="cb3-8"><a href="#cb3-8"></a></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co"># 스트리밍 출력을 위하여 invoke() 대신 stream()을 사용합니다.</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>answer <span class="op">=</span> gpt.stream(<span class="st">"사랑이 뭔가요?"</span>)</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="co"># 답변 출력</span></span>
<span id="cb3-13"><a href="#cb3-13"></a><span class="im">from</span> langchain_teddynote.messages <span class="im">import</span> stream_response</span>
<span id="cb3-14"><a href="#cb3-14"></a>stream_response(answer)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>사랑은 매우 복잡하고 다양한 감정, 행동, 그리고 관계의 형태로 나타나는 개념입니다. 일반적으로 사랑은 깊은 애정과 관심, 그리고 타인에 대한 헌신을 포함합니다. 사랑은 여러 형태로 나타날 수 있으며, 그 중 몇 가지는 다음과 같습니다:

1. **로맨틱 사랑**: 두 사람 간의 깊은 정서적, 육체적 끌림을 포함하는 사랑입니다. 연인이나 배우자 사이에서 주로 나타납니다.

2. **가족 사랑**: 부모와 자식, 형제자매 등 가족 구성원 간의 사랑입니다. 이 사랑은 보호, 지원, 그리고 무조건적인 애정을 포함합니다.

3. **우정**: 친구들 간의 사랑으로, 상호 신뢰, 존중, 그리고 즐거움을 기반으로 합니다.

4. **자기 사랑**: 자신을 존중하고 돌보는 마음입니다. 이는 건강한 자아 존중감과 정신적, 신체적 웰빙을 유지하는 데 중요합니다.

5. **이타적 사랑**: 타인의 행복과 복지를 위해 헌신하는 사랑입니다. 이는 자선 활동이나 봉사와 같은 형태로 나타날 수 있습니다.

사랑은 사람마다 다르게 경험되고 표현될 수 있으며, 문화적, 사회적, 개인적 요인에 따라 그 의미가 달라질 수 있습니다.</code></pre>
</section>
</section>
</section>
<section id="anthropic" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Anthropic</h1>
<p>Anthropic은 인공지능(AI) 안전성과 연구에 중점을 둔 미국의 스타트업 기업입니다. 주요 정보는 다음과 같습니다:</p>
<ul>
<li><strong>설립 연도</strong>: 2021년</li>
<li><strong>위치</strong>: 미국 샌프란시스코</li>
<li><strong>창립자</strong>: OpenAI 출신 직원들 (Daniela Amodei와 Dario Amodei 등)</li>
<li><strong>기업 형태</strong>: 공익기업(Public Benefit Corporation)으로 등록</li>
</ul>
<section id="claude" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="claude"><span class="header-section-number">3.1</span> Claude</h2>
<p>Claude는 Anthropic의 대표적인 대규모 언어 모델(LLM) 제품군입니다.</p>
<ul>
<li><strong>API 키 발급</strong>: <a href="https://console.anthropic.com/settings/keys">https://console.anthropic.com/settings/keys</a></li>
<li><strong>모델 리스트</strong>: <a href="https://docs.anthropic.com/en/docs/about-claude/models">https://docs.anthropic.com/en/docs/about-claude/models</a></li>
</ul>
<p><img src="images/anthropic-20241023.png" class="img-fluid"></p>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 20%">
<col style="width: 24%">
<col style="width: 25%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>model_name</th>
<th>model</th>
<th>Anthropic API</th>
<th>AWS Bedrock</th>
<th>GCP Vertex AI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Claude 3.5 Opus</td>
<td>연말 출시 예정</td>
<td>연말 출시 예정</td>
<td>연말 출시 예정</td>
<td>연말 출시 예정</td>
</tr>
<tr class="even">
<td>Claude 3.5 Sonnet</td>
<td>claude-3-5-sonnet-20241022</td>
<td>claude-3-5-sonnet-20241022</td>
<td>anthropic.claude-3-5-sonnet-20241022-v2:0</td>
<td>claude-3-5-sonnet-v2@20241022</td>
</tr>
<tr class="odd">
<td>Claude 3.5 Haiku</td>
<td>연말 출시 예정</td>
<td>연말 출시 예정</td>
<td>연말 출시 예정</td>
<td>연말 출시 예정</td>
</tr>
<tr class="even">
<td>Claude 3 Opus</td>
<td>claude-3-opus-20240229</td>
<td>claude-3-opus-20240229</td>
<td>anthropic.claude-3-opus-20240229-v1:0</td>
<td>claude-3-opus@20240229</td>
</tr>
<tr class="odd">
<td>Claude 3 Sonnet</td>
<td>claude-3-sonnet-20240229</td>
<td>claude-3-sonnet-20240229</td>
<td>anthropic.claude-3-sonnet-20240229-v1:0</td>
<td>claude-3-sonnet@20240229</td>
</tr>
<tr class="even">
<td>Claude 3 Haiku</td>
<td>claude-3-haiku-20240307</td>
<td>claude-3-haiku-20240307</td>
<td>anthropic.claude-3-haiku-20240307-v1:0</td>
<td>claude-3-haiku@20240307</td>
</tr>
</tbody>
</table>
<div id="d11fd5c2" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">from</span> langchain_anthropic <span class="im">import</span> ChatAnthropic</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="co"># ChatAnthropic 객체를 생성합니다.</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>anthropic <span class="op">=</span> ChatAnthropic(model_name<span class="op">=</span><span class="st">"claude-3-5-sonnet-20241022"</span>)</span>
<span id="cb5-5"><a href="#cb5-5"></a></span>
<span id="cb5-6"><a href="#cb5-6"></a><span class="co"># 스트리밍 출력을 위하여 invoke() 대신 stream()을 사용합니다.</span></span>
<span id="cb5-7"><a href="#cb5-7"></a>answer <span class="op">=</span> anthropic.stream(<span class="st">"사랑이 뭔가요?"</span>)</span>
<span id="cb5-8"><a href="#cb5-8"></a></span>
<span id="cb5-9"><a href="#cb5-9"></a><span class="co"># 답변 출력</span></span>
<span id="cb5-10"><a href="#cb5-10"></a>stream_response(answer)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>사랑은 매우 복잡하고 주관적인 감정입니다. 다음과 같은 측면들이 포함될 수 있습니다:

1. 정서적 측면
- 상대방을 향한 깊은 애정
- 행복감과 설렘
- 상대를 위한 희생과 배려

2. 행동적 측면
- 함께하고 싶은 욕구
- 상대방을 보호하고 돕고자 하는 마음
- 상대의 행복을 위한 노력

3. 생물학적 측면
- 호르몬의 변화
- 신체적 반응

4. 사회문화적 측면
- 문화와 시대에 따라 다른 표현방식
- 사회적 규범과의 관계

사랑은 개인마다 다르게 경험되고 표현되는 매우 개인적인 감정이며, 시간에 따라 변화하고 성장할 수 있는 것입니다.</code></pre>
</section>
</section>
<section id="perplexity" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Perplexity</h1>
<p>링크: https://www.perplexity.ai/</p>
<ul>
<li><strong>설립연도</strong>: 2022년</li>
<li><strong>주요 투자자</strong>: Jeff Bezos, Nvidia, Databricks, Bessemer Venture Partners, IVP, Wayra 등</li>
<li><strong>최근 펀딩</strong>: 5억 달러 (2024년 10월)</li>
<li><strong>기업 가치</strong>: 약 90억 달러 (2024년 11월 기준)</li>
<li><strong>월간 활성 사용자</strong>: 1,500만 명</li>
</ul>
<section id="perplexity-pro-정확한-특징" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="perplexity-pro-정확한-특징"><span class="header-section-number">4.1</span> Perplexity Pro 정확한 특징</h2>
<ul>
<li><strong>일일 Pro 검색</strong>: 300회</li>
<li><strong>AI 모델 선택</strong>: GPT-4 Omni, Claude 3 Sonnet/Haiku, Sonar Large 32k[5]</li>
<li><strong>파일 분석</strong>: PDF, CSV, 이미지 파일 지원</li>
<li><strong>가격</strong>: 월 $20 또는 연 $200</li>
</ul>
</section>
<section id="perplexity-api-사용-방법" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="perplexity-api-사용-방법"><span class="header-section-number">4.2</span> Perplexity API 사용 방법</h2>
<p><strong>가격</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="attachment:perplexity-pricing.png" class="img-fluid figure-img"></p>
<figcaption>perplexity-pricing.png</figcaption>
</figure>
</div>
<ul>
<li><strong>API 크레딧 획득</strong>
<ul>
<li>Perplexity Pro 구독 시 <strong>매월 $5 상당의 API 크레딧 제공</strong></li>
</ul></li>
<li><strong>API 모델 옵션</strong>
<ul>
<li>Llama 3 기반 모델</li>
<li>Perplexity 온라인 LLM</li>
<li>인용 기능 포함</li>
</ul></li>
<li>API 키 발급: <a href="https://www.perplexity.ai/settings/api">API 콘솔</a></li>
</ul>
<p>API 키 발급 후 <code>.env</code> 파일에 키 저장</p>
<pre><code>PPLX_API_KEY=이곳에 API 키를 입력하세요.</code></pre>
<p>혹은</p>
<pre><code>import os

os.environ["PPLX_API_KEY"] = "이곳에 API 키를 입력하세요."</code></pre>
<p><strong>참고</strong></p>
<ul>
<li><a href="https://docs.perplexity.ai/api-reference/chat-completions">API 문서</a></li>
</ul>
</section>
<section id="지원-모델" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="지원-모델"><span class="header-section-number">4.3</span> 지원 모델</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 42%">
<col style="width: 18%">
<col style="width: 17%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>Parameter Count</th>
<th>Context Length</th>
<th>Model Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>llama-3.1-sonar-small-128k-online</code></td>
<td>8B</td>
<td>127,072</td>
<td>Chat Completion</td>
</tr>
<tr class="even">
<td><code>llama-3.1-sonar-large-128k-online</code></td>
<td>70B</td>
<td>127,072</td>
<td>Chat Completion</td>
</tr>
<tr class="odd">
<td><code>llama-3.1-sonar-huge-128k-online</code></td>
<td>405B</td>
<td>127,072</td>
<td>Chat Completion</td>
</tr>
</tbody>
</table>
</section>
<section id="chatperplexity-매개변수" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="chatperplexity-매개변수"><span class="header-section-number">4.4</span> ChatPerplexity 매개변수</h2>
<p><code>model</code><br>
사용할 언어 모델을 지정 (예: “llama-3.1-sonar-small-128k-online”) - 기본 성능과 능력을 결정.</p>
<p><code>temperature</code><br>
응답의 무작위성을 조절 (0.0-1.0), 0은 결정적, 1은 가장 무작위한 응답 생성.</p>
<p><code>top_p</code><br>
토큰 샘플링의 확률 임계값 설정 (0.0-1.0), 높을수록 더 다양한 출력 허용.</p>
<p><code>search_domain_filter</code><br>
검색 결과를 지정된 도메인으로 제한, 리스트 형태로 제공 (예: [“perplexity.ai”]).</p>
<p><code>return_images</code><br>
응답에 이미지 포함 여부를 결정하는 불리언 플래그.</p>
<p><code>return_related_questions</code><br>
관련 질문 제안 기능을 활성화/비활성화하는 불리언 플래그.</p>
<p><code>top_k</code><br>
사용할 검색 결과의 수 제한 (0은 제한 없음을 의미).</p>
<p><code>streaming</code><br>
응답을 스트리밍으로 받을지 완성된 형태로 받을지 결정하는 불리언 플래그.</p>
<p><code>presence_penalty</code><br>
토큰 반복에 대한 페널티 (-2.0에서 2.0), 높을수록 재사용을 억제.</p>
<p><code>frequency_penalty</code><br>
일반적/희귀 토큰 선호도 조정 (-2.0에서 2.0), 높을수록 희귀 토큰 선호.</p>
<div id="0205fc0b" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="im">from</span> langchain_teddynote.models <span class="im">import</span> ChatPerplexity</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a>perplexity <span class="op">=</span> ChatPerplexity(</span>
<span id="cb9-4"><a href="#cb9-4"></a>    model<span class="op">=</span><span class="st">"llama-3.1-sonar-large-128k-online"</span>,</span>
<span id="cb9-5"><a href="#cb9-5"></a>    temperature<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb9-6"><a href="#cb9-6"></a>    top_p<span class="op">=</span><span class="fl">0.9</span>,</span>
<span id="cb9-7"><a href="#cb9-7"></a>    search_domain_filter<span class="op">=</span>[<span class="st">"perplexity.ai"</span>],</span>
<span id="cb9-8"><a href="#cb9-8"></a>    return_images<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-9"><a href="#cb9-9"></a>    return_related_questions<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-10"><a href="#cb9-10"></a>    <span class="co"># search_recency_filter="month",</span></span>
<span id="cb9-11"><a href="#cb9-11"></a>    top_k<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb9-12"><a href="#cb9-12"></a>    streaming<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-13"><a href="#cb9-13"></a>    presence_penalty<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb9-14"><a href="#cb9-14"></a>    frequency_penalty<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb9-15"><a href="#cb9-15"></a>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>응답을 출력: <code>ChatPerplexity</code> 는 지식 정보의 출처를 <code>citations</code> 속성에 저장</p>
<div id="e343cd3c" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># 응답 출력</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>response <span class="op">=</span> perplexity.invoke(<span class="st">"2024년 노벨문학상 수상자를 조사해 주세요"</span>)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="bu">print</span>(response.content)</span>
<span id="cb10-4"><a href="#cb10-4"></a></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="bu">print</span>()</span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="cf">for</span> i, citation <span class="kw">in</span> <span class="bu">enumerate</span>(response.citations):</span>
<span id="cb10-7"><a href="#cb10-7"></a>    <span class="bu">print</span>(<span class="ss">f"[</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>citation<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>2024년 노벨문학상은 한국의 소설가 한강이 수상했습니다.

한강은 그의 작품들이 “역사적 트라우마에 맞서고, 인간의 삶의 연약함을 드러낸 강렬한 시적이고 실험적인 문체”를 통해 현대 산문의 혁신을 보여준 점을 인정받았습니다. 그의 주요 작품들 중 『채식주의자』, 『소년이 온다』, 『작별하지 않는다』 등이 특별히 언급되었습니다[1][3][4].

한강은 아시아 여성 작가로서 최초로 노벨문학상을 수상한 것으로, 이는 한국 문학계와 아시아 문학계에 큰 의미를 가진 사건입니다. 또한, 그는 이전에 2016년 맨부커상과 2023년 메디치 외국문학상을 수상한 바 있습니다[1][4].

[1] https://times.postech.ac.kr/news/articleView.html?idxno=23342
[2] https://www.segye.com/newsView/20241115508113
[3] https://www.hani.co.kr/arti/science/science_general/1165375.html
[4] https://www.umnews.org/ko/news/about-han-kangs-nobel-prize-in-literature
[5] https://news.kbs.co.kr/news/pc/view/view.do?ncd=8097555</code></pre>
<p>스트리밍 출력</p>
<div id="6f07952a" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>response <span class="op">=</span> perplexity.stream(<span class="st">"2024년 노벨문학상 수상자를 조사해 주세요"</span>)</span>
<span id="cb12-2"><a href="#cb12-2"></a></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="cf">for</span> token <span class="kw">in</span> response:</span>
<span id="cb12-4"><a href="#cb12-4"></a>    <span class="bu">print</span>(token.content, end<span class="op">=</span><span class="st">""</span>, flush<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-5"><a href="#cb12-5"></a></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb12-7"><a href="#cb12-7"></a><span class="cf">for</span> i, citation <span class="kw">in</span> <span class="bu">enumerate</span>(token.citations):</span>
<span id="cb12-8"><a href="#cb12-8"></a>    <span class="bu">print</span>(<span class="ss">f"[</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>citation<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<pre><code>2024년 노벨문학상은 한국의 소설가 한강이 수상했습니다.

한강은 그의 작품들이 “역사적 트라우마에 맞서고, 인간의 삶의 연약함을 드러낸 강렬한 시적이고 실험적인 문체”를 통해 현대 산문의 혁신을 보여준 점을 인정받았습니다. 스웨덴 한림원은 그의 작품들, 특히 『채식주의자』, 『소년이 온다』, 『작별하지 않는다』 등을 높이 평가했습니다. 한강은 아시아 여성 작가로서는 최초로, 한국인으로서는 최초로 노벨문학상을 수상한 작가입니다[1][3][4].

[1] https://times.postech.ac.kr/news/articleView.html?idxno=23342
[2] https://www.segye.com/newsView/20241115508113
[3] https://www.hani.co.kr/arti/science/science_general/1165375.html
[4] https://www.umnews.org/ko/news/about-han-kangs-nobel-prize-in-literature
[5] https://news.kbs.co.kr/news/pc/view/view.do?ncd=8097555</code></pre>
</section>
<section id="together-ai" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="together-ai"><span class="header-section-number">4.5</span> Together AI</h2>
<ul>
<li>링크: https://www.together.ai/</li>
<li>API 키 발급: https://api.together.ai/</li>
<li><code>TOGETHER_API_KEY</code> 환경변수 설정</li>
</ul>
<p>Together AI는 2022년 샌프란시스코에서 설립된 생성형 AI 클라우드 플랫폼 회사입니다(NVIDIA, Kleiner Perkins, Lux, NEA 등으로부터 1억 2천만 달러 이상의 투자를 유치했습니다).</p>
<section id="주요-제품과-특징" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="주요-제품과-특징"><span class="header-section-number">4.5.1</span> 주요 제품과 특징</h3>
<p><strong>Together Inference</strong></p>
<ul>
<li>업계에서 가장 빠른 추론 스택을 제공하며, vLLM보다 최대 4배 빠른 성능을 보입니다</li>
<li>Llama-3 70B 사용 시 GPT-4 대비 11배 낮은 비용으로 운영 가능</li>
<li>자동 확장 기능으로 API 요청 볼륨에 맞춰 용량이 자동으로 조정됩니다</li>
</ul>
<p><strong>Together Custom Models</strong></p>
<ul>
<li>사용자 맞춤형 AI 모델 학습 및 Fine-tuning 지원</li>
<li>FlashAttention-3와 같은 최신 최적화 기술 적용</li>
<li>학습된 모델에 대한 완전한 소유권 보장</li>
</ul>
</section>
<section id="기술적-특징" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="기술적-특징"><span class="header-section-number">4.5.2</span> 기술적 특징</h3>
<p><strong>성능 최적화</strong></p>
<ul>
<li>FlashAttention-3 커널과 독점 커널을 통합한 추론 엔진 보유</li>
<li>Medusa와 SpecExec 같은 추측적 디코딩 알고리즘 적용</li>
<li>최고의 정확도와 성능을 위한 독자적인 양자화 기술 사용</li>
</ul>
<p><strong>지원 모델</strong></p>
<ul>
<li>Google Gemma, Meta의 Llama 3.3, Qwen2.5, Mistral AI의 Mistral/Mixtral 등 200개 이상의 오픈소스 모델 지원</li>
<li>멀티모달 AI 모델 지원으로 다양한 형태의 데이터 처리 가능</li>
</ul>
<p><strong>보안 및 프라이버시</strong></p>
<ul>
<li>사용자가 명시적으로 동의하지 않는 한 데이터는 새로운 모델 학습에 사용되지 않음</li>
<li>데이터 보관에 대한 완전한 제어권을 사용자에게 제공</li>
</ul>
<div id="35f67e88" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="im">from</span> langchain_teddynote.messages <span class="im">import</span> stream_response</span>
<span id="cb14-2"><a href="#cb14-2"></a><span class="im">from</span> langchain_together <span class="im">import</span> ChatTogether</span>
<span id="cb14-3"><a href="#cb14-3"></a></span>
<span id="cb14-4"><a href="#cb14-4"></a>together <span class="op">=</span> ChatTogether(model<span class="op">=</span><span class="st">"meta-llama/Llama-3.3-70B-Instruct-Turbo"</span>, temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="co"># together = ChatTogether(model="google/gemma-2-27b-it", temperature=0)</span></span>
<span id="cb14-6"><a href="#cb14-6"></a></span>
<span id="cb14-7"><a href="#cb14-7"></a>answer <span class="op">=</span> together.stream(<span class="st">"로또 생성기 파이썬 코드를 작성하세요"</span>)</span>
<span id="cb14-8"><a href="#cb14-8"></a>stream_response(answer)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>function calling 지원</p>
<div id="c93434f0" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel</span>
<span id="cb15-2"><a href="#cb15-2"></a><span class="im">from</span> typing <span class="im">import</span> List</span>
<span id="cb15-3"><a href="#cb15-3"></a></span>
<span id="cb15-4"><a href="#cb15-4"></a></span>
<span id="cb15-5"><a href="#cb15-5"></a><span class="kw">class</span> Lotto(BaseModel):</span>
<span id="cb15-6"><a href="#cb15-6"></a>    numbers: List[<span class="bu">int</span>]</span>
<span id="cb15-7"><a href="#cb15-7"></a></span>
<span id="cb15-8"><a href="#cb15-8"></a></span>
<span id="cb15-9"><a href="#cb15-9"></a>together_structured <span class="op">=</span> together.with_structured_output(Lotto)</span>
<span id="cb15-10"><a href="#cb15-10"></a></span>
<span id="cb15-11"><a href="#cb15-11"></a>answer <span class="op">=</span> together_structured.invoke(<span class="st">"로또 번호 6개를 추천해 주세요"</span>)</span>
<span id="cb15-12"><a href="#cb15-12"></a><span class="bu">print</span>(answer)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
<section id="cohere" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Cohere</h1>
<p>Cohere는 기업용 인공지능 솔루션을 제공하는 선도적인 AI 기업으로, 대규모 언어 모델(LLM)을 개발하여 기업들이 AI 기술을 쉽게 도입하고 활용할 수 있도록 돕고 있습니다.</p>
<section id="cohere-개요" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="cohere-개요"><span class="header-section-number">5.1</span> Cohere 개요</h2>
<ul>
<li><strong>설립연도</strong>: 2020년</li>
<li><strong>주요 투자자</strong>: Inovia Capital, NVIDIA, Oracle, Salesforce Ventures</li>
<li><strong>시리즈 C 펀딩</strong>: 2억 7000만 달러 유치</li>
<li><strong>기업 미션</strong>: 기업용 AI 플랫폼 제공</li>
</ul>
</section>
<section id="주요-제품" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="주요-제품"><span class="header-section-number">5.2</span> 주요 제품</h2>
<section id="command-r" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="command-r"><span class="header-section-number">5.2.1</span> Command R+</h3>
<p>Command R+는 기업용으로 최적화된 Cohere의 최신 LLM입니다.</p>
<section id="주요-특징" class="level4" data-number="5.2.1.1">
<h4 data-number="5.2.1.1" class="anchored" data-anchor-id="주요-특징"><span class="header-section-number">5.2.1.1</span> 주요 특징</h4>
<ul>
<li><strong>긴 컨텍스트 윈도우</strong>: 128k 토큰 지원</li>
<li><strong>고급 RAG 기능</strong>: 검색 강화 생성 기능 제공</li>
<li><strong>다국어 지원</strong>: 10개 주요 비즈니스 언어 지원</li>
<li><strong>자동화 도구 사용 기능</strong>: 복잡한 비즈니스 프로세스 자동화</li>
</ul>
</section>
</section>
<section id="aya" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="aya"><span class="header-section-number">5.2.2</span> Aya</h3>
<p>Aya는 Cohere의 비영리 연구소인 Cohere for AI에서 개발한 오픈소스 다국어 LLM입니다.</p>
<section id="주요-특징-1" class="level4" data-number="5.2.2.1">
<h4 data-number="5.2.2.1" class="anchored" data-anchor-id="주요-특징-1"><span class="header-section-number">5.2.2.1</span> 주요 특징</h4>
<ul>
<li><strong>언어 지원</strong>: 101개 언어 지원 (기존 오픈소스 모델의 두 배 이상)</li>
<li><strong>훈련 데이터셋</strong>: 5억 1300만 개의 데이터 포인트 포함하는 대규모 다국어 훈련 데이터셋 공개</li>
</ul>
<div id="cb02c82f" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="im">from</span> langchain_cohere <span class="im">import</span> ChatCohere</span>
<span id="cb16-2"><a href="#cb16-2"></a></span>
<span id="cb16-3"><a href="#cb16-3"></a><span class="co"># ChatCohere 객체를 생성합니다.</span></span>
<span id="cb16-4"><a href="#cb16-4"></a>cohere <span class="op">=</span> ChatCohere(temperature<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-5"><a href="#cb16-5"></a></span>
<span id="cb16-6"><a href="#cb16-6"></a><span class="co"># 스트리밍 출력을 위하여 invoke() 대신 stream()을 사용합니다.</span></span>
<span id="cb16-7"><a href="#cb16-7"></a>answer <span class="op">=</span> cohere.stream(<span class="st">"사랑이 뭔가요?"</span>)</span>
<span id="cb16-8"><a href="#cb16-8"></a></span>
<span id="cb16-9"><a href="#cb16-9"></a><span class="co"># 답변 출력</span></span>
<span id="cb16-10"><a href="#cb16-10"></a>stream_response(answer)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
</section>
<section id="upstage" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Upstage</h1>
<p>Upstage는 인공지능(AI) 기술, 특히 대규모 언어 모델(LLM)과 문서 AI 분야에 특화된 국내 스타트업입니다.</p>
<section id="주요-제품-및-기술" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="주요-제품-및-기술"><span class="header-section-number">6.1</span> 주요 제품 및 기술</h2>
<section id="solar-llm" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="solar-llm"><span class="header-section-number">6.1.1</span> Solar LLM</h3>
<ul>
<li><strong>주요 특징</strong>: Upstage의 주력 대규모 언어 모델로, 빠른 성능과 비용 효율성으로 주목받고 있습니다.</li>
<li><strong>기술적 접근</strong>: Depth-Up Scaling (DUS) 기술을 적용하여 성능을 극대화합니다.</li>
<li><strong>플랫폼 통합</strong>: Amazon SageMaker JumpStart 등 다양한 플랫폼을 통해 API로 통합 제공됩니다.</li>
</ul>
</section>
<section id="document-ai-pack" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="document-ai-pack"><span class="header-section-number">6.1.2</span> Document AI Pack</h3>
<ul>
<li><strong>기능</strong>: OCR 기술을 기반으로 한 문서 처리 솔루션으로, 복잡한 문서에서 필요한 내용을 정확히 추출하고 디지털화합니다.</li>
</ul>
</section>
<section id="askup-seargest" class="level3" data-number="6.1.3">
<h3 data-number="6.1.3" class="anchored" data-anchor-id="askup-seargest"><span class="header-section-number">6.1.3</span> AskUp Seargest</h3>
<ul>
<li><strong>특징</strong>: 개인화된 검색 및 추천 서비스를 제공하며, 기존의 ChatGPT 통합 무료 챗봇 AskUp의 업그레이드 버전입니다.</li>
</ul>
</section>
</section>
<section id="api-키-발급" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="api-키-발급"><span class="header-section-number">6.2</span> API 키 발급</h2>
<p>API 키 발급은 <a href="https://console.upstage.ai/api-keys">여기</a>에서 가능합니다.</p>
<div id="aa98cc9a" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># UPSTAGE API KEY 설정</span></span>
<span id="cb17-2"><a href="#cb17-2"></a><span class="co"># import os</span></span>
<span id="cb17-3"><a href="#cb17-3"></a></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="co"># os.environ["UPSTAGE_API_KEY"] = "이곳에 API KEY를 입력하세요."</span></span>
<span id="cb17-5"><a href="#cb17-5"></a></span>
<span id="cb17-6"><a href="#cb17-6"></a><span class="im">from</span> langchain_upstage <span class="im">import</span> ChatUpstage</span>
<span id="cb17-7"><a href="#cb17-7"></a></span>
<span id="cb17-8"><a href="#cb17-8"></a><span class="co"># ChatUpstage 객체를 생성합니다.</span></span>
<span id="cb17-9"><a href="#cb17-9"></a>upstage <span class="op">=</span> ChatUpstage(model<span class="op">=</span><span class="st">"solar-pro"</span>)</span>
<span id="cb17-10"><a href="#cb17-10"></a></span>
<span id="cb17-11"><a href="#cb17-11"></a><span class="co"># 스트리밍 출력을 위하여 invoke() 대신 stream()을 사용합니다.</span></span>
<span id="cb17-12"><a href="#cb17-12"></a>answer <span class="op">=</span> upstage.stream(<span class="st">"사랑이 뭔가요?"</span>)</span>
<span id="cb17-13"><a href="#cb17-13"></a></span>
<span id="cb17-14"><a href="#cb17-14"></a><span class="co"># 답변 출력</span></span>
<span id="cb17-15"><a href="#cb17-15"></a>stream_response(answer)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="xionic" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="xionic"><span class="header-section-number">6.3</span> Xionic</h2>
<p>사이오닉에이아이(Sionic AI)는 대한민국의 유망한 인공지능 스타트업으로, 기업용 생성형 AI 솔루션을 개발하고 있습니다. 다음은 이 회사에 대한 주요 정보입니다:</p>
<section id="주요-제품-1" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="주요-제품-1"><span class="header-section-number">6.3.1</span> 주요 제품</h3>
<ol type="1">
<li><strong>STORM Platform</strong>: 기업이 생성형 AI를 기술적 고민 없이 바로 적용할 수 있도록 하는 플랫폼</li>
<li><strong>STORM Answer</strong>: 기업에 최적화된 생성형 AI 솔루션으로 비즈니스 생산성 향상을 목표로 함</li>
<li><strong>Xionic</strong>: 상업적 이용이 가능한 라이센스의 한국어 AI 모델</li>
</ol>
<p>상업적 이용이 가능한 라이센스의 한국어 모델</p>
<ul>
<li>링크: https://github.com/sionic-ai/xionic</li>
</ul>
<p>(참고) 2024.11.29 기준 사용불가 (API 서버 오류)</p>
<div id="572ba972" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>코드</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="im">from</span> langchain_openai <span class="im">import</span> ChatOpenAI</span>
<span id="cb18-2"><a href="#cb18-2"></a><span class="im">from</span> langchain_teddynote.messages <span class="im">import</span> stream_response</span>
<span id="cb18-3"><a href="#cb18-3"></a></span>
<span id="cb18-4"><a href="#cb18-4"></a><span class="co"># 2024. 11. 21 업데이트 코드</span></span>
<span id="cb18-5"><a href="#cb18-5"></a>xionic <span class="op">=</span> ChatOpenAI(</span>
<span id="cb18-6"><a href="#cb18-6"></a>    model_name<span class="op">=</span><span class="st">"xionic-1-72b-20240919"</span>,</span>
<span id="cb18-7"><a href="#cb18-7"></a>    base_url<span class="op">=</span><span class="st">"https://sionic.chat/v1/"</span>,</span>
<span id="cb18-8"><a href="#cb18-8"></a>    api_key<span class="op">=</span><span class="st">"934c4bbc-c384-4bea-af82-1450d7f8128d"</span>,</span>
<span id="cb18-9"><a href="#cb18-9"></a>)</span>
<span id="cb18-10"><a href="#cb18-10"></a></span>
<span id="cb18-11"><a href="#cb18-11"></a><span class="co"># 스트리밍 출력을 위하여 invoke() 대신 stream()을 사용합니다.</span></span>
<span id="cb18-12"><a href="#cb18-12"></a>answer <span class="op">=</span> xionic.stream(<span class="st">"사랑이 뭔가요?"</span>)</span>
<span id="cb18-13"><a href="#cb18-13"></a></span>
<span id="cb18-14"><a href="#cb18-14"></a><span class="co"># 답변 출력</span></span>
<span id="cb18-15"><a href="#cb18-15"></a>stream_response(answer)</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
</section>
<section id="logickor" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> LogicKor</h1>
<p>LogicKor는 한국어 언어 모델의 다분야 사고력을 평가하기 위해 만들어진 벤치마크 리더보드입니다.</p>
<section id="목적" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="목적"><span class="header-section-number">7.1</span> 목적</h2>
<p>한국어 언어 모델의 다양한 분야에서의 사고력을 측정하는 벤치마크</p>
</section>
<section id="평가-영역" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="평가-영역"><span class="header-section-number">7.2</span> 평가 영역</h2>
<ul>
<li>한국어 추론</li>
<li>수학</li>
<li>글쓰기</li>
<li>코딩</li>
<li>이해력</li>
</ul>
</section>
<section id="주요-특징-2" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="주요-특징-2"><span class="header-section-number">7.3</span> 주요 특징</h2>
<ol type="1">
<li><strong>다양한 모델 평가</strong>: 국내외 다양한 언어 모델들의 성능을 비교할 수 있음</li>
<li><strong>객관적 성능 측정</strong>: 모델의 실제 성능을 다각도로 평가하여 객관적인 지표 제공</li>
<li><strong>오픈 소스</strong>: 누구나 접근하고 결과를 확인할 수 있는 오픈 플랫폼</li>
</ol>
<p>LogicKor 리더보드는 한국어 AI 모델의 발전을 위한 중요한 도구로 자리잡고 있으며, 지속적인 개선과 발전이 기대되고 있습니다.</p>
<ul>
<li>링크: <a href="https://lk.instruct.kr/">LogicKor 리더보드</a></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup" style="padding-bottom: 1em; max-width: 400px;" class="ms-auto me-auto">
  <p style="font-weight: 600; margin-bottom: 0;">Subscribe</p>
  <span style="font-size: 0.9em;">Enjoy this blog? Get notified of new posts by email:</span>
<form action="https://quarto.us14.list-manage.com/subscribe/post?u=c79fb56a311ae347fbe916740&amp;id=ec05dfca03" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate="">
    <div id="mc_embed_signup_scroll">
	
        <div class="input-group mt-1 mb-2">
        <input type="email" class="form-control" placeholder="Email Address" aria-label="Email Address" name="EMAIL" style="font-size: 0.8em; padding: .2em;">
        </div>              

	<div id="mce-responses" class="clear foot">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_c79fb56a311ae347fbe916740_ec05dfca03" tabindex="-1" value=""></div>
        <div class="optionalParent">
            <div class="clear foot" style="display: flex; align-items: center; justify-content: center;">
              
              
                <input type="submit" value="Subscribe" name="subscribe" style="min-width: 150px; font-size: 0.8em;" id="mc-embedded-subscribe" class="button btn btn-light btn-sm ms-auto me-auto">
            </div>
        </div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("kk3225\.netlify\.app");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="kmink3225/blog" data-repo-id="R_kgDOLCZyDg" data-category="Blog" data-category-id="" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Kwangmin Kim</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../../../about.html">
<p>About</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kmink3225/blog">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>