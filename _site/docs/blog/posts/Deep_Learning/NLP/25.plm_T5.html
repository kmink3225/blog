<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko" xml:lang="ko"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kwangmin Kim">
<meta name="description" content="T5는 Google Research에서 2019년 발표한 혁신적인 사전 학습 모델로, 모든 자연어 처리 태스크를 텍스트-투-텍스트 형식으로 통일한 Text-to-Text 프레임워크를 제시했다. 분류에서 생성까지 모든 문제를 일관된 방식으로 해결하며, 현대 대규모 언어 모델들의 설계 철학에 큰 영향을 미쳤다. T5의 구조, 학습 방법, Text-to-Text 접근법의 혁신성과 함께 후속 모델들에 미친 영향을 분석한다.">

<title>T5: Text-to-Text Transfer Transformer – Kwangmin Kim</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete-preset-algolia.umd.js"></script>
<meta name="quarto:offset" content="../../../../../">
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "algolia": {
    "application-id": "DUOR1DRC9D",
    "search-only-api-key": "f264da5dea684ffb9e9b4a574af3ed61",
    "index-name": "prod_QUARTO",
    "analytics-events": true,
    "show-logo": true,
    "libDir": "site_libs"
  },
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "검색"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.5.1/dist/algoliasearch-lite.umd.js"></script>


<script type="text/javascript">
var ALGOLIA_INSIGHTS_SRC = "https://cdn.jsdelivr.net/npm/search-insights/dist/search-insights.iife.min.js";
!function(e,a,t,n,s,i,c){e.AlgoliaAnalyticsObject=s,e[s]=e[s]||function(){
(e[s].queue=e[s].queue||[]).push(arguments)},i=a.createElement(t),c=a.getElementsByTagName(t)[0],
i.async=1,i.src=n,c.parentNode.insertBefore(i,c)
}(window,document,"script",ALGOLIA_INSIGHTS_SRC,"aa");
</script>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@algolia/autocomplete-plugin-algolia-insights">

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6W0EKFMWBN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-6W0EKFMWBN', { 'anonymize_ip': true});
</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: black;
      }

      .quarto-title-block .quarto-title-banner {
        color: black;
background: #EDF3F9;
      }
</style>
<style>
.custom-footer { 
  text-align: center; 
  font-size: 0.8em; 
  color: #666; 
  margin-top: 2rem; 
}
</style>


<link rel="stylesheet" href="../../../../../styles.css">
<meta property="og:title" content="T5: Text-to-Text Transfer Transformer – Kwangmin Kim">
<meta property="og:description" content="T5는 Google Research에서 2019년 발표한 혁신적인 사전 학습 모델로, 모든 자연어 처리 태스크를 텍스트-투-텍스트 형식으로 통일한 Text-to-Text 프레임워크를 제시했다. 분류에서 생성까지 모든 문제를 일관된 방식으로 해결하며, 현대 대규모 언어 모델들의 설계 철학에 큰 영향을 미쳤다. T5의 구조, 학습 방법, Text-to-Text 접근법의 혁신성과 함께 후속 모델들에 미친 영향을 분석한다.">
<meta property="og:site_name" content="Kwangmin Kim">
<meta name="twitter:title" content="T5: Text-to-Text Transfer Transformer – Kwangmin Kim">
<meta name="twitter:description" content="T5는 Google Research에서 2019년 발표한 혁신적인 사전 학습 모델로, 모든 자연어 처리 태스크를 텍스트-투-텍스트 형식으로 통일한 Text-to-Text 프레임워크를 제시했다. 분류에서 생성까지 모든 문제를 일관된 방식으로 해결하며, 현대 대규모 언어 모델들의 설계 철학에 큰 영향을 미쳤다. T5의 구조, 학습 방법, Text-to-Text 접근법의 혁신성과 함께 후속 모델들에 미친 영향을 분석한다.">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../.././images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">Kwangmin Kim</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="검색"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../about.html"> 
<span class="menu-text">Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kmink3225"> <i class="bi bi-github" role="img" aria-label="Github">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/kwangmin-kim-a5241b200/"> <i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="다크 모드 전환"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">T5: Text-to-Text Transfer Transformer</h1>
            <p class="subtitle lead">모든 NLP 태스크를 텍스트 생성으로 통합한 혁신적 프레임워크</p>
                  <div>
        <div class="description">
          <p>T5는 Google Research에서 2019년 발표한 혁신적인 사전 학습 모델로, 모든 자연어 처리 태스크를 텍스트-투-텍스트 형식으로 통일한 Text-to-Text 프레임워크를 제시했다. 분류에서 생성까지 모든 문제를 일관된 방식으로 해결하며, 현대 대규모 언어 모델들의 설계 철학에 큰 영향을 미쳤다. T5의 구조, 학습 방법, Text-to-Text 접근법의 혁신성과 함께 후속 모델들에 미친 영향을 분석한다.</p>
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">Deep Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      <div>
      <div class="quarto-title-meta-heading">저자</div>
      <div class="quarto-title-meta-contents">
               <p>Kwangmin Kim </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">공개</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2025년 01월 25일</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#요약" id="toc-요약" class="nav-link active" data-scroll-target="#요약"><span class="header-section-number">1</span> 요약</a></li>
  <li><a href="#nlp-모델-발전-과정" id="toc-nlp-모델-발전-과정" class="nav-link" data-scroll-target="#nlp-모델-발전-과정"><span class="header-section-number">2</span> NLP 모델 발전 과정</a></li>
  <li><a href="#t5-이전-모델들의-한계점" id="toc-t5-이전-모델들의-한계점" class="nav-link" data-scroll-target="#t5-이전-모델들의-한계점"><span class="header-section-number">3</span> T5 이전 모델들의 한계점</a>
  <ul class="collapse">
  <li><a href="#기존-언어-모델의-문제점" id="toc-기존-언어-모델의-문제점" class="nav-link" data-scroll-target="#기존-언어-모델의-문제점"><span class="header-section-number">3.1</span> 기존 언어 모델의 문제점</a></li>
  </ul></li>
  <li><a href="#t5-text-to-text-transfer-transformer" id="toc-t5-text-to-text-transfer-transformer" class="nav-link" data-scroll-target="#t5-text-to-text-transfer-transformer"><span class="header-section-number">4</span> T5 (Text-to-Text Transfer Transformer)</a>
  <ul class="collapse">
  <li><a href="#개요와-기본-개념" id="toc-개요와-기본-개념" class="nav-link" data-scroll-target="#개요와-기본-개념"><span class="header-section-number">4.1</span> 개요와 기본 개념</a>
  <ul class="collapse">
  <li><a href="#핵심-아이디어" id="toc-핵심-아이디어" class="nav-link" data-scroll-target="#핵심-아이디어"><span class="header-section-number">4.1.1</span> 핵심 아이디어</a></li>
  </ul></li>
  <li><a href="#text-to-text-프레임워크" id="toc-text-to-text-프레임워크" class="nav-link" data-scroll-target="#text-to-text-프레임워크"><span class="header-section-number">4.2</span> Text-to-Text 프레임워크</a>
  <ul class="collapse">
  <li><a href="#기본-원리" id="toc-기본-원리" class="nav-link" data-scroll-target="#기본-원리"><span class="header-section-number">4.2.1</span> 기본 원리</a></li>
  <li><a href="#태스크별-변환-예시" id="toc-태스크별-변환-예시" class="nav-link" data-scroll-target="#태스크별-변환-예시"><span class="header-section-number">4.2.2</span> 태스크별 변환 예시</a></li>
  <li><a href="#prefix-기반-태스크-식별" id="toc-prefix-기반-태스크-식별" class="nav-link" data-scroll-target="#prefix-기반-태스크-식별"><span class="header-section-number">4.2.3</span> Prefix 기반 태스크 식별</a></li>
  </ul></li>
  <li><a href="#아키텍처-상세" id="toc-아키텍처-상세" class="nav-link" data-scroll-target="#아키텍처-상세"><span class="header-section-number">4.3</span> 아키텍처 상세</a>
  <ul class="collapse">
  <li><a href="#encoder-decoder-구조" id="toc-encoder-decoder-구조" class="nav-link" data-scroll-target="#encoder-decoder-구조"><span class="header-section-number">4.3.1</span> Encoder-Decoder 구조</a></li>
  <li><a href="#주요-구성-요소" id="toc-주요-구성-요소" class="nav-link" data-scroll-target="#주요-구성-요소"><span class="header-section-number">4.3.2</span> 주요 구성 요소</a></li>
  </ul></li>
  <li><a href="#사전-학습-방법론" id="toc-사전-학습-방법론" class="nav-link" data-scroll-target="#사전-학습-방법론"><span class="header-section-number">4.4</span> 사전 학습 방법론</a>
  <ul class="collapse">
  <li><a href="#span-corruption-목표" id="toc-span-corruption-목표" class="nav-link" data-scroll-target="#span-corruption-목표"><span class="header-section-number">4.4.1</span> Span Corruption 목표</a></li>
  <li><a href="#c4-데이터셋" id="toc-c4-데이터셋" class="nav-link" data-scroll-target="#c4-데이터셋"><span class="header-section-number">4.4.2</span> C4 데이터셋</a></li>
  <li><a href="#다양한-사전-학습-목표-비교" id="toc-다양한-사전-학습-목표-비교" class="nav-link" data-scroll-target="#다양한-사전-학습-목표-비교"><span class="header-section-number">4.4.3</span> 다양한 사전 학습 목표 비교</a></li>
  </ul></li>
  <li><a href="#모델-크기와-변형" id="toc-모델-크기와-변형" class="nav-link" data-scroll-target="#모델-크기와-변형"><span class="header-section-number">4.5</span> 모델 크기와 변형</a>
  <ul class="collapse">
  <li><a href="#t5-모델-크기별-구성" id="toc-t5-모델-크기별-구성" class="nav-link" data-scroll-target="#t5-모델-크기별-구성"><span class="header-section-number">4.5.1</span> T5 모델 크기별 구성</a></li>
  <li><a href="#scaling-laws-검증" id="toc-scaling-laws-검증" class="nav-link" data-scroll-target="#scaling-laws-검증"><span class="header-section-number">4.5.2</span> Scaling Laws 검증</a></li>
  </ul></li>
  <li><a href="#성능-및-벤치마크" id="toc-성능-및-벤치마크" class="nav-link" data-scroll-target="#성능-및-벤치마크"><span class="header-section-number">4.6</span> 성능 및 벤치마크</a>
  <ul class="collapse">
  <li><a href="#glue-benchmark" id="toc-glue-benchmark" class="nav-link" data-scroll-target="#glue-benchmark"><span class="header-section-number">4.6.1</span> GLUE Benchmark</a></li>
  <li><a href="#superglue-benchmark" id="toc-superglue-benchmark" class="nav-link" data-scroll-target="#superglue-benchmark"><span class="header-section-number">4.6.2</span> SuperGLUE Benchmark</a></li>
  <li><a href="#생성-태스크-성능" id="toc-생성-태스크-성능" class="nav-link" data-scroll-target="#생성-태스크-성능"><span class="header-section-number">4.6.3</span> 생성 태스크 성능</a></li>
  </ul></li>
  <li><a href="#t5의-혁신과-영향" id="toc-t5의-혁신과-영향" class="nav-link" data-scroll-target="#t5의-혁신과-영향"><span class="header-section-number">4.7</span> T5의 혁신과 영향</a>
  <ul class="collapse">
  <li><a href="#지속적-학습continual-learning-지원" id="toc-지속적-학습continual-learning-지원" class="nav-link" data-scroll-target="#지속적-학습continual-learning-지원"><span class="header-section-number">4.7.1</span> 지속적 학습(Continual Learning) 지원</a></li>
  <li><a href="#다국어-확장과-mt5" id="toc-다국어-확장과-mt5" class="nav-link" data-scroll-target="#다국어-확장과-mt5"><span class="header-section-number">4.7.2</span> 다국어 확장과 mT5</a></li>
  <li><a href="#효율성-개선-모델들" id="toc-효율성-개선-모델들" class="nav-link" data-scroll-target="#효율성-개선-모델들"><span class="header-section-number">4.7.3</span> 효율성 개선 모델들</a></li>
  </ul></li>
  <li><a href="#현대-llm에-미친-영향" id="toc-현대-llm에-미친-영향" class="nav-link" data-scroll-target="#현대-llm에-미친-영향"><span class="header-section-number">4.8</span> 현대 LLM에 미친 영향</a>
  <ul class="collapse">
  <li><a href="#instruction-following의-기초" id="toc-instruction-following의-기초" class="nav-link" data-scroll-target="#instruction-following의-기초"><span class="header-section-number">4.8.1</span> Instruction Following의 기초</a></li>
  <li><a href="#통합-모델-아키텍처의-확산" id="toc-통합-모델-아키텍처의-확산" class="nav-link" data-scroll-target="#통합-모델-아키텍처의-확산"><span class="header-section-number">4.8.2</span> 통합 모델 아키텍처의 확산</a></li>
  <li><a href="#멀티모달-ai로의-확장" id="toc-멀티모달-ai로의-확장" class="nav-link" data-scroll-target="#멀티모달-ai로의-확장"><span class="header-section-number">4.8.3</span> 멀티모달 AI로의 확장</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#결론" id="toc-결론" class="nav-link" data-scroll-target="#결론"><span class="header-section-number">5</span> 결론</a>
  <ul class="collapse">
  <li><a href="#t5의-핵심-기여" id="toc-t5의-핵심-기여" class="nav-link" data-scroll-target="#t5의-핵심-기여"><span class="header-section-number">5.1</span> T5의 핵심 기여</a></li>
  <li><a href="#후속-발전에-미친-영향" id="toc-후속-발전에-미친-영향" class="nav-link" data-scroll-target="#후속-발전에-미친-영향"><span class="header-section-number">5.2</span> 후속 발전에 미친 영향</a></li>
  <li><a href="#현재적-의미와-미래-전망" id="toc-현재적-의미와-미래-전망" class="nav-link" data-scroll-target="#현재적-의미와-미래-전망"><span class="header-section-number">5.3</span> 현재적 의미와 미래 전망</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">





<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>T5(Text-to-Text Transfer Transformer)는 2019년 Google Research에서 발표한 혁신적인 사전 학습 언어 모델이다. 기존 모델들이 태스크별로 다른 출력 형식을 사용했던 것과 달리, 모든 자연어 처리 태스크를 <strong>텍스트-투-텍스트</strong> 형식으로 통일하여 처리하는 획기적인 프레임워크를 제시했다.</p>
<p>주요 특징과 혁신 사항은 다음과 같다:</p>
<ul>
<li><strong>Text-to-Text 통합 프레임워크</strong>:
<ul>
<li>분류, 회귀, 생성 등 모든 NLP 태스크를 텍스트 생성 문제로 변환</li>
<li>“classify: 이 리뷰는 긍정적입니다” → “positive” 형태로 출력</li>
<li>태스크별 특수 헤드가 불필요한 완전히 통일된 접근법</li>
<li>인덱스 예측 대신 자연어 텍스트 생성을 통한 문제 해결</li>
</ul></li>
<li><strong>Encoder-Decoder 아키텍처</strong>:
<ul>
<li>BERT의 양방향 이해 능력과 GPT의 생성 능력을 결합</li>
<li>원본 Transformer와 동일한 구조로 검증된 안정성</li>
<li>Cross-attention을 통한 효과적인 정보 전달</li>
<li>입력 길이와 출력 길이의 독립적 처리</li>
</ul></li>
<li><strong>혁신적인 사전 학습 방식</strong>:
<ul>
<li><strong>Span Corruption</strong>: 연속된 토큰들을 마스킹하고 복원</li>
<li>다양한 사전 학습 목표의 체계적 비교 연구</li>
<li>C4(Colossal Clean Crawled Corpus) 데이터셋 활용</li>
<li>750GB의 필터링된 고품질 텍스트로 학습</li>
</ul></li>
<li><strong>확장성과 성능</strong>:
<ul>
<li>T5-Small(60M)부터 T5-11B(11B)까지 다양한 크기</li>
<li>GLUE, SuperGLUE에서 SOTA 달성</li>
<li>CNN/DailyMail 요약에서 뛰어난 성능</li>
<li>WMT 번역 태스크에서 경쟁력 있는 결과</li>
</ul></li>
<li><strong>현대 LLM의 설계 철학 확립</strong>:
<ul>
<li>모든 문제를 생성 태스크로 해결하는 접근법</li>
<li>Instruction following의 기초 마련</li>
<li>현재 ChatGPT, GPT-4 등 대화형 AI의 설계 원리</li>
<li>Fine-tuning 시 추가 레이어 불필요</li>
</ul></li>
</ul>
<p>T5는 단순한 성능 향상을 넘어 <strong>모든 NLP 태스크를 통합하는 새로운 패러다임</strong>을 제시했으며, 현재 대규모 언어 모델들의 설계 철학에 결정적 영향을 미쳤다.</p>
</section>
<section id="nlp-모델-발전-과정" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> NLP 모델 발전 과정</h1>
<pre><code>RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa
|   └── ALBERT
|
├── BERT 변형 모델들
|   ├── RoBERTa (Facebook, 2019)
|   ├── ALBERT (Google, 2019)
|   ├── DistilBERT (Hugging Face, 2019)
|   └── ELECTRA (Google, 2020)
|
└── 후속 발전 모델들
    ├── T5, XLNet, DeBERTa
    └── GPT-2/3/4, ChatGPT, PaLM 등</code></pre>
</section>
<section id="t5-이전-모델들의-한계점" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> T5 이전 모델들의 한계점</h1>
<section id="기존-언어-모델의-문제점" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="기존-언어-모델의-문제점"><span class="header-section-number">3.1</span> 기존 언어 모델의 문제점</h2>
<p><strong>태스크별 다른 출력 형식의 혼재</strong>: - 텍스트 분류: 클래스 인덱스 예측 (0, 1, 2…) - 개체명 인식: BIO 태깅 (B-PER, I-LOC, O…) - 질의응답: 시작/끝 위치 예측 (start_idx, end_idx) - 텍스트 생성: 토큰 시퀀스 생성 - 각 태스크마다 다른 출력 헤드와 손실 함수 필요</p>
<p><strong>모델 아키텍처의 태스크별 특화</strong>: - BERT: 분류/이해 태스크에 특화된 encoder-only 구조 - GPT: 생성 태스크에 특화된 decoder-only 구조 - 하나의 모델로 모든 태스크를 효과적으로 처리하기 어려움 - 태스크 전환 시 아키텍처 변경 또는 별도 모델 필요</p>
<p><strong>Fine-tuning의 복잡성</strong>: - 태스크별로 다른 추가 레이어 설계 필요 - 출력 형식에 맞는 특수 헤드(classification head, regression head 등) 구현 - 태스크별 다른 손실 함수와 평가 메트릭 - 모델 개발과 유지보수의 복잡성 증가</p>
<p><strong>통합적 학습의 어려움</strong>: - 여러 태스크를 동시에 학습하기 위한 복잡한 멀티태스크 설정 - 태스크 간 간섭(interference) 문제 - 태스크별 가중치 조정의 어려움 - 새로운 태스크 추가 시 전체 시스템 재설계 필요</p>
<p><strong>자연어 이해와 생성의 분리</strong>: - 이해 모델(BERT)과 생성 모델(GPT)이 별도로 발전 - 통합된 프레임워크의 부재로 인한 효율성 저하 - 인간의 언어 처리와 다른 분절된 접근법</p>
</section>
</section>
<section id="t5-text-to-text-transfer-transformer" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> T5 (Text-to-Text Transfer Transformer)</h1>
<section id="개요와-기본-개념" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="개요와-기본-개념"><span class="header-section-number">4.1</span> 개요와 기본 개념</h2>
<p>T5는 <strong>모든 자연어 처리 태스크를 텍스트-투-텍스트 문제로 통일</strong>한 혁신적인 언어 모델이다. 2019년 Google Research에서 발표된 T5는 “Text-to-Text Transfer Transformer”의 줄임말로, 입력과 출력 모두 텍스트 형태로 처리하는 완전히 새로운 패러다임을 제시했다.</p>
<section id="핵심-아이디어" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="핵심-아이디어"><span class="header-section-number">4.1.1</span> 핵심 아이디어</h3>
<ul>
<li><strong>통일된 프레임워크</strong>: 모든 NLP 태스크를 “텍스트 입력 → 텍스트 출력” 형태로 변환</li>
<li><strong>자연어 기반 출력</strong>: 숫자나 인덱스 대신 자연어 텍스트로 답변 생성</li>
<li><strong>태스크 무관한 아키텍처</strong>: 하나의 모델 구조로 모든 문제 해결</li>
<li><strong>인간친화적 접근</strong>: 인간이 이해하기 쉬운 형태의 입출력</li>
</ul>
</section>
</section>
<section id="text-to-text-프레임워크" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="text-to-text-프레임워크"><span class="header-section-number">4.2</span> Text-to-Text 프레임워크</h2>
<section id="기본-원리" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="기본-원리"><span class="header-section-number">4.2.1</span> 기본 원리</h3>
<p><strong>“모든 텍스트 처리 문제를 텍스트 생성 문제로 변환”</strong></p>
<pre><code>기존 방식: 입력 텍스트 → 특수 출력 (클래스 ID, 확률, 위치 등)
T5 방식: 입력 텍스트 → 출력 텍스트</code></pre>
</section>
<section id="태스크별-변환-예시" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="태스크별-변환-예시"><span class="header-section-number">4.2.2</span> 태스크별 변환 예시</h3>
<p><strong>1. 텍스트 분류</strong></p>
<pre><code>기존: "This movie is great!" → [1] (긍정 클래스)
T5: "sentiment: This movie is great!" → "positive"</code></pre>
<p><strong>2. 번역</strong></p>
<pre><code>기존: "Hello world" → sequence of token IDs
T5: "translate English to German: Hello world" → "Hallo Welt"</code></pre>
<p><strong>3. 질의응답</strong></p>
<pre><code>기존: Question + Context → [start_pos, end_pos]
T5: "question: What is the capital? context: France's capital is Paris" → "Paris"</code></pre>
<p><strong>4. 요약</strong></p>
<pre><code>기존: Long text → Abstract representation → Summary
T5: "summarize: [long article text]" → "Brief summary text"</code></pre>
<p><strong>5. 문법 오류 수정</strong></p>
<pre><code>T5: "grammar: She are going to school" → "She is going to school"</code></pre>
<p><strong>6. 자연어 추론</strong></p>
<pre><code>T5: "nli premise: A man is sleeping hypothesis: A person is resting" → "entailment"</code></pre>
</section>
<section id="prefix-기반-태스크-식별" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="prefix-기반-태스크-식별"><span class="header-section-number">4.2.3</span> Prefix 기반 태스크 식별</h3>
<p><strong>태스크별 접두사(Prefix) 사용</strong>: - <code>translate English to German:</code> - 영독 번역 - <code>summarize:</code> - 텍스트 요약<br>
- <code>question:</code> - 질의응답 - <code>sentiment:</code> - 감정 분석 - <code>cola sentence:</code> - 문법성 판단</p>
<p>이 접두사를 통해 모델이 수행할 태스크를 명확히 지시할 수 있다.</p>
</section>
</section>
<section id="아키텍처-상세" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="아키텍처-상세"><span class="header-section-number">4.3</span> 아키텍처 상세</h2>
<section id="encoder-decoder-구조" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="encoder-decoder-구조"><span class="header-section-number">4.3.1</span> Encoder-Decoder 구조</h3>
<p>T5는 원본 Transformer와 동일한 encoder-decoder 구조를 사용한다.</p>
<pre><code>Input Text (with task prefix)
    ↓
Encoder (Bidirectional Self-Attention)
├── Multi-Head Self-Attention
├── Feed-Forward Network  
└── Layer Normalization
    ↓
Encoder Representations
    ↓
Decoder (Causal Self-Attention + Cross-Attention)
├── Masked Multi-Head Self-Attention
├── Cross-Attention (to Encoder)
├── Feed-Forward Network
└── Layer Normalization
    ↓
Output Text</code></pre>
</section>
<section id="주요-구성-요소" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="주요-구성-요소"><span class="header-section-number">4.3.2</span> 주요 구성 요소</h3>
<p><strong>Encoder</strong>: - 입력 텍스트의 양방향 문맥 이해 - BERT와 유사한 구조로 전체 입력 동시 처리 - Self-attention을 통한 풍부한 표현 학습 - 태스크 prefix를 포함한 전체 입력 인코딩</p>
<p><strong>Decoder</strong>: - 출력 텍스트의 순차적 생성 - GPT와 유사한 causal masking 적용 - Cross-attention으로 encoder 정보 활용 - 자연어 형태의 답변 생성</p>
<p><strong>Position Encoding</strong>: - 상대적 위치 인코딩(Relative Position Encoding) 사용 - 절대 위치 대신 토큰 간 상대적 거리 정보 활용 - 더 긴 시퀀스에 대한 일반화 능력 향상</p>
</section>
</section>
<section id="사전-학습-방법론" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="사전-학습-방법론"><span class="header-section-number">4.4</span> 사전 학습 방법론</h2>
<section id="span-corruption-목표" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="span-corruption-목표"><span class="header-section-number">4.4.1</span> Span Corruption 목표</h3>
<p><strong>기본 개념</strong>: T5의 주요 사전 학습 목표는 “Span Corruption”이다.</p>
<pre><code>원본: "The quick brown fox jumps over the lazy dog"
마스킹: "The quick &lt;X&gt; jumps over &lt;Y&gt; dog"
목표: "&lt;X&gt; brown fox &lt;Y&gt; the lazy"</code></pre>
<p><strong>작동 방식</strong>: 1. <strong>Span 선택</strong>: 연속된 토큰들을 임의로 선택 (평균 3개 토큰) 2. <strong>마스킹</strong>: 선택된 span을 특수 토큰으로 대체 (<code>&lt;X&gt;</code>, <code>&lt;Y&gt;</code>, <code>&lt;Z&gt;</code> 등) 3. <strong>복원</strong>: 디코더가 마스킹된 부분을 순차적으로 생성</p>
<p><strong>BERT MLM과의 차이점</strong>: - BERT: 개별 토큰 마스킹 → 각 위치별 독립 예측 - T5: 연속 span 마스킹 → 순차적 생성으로 복원 - T5가 더 자연스러운 텍스트 생성 능력 학습</p>
</section>
<section id="c4-데이터셋" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="c4-데이터셋"><span class="header-section-number">4.4.2</span> C4 데이터셋</h3>
<p><strong>Colossal Clean Crawled Corpus (C4)</strong>: - Common Crawl에서 추출한 웹 텍스트 - 750GB의 정제된 영어 텍스트 - 품질 필터링과 중복 제거 적용 - 다양한 도메인과 스타일 포함</p>
<p><strong>전처리 과정</strong>: 1. <strong>언어 식별</strong>: 영어 텍스트만 선별 2. <strong>품질 필터링</strong>: 문법적으로 올바른 문장 선택 3. <strong>중복 제거</strong>: 동일하거나 유사한 내용 제거 4. <strong>독성 콘텐츠 제거</strong>: 부적절한 내용 필터링</p>
</section>
<section id="다양한-사전-학습-목표-비교" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="다양한-사전-학습-목표-비교"><span class="header-section-number">4.4.3</span> 다양한 사전 학습 목표 비교</h3>
<p>T5 논문에서는 여러 사전 학습 방식을 체계적으로 비교했다:</p>
<p><strong>1. BERT-style (Mask Language Model)</strong>: - 개별 토큰을 [MASK]로 대체 - 각 위치에서 원래 토큰 예측</p>
<p><strong>2. Prefix LM</strong>: - 문장의 앞부분을 보고 뒷부분 예측 - GPT와 유사한 방식</p>
<p><strong>3. Span Corruption (T5의 선택)</strong>: - 연속된 토큰 span을 마스킹 - 순차적 생성으로 복원</p>
<p><strong>실험 결과</strong>: Span Corruption이 downstream 태스크에서 가장 좋은 성능을 보였다.</p>
</section>
</section>
<section id="모델-크기와-변형" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="모델-크기와-변형"><span class="header-section-number">4.5</span> 모델 크기와 변형</h2>
<section id="t5-모델-크기별-구성" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="t5-모델-크기별-구성"><span class="header-section-number">4.5.1</span> T5 모델 크기별 구성</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>모델</th>
<th>파라미터</th>
<th>레이어</th>
<th>d_model</th>
<th>d_ff</th>
<th>Heads</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>T5-Small</td>
<td>60M</td>
<td>6</td>
<td>512</td>
<td>2,048</td>
<td>8</td>
</tr>
<tr class="even">
<td>T5-Base</td>
<td>220M</td>
<td>12</td>
<td>768</td>
<td>3,072</td>
<td>12</td>
</tr>
<tr class="odd">
<td>T5-Large</td>
<td>770M</td>
<td>24</td>
<td>1,024</td>
<td>4,096</td>
<td>16</td>
</tr>
<tr class="even">
<td>T5-3B</td>
<td>3B</td>
<td>24</td>
<td>1,024</td>
<td>16,384</td>
<td>32</td>
</tr>
<tr class="odd">
<td>T5-11B</td>
<td>11B</td>
<td>24</td>
<td>1,024</td>
<td>65,536</td>
<td>128</td>
</tr>
</tbody>
</table>
</section>
<section id="scaling-laws-검증" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="scaling-laws-검증"><span class="header-section-number">4.5.2</span> Scaling Laws 검증</h3>
<p>T5는 모델 크기, 데이터 크기, 계산량에 따른 성능 변화를 체계적으로 연구: - 모델이 클수록 거의 모든 태스크에서 성능 향상 - 데이터 양 증가도 지속적인 성능 개선 효과 - 계산 자원 투입 대비 예측 가능한 성능 향상</p>
</section>
</section>
<section id="성능-및-벤치마크" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="성능-및-벤치마크"><span class="header-section-number">4.6</span> 성능 및 벤치마크</h2>
<section id="glue-benchmark" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="glue-benchmark"><span class="header-section-number">4.6.1</span> GLUE Benchmark</h3>
<p><strong>General Language Understanding Evaluation</strong>: - CoLA(문법성): 83.6 (Matthews correlation) - SST-2(감정): 97.5% (accuracy)<br>
- MRPC(패러프레이즈): 93.4% (F1) - QQP(질문 유사성): 89.9% (F1) - MNLI(자연어 추론): 90.6% (accuracy) - QNLI(질의응답): 95.9% (accuracy) - RTE(텍스트 함의): 93.1% (accuracy) - WNLI(대명사 해소): 94.4% (accuracy)</p>
<p><strong>평균 GLUE 점수</strong>: 88.9 (당시 SOTA)</p>
</section>
<section id="superglue-benchmark" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="superglue-benchmark"><span class="header-section-number">4.6.2</span> SuperGLUE Benchmark</h3>
<p>더 어려운 태스크들에서도 우수한 성능: - BoolQ: 87.7% - CB: 96.9%<br>
- COPA: 84.0% - MultiRC: 88.1% - ReCoRD: 94.1% - RTE: 93.1% - WiC: 77.8% - WSC: 95.2%</p>
</section>
<section id="생성-태스크-성능" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="생성-태스크-성능"><span class="header-section-number">4.6.3</span> 생성 태스크 성능</h3>
<p><strong>CNN/DailyMail 요약</strong>: - ROUGE-1: 43.5 - ROUGE-2: 21.0 - ROUGE-L: 40.7</p>
<p><strong>WMT English-German 번역</strong>: - BLEU: 27.5 (당시 경쟁력 있는 수준)</p>
<p><strong>SQuAD 질의응답</strong>: - Exact Match: 85.8% - F1 Score: 90.0%</p>
</section>
</section>
<section id="t5의-혁신과-영향" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="t5의-혁신과-영향"><span class="header-section-number">4.7</span> T5의 혁신과 영향</h2>
<section id="지속적-학습continual-learning-지원" class="level3" data-number="4.7.1">
<h3 data-number="4.7.1" class="anchored" data-anchor-id="지속적-학습continual-learning-지원"><span class="header-section-number">4.7.1</span> 지속적 학습(Continual Learning) 지원</h3>
<p>T5는 새로운 태스크를 추가할 때 기존 지식을 유지하면서 학습할 수 있는 구조를 제공한다: - <strong>태스크 접두사 확장</strong>: 새로운 prefix만 추가하면 새로운 태스크 처리 가능 - <strong>Catastrophic Forgetting 완화</strong>: 통일된 출력 형식으로 태스크 간 간섭 최소화 - <strong>점진적 능력 확장</strong>: 기존 능력을 손상시키지 않고 새로운 능력 획득</p>
</section>
<section id="다국어-확장과-mt5" class="level3" data-number="4.7.2">
<h3 data-number="4.7.2" class="anchored" data-anchor-id="다국어-확장과-mt5"><span class="header-section-number">4.7.2</span> 다국어 확장과 mT5</h3>
<p><strong>Multilingual T5 (mT5)</strong>: - 101개 언어 지원 - 언어 간 지식 전이 효과 확인 - 저자원 언어에서도 우수한 성능 - Cross-lingual 태스크에서 획기적 성과</p>
</section>
<section id="효율성-개선-모델들" class="level3" data-number="4.7.3">
<h3 data-number="4.7.3" class="anchored" data-anchor-id="효율성-개선-모델들"><span class="header-section-number">4.7.3</span> 효율성 개선 모델들</h3>
<p><strong>T5 기반 파생 모델들</strong>: - <strong>UL2</strong>: Unified Language Learner, 다양한 denoising 목표 통합 - <strong>PaLM</strong>: T5의 스케일링 연장선, 540B 파라미터 - <strong>Flan-T5</strong>: Instruction tuning으로 성능 향상 - <strong>T5X</strong>: 더 효율적인 구현과 학습 방법</p>
</section>
</section>
<section id="현대-llm에-미친-영향" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="현대-llm에-미친-영향"><span class="header-section-number">4.8</span> 현대 LLM에 미친 영향</h2>
<section id="instruction-following의-기초" class="level3" data-number="4.8.1">
<h3 data-number="4.8.1" class="anchored" data-anchor-id="instruction-following의-기초"><span class="header-section-number">4.8.1</span> Instruction Following의 기초</h3>
<p>T5의 prefix 기반 태스크 지시는 현재 instruction following의 원형이다:</p>
<pre><code>T5: "translate English to Korean: Hello" → "안녕하세요"
GPT-4: "Translate this to Korean: Hello" → "안녕하세요"</code></pre>
</section>
<section id="통합-모델-아키텍처의-확산" class="level3" data-number="4.8.2">
<h3 data-number="4.8.2" class="anchored" data-anchor-id="통합-모델-아키텍처의-확산"><span class="header-section-number">4.8.2</span> 통합 모델 아키텍처의 확산</h3>
<p><strong>현재 주요 모델들의 T5 영향</strong>: - <strong>ChatGPT/GPT-4</strong>: 모든 태스크를 대화/생성으로 통일 - <strong>PaLM, LaMDA</strong>: T5의 encoder-decoder 구조 활용 - <strong>BART, Pegasus</strong>: Text-to-Text 패러다임 적용 - <strong>UL2</strong>: T5의 denoising 방식 확장</p>
</section>
<section id="멀티모달-ai로의-확장" class="level3" data-number="4.8.3">
<h3 data-number="4.8.3" class="anchored" data-anchor-id="멀티모달-ai로의-확장"><span class="header-section-number">4.8.3</span> 멀티모달 AI로의 확장</h3>
<p>T5의 Text-to-Text 프레임워크는 멀티모달로 자연스럽게 확장:</p>
<pre><code>Vision-Language: 이미지 → 텍스트 설명
Speech-to-Text: 음성 → 텍스트 전사  
Text-to-Code: 자연어 → 프로그래밍 코드</code></pre>
</section>
</section>
</section>
<section id="결론" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> 결론</h1>
<p>T5는 자연어 처리 분야에서 <strong>패러다임 통합</strong>을 이뤄낸 혁신적인 모델로, 2019년 발표 이후 NLP 연구와 산업 응용의 방향을 근본적으로 바꿨다.</p>
<section id="t5의-핵심-기여" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="t5의-핵심-기여"><span class="header-section-number">5.1</span> T5의 핵심 기여</h2>
<p><strong>프레임워크 통합</strong>: - 모든 NLP 태스크를 하나의 일관된 Text-to-Text 형태로 통일 - 태스크별 특수 아키텍처의 필요성을 제거하고 범용성 확보 - 인간이 이해하기 쉬운 자연어 입출력으로 해석 가능성 향상</p>
<p><strong>아키텍처 검증</strong>: - Encoder-Decoder 구조의 효과성을 대규모로 검증 - Span Corruption을 통한 효율적인 사전 학습 방법 제시 - 모델 크기와 성능 간 예측 가능한 관계(Scaling Laws) 확립</p>
<p><strong>실용적 혁신</strong>: - Fine-tuning 시 추가 레이어가 불필요한 완전 통합 모델 - 새로운 태스크 추가 시 prefix만 변경하면 되는 확장성 - 다국어, 멀티모달로의 자연스러운 확장 가능성</p>
</section>
<section id="후속-발전에-미친-영향" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="후속-발전에-미친-영향"><span class="header-section-number">5.2</span> 후속 발전에 미친 영향</h2>
<p>T5의 등장은 <strong>“생성으로 모든 것을 해결한다”</strong>는 새로운 AI 패러다임의 출발점이었다.</p>
<p><strong>직접적 영향</strong>: - mT5, UL2, Flan-T5 등 직접적 개선 모델들 - BART, Pegasus 등 동시대 모델들의 설계 방향 제시 - Instruction tuning 연구의 기초 프레임워크 제공</p>
<p><strong>간접적 영향</strong>: - <strong>ChatGPT/GPT-4</strong>: 모든 태스크를 대화 생성으로 통일하는 접근법 - <strong>Large Language Models</strong>: 모든 문제를 텍스트 생성으로 해결하는 철학 - <strong>Multimodal AI</strong>: Vision-Language, Speech-Text 등 다양한 모달리티 통합</p>
<p><strong>산업적 응용</strong>: - 구글 검색, 번역, Gmail 스마트 컴포즈 등에 T5 기술 활용 - Hugging Face 등 오픈소스 생태계의 핵심 모델 - 다양한 도메인별 특화 모델의 기반 아키텍처</p>
</section>
<section id="현재적-의미와-미래-전망" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="현재적-의미와-미래-전망"><span class="header-section-number">5.3</span> 현재적 의미와 미래 전망</h2>
<p>T5는 단순한 성능 향상을 넘어 <strong>AI가 문제를 해결하는 방식의 근본적 변화</strong>를 제시했다.</p>
<p><strong>현재 상황</strong>: - 현재 대부분의 대규모 언어 모델이 T5의 설계 철학을 따름 - 모든 AI 태스크를 생성 문제로 변환하는 접근법이 표준이 됨 - Instruction following, Few-shot learning의 기초 프레임워크 역할</p>
<p><strong>미래 전망</strong>: - <strong>Unified AI Systems</strong>: 언어, 시각, 음성을 통합하는 멀티모달 AI의 기초 - <strong>Personalized AI</strong>: 개인별 맞춤형 AI 어시스턴트의 핵심 아키텍처 - <strong>Domain-Specific AI</strong>: 의료, 법률, 과학 등 전문 분야 AI의 기반 모델 - <strong>Interactive AI</strong>: 실시간 대화와 협업이 가능한 AI 시스템</p>
<p><strong>장기적 영향</strong>: T5가 제시한 “모든 문제를 텍스트 생성으로 해결”하는 패러다임은 AGI(Artificial General Intelligence) 구현의 중요한 단계로 평가된다. 인간의 언어 사용 방식을 모방하여 다양한 문제를 일관된 방식으로 해결하는 접근법은 더욱 인간다운 AI 시스템 구축의 기초가 되고 있다.</p>
<p>T5의 등장은 자연어 처리를 넘어 <strong>인공지능 전반의 설계 철학을 바꾼 역사적 전환점</strong>이었으며, 현재 우리가 경험하고 있는 생성형 AI 혁명의 이론적 토대를 마련했다.</p>


</section>
</section>

</main> <!-- /main -->
<script type="text/javascript">

// replace cmd keyboard shortcut w/ control on non-Mac platforms
const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
if (!kPlatformMac) {
   var kbds = document.querySelectorAll("kbd")
   kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
   });
}

// tweak headings in pymd
document.querySelectorAll(".pymd span.co").forEach(el => {
   if (!el.innerText.startsWith("#|")) {
      el.style.fontWeight = 1000;
   }
});

</script>
<!-- Begin Mailchimp Signup Form -->
<div id="mc_embed_signup" style="padding-bottom: 1em; max-width: 400px;" class="ms-auto me-auto">
  <p style="font-weight: 600; margin-bottom: 0;">Subscribe</p>
  <span style="font-size: 0.9em;">Enjoy this blog? Get notified of new posts by email:</span>
<form action="https://quarto.us14.list-manage.com/subscribe/post?u=c79fb56a311ae347fbe916740&amp;id=ec05dfca03" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate="">
    <div id="mc_embed_signup_scroll">
	
        <div class="input-group mt-1 mb-2">
        <input type="email" class="form-control" placeholder="Email Address" aria-label="Email Address" name="EMAIL" style="font-size: 0.8em; padding: .2em;">
        </div>              

	<div id="mce-responses" class="clear foot">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_c79fb56a311ae347fbe916740_ec05dfca03" tabindex="-1" value=""></div>
        <div class="optionalParent">
            <div class="clear foot" style="display: flex; align-items: center; justify-content: center;">
              
              
                <input type="submit" value="Subscribe" name="subscribe" style="min-width: 150px; font-size: 0.8em;" id="mc-embedded-subscribe" class="button btn btn-light btn-sm ms-auto me-auto">
            </div>
        </div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("kk3225\.netlify\.app");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="kmink3225/blog" data-repo-id="R_kgDOLCZyDg" data-category="Blog" data-category-id="" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Kwangmin Kim</p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../../../../about.html">
<p>About</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kmink3225/blog">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>