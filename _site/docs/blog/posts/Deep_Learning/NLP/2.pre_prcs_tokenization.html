<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kwangmin Kim">
<meta name="dcterms.date" content="2025-01-02">
<meta name="description" content="토큰화는 자연어 처리의 첫 번째이자 가장 중요한 전처리 과정이다. 텍스트를 의미 있는 단위로 분할하여 기계가 처리할 수 있도록 변환하는 과정을 다룬다.">

<title>토큰화 (Tokenization) – Kwangmin Kim</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../../site_libs/quarto-search/quarto-search.js"></script>
<script src="../../../../../site_libs/quarto-search/autocomplete-preset-algolia.umd.js"></script>
<meta name="quarto:offset" content="../../../../../">
<script src="../../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "algolia": {
    "application-id": "DUOR1DRC9D",
    "search-only-api-key": "f264da5dea684ffb9e9b4a574af3ed61",
    "index-name": "prod_QUARTO",
    "analytics-events": true,
    "show-logo": true,
    "libDir": "site_libs"
  },
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": true,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.5.1/dist/algoliasearch-lite.umd.js"></script>


<script type="text/javascript">
var ALGOLIA_INSIGHTS_SRC = "https://cdn.jsdelivr.net/npm/search-insights/dist/search-insights.iife.min.js";
!function(e,a,t,n,s,i,c){e.AlgoliaAnalyticsObject=s,e[s]=e[s]||function(){
(e[s].queue=e[s].queue||[]).push(arguments)},i=a.createElement(t),c=a.getElementsByTagName(t)[0],
i.async=1,i.src=n,c.parentNode.insertBefore(i,c)
}(window,document,"script",ALGOLIA_INSIGHTS_SRC,"aa");
</script>

<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@algolia/autocomplete-plugin-algolia-insights">

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6W0EKFMWBN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-6W0EKFMWBN', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../../../../../styles.css">
<meta property="og:title" content="토큰화 (Tokenization) – Kwangmin Kim">
<meta property="og:description" content="토큰화는 자연어 처리의 첫 번째이자 가장 중요한 전처리 과정이다. 텍스트를 의미 있는 단위로 분할하여 기계가 처리할 수 있도록 변환하는 과정을 다룬다.">
<meta property="og:site_name" content="Kwangmin Kim">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../.././images/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../../../index.html">
    <span class="navbar-title">Kwangmin Kim</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../../docs/blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../../about.html"> 
<span class="menu-text">Me</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kmink3225"> <i class="bi bi-github" role="img" aria-label="Github">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/kwangmin-kim-a5241b200/"> <i class="bi bi-linkedin" role="img" aria-label="Linkedin">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#내용-요약" id="toc-내용-요약" class="nav-link active" data-scroll-target="#내용-요약"><span class="header-section-number">1</span> 내용 요약</a></li>
  <li><a href="#토큰화-개요" id="toc-토큰화-개요" class="nav-link" data-scroll-target="#토큰화-개요"><span class="header-section-number">2</span> 토큰화 개요</a>
  <ul class="collapse">
  <li><a href="#토큰화의-정의와-목적" id="toc-토큰화의-정의와-목적" class="nav-link" data-scroll-target="#토큰화의-정의와-목적"><span class="header-section-number">2.1</span> 토큰화의 정의와 목적</a>
  <ul class="collapse">
  <li><a href="#주요-목적" id="toc-주요-목적" class="nav-link" data-scroll-target="#주요-목적"><span class="header-section-number">2.1.1</span> 주요 목적</a></li>
  </ul></li>
  <li><a href="#토큰화의-종류" id="toc-토큰화의-종류" class="nav-link" data-scroll-target="#토큰화의-종류"><span class="header-section-number">2.2</span> 토큰화의 종류</a>
  <ul class="collapse">
  <li><a href="#문장-토큰화-sentence-tokenization" id="toc-문장-토큰화-sentence-tokenization" class="nav-link" data-scroll-target="#문장-토큰화-sentence-tokenization"><span class="header-section-number">2.2.1</span> 문장 토큰화 (Sentence Tokenization)</a></li>
  <li><a href="#단어-토큰화-word-tokenization" id="toc-단어-토큰화-word-tokenization" class="nav-link" data-scroll-target="#단어-토큰화-word-tokenization"><span class="header-section-number">2.2.2</span> 단어 토큰화 (Word Tokenization)</a></li>
  <li><a href="#서브워드-토큰화-subword-tokenization" id="toc-서브워드-토큰화-subword-tokenization" class="nav-link" data-scroll-target="#서브워드-토큰화-subword-tokenization"><span class="header-section-number">2.2.3</span> 서브워드 토큰화 (Subword Tokenization)</a></li>
  </ul></li>
  <li><a href="#토큰화-도구와-라이브러리" id="toc-토큰화-도구와-라이브러리" class="nav-link" data-scroll-target="#토큰화-도구와-라이브러리"><span class="header-section-number">2.3</span> 토큰화 도구와 라이브러리</a>
  <ul class="collapse">
  <li><a href="#영어-토큰화-도구" id="toc-영어-토큰화-도구" class="nav-link" data-scroll-target="#영어-토큰화-도구"><span class="header-section-number">2.3.1</span> 영어 토큰화 도구</a></li>
  <li><a href="#한국어-토큰화-도구" id="toc-한국어-토큰화-도구" class="nav-link" data-scroll-target="#한국어-토큰화-도구"><span class="header-section-number">2.3.2</span> 한국어 토큰화 도구</a></li>
  <li><a href="#다국어-및-고급-토큰화-도구" id="toc-다국어-및-고급-토큰화-도구" class="nav-link" data-scroll-target="#다국어-및-고급-토큰화-도구"><span class="header-section-number">2.3.3</span> 다국어 및 고급 토큰화 도구</a></li>
  <li><a href="#도메인별-특화-도구" id="toc-도메인별-특화-도구" class="nav-link" data-scroll-target="#도메인별-특화-도구"><span class="header-section-number">2.3.4</span> 도메인별 특화 도구</a></li>
  <li><a href="#언어별-권장-도구-조합" id="toc-언어별-권장-도구-조합" class="nav-link" data-scroll-target="#언어별-권장-도구-조합"><span class="header-section-number">2.3.5</span> 언어별 권장 도구 조합</a></li>
  <li><a href="#성능과-정확도-비교" id="toc-성능과-정확도-비교" class="nav-link" data-scroll-target="#성능과-정확도-비교"><span class="header-section-number">2.3.6</span> 성능과 정확도 비교</a></li>
  <li><a href="#선택-기준" id="toc-선택-기준" class="nav-link" data-scroll-target="#선택-기준"><span class="header-section-number">2.3.7</span> 선택 기준</a></li>
  <li><a href="#결론" id="toc-결론" class="nav-link" data-scroll-target="#결론"><span class="header-section-number">2.3.8</span> 결론</a></li>
  </ul></li>
  <li><a href="#토큰화의-도전과제" id="toc-토큰화의-도전과제" class="nav-link" data-scroll-target="#토큰화의-도전과제"><span class="header-section-number">2.4</span> 토큰화의 도전과제</a>
  <ul class="collapse">
  <li><a href="#언어별-특성" id="toc-언어별-특성" class="nav-link" data-scroll-target="#언어별-특성"><span class="header-section-number">2.4.1</span> 언어별 특성</a></li>
  <li><a href="#도메인별-특수성" id="toc-도메인별-특수성" class="nav-link" data-scroll-target="#도메인별-특수성"><span class="header-section-number">2.4.2</span> 도메인별 특수성</a></li>
  <li><a href="#vocabulary" id="toc-vocabulary" class="nav-link" data-scroll-target="#vocabulary"><span class="header-section-number">2.4.3</span> Vocabulary</a></li>
  <li><a href="#out-of-vocabulary-oov-문제" id="toc-out-of-vocabulary-oov-문제" class="nav-link" data-scroll-target="#out-of-vocabulary-oov-문제"><span class="header-section-number">2.4.4</span> Out-of-Vocabulary (OOV) 문제</a></li>
  </ul></li>
  <li><a href="#평가-메트릭" id="toc-평가-메트릭" class="nav-link" data-scroll-target="#평가-메트릭"><span class="header-section-number">2.5</span> 평가 메트릭</a>
  <ul class="collapse">
  <li><a href="#어휘-크기-vocabulary-size" id="toc-어휘-크기-vocabulary-size" class="nav-link" data-scroll-target="#어휘-크기-vocabulary-size"><span class="header-section-number">2.5.1</span> 어휘 크기 (Vocabulary Size)</a></li>
  <li><a href="#압축률-compression-rate" id="toc-압축률-compression-rate" class="nav-link" data-scroll-target="#압축률-compression-rate"><span class="header-section-number">2.5.2</span> 압축률 (Compression Rate)</a></li>
  <li><a href="#의미-보존도" id="toc-의미-보존도" class="nav-link" data-scroll-target="#의미-보존도"><span class="header-section-number">2.5.3</span> 의미 보존도</a></li>
  </ul></li>
  <li><a href="#실제-적용-사례" id="toc-실제-적용-사례" class="nav-link" data-scroll-target="#실제-적용-사례"><span class="header-section-number">2.6</span> 실제 적용 사례</a>
  <ul class="collapse">
  <li><a href="#기계-번역" id="toc-기계-번역" class="nav-link" data-scroll-target="#기계-번역"><span class="header-section-number">2.6.1</span> 기계 번역</a></li>
  <li><a href="#감정-분석" id="toc-감정-분석" class="nav-link" data-scroll-target="#감정-분석"><span class="header-section-number">2.6.2</span> 감정 분석</a></li>
  <li><a href="#질의응답-시스템" id="toc-질의응답-시스템" class="nav-link" data-scroll-target="#질의응답-시스템"><span class="header-section-number">2.6.3</span> 질의응답 시스템</a></li>
  </ul></li>
  <li><a href="#최신-동향" id="toc-최신-동향" class="nav-link" data-scroll-target="#최신-동향"><span class="header-section-number">2.7</span> 최신 동향</a>
  <ul class="collapse">
  <li><a href="#다국어-토큰화" id="toc-다국어-토큰화" class="nav-link" data-scroll-target="#다국어-토큰화"><span class="header-section-number">2.7.1</span> 다국어 토큰화</a></li>
  <li><a href="#적응형-토큰화" id="toc-적응형-토큰화" class="nav-link" data-scroll-target="#적응형-토큰화"><span class="header-section-number">2.7.2</span> 적응형 토큰화</a></li>
  <li><a href="#신경망-기반-토큰화" id="toc-신경망-기반-토큰화" class="nav-link" data-scroll-target="#신경망-기반-토큰화"><span class="header-section-number">2.7.3</span> 신경망 기반 토큰화</a></li>
  </ul></li>
  <li><a href="#결론-1" id="toc-결론-1" class="nav-link" data-scroll-target="#결론-1"><span class="header-section-number">2.8</span> 결론</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">토큰화 (Tokenization)</h1>
<p class="subtitle lead">자연어 처리의 첫 번째 단계 - 텍스트를 기계가 이해할 수 있는 단위로 분할</p>
  <div class="quarto-categories">
    <div class="quarto-category">NLP</div>
    <div class="quarto-category">Deep Learning</div>
  </div>
  </div>

<div>
  <div class="description">
    <p>토큰화는 자연어 처리의 첫 번째이자 가장 중요한 전처리 과정이다. 텍스트를 의미 있는 단위로 분할하여 기계가 처리할 수 있도록 변환하는 과정을 다룬다.</p>
  </div>
</div>


<div class="quarto-title-meta column-page-left">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Kwangmin Kim </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 2, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="내용-요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 내용 요약</h1>
<ul>
<li>토큰화란?:
<ul>
<li>자연어 처리(NLP)의 첫 단계로, 텍스트를 컴퓨터가 이해할 수 있는 의미 있는 단위(토큰)로 분할하는 과정</li>
</ul></li>
<li>왜 중요한가?:
<ul>
<li>텍스트를 구조화하고, 표준화하며, 후속 NLP 작업의 효율성을 높이고, 언어적 의미를 보존</li>
</ul></li>
<li>어떤 종류가 있나?:
<ul>
<li>문장 토큰화: 텍스트를 문장 단위로 나눈다. (예: 마침표, 물음표 등 구분)</li>
<li>단어 토큰화: 문장을 단어 단위로 나눈다. (예: 공백, 구두점 등 기준)</li>
<li>서브워드 토큰화: 단어를 더 작은 의미 단위(subword)로 나눈다. (예: BPE, WordPiece, SentencePiece)</li>
</ul></li>
<li>고려할 점은?:
<ul>
<li>각 토큰화 방법은 장단점이 있으며, 특히 문장/단어 토큰화는 다양한 예외 케이스(약어, 특수문자, 이메일 주소 등)로 인해 복잡할 수 있다.</li>
<li>언어별 특성(한국어 교착어 등), 도메인 특성(소셜미디어 약어 등)에 따라 상세한 규칙을 적용해 처리해야 한다.</li>
<li>규칙을 만들어 구현하는 것 보다는 이미 검증된 도구를 활용하는 것이 좋다.</li>
</ul></li>
<li>어떤 도구를 쓰나?:
<ul>
<li>NLTK, KoNLPy, spaCy, Transformers 라이브러리 등 검증된 도구를 활용하는 것이 좋다.
<ul>
<li><strong>NLTK (Natural Language Toolkit)</strong>:
<ul>
<li>설명: 영어 자연어 처리를 위한 대표적인 라이브러리. 교육 및 연구 목적으로 많이 사용됨.</li>
<li>특징: TreebankWordTokenizer (단어), sent_tokenize (문장) 등 다양한 토큰화 기능 제공.</li>
<li>장점: 사용이 간편하고 다양한 기능을 제공. Penn Treebank 규칙 등 검증된 방식 사용.</li>
<li>단점: 다른 라이브러리에 비해 처리 속도가 느릴 수 있음.</li>
</ul></li>
<li><strong>KoNLPy (Korean NLP Library)</strong>:
<ul>
<li>설명: 한국어 형태소 분석 및 자연어 처리를 위한 파이썬 패키지 모음.</li>
<li>특징: Okt, Komoran, Hannanum 등 다양한 형태소 분석기 포함.</li>
<li>장점: 한국어의 교착어 특성을 고려한 형태소 분석 가능. 다양한 분석기 선택 가능.</li>
<li>단점: 형태소 분석기마다 성능과 속도 차이가 있으며, 일부는 설치가 복잡할 수 있음.</li>
</ul></li>
<li><strong>spaCy (English Language Library)</strong>:
<ul>
<li>설명: 산업 수준의 빠르고 효율적인 NLP 라이브러리.</li>
<li>특징: 다국어 지원(한국어 포함), 빠른 처리 속도, 통합된 NLP 파이프라인 제공.</li>
<li>장점: 속도가 매우 빠르고 안정적이며, 다양한 언어 및 기능을 지원하여 실제 제품 환경에 적합.</li>
<li>단점: 특정 언어나 도메인에 대한 세밀한 조정은 NLTK나 KoNLPy보다 유연성이 떨어질 수 있음.</li>
</ul></li>
<li><strong>Transformers (Hugging Face)</strong>:
<ul>
<li>설명: 최신 딥러닝 모델(BERT, GPT 등)에서 사용되는 토크나이저를 제공하는 라이브러리.</li>
<li>특징: 서브워드 토큰화(BPE, WordPiece, SentencePiece) 기반. AutoTokenizer로 다양한 모델의 토크나이저 쉽게 로드.</li>
<li>장점: OOV(Out-of-Vocabulary) 문제에 강하고, 딥러닝 모델의 성능을 극대화. 다국어 모델 지원.</li>
<li>단점: 기존 규칙 기반 토큰화보다 직관성이 떨어질 수 있으며, 모델별 토큰화 방식이 다를 수 있음.</li>
</ul></li>
</ul></li>
</ul></li>
<li>추가적으로:
<ul>
<li>언어별 특성(한국어 교착어 등), 도메인 특성(소셜미디어 약어 등)에 따라 적절한 도구와 전략을 선택해야 한다.</li>
</ul></li>
<li>이러한 도전 과제, 평가 방법, 실제 적용 사례 및 최신 연구 동향도 간략히 소개한다.</li>
</ul>
</section>
<section id="토큰화-개요" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 토큰화 개요</h1>
<ul>
<li>토큰화(Tokenization)는 자연어 처리에서 가장 기본이 되는 전처리 과정이다. *컴퓨터가 이해할 수 있도록 연속된 텍스트를 의미 있는 단위(토큰)로 분할하는 작업을 의미한다.</li>
</ul>
<section id="토큰화의-정의와-목적" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="토큰화의-정의와-목적"><span class="header-section-number">2.1</span> 토큰화의 정의와 목적</h2>
<p><strong>토큰화</strong>란 기계에게 어느 구간까지가 문장이고 단어인지를 알려주는 과정이다. 인간은 자연스럽게 문장의 구조를 이해하지만, 컴퓨터는 명시적으로 경계를 정해줘야 한다.</p>
<section id="주요-목적" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="주요-목적"><span class="header-section-number">2.1.1</span> 주요 목적</h3>
<ul>
<li>구조화: 비구조화된 텍스트를 구조화된 형태로 변환한다.</li>
<li>표준화: 일관된 처리 단위를 제공한다.</li>
<li>효율성: 후속 NLP 작업의 효율성을 향상시킨다.</li>
<li>의미 보존: 언어의 의미를 최대한 보존하면서 분할한다.</li>
</ul>
</section>
</section>
<section id="토큰화의-종류" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="토큰화의-종류"><span class="header-section-number">2.2</span> 토큰화의 종류</h2>
<p>토큰화는 분할 단위에 따라 여러 가지 방법으로 분류할 수 있다.</p>
<section id="문장-토큰화-sentence-tokenization" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="문장-토큰화-sentence-tokenization"><span class="header-section-number">2.2.1</span> 문장 토큰화 (Sentence Tokenization)</h3>
<p>텍스트를 문장 단위로 분할하는 과정이다.</p>
<p><strong>한글 예시:</strong></p>
<pre><code>입력: "자연어 처리는 매우 흥미로운 분야입니다. 컴퓨터가 인간의 언어를 이해하고 처리할 수 있게 만드는 기술이죠. 최근 딥러닝 기술의 발전으로 놀라운 성과를 보이고 있습니다. 특히 GPT나 BERT 같은 모델들이 주목받고 있어요."

출력: [
  "자연어 처리는 매우 흥미로운 분야입니다.",
  "컴퓨터가 인간의 언어를 이해하고 처리할 수 있게 만드는 기술이죠.",
  "최근 딥러닝 기술의 발전으로 놀라운 성과를 보이고 있습니다.",
  "특히 GPT나 BERT 같은 모델들이 주목받고 있어요."
]</code></pre>
<p><strong>영어 예시:</strong></p>
<pre><code>입력: "Natural language processing is a fascinating field of study. It combines linguistics, computer science, and artificial intelligence to help computers understand human language. Recent advances in deep learning have revolutionized this area. Models like GPT and BERT have achieved remarkable performance on various NLP tasks."

출력: [
  "Natural language processing is a fascinating field of study.",
  "It combines linguistics, computer science, and artificial intelligence to help computers understand human language.",
  "Recent advances in deep learning have revolutionized this area.",
  "Models like GPT and BERT have achieved remarkable performance on various NLP tasks."
]</code></pre>
<p><strong>주요 고려사항:</strong> - 마침표, 느낌표, 물음표 등의 문장 종결 부호 - 줄임말과 약어 처리 (예: “Dr.”, “etc.”) - 인용문 내의 문장 부호</p>
<section id="문장-토큰화에-대한-고민" class="level4" data-number="2.2.1.1">
<h4 data-number="2.2.1.1" class="anchored" data-anchor-id="문장-토큰화에-대한-고민"><span class="header-section-number">2.2.1.1</span> 문장 토큰화에 대한 고민</h4>
<ul>
<li>문장 토큰화는 겉보기에는 간단해 보이지만, 실제로는 매우 복잡한 언어학적 문제들을 내포하고 있다.</li>
<li>비전문가들은 마침표, 쉼표, 느낌표, 물음표만 있으면 문장을 쉽게 구분할 수 있다고 생각하지만, 현실은 그렇게 단순하지 않다.</li>
</ul>
<p><strong>1. 마침표의 다중 의미 딜레마</strong></p>
<p>마침표가 항상 문장의 끝을 의미하는 것은 아니다. 동일한 기호가 완전히 다른 용도로 사용되는 경우가 빈번하다.</p>
<pre><code>예시 1: 약어와 문장 종료의 혼재
"Dr. Smith earned his Ph.D. from MIT in 1995. He now works at NASA."

잘못된 분할:
- "Dr."
- "Smith earned his Ph."
- "D."
- "from MIT in 1995."
- "He now works at NASA."

올바른 분할:
- "Dr. Smith earned his Ph.D. from MIT in 1995."
- "He now works at NASA."</code></pre>
<p>같은 마침표이지만 “Dr.”와 “Ph.D.”는 약어를 나타내고, 마지막 마침표만이 실제 문장의 끝을 의미한다.</p>
<p><strong>2. 이메일 주소의 함정</strong></p>
<pre><code>예시 2: 이메일과 URL이 포함된 텍스트
"Contact john.doe@company.com for details. Visit www.company.com. Our office is open 9 A.M. to 5 P.M."

잘못된 분할:
- "Contact john."
- "doe@company."
- "com for details."
- "Visit www."
- "company."
- "com."
- "Our office is open 9 A."
- "M."
- "to 5 P."
- "M."

올바른 분할:
- "Contact john.doe@company.com for details."
- "Visit www.company.com."
- "Our office is open 9 A.M. to 5 P.M."</code></pre>
<p>이메일 주소와 웹사이트 URL 내의 마침표들은 문장 구분자가 아닙니다.</p>
<p><strong>3. 숫자와 소수점의 복잡성</strong></p>
<pre><code>예시 3: 숫자와 측정값
"The temperature reached 98.6°F yesterday. Sales increased by 15.7% this quarter. Our target is $1.5M."

잘못된 분할:
- "The temperature reached 98."
- "6°F yesterday."
- "Sales increased by 15."
- "7% this quarter."
- "Our target is $1."
- "5M."

올바른 분할:
- "The temperature reached 98.6°F yesterday."
- "Sales increased by 15.7% this quarter."
- "Our target is $1.5M."</code></pre>
<p>소수점, 통화 표시, 백분율 등에서 사용되는 마침표는 문장 구분자가 아니다.</p>
<p><strong>4. IP 주소와 기술 용어</strong></p>
<pre><code>예시 4: 기술 문서
"Connect to server 192.168.1.1 on port 8080. Use API version 2.3. Check logs at /var/log/app.log for errors."

잘못된 분할:
- "Connect to server 192."
- "168."
- "1."
- "1 on port 8080."
- "Use API version 2."
- "3."
- "Check logs at /var/log/app."
- "log for errors."

올바른 분할:
- "Connect to server 192.168.1.1 on port 8080."
- "Use API version 2.3."
- "Check logs at /var/log/app.log for errors."</code></pre>
<p>IP 주소, 버전 번호, 파일 경로에서 사용되는 마침표들은 모두 문장 구분자가 아니다.</p>
<p><strong>5. 인용문과 대화체의 복잡성</strong></p>
<pre><code>예시 5: 직접 인용문
'He said, "I don't think so. Maybe tomorrow?" Then he left.'

잘못된 분할:
- 'He said, "I don't think so.'
- 'Maybe tomorrow?"'
- 'Then he left.'

올바른 분할:
- 'He said, "I don't think so. Maybe tomorrow?" Then he left.'</code></pre>
<p>인용문 내부의 문장 부호는 전체 문장의 구조를 고려해야 한다.</p>
<p><strong>6. 줄임표와 생략 표현</strong></p>
<pre><code>예시 6: 줄임표의 혼란
"Well... I'm not sure. He seemed hesitant... maybe nervous? The meeting went on and on..."

문제점:
- "Well..."의 "..."는 망설임을 표현
- "hesitant..."의 "..."는 말끝을 흐림  
- "on and on..."의 "..."는 문장의 실제 종료

이런 경우 어디서 문장을 나눠야 할지 판단하기 어렵다.</code></pre>
<ol start="7" type="1">
<li>이외에도, 다양한 유형의 문장 토큰화 문제가 있다.</li>
</ol>
<ul>
<li><strong>프로그래밍 코드가 포함된 텍스트</strong></li>
<li><strong>시간과 날짜 표기법</strong></li>
<li><strong>학술 논문과 참고문헌</strong></li>
</ul>
<p>결론적으로, 문장 토큰화는 단순한 규칙 기반 접근법으로는 해결되지 않는다. 다음과 같은 요소들을 종합적으로 고려해야 한다:</p>
<ul>
<li><strong>문맥 정보</strong>: 주변 단어와 문장의 맥락</li>
<li><strong>도메인 지식</strong>: 의학, 법률, 기술 문서의 특수성</li>
<li><strong>언어적 규칙</strong>: 각 언어의 고유한 문법과 표기법</li>
<li><strong>의미론적 이해</strong>: 문장의 완결성과 논리적 구조</li>
<li><strong>다중 언어 처리</strong>: 코드 스위칭과 외래어 처리</li>
</ul>
<p>이러한 복잡성 때문에 현대의 문장 토큰화 도구들은 기계학습 기반의 접근법을 사용하여 문맥을 이해하고 더 정확한 분할을 수행하려고 시도한다. 하지만 여전히 완벽한 해결책은 없으며, 지속적인 연구와 개선이 필요한 영역이다.</p>
</section>
</section>
<section id="단어-토큰화-word-tokenization" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="단어-토큰화-word-tokenization"><span class="header-section-number">2.2.2</span> 단어 토큰화 (Word Tokenization)</h3>
<p>문장을 단어 단위로 분할하는 과정이다.</p>
<p><strong>한글 예시:</strong></p>
<pre><code>입력: "자연어 처리는 매우 흥미로운 분야입니다. 컴퓨터가 인간의 언어를 이해하고 처리할 수 있게 만드는 기술이죠. 최근 딥러닝 기술의 발전으로 놀라운 성과를 보이고 있습니다. 특히 GPT나 BERT 같은 모델들이 주목받고 있어요."

출력: [
  "자연어", "처리", "는", "매우", "흥미로운", "분야입니다", ".", "컴퓨터가", "인간의", "언어를", "이해하고", "처리할", "수", "있게", "만드는", "기술이죠", ".", "최근", "딥러닝", "기술의", "발전으로", "놀라운", "성과를", "보이고", "있습니다", ".", "특히", "GPT나", "BERT", "같은", "모델들이", "주목받고", "있어요"
]</code></pre>
<p><strong>영어 예시:</strong></p>
<pre><code>입력: "Natural language processing is a fascinating field of study. It combines linguistics, computer science, and artificial intelligence to help computers understand human language. Recent advances in deep learning have revolutionized this area. Models like GPT and BERT have achieved remarkable performance on various NLP tasks."

출력: [
  "Natural", "language", "processing", "is", "a", "fascinating", "field", "of", "study", ".", "It", "combines", "linguistics", "computer", "science", "and", "artificial", "intelligence", "to", "help", "computers", "understand", "human", "language", ".", "Recent", "advances", "in", "deep", "learning", "have", "revolutionized", "this", "area", ".", "Models", "like", "GPT", "and", "BERT", "have", "achieved", "remarkable", "performance", "on", "various", "NLP", "tasks"
]</code></pre>
<p><strong>언어별 특성:</strong></p>
<ul>
<li>영어
<ul>
<li>공백을 기준으로 비교적 쉽게 분할 가능</li>
<li>구두점 처리가 주요 과제</li>
</ul></li>
<li>한국어
<ul>
<li>교착어 특성으로 복잡한 어미 변화</li>
<li>공백만으로는 정확한 분할 어려움</li>
</ul></li>
<li>형태소 분석이 필요</li>
</ul>
<section id="단어-토큰화에-대한-고민" class="level4" data-number="2.2.2.1">
<h4 data-number="2.2.2.1" class="anchored" data-anchor-id="단어-토큰화에-대한-고민"><span class="header-section-number">2.2.2.1</span> 단어 토큰화에 대한 고민</h4>
<p>문장 토큰화와 마찬가지로, 단어 토큰화 역시 많은 복잡한 문제들을 내포하고 있다.</p>
<p><strong>1. 특수문자 처리의 딜레마</strong></p>
<p>문장 내에서 단어를 어떻게 구분할까? 느낌표나 어포스트로피 같은 특수문자가 들어갔을 때 문제가 발생한다.</p>
<pre><code>예시:
"I can't believe it!" 

처리 방법 1: ["I", "can't", "believe", "it!"]
처리 방법 2: ["I", "can", "'", "t", "believe", "it", "!"]
처리 방법 3: ["I", "cannot", "believe", "it"]</code></pre>
<p>어떤 방법이 정답일까? 각각 장단점이 있어 선택하기 어렵다.</p>
<p><strong>2. 동일한 의미, 다른 토큰화 결과</strong></p>
<p>의미가 동일한 문장들에 대해서 <strong>띄어쓰기 단위</strong>로 단어를 나눠본다면, 같은 의미이지만 컴퓨터는 다르게 취급한다.</p>
<pre><code>문장 1: "He is a hero."
문장 2: "He is a hero?"
문장 3: "He is a hero!"

토큰화 결과:
문장 1: ["He", "is", "a", "hero."]
문장 2: ["He", "is", "a", "hero?"]  
문장 3: ["He", "is", "a", "hero!"]</code></pre>
<p>의미가 동일함에도 전부 다른 결과를 얻는다. <code>hero</code> ≠ <code>hero?</code> ≠ <code>hero!</code> 왜냐하면 컴퓨터가 인식하기에는 전부 다른 단어들이기 때문이다.</p>
<p><strong>3. 특수문자 제거의 부작용</strong></p>
<p><strong>특수 문자</strong>가 토큰화에 방해가 된다고 해서 모든 특수 문자를 제거하는 규칙을 넣는다면?</p>
<pre><code>원본: "He has a Ph.D in computer science."
특수문자 제거 후: "He has a Ph D in computer science."

토큰화 결과:
원본: ["He", "has", "a", "Ph.D", "in", "computer", "science", "."]
제거 후: ["He", "has", "a", "Ph", "D", "in", "computer", "science"]</code></pre>
<p><code>Ph.D</code> ≠ <code>Ph D</code> - 특수 문자 제거로 인해 본래 의미를 상실하는 경우가 발생한다.</p>
<p><strong>4. 더 복잡한 사례들</strong></p>
<pre><code>- "U.S.A" vs "USA" vs "U S A"
- "don't" vs "do not" vs "dont"  
- "New York" vs "New-York" vs "NewYork"
- "COVID-19" vs "COVID 19" vs "COVID19"
- "machine-learning" vs "machine learning"</code></pre>
<p>각각은 같은 의미를 담고 있지만, 토큰화 결과는 완전히 다르다.</p>
<p><strong>5. 언어별 특수성</strong></p>
<pre><code>한국어:
"안녕하세요" vs "안녕 하세요" vs "안녕하 세요"
"먹었습니다" → ["먹", "었", "습니다"] vs ["먹었습니다"]

영어:
"state-of-the-art" → ["state", "of", "the", "art"] vs ["state-of-the-art"]</code></pre>
<p><strong>결론: 섬세한 규칙 설계의 필요성</strong></p>
<ul>
<li><p>단어 토큰화 작업은 상당히 섬세한 규칙을 설계해야만 한다.</p></li>
<li><p>단순히 공백으로 나누는 것으로는 해결되지 않으며, 다음과 같은 요소들을 종합적으로 고려해야 한다:</p></li>
<li><p><strong>도메인 특성</strong>: 의학, 법률, 소셜미디어 등</p></li>
<li><p><strong>언어 특성</strong>: 형태소, 문법 구조</p></li>
<li><p><strong>목적</strong>: 번역, 감정분석, 검색 등</p></li>
<li><p><strong>일관성</strong>: 동일한 규칙의 지속적 적용</p></li>
</ul>
<p>이러한 복잡성 때문에 최근에는 서브워드 토큰화 방법들이 주목받고 있다.</p>
</section>
</section>
<section id="서브워드-토큰화-subword-tokenization" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="서브워드-토큰화-subword-tokenization"><span class="header-section-number">2.2.3</span> 서브워드 토큰화 (Subword Tokenization)</h3>
<p>단어보다 작은 단위로 분할하는 방법으로, 최근 딥러닝 모델에서 널리 사용된다.</p>
<section id="byte-pair-encoding-bpe" class="level4" data-number="2.2.3.1">
<h4 data-number="2.2.3.1" class="anchored" data-anchor-id="byte-pair-encoding-bpe"><span class="header-section-number">2.2.3.1</span> Byte Pair Encoding (BPE)</h4>
<p>가장 빈번하게 등장하는 문자 쌍을 반복적으로 병합하는 방법이다.</p>
<p><strong>과정:</strong> 1. 모든 단어를 문자 단위로 분할 2. 가장 빈번한 문자 쌍 찾기 3. 해당 쌍을 하나의 토큰으로 병합 4. 원하는 어휘 크기까지 반복</p>
<p><strong>예시:</strong></p>
<pre><code>초기: ["l", "o", "w", "e", "s", "t"]
1단계: ["lo", "w", "e", "s", "t"]    # "l"+"o" 병합
2단계: ["low", "e", "s", "t"]        # "lo"+"w" 병합
3단계: ["low", "es", "t"]            # "e"+"s" 병합
최종: ["low", "est"]                 # "es"+"t" 병합</code></pre>
</section>
<section id="wordpiece" class="level4" data-number="2.2.3.2">
<h4 data-number="2.2.3.2" class="anchored" data-anchor-id="wordpiece"><span class="header-section-number">2.2.3.2</span> WordPiece</h4>
<p>Google에서 개발한 방법으로, BERT 등에서 사용된다.</p>
<p><strong>특징:</strong> - 가능도(likelihood)를 최대화하는 방향으로 병합 - “##” 접두사로 서브워드 표시</p>
<p><strong>예시:</strong></p>
<pre><code>"playing" → ["play", "##ing"]
"walked" → ["walk", "##ed"]</code></pre>
</section>
<section id="sentencepiece" class="level4" data-number="2.2.3.3">
<h4 data-number="2.2.3.3" class="anchored" data-anchor-id="sentencepiece"><span class="header-section-number">2.2.3.3</span> SentencePiece</h4>
<p>언어에 독립적인 토큰화 방법이다.</p>
<p><strong>특징:</strong> - 공백도 특수 문자로 처리 - 다양한 언어에 적용 가능 - 전처리 없이 raw text 직접 처리</p>
</section>
</section>
</section>
<section id="토큰화-도구와-라이브러리" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="토큰화-도구와-라이브러리"><span class="header-section-number">2.3</span> 토큰화 도구와 라이브러리</h2>
<ul>
<li>앞서 살펴본 토큰화의 복잡성과 다양한 예외 상황들을 고려할 때, 개발자가 직접 상세한 규칙을 만들어 구현하려 하지 말고 이미 잘 개발되고 검증된 패키지들을 사용하는 것이 현명한 접근법이다.</li>
<li>기존에 검증된 패키지로 처리 불가한 예외적인 부분들만 커스터마이징해서 처리하면 된다.</li>
</ul>
<section id="영어-토큰화-도구" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="영어-토큰화-도구"><span class="header-section-number">2.3.1</span> 영어 토큰화 도구</h3>
<section id="단어-토큰화-treebankwordtokenizer" class="level4" data-number="2.3.1.1">
<h4 data-number="2.3.1.1" class="anchored" data-anchor-id="단어-토큰화-treebankwordtokenizer"><span class="header-section-number">2.3.1.1</span> 단어 토큰화: TreebankWordTokenizer</h4>
<p>Penn Treebank 코퍼스의 토큰화 규칙을 따르는 검증된 도구이다.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> TreebankWordTokenizer</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> TreebankWordTokenizer()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"He said, </span><span class="ch">\"</span><span class="st">I can't believe it's working!</span><span class="ch">\"</span><span class="st"> Dr. Smith agreed."</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tokenizer.tokenize(text)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ['He', 'said', ',', '``', 'I', 'ca', "n't", 'believe', 'it', "'s", 'working', '!', "''", 'Dr.', 'Smith', 'agreed', '.']</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>장점:</strong> - 축약형을 적절히 분리 (“can’t” → “ca”, “n’t”) - 인용문 처리 (<code></code> 와 ’’ 로 변환) - 약어 보존 (“Dr.” 유지) - 수십 년간 검증된 규칙</p>
</section>
<section id="문장-토큰화-nltk-sentence-tokenizer" class="level4" data-number="2.3.1.2">
<h4 data-number="2.3.1.2" class="anchored" data-anchor-id="문장-토큰화-nltk-sentence-tokenizer"><span class="header-section-number">2.3.1.2</span> 문장 토큰화: NLTK Sentence Tokenizer</h4>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Dr. Smith earned his Ph.D. from MIT. He works at NASA. Contact him at john.doe@company.com."</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> sent_tokenize(text)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sentences)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ['Dr. Smith earned his Ph.D. from MIT.', 'He works at NASA.', 'Contact him at john.doe@company.com.']</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>특징:</strong> - 약어 목록을 내장하여 문맥 고려 - 이메일 주소 내 마침표 구분 - 다양한 언어 지원</p>
</section>
</section>
<section id="한국어-토큰화-도구" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="한국어-토큰화-도구"><span class="header-section-number">2.3.2</span> 한국어 토큰화 도구</h3>
<section id="문장-토큰화-kss-korean-sentence-splitter" class="level4" data-number="2.3.2.1">
<h4 data-number="2.3.2.1" class="anchored" data-anchor-id="문장-토큰화-kss-korean-sentence-splitter"><span class="header-section-number">2.3.2.1</span> 문장 토큰화: KSS (Korean Sentence Splitter)</h4>
<p>한국어 문장 분할에 특화된 고성능 라이브러리이다.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> kss</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"안녕하세요. 제 이메일은 user@domain.co.kr입니다. 연락 주세요!"</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> kss.split_sentences(text)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sentences)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ['안녕하세요.', '제 이메일은 user@domain.co.kr입니다.', '연락 주세요!']</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>장점:</strong> - 한국어 특화 규칙 - 이메일, URL 등 특수 패턴 인식 - 높은 정확도와 빠른 처리 속도</p>
</section>
<section id="단어-토큰화-konlpy-생태계" class="level4" data-number="2.3.2.2">
<h4 data-number="2.3.2.2" class="anchored" data-anchor-id="단어-토큰화-konlpy-생태계"><span class="header-section-number">2.3.2.2</span> 단어 토큰화: KoNLPy 생태계</h4>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> konlpy.tag <span class="im">import</span> Okt, Komoran, Hannanum</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Okt (Open Korean Text)</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>okt <span class="op">=</span> Okt()</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"아버지가방에들어가신다"</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> okt.morphs(text)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ['아버지', '가', '방', '에', '들어가', '신다']</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Komoran</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>komoran <span class="op">=</span> Komoran()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> komoran.morphs(text)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ['아버지', '가', '방', '에', '들어가', '시', 'ㄴ다']</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="다국어-및-고급-토큰화-도구" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="다국어-및-고급-토큰화-도구"><span class="header-section-number">2.3.3</span> 다국어 및 고급 토큰화 도구</h3>
<section id="spacy" class="level4" data-number="2.3.3.1">
<h4 data-number="2.3.3.1" class="anchored" data-anchor-id="spacy"><span class="header-section-number">2.3.3.1</span> spaCy</h4>
<p>산업 수준의 NLP 라이브러리</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 영어</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>nlp_en <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp_en(<span class="st">"Dr. Smith's email is john@company.com. He earned his Ph.D. in 1995."</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [sent.text <span class="cf">for</span> sent <span class="kw">in</span> doc.sents]</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> [token.text <span class="cf">for</span> token <span class="kw">in</span> doc]</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 한국어 (spacy-korean)</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>nlp_ko <span class="op">=</span> spacy.load(<span class="st">"ko_core_news_sm"</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp_ko(<span class="st">"안녕하세요. 저는 데이터 과학자입니다."</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [sent.text <span class="cf">for</span> sent <span class="kw">in</span> doc.sents]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>특징:</strong> - 다양한 언어 지원 - 빠른 처리 속도 - 통합된 NLP 파이프라인 - 산업 환경에 최적화</p>
</section>
<section id="transformers-토크나이저" class="level4" data-number="2.3.3.2">
<h4 data-number="2.3.3.2" class="anchored" data-anchor-id="transformers-토크나이저"><span class="header-section-number">2.3.3.2</span> Transformers 토크나이저</h4>
<p>최신 딥러닝 모델에서 사용되는 서브워드 토큰화이다.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># BERT 토크나이저</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"bert-base-uncased"</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Hello, I can't believe it's working!"</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tokenizer.tokenize(text)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ['hello', ',', 'i', 'can', "'", 't', 'believe', 'it', "'", 's', 'working', '!']</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 한국어 BERT</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>tokenizer_ko <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"klue/bert-base"</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"안녕하세요. 한국어 토큰화입니다."</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tokenizer_ko.tokenize(text)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co"># ['안녕', '##하세요', '.', '한국어', '토큰', '##화', '##입니다', '.']</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="도메인별-특화-도구" class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="도메인별-특화-도구"><span class="header-section-number">2.3.4</span> 도메인별 특화 도구</h3>
<section id="소셜미디어-tweettokenizer" class="level4" data-number="2.3.4.1">
<h4 data-number="2.3.4.1" class="anchored" data-anchor-id="소셜미디어-tweettokenizer"><span class="header-section-number">2.3.4.1</span> 소셜미디어: TweetTokenizer</h4>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> TweetTokenizer</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>tknzr <span class="op">=</span> TweetTokenizer(strip_handles<span class="op">=</span><span class="va">True</span>, reduce_len<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"@user This is sooooo cool! 😊 http://example.com #NLP"</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> tknzr.tokenize(text)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokens)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ['This', 'is', 'sooo', 'cool', '!', '😊', 'http://example.com', '#NLP']</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="의학과학-텍스트-scispacy" class="level4" data-number="2.3.4.2">
<h4 data-number="2.3.4.2" class="anchored" data-anchor-id="의학과학-텍스트-scispacy"><span class="header-section-number">2.3.4.2</span> 의학/과학 텍스트: SciSpaCy</h4>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scispacy</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_sci_sm"</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"The patient has a temperature of 101.5°F. Administer 2.5mg of medication."</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(text)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>sentences <span class="op">=</span> [sent.text <span class="cf">for</span> sent <span class="kw">in</span> doc.sents]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="언어별-권장-도구-조합" class="level3" data-number="2.3.5">
<h3 data-number="2.3.5" class="anchored" data-anchor-id="언어별-권장-도구-조합"><span class="header-section-number">2.3.5</span> 언어별 권장 도구 조합</h3>
<section id="영어" class="level4" data-number="2.3.5.1">
<h4 data-number="2.3.5.1" class="anchored" data-anchor-id="영어"><span class="header-section-number">2.3.5.1</span> 영어</h4>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 실용적인 영어 처리 파이프라인</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize, TreebankWordTokenizer</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_english_text(text):</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. 문장 분할</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    sentences <span class="op">=</span> sent_tokenize(text)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. 단어 토큰화</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>    word_tokenizer <span class="op">=</span> TreebankWordTokenizer()</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    tokenized_sentences <span class="op">=</span> []</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>        words <span class="op">=</span> word_tokenizer.tokenize(sentence)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>        tokenized_sentences.append(words)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sentences, tokenized_sentences</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="한국어" class="level4" data-number="2.3.5.2">
<h4 data-number="2.3.5.2" class="anchored" data-anchor-id="한국어"><span class="header-section-number">2.3.5.2</span> 한국어</h4>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 실용적인 한국어 처리 파이프라인</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> kss</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> konlpy.tag <span class="im">import</span> Okt</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_korean_text(text):</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1. 문장 분할</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    sentences <span class="op">=</span> kss.split_sentences(text)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2. 형태소 분석</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    okt <span class="op">=</span> Okt()</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    tokenized_sentences <span class="op">=</span> []</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>        morphs <span class="op">=</span> okt.morphs(sentence)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        tokenized_sentences.append(morphs)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sentences, tokenized_sentences</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="성능과-정확도-비교" class="level3" data-number="2.3.6">
<h3 data-number="2.3.6" class="anchored" data-anchor-id="성능과-정확도-비교"><span class="header-section-number">2.3.6</span> 성능과 정확도 비교</h3>
<section id="처리-속도-상대적-비교" class="level4" data-number="2.3.6.1">
<h4 data-number="2.3.6.1" class="anchored" data-anchor-id="처리-속도-상대적-비교"><span class="header-section-number">2.3.6.1</span> 처리 속도 (상대적 비교)</h4>
<ul>
<li><strong>spaCy</strong>: 매우 빠름 (산업용)</li>
<li><strong>KSS</strong>: 빠름 (한국어 특화)</li>
<li><strong>TreebankWordTokenizer</strong>: 보통</li>
<li><strong>KoNLPy</strong>: 보통-느림 (정확도 높음)</li>
</ul>
</section>
<section id="정확도-도메인별" class="level4" data-number="2.3.6.2">
<h4 data-number="2.3.6.2" class="anchored" data-anchor-id="정확도-도메인별"><span class="header-section-number">2.3.6.2</span> 정확도 (도메인별)</h4>
<ul>
<li><strong>일반 텍스트</strong>: spaCy, NLTK</li>
<li><strong>소셜미디어</strong>: TweetTokenizer</li>
<li><strong>학술/의학</strong>: SciSpaCy</li>
<li><strong>한국어</strong>: KSS + KoNLPy</li>
</ul>
</section>
</section>
<section id="선택-기준" class="level3" data-number="2.3.7">
<h3 data-number="2.3.7" class="anchored" data-anchor-id="선택-기준"><span class="header-section-number">2.3.7</span> 선택 기준</h3>
<section id="프로젝트-요구사항별-선택" class="level4" data-number="2.3.7.1">
<h4 data-number="2.3.7.1" class="anchored" data-anchor-id="프로젝트-요구사항별-선택"><span class="header-section-number">2.3.7.1</span> 프로젝트 요구사항별 선택</h4>
<ol type="1">
<li><strong>프로토타이핑</strong>: NLTK (간편함)</li>
<li><strong>제품 환경</strong>: spaCy (속도와 안정성)</li>
<li><strong>한국어 중심</strong>: KSS + KoNLPy</li>
<li><strong>딥러닝 모델</strong>: Transformers 토크나이저</li>
<li><strong>특수 도메인</strong>: 도메인별 특화 도구</li>
</ol>
</section>
<section id="실무-권장사항" class="level4" data-number="2.3.7.2">
<h4 data-number="2.3.7.2" class="anchored" data-anchor-id="실무-권장사항"><span class="header-section-number">2.3.7.2</span> 실무 권장사항</h4>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 범용적인 다국어 처리 환경 구축</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> kss</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UniversalTokenizer:</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.en_nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bert_tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">"bert-base-multilingual-cased"</span>)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> tokenize_sentences(<span class="va">self</span>, text, language<span class="op">=</span><span class="st">'auto'</span>):</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> language <span class="op">==</span> <span class="st">'ko'</span>:</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> kss.split_sentences(text)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> language <span class="op">==</span> <span class="st">'en'</span>:</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>            doc <span class="op">=</span> <span class="va">self</span>.en_nlp(text)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> [sent.text <span class="cf">for</span> sent <span class="kw">in</span> doc.sents]</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 자동 언어 감지 로직</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._auto_detect_and_tokenize(text)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> tokenize_for_model(<span class="va">self</span>, text):</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.bert_tokenizer.tokenize(text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="결론" class="level3" data-number="2.3.8">
<h3 data-number="2.3.8" class="anchored" data-anchor-id="결론"><span class="header-section-number">2.3.8</span> 결론</h3>
<ul>
<li>토큰화는 복잡한 언어학적 문제이므로, 수년간 연구되고 검증된 도구들을 활용하는 것이 가장 효율적이고 안정적인 접근법이다.</li>
<li>각 도구의 특성을 이해하고 프로젝트의 요구사항에 맞는 적절한 조합을 선택하는 것이 성공적인 NLP 프로젝트의 첫걸음이다.</li>
</ul>
</section>
</section>
<section id="토큰화의-도전과제" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="토큰화의-도전과제"><span class="header-section-number">2.4</span> 토큰화의 도전과제</h2>
<section id="언어별-특성" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="언어별-특성"><span class="header-section-number">2.4.1</span> 언어별 특성</h3>
<p><strong>한국어:</strong> - 어미 변화가 복잡 - 띄어쓰기 규칙이 일관되지 않음 - 복합어 처리 어려움</p>
<p><strong>영어:</strong> - 축약형 처리 (예: “don’t”, “I’m”) - 하이픈으로 연결된 단어 - 대소문자 처리</p>
</section>
<section id="도메인별-특수성" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="도메인별-특수성"><span class="header-section-number">2.4.2</span> 도메인별 특수성</h3>
<p><strong>소셜미디어:</strong> - 이모티콘과 이모지 - 해시태그와 멘션 - 비표준 언어 사용</p>
<p><strong>의학/법률 텍스트:</strong> - 전문 용어 - 약어와 기호 - 정확성이 중요</p>
</section>
<section id="vocabulary" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="vocabulary"><span class="header-section-number">2.4.3</span> Vocabulary</h3>
<ul>
<li><strong>Vocabulary</strong>란 텍스트를 토큰화하고, 고유한 토큰들로 이루어진 집합으로 쉽게 말해 기계가 알고있는 단어들의 집합이다.</li>
<li>기계가 텍스트를 처리하기 위해서는 이를 숫자 형태로 변환하는 과정이 필요하다.</li>
<li>이를 위해 먼저 텍스트를 토큰화하고, 토큰을 숫자로 매핑하는 과정이 필요하다.
<ol type="1">
<li>텍스트를 의미 있는 단위인 토큰으로 분할하고(토큰화),</li>
<li>각 고유 토큰에 숫자(정수 인덱스 등)를 부여하여 어휘집(Vocabulary)을 구축한 후,</li>
<li>이 어휘집을 바탕으로 원래의 토큰 시퀀스를 숫자 시퀀스로 변환하는 단계를 포함합니다.</li>
</ol></li>
<li>이렇게 매핑된 숫자를 통해 기계가 텍스트를 이해할 수 있도록 한다.</li>
</ul>
</section>
<section id="out-of-vocabulary-oov-문제" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="out-of-vocabulary-oov-문제"><span class="header-section-number">2.4.4</span> Out-of-Vocabulary (OOV) 문제</h3>
<p><strong>문제:</strong> - 모델이 학습한 어휘집(Vocabulary)에 포함되지 않은 단어가 입력으로 들어올 때 발생 - 이는 특히 다음과 같은 경우에 문제가 된다: - <strong>새로운 단어</strong>: 신조어, 기술 용어, 브랜드 이름 등 - <strong>오타 및 비표준 표현</strong>: 사용자의 입력 실수나 비공식적인 언어 사용 - <strong>다양한 언어적 변형</strong>: 복합어, 축약형, 방언 등 - OOV 단어가 포함된 문장을 제대로 이해하지 못하거나, 잘못된 예측을 할 수 있다.</p>
<p><strong>해결 방안:</strong> - <strong>서브워드 토큰화 사용</strong> - 최근 가장 널리 사용되는 방법 중 하나로, 다양한 자연어 처리 모델에서 효과적으로 활용되고 있다. - 이 방법들은 단어를 더 작은 의미 단위로 분할하여 처리하므로, 새로운 단어가 등장하더라도 부분적으로 이해할 수 있다. - <strong>문자 단위 처리</strong> - 단어를 문자 단위로 분할하여 처리하는 방법도 있다. - 이는 모든 단어를 개별 문자로 분해하여 처리하므로, OOV 문제를 근본적으로 해결할 수 있다. - 그러나 이 방법은 문맥 이해가 어려워질 수 있다. - <strong>사전 확장</strong> - 지속적으로 어휘집을 업데이트하여 새로운 단어를 포함시키는 방법. - 이는 시간이 지남에 따라 어휘집을 확장하여 OOV 문제를 줄일 수 있다.</p>
</section>
</section>
<section id="평가-메트릭" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="평가-메트릭"><span class="header-section-number">2.5</span> 평가 메트릭</h2>
<section id="어휘-크기-vocabulary-size" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="어휘-크기-vocabulary-size"><span class="header-section-number">2.5.1</span> 어휘 크기 (Vocabulary Size)</h3>
<ul>
<li>모델의 메모리 사용량과 직결</li>
<li>너무 크면 비효율적, 너무 작으면 표현력 부족</li>
</ul>
</section>
<section id="압축률-compression-rate" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="압축률-compression-rate"><span class="header-section-number">2.5.2</span> 압축률 (Compression Rate)</h3>
<ul>
<li>원본 텍스트 대비 토큰 수의 비율</li>
<li>효율적인 표현을 위해 중요</li>
</ul>
</section>
<section id="의미-보존도" class="level3" data-number="2.5.3">
<h3 data-number="2.5.3" class="anchored" data-anchor-id="의미-보존도"><span class="header-section-number">2.5.3</span> 의미 보존도</h3>
<ul>
<li>토큰화 후에도 원래 의미가 유지되는 정도</li>
<li>정성적 평가가 주로 사용됨</li>
</ul>
</section>
</section>
<section id="실제-적용-사례" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="실제-적용-사례"><span class="header-section-number">2.6</span> 실제 적용 사례</h2>
<section id="기계-번역" class="level3" data-number="2.6.1">
<h3 data-number="2.6.1" class="anchored" data-anchor-id="기계-번역"><span class="header-section-number">2.6.1</span> 기계 번역</h3>
<ul>
<li>다국어 처리를 위한 공통 서브워드 어휘</li>
<li>언어 간 토큰 정렬</li>
</ul>
</section>
<section id="감정-분석" class="level3" data-number="2.6.2">
<h3 data-number="2.6.2" class="anchored" data-anchor-id="감정-분석"><span class="header-section-number">2.6.2</span> 감정 분석</h3>
<ul>
<li>감정을 나타내는 키워드 보존</li>
<li>이모티콘과 특수 문자 처리</li>
</ul>
</section>
<section id="질의응답-시스템" class="level3" data-number="2.6.3">
<h3 data-number="2.6.3" class="anchored" data-anchor-id="질의응답-시스템"><span class="header-section-number">2.6.3</span> 질의응답 시스템</h3>
<ul>
<li>질문과 답변의 일관된 토큰화</li>
<li>개체명 인식과의 연계</li>
</ul>
</section>
</section>
<section id="최신-동향" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="최신-동향"><span class="header-section-number">2.7</span> 최신 동향</h2>
<section id="다국어-토큰화" class="level3" data-number="2.7.1">
<h3 data-number="2.7.1" class="anchored" data-anchor-id="다국어-토큰화"><span class="header-section-number">2.7.1</span> 다국어 토큰화</h3>
<ul>
<li>mBERT, XLM-R 등 다국어 모델</li>
<li>언어별 특성을 고려한 통합 토큰화</li>
</ul>
</section>
<section id="적응형-토큰화" class="level3" data-number="2.7.2">
<h3 data-number="2.7.2" class="anchored" data-anchor-id="적응형-토큰화"><span class="header-section-number">2.7.2</span> 적응형 토큰화</h3>
<ul>
<li>도메인별 최적화</li>
<li>동적 어휘 확장</li>
</ul>
</section>
<section id="신경망-기반-토큰화" class="level3" data-number="2.7.3">
<h3 data-number="2.7.3" class="anchored" data-anchor-id="신경망-기반-토큰화"><span class="header-section-number">2.7.3</span> 신경망 기반 토큰화</h3>
<ul>
<li>학습 가능한 토큰화</li>
<li>End-to-end 학습</li>
</ul>
</section>
</section>
<section id="결론-1" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="결론-1"><span class="header-section-number">2.8</span> 결론</h2>
<ul>
<li>토큰화는 자연어 처리의 첫 단계이자 전체 성능을 좌우하는 중요한 과정.</li>
<li>언어의 특성과 도메인의 요구사항을 고려하여 적절한 토큰화 방법을 선택하는 것이 중요.</li>
<li>최근에는 서브워드 토큰화가 주류가 되었지만, 여전히 각 방법의 장단점을 이해하고 상황에 맞게 적용하는 것이 필요.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("kk3225\.netlify\.app");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>