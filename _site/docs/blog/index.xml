<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kwangmin Kim</title>
<link>kk3225.netlify.app/docs/blog/</link>
<atom:link href="kk3225.netlify.app/docs/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>blog</description>
<generator>quarto-1.4.543</generator>
<lastBuildDate>Tue, 31 Dec 2999 15:00:00 GMT</lastBuildDate>
<item>
  <title>Blog Content List</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/content_list.html</link>
  <description><![CDATA[ 




<section id="contents" class="level1">

<ul>
<li><a href="../posts/Surveilance/guide_map/_index.qmd">Data Governance</a></li>
<li><a href="../posts/Engineering/guide_map/_index.qmd">Engineering</a></li>
<li><a href="../posts/Surveilance/guide_map/_index.qmd">Surveilance</a></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Scalars are denoted with a lower-case letter (ex a ) or a non-bolded lower-case Greek letter (ex <img src="https://latex.codecogs.com/png.latex?%5Calpha"> ).</li>
<li>Vectors are denoted using a bold-faced lower-case letter (ex <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20a">).</li>
<li>Matrices are denoted using a bold-faced upper-case letter (ex <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A">, <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5Cphi">) or a bold-faced upper-case Greek letter (ex <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20%5CPhi">).</li>
<li>Tensors are denoted using a bold-faced upper-case letter with multiple subscripts or superscripts, indicating the number of indices and the dimensions of the tensor along each axis.
<ul>
<li>A second-order tensor (also known as a matrix) <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A"> with dimensions <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m"> can be represented as: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A_%7Bij%7D"> where <img src="https://latex.codecogs.com/png.latex?i%20=%201,%5Cdots,m"> and <img src="https://latex.codecogs.com/png.latex?j%20=%201,%5Cdots,n">, which are the indices that run over the rows and columns of the matrix, respectively.</li>
<li>A third-order tensor <img src="https://latex.codecogs.com/png.latex?T"> with dimensions <img src="https://latex.codecogs.com/png.latex?n%20%5Ctimes%20m%20%5Ctimes%20p"> can be represented as: <img src="https://latex.codecogs.com/png.latex?%5Cmathbf%20A_%7Bijk%7D"> where <img src="https://latex.codecogs.com/png.latex?i%20=%201,%5Cdots,m">, <img src="https://latex.codecogs.com/png.latex?j%20=%201,%5Cdots,n">, which are <img src="https://latex.codecogs.com/png.latex?i">, and <img src="https://latex.codecogs.com/png.latex?k%20=%201,%5Cdots,p"> <img src="https://latex.codecogs.com/png.latex?j">, and <img src="https://latex.codecogs.com/png.latex?k">, which are the indices that run over the three dimensions of the tensor.</li>
</ul></li>
</ul>
</div>
</div>


</section>

 ]]></description>
  <guid>kk3225.netlify.app/docs/blog/posts/content_list.html</guid>
  <pubDate>Tue, 31 Dec 2999 15:00:00 GMT</pubDate>
</item>
<item>
  <title>VSCode 환경설정</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/RAG/2-3.settings_VScode_JASON.html</link>
  <description><![CDATA[ 




<section id="vs-code-환경설정-optional" class="level1" data-number="1">

<ul>
<li>안해도됨</li>
<li><code>ctrl + shift + p</code>: ‘Preferences: Open User Settings (JSON)’
<ul>
<li>아래 내용 추가</li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-2">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">에디터</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">관련</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.fontSize"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">에디터의</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">기본</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">글꼴</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">크기를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">16으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-4">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.fontVariations"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">글꼴</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">스타일</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">변형을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">사용하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.defaultFormatter"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ms-python.black-formatter"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">에디터의</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">기본</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">코드</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">포맷터로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Black을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">지정</span></span>
<span id="cb1-6">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.autoClosingBrackets"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"never"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">괄호</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">닫기</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">기능을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">사용하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-7">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.autoClosingQuotes"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"never"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">인용</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">부호</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">닫기</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">기능을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">사용하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-8">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.inlineSuggest.enabled"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">인라인</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">완성을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">활성화</span></span>
<span id="cb1-9">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.parameterHints.enabled"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">함수</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">호출</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">파라미터</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">정보를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">보여주는</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">힌트를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">활성화</span></span>
<span id="cb1-10">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.quickSuggestions"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-11">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"other"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">기타</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">텍스트에서는</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">활성화</span></span>
<span id="cb1-12">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"comments"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">주석에서는</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">비활성화</span></span>
<span id="cb1-13">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"strings"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">문자열</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">내에서는</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">비활성화</span></span>
<span id="cb1-14">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb1-15">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.quickSuggestionsDelay"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">빠른</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안이</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">나타나기까지의</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">지연</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시간(밀리초)을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-16">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.suggestOnTriggerCharacters"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">트리거</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">문자</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">입력</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">표시</span></span>
<span id="cb1-17">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.suggest.localityBonus"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">커서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">근처에</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">나타나는</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">단어를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">우선적으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안</span></span>
<span id="cb1-18">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.wordBasedSuggestions"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"matchingDocuments"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">문서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">내</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">매칭된</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">단어</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">기반의</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">활성화</span></span>
<span id="cb1-19">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.acceptSuggestionOnCommitCharacter"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">커밋</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">문자에서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">수락</span></span>
<span id="cb1-20">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.acceptSuggestionOnEnter"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"on"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Enter</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">키를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">누를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">때</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">제안을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">수락</span></span>
<span id="cb1-21"></span>
<span id="cb1-22">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">터미널</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-23">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"terminal.integrated.fontSize"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">터미널</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">내부의</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">글꼴</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">크기를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">20으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-24">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"terminal.integrated.inheritEnv"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">터미널이</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시스템</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">환경</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">변수를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">상속받지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않도록</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-25"></span>
<span id="cb1-26">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Git</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-27">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"git.autofetch"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Git</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">저장소를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">fetch하는</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">기능을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">활성화</span></span>
<span id="cb1-28"></span>
<span id="cb1-29">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">마크다운</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-30">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"markdown.preview.fontSize"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">마크다운</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">미리보기에서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">사용할</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">글꼴</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">크기를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">20으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-31">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"markdown.styles"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">마크다운</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">스타일시트</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">URL을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-32">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://use.fontawesome.com/releases/v5.7.1/css/all.css"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-33">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"markdown-stype.css"</span></span>
<span id="cb1-34">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-35"></span>
<span id="cb1-36">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">소스</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">코드</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">관리</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-37">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"scm.inputFontSize"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">소스</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">코드</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">관리</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">입력</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">필드의</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">글꼴</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">크기를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">20으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-38"></span>
<span id="cb1-39">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">워크벤치</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-40">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"workbench.startupEditor"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"none"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">VS</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Code</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시작</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">에디터를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">열지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않도록</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-41"></span>
<span id="cb1-42">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">보안</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-43">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"security.workspace.trust.untrustedFiles"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"open"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">신뢰되지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않은</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">파일을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">열</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">때</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">염</span></span>
<span id="cb1-44"></span>
<span id="cb1-45">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">탐색기</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-46">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"explorer.confirmDelete"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">파일을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">삭제할</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">때</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">확인</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">메시지를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">표시하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-47">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"explorer.compactFolders"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">탐색기에서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">폴더를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">컴팩트하게</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">표시하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-48">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"explorer.confirmDragAndDrop"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">드래그</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">앤</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">드롭을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">할</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">때</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">확인</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">메시지를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">표시하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-49">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"explorer.confirmPasteNative"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">네이티브</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">파일을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">붙여넣을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">때</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">확인</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">메시지를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">표시하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-50"></span>
<span id="cb1-51">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">파일</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-52">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"files.autoSave"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"afterDelay"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">파일을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">변경</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">후</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">일정</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시간이</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">지나면</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">저장</span></span>
<span id="cb1-53"></span>
<span id="cb1-54">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">브레드크럼</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-55">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"breadcrumbs.enabled"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">파일</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">경로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">내비게이션을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">비활성화</span></span>
<span id="cb1-56"></span>
<span id="cb1-57">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Jupyter</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-58">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"jupyter.themeMatplotlibPlots"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Jupyter에서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Matplotlib</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">플롯을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">현재</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">테마에</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">맞게</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">색상화</span></span>
<span id="cb1-59">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"jupyter.askForKernelRestart"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">false</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Jupyter</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">커널</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">재시작을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">요청하지</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">않음</span></span>
<span id="cb1-60">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"jupyter.widgetScriptSources"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">[</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">Jupyter</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">위젯을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">위한</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">스크립트</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">소스를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-61">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"jsdelivr.com"</span><span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-62">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"unpkg.com"</span></span>
<span id="cb1-63">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">]</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-64"></span>
<span id="cb1-65">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">노트북</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-66">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"notebook.output.wordWrap"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">노트북</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">출력에서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">줄바꿈을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">활성화</span></span>
<span id="cb1-67">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"notebook.formatOnSave.enabled"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">노트북</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">저장</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">시</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">자동으로</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">포맷</span></span>
<span id="cb1-68">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"notebook.output.scrolling"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">노트북</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">출력을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">스크롤</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">가능하게</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-69">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"notebook.lineNumbers"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"on"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">노트북에서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">줄</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">번호를</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">표시</span></span>
<span id="cb1-70"></span>
<span id="cb1-71">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">CSS</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span></span>
<span id="cb1-72">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"css.lint.emptyRules"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span>  <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">CSS</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">린트에서</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">빈</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">규칙을</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">무시</span></span>
<span id="cb1-73"></span>
<span id="cb1-74">    <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">//</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">언어별</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">설정</span> <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(Python)</span></span>
<span id="cb1-75">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"[python]"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb1-76">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.defaultFormatter"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ms-python.black-formatter"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-77">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.formatOnType"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-78">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.formatOnSave"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-79">        <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">"editor.parameterHints.enabled"</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">:</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">true</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-80">    <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb1-81"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">}</span></span></code></pre></div></li>
<li>extension 설치
<ul>
<li>Black Formatter</li>
<li>Ruff Linter</li>
</ul></li>
</ul>


</section>

 ]]></description>
  <category>RAG</category>
  <guid>kk3225.netlify.app/docs/blog/posts/RAG/2-3.settings_VScode_JASON.html</guid>
  <pubDate>Wed, 04 Jun 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>LangChain 소개</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/RAG/3-0.LangChain_intro.html</link>
  <description><![CDATA[ 




<section id="langchain-소개" class="level1" data-number="1">

<section id="langchain이란" class="level2" data-number="1.1">

<ul>
<li>LangChain은 대규모 언어 모델(LLM)을 활용한 애플리케이션을 쉽게 개발할 수 있도록 도와주는 오픈소스 프레임워크다.</li>
<li>똑똑한 LLM을 제대로 사용하기 위해선 Prompt에 질문을 잘 입력해야하지만 어렵거나 많은 대화를 주고 받아야한다.</li>
<li>LangChain은 이러한 문제를 해결하여 원하는 비즈니스 로직을 구현하기 위한 프레임워크다.
<ul>
<li>자동화 또는 workflow들을 chain으로 엮어 관리</li>
</ul></li>
<li>예를 들어, 문서를 넣고 임베딩하여 벡터 데이터베이스에 저장하고, 검색하여 원하는 정보를 추출하는 것을 자동화 할 수 있다.
<ul>
<li>langchain에서는 이 과정이 굉장히 편하게 구현될 수 있다.</li>
<li>문서의 어떤 부분이 입력부분으로 사용되는지</li>
<li>프롬프트는 어떻게 작성되었는지</li>
<li>출력은 어떻게 되는지를 세세하게 관찰 및 관리하여 성능을 높혀야한다.</li>
</ul></li>
<li>Langchain의 규모는 점점 커지고 있고 많은 DBMS 기업들과 같은 대형 기업들이 Langchain 개발사와 협력하고 있다.</li>
<li>여러 지원 프로그램을 사용해서 더 쉽게 사용할 수 있다.
<ul>
<li>LangSmith: 추적 기능 서비스</li>
<li>LangGraph: 다중 협업 관리 서비스</li>
<li>LangServe: 배포를 쉽게 할 수 있는 서비스</li>
</ul></li>
</ul>
<section id="주요-특징" class="level3" data-number="1.1.1">

<ul>
<li><strong>모듈화된 구조</strong>: 각 기능을 독립적인 모듈로 제공하여 필요한 부분만 선택적으로 사용 가능</li>
<li><strong>다양한 LLM 지원</strong>: OpenAI GPT, Anthropic Claude, Google PaLM 등 다양한 LLM 모델 지원</li>
<li><strong>체인 구성</strong>: 여러 작업을 연결하여 복잡한 워크플로우 구성 가능</li>
<li><strong>메모리 관리</strong>: 대화 기록 및 컨텍스트 관리 기능 제공</li>
<li><strong>외부 도구 연동</strong>: 검색 엔진, 데이터베이스, API 등 외부 도구와의 연동 지원</li>
</ul>
</section>
</section>
<section id="langchain의-핵심-구성-요소" class="level2" data-number="1.2">

<section id="models-모델" class="level3" data-number="1.2.1">

<ul>
<li><strong>LLMs</strong>: 텍스트 입력을 받아 텍스트를 생성하는 모델</li>
<li><strong>Chat Models</strong>: 대화형 인터페이스를 제공하는 모델</li>
<li><strong>Text Embedding Models</strong>: 텍스트를 벡터로 변환하는 모델</li>
</ul>
</section>
<section id="prompts-프롬프트" class="level3" data-number="1.2.2">

<ul>
<li><strong>Prompt Templates</strong>: 동적으로 프롬프트를 생성하는 템플릿</li>
<li><strong>Example Selectors</strong>: 상황에 맞는 예시를 선택하는 도구</li>
<li><strong>Output Parsers</strong>: LLM 출력을 구조화된 형태로 파싱</li>
</ul>
</section>
<section id="chains-체인" class="level3" data-number="1.2.3">

<ul>
<li><strong>Simple Chains</strong>: 단순한 작업 연결</li>
<li><strong>Sequential Chains</strong>: 순차적 작업 실행</li>
<li><strong>Router Chains</strong>: 조건에 따른 분기 처리</li>
</ul>
</section>
<section id="memory-메모리" class="level3" data-number="1.2.4">

<ul>
<li><strong>Conversation Buffer Memory</strong>: 대화 기록 저장</li>
<li><strong>Conversation Summary Memory</strong>: 대화 요약 저장</li>
<li><strong>Vector Store Memory</strong>: 벡터 기반 메모리 저장</li>
</ul>
</section>
<section id="agents-에이전트" class="level3" data-number="1.2.5">

<ul>
<li><strong>Tool-using Agents</strong>: 외부 도구를 사용하는 에이전트</li>
<li><strong>Conversational Agents</strong>: 대화형 에이전트</li>
<li><strong>Custom Agents</strong>: 사용자 정의 에이전트</li>
</ul>
</section>
</section>
<section id="langchain의-장점" class="level2" data-number="1.3">

<section id="개발-생산성-향상" class="level3" data-number="1.3.1">

<ul>
<li>복잡한 LLM 애플리케이션을 간단한 코드로 구현 가능</li>
<li>재사용 가능한 컴포넌트 제공</li>
<li>풍부한 문서와 예제 제공</li>
</ul>
</section>
<section id="확장성" class="level3" data-number="1.3.2">

<ul>
<li>모듈화된 구조로 필요에 따라 기능 추가/제거 가능</li>
<li>다양한 LLM 모델과 외부 서비스 연동 지원</li>
<li>커스텀 컴포넌트 개발 가능</li>
</ul>
</section>
<section id="유연성" class="level3" data-number="1.3.3">

<ul>
<li>다양한 사용 사례에 맞는 템플릿 제공</li>
<li>체인을 통한 복잡한 워크플로우 구성</li>
<li>조건부 로직 및 분기 처리 지원</li>
</ul>
</section>
</section>
<section id="주요-사용-사례" class="level2" data-number="1.4">

<section id="챗봇-개발" class="level3" data-number="1.4.1">

<ul>
<li>고객 서비스 챗봇</li>
<li>개인 비서 챗봇</li>
<li>도메인 특화 Q&amp;A 시스템</li>
</ul>
</section>
<section id="문서-분석" class="level3" data-number="1.4.2">

<ul>
<li>문서 요약</li>
<li>정보 추출</li>
<li>문서 검색 및 질의응답</li>
</ul>
</section>
<section id="코드-생성" class="level3" data-number="1.4.3">

<ul>
<li>자동 코드 생성</li>
<li>코드 리뷰 및 최적화</li>
<li>기술 문서 생성</li>
</ul>
</section>
<section id="데이터-분석" class="level3" data-number="1.4.4">

<ul>
<li>자연어 기반 데이터 쿼리</li>
<li>보고서 자동 생성</li>
<li>인사이트 추출</li>
</ul>
</section>
</section>
<section id="langchain-vs-다른-프레임워크" class="level2" data-number="1.5">

<section id="langchain의-차별점" class="level3" data-number="1.5.1">

<ul>
<li><strong>포괄적인 생태계</strong>: LLM 애플리케이션 개발에 필요한 모든 도구 제공</li>
<li><strong>활발한 커뮤니티</strong>: 지속적인 업데이트와 풍부한 리소스</li>
<li><strong>실용적 접근</strong>: 실제 프로덕션 환경에서 사용 가능한 안정성</li>
<li><strong>교육 자료</strong>: 체계적인 학습 자료와 튜토리얼 제공</li>
</ul>
</section>
</section>
<section id="시작하기-전-준비사항" class="level2" data-number="1.6">

<section id="필수-지식" class="level3" data-number="1.6.1">

<ul>
<li>Python 기본 문법</li>
<li>API 사용 경험</li>
<li>기본적인 머신러닝 개념</li>
</ul>
</section>
<section id="권장-지식" class="level3" data-number="1.6.2">

<ul>
<li>자연어 처리 기초</li>
<li>벡터 데이터베이스 개념</li>
<li>클라우드 서비스 사용 경험</li>
</ul>
</section>
<section id="개발-환경" class="level3" data-number="1.6.3">

<ul>
<li>Python 3.8 이상</li>
<li>OpenAI API 키 (또는 다른 LLM 서비스 키)</li>
<li>적절한 IDE (VSCode, PyCharm 등)</li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>RAG</category>
  <guid>kk3225.netlify.app/docs/blog/posts/RAG/3-0.LangChain_intro.html</guid>
  <pubDate>Wed, 04 Jun 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>LangSmith 환경설정</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/RAG/2-2.settings_LangSmith.html</link>
  <description><![CDATA[ 




<section id="langsmith-추적-환경설정" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> LangSmith 추적 환경설정</h1>
<ul>
<li>LangSmith는 LLM 애플리케이션 개발, 모니터링 및 테스트 를 위한 플랫폼</li>
<li>프로젝트나 LangChain 학습자들은 LangSmith를 설정 후 진행하는 것을 추천</li>
</ul>
<section id="langsmith-의-추적기능" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="langsmith-의-추적기능"><span class="header-section-number">1.1</span> LangSmith 의 추적기능</h2>
<ul>
<li>추적은 LLM 애플리케이션의 동작을 이해하기 위한 강력한 도구</li>
<li>LangSmith는 LangChain 사용 여부와 관계없이 동급 최고의 추적 기능을 제공</li>
<li>추적은 다음과 같은 문제를 추적하는 데 도움이 될 수 있음
<ul>
<li>예상치 못한 최종 결과</li>
<li>에이전트가 루핑되는 이유</li>
<li>체인이 예상보다 느린 이유</li>
<li>에이전트가 각 단계에서 사용한 토큰 수</li>
<li>프로젝트 단위 추적
<ul>
<li>프로젝트 단위로 실행 카운트, Error 발생률, 토큰 사용량, 과금 정보등을 확인</li>
</ul></li>
</ul></li>
<li><a href="https://smith.langchain.com/">Lang Smith, https://smith.langchain.com/</a></li>
<li>회원 가입 및 API 키 발급
<ul>
<li><p>LangSmith API Key 발급</p>
<ul>
<li>https://smith.langchain.com/ 으로 접속하여 회원가입을 진행</li>
<li>가입후 이메일 인증하는 절차를 진행</li>
<li>왼쪽 톱니바퀴(Setting) - 가운데 “Personal” - “Create API Key” 를 눌러 API 키를 발급</li>
</ul></li>
<li><p>.env 에 LangSmith 키 설정</p>
<ul>
<li>먼저, .env 파일에 LangSmith 에서 발급받은 키와 프로젝트 정보를 입력</li>
<li>LANGCHAIN_TRACING_V2: “true” 로 설정하면 추적을 시작</li>
<li>LANGCHAIN_ENDPOINT: https://api.smith.langchain.com 변경하지 않는다.</li>
<li>LANGCHAIN_API_KEY: 이전 단계에서 발급받은 키 를 입력</li>
<li>LANGCHAIN_PROJECT: 프로젝트 명 을 기입하면 해당 프로젝트 그룹으로 모든 실행(Run) 이 추적</li>
</ul></li>
<li><p><code>.env</code> 파일에 발급받은 API 키 입력</p>
<pre><code>OPENAI_API_KEY=sk-proj-81qk0Zx...... # open AI key
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=lsv2_pt....... # lang smith key
LANGSMITH_PROJECT=Rag-Test</code></pre></li>
</ul></li>
</ul>
</section>
<section id="langsmith-추적-활성화" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="langsmith-추적-활성화"><span class="header-section-number">1.2</span> LangSmith 추적 활성화</h2>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dotenv <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dotenv</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># .env 에 설정한 내용을 불러옴</span></span>
<span id="cb2-4">load_dotenv()</span></code></pre></div>
<ul>
<li>퀄리 날리고 API 호출해서 사용 후</li>
<li>LangSmith 웹사이트에 접속 해서 추적 확인</li>
</ul>
</section>
<section id="변경사항을-저장하고-싶을-떄" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="변경사항을-저장하고-싶을-떄"><span class="header-section-number">1.3</span> 변경사항을 저장하고 싶을 떄</h2>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb3-2"></span>
<span id="cb3-3">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LANGCHAIN_TRACING_V2"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"true"</span></span>
<span id="cb3-4">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LANGCHAIN_ENDPOINT"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.smith.langchain.com"</span></span>
<span id="cb3-5">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LANGCHAIN_PROJECT"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LangChain 프로젝트명"</span></span>
<span id="cb3-6">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LANGCHAIN_API_KEY"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LangChain API KEY 입력"</span></span></code></pre></div>
</section>
<section id="langchain-teddynote-사용" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="langchain-teddynote-사용"><span class="header-section-number">1.4</span> langchain-teddynote 사용</h2>
<ul>
<li>langchain-teddynote 패키지: langchain 관련 기능을 보다 더 편리하게 사용하기 위한 목적으로 만들어진 패키지</li>
<li>패키지 설치: <code>pip install langchain-teddynote</code></li>
</ul>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_teddynote <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> logging</span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 프로젝트 이름을 입력합니다.</span></span>
<span id="cb4-4">logging.langsmith(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"원하는 프로젝트명"</span>)</span>
<span id="cb4-5"></span>
<span id="cb4-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 출력</span></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#LangSmith 추적을 시작합니다.</span></span>
<span id="cb4-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#[프로젝트명]</span></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#랭체인 튜토리얼 프로젝트</span></span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 출력을 원하지 않을 때</span></span>
<span id="cb4-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_teddynote <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> logging</span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># set_enable=False 로 지정하면 추적을 하지 않습니다.</span></span>
<span id="cb4-16">logging.langsmith(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"랭체인 튜토리얼 프로젝트"</span>, set_enable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>


</section>
</section>

 ]]></description>
  <category>RAG</category>
  <guid>kk3225.netlify.app/docs/blog/posts/RAG/2-2.settings_LangSmith.html</guid>
  <pubDate>Tue, 03 Jun 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>OpenAI API 설정</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/RAG/2-1.settings_api_issue.html</link>
  <description><![CDATA[ 




<section id="openai-키-발급" class="level2" data-number="1">

<ul>
<li>OpenAI API 웹사이트에 접속</li>
<li><a href="https://platform.openai.com/docs/overview">링크: https://platform.openai.com/docs/overview</a></li>
<li>설정 &gt; Billing &gt; Payment methods &gt; 신용카드 등록 &gt; add to credit &gt; $10 충전 &gt; continue &gt; Usage Limits
<ul>
<li>“Set a monthly budge”: 월간 사용한도를 지정. 이 금액에 도달하면 더이상 과금하지 않고 API 는 사용을 멈춤</li>
<li>“Set an email notification threshold”: 이메일이 발송되는 요금을 지정. 이 금액에 도달하면 이메일이 발송됨</li>
</ul></li>
<li>우측 프로필 이미지 클릭 - “Your profile”</li>
<li>API Key 관리 메뉴 로 접속
<ul>
<li><a href="https://platform.openai.com/api-keys">링크: https://platform.openai.com/api-keys</a></li>
<li>“Create new secret key” 를 클릭</li>
<li>생성된 API key 복사</li>
<li>키가 유출되면 다른 사람이 내 API KEY 를 사용하여 GPT 를 사용할 수 있다.</li>
<li>절대 키는 타인에게 공유하지 말고, 안전한 곳에 보관</li>
</ul></li>
</ul>
</section>
<section id="env-파일-설정" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="env-파일-설정"><span class="header-section-number">2</span> .env 파일 설정</h2>
<ul>
<li>프로젝트 루트 디렉토리에 .env 파일을 생성</li>
<li>.env 파일에 OPENAI_API_KEY=방금복사한 키를 입력 한 뒤 Ctrl + S 를 눌러 저장하고 파일을 닫는다.</li>
</ul>
<pre><code>OPENAI_API_KEY=sk-proj-81q....</code></pre>
</section>
<section id="환경변수-설정" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="환경변수-설정"><span class="header-section-number">3</span> 환경변수 설정</h2>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># API KEY를 환경변수로 관리하기 위한 설정 파일</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dotenv <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dotenv</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># API KEY 정보로드</span></span>
<span id="cb2-5">load_dotenv()</span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 출력: True</span></span>
<span id="cb2-7"></span>
<span id="cb2-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[API KEY]</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>os<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'OPENAI_API_KEY'</span>][:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"*"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>)</span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 출력: sk-proj-81qk0Z***************</span></span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 객체 생성</span></span>
<span id="cb3-4">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(</span>
<span id="cb3-5">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 창의성 (0.0 ~ 2.0)</span></span>
<span id="cb3-6">    model_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4.1-mini"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모델명</span></span>
<span id="cb3-7">)</span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 질의내용</span></span>
<span id="cb3-10">question <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"대한민국의 수도는 어디인가요?"</span></span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 질의</span></span>
<span id="cb3-13"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[답변]: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>llm<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>invoke(question)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 출력: [답변]: content='대한민국의 수도는 서울특별시입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 16, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_658b958c37', 'id': 'chatcmpl-BgLGZlSCdQpopkgabeEolgKOjSec5', 'finish_reason': 'stop', 'logprobs': None} id='run-7cd14eae-4ceb-4eda-9565-3076148bf702-0' usage_metadata={'input_tokens': 16, 'output_tokens': 11, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}</span></span>
<span id="cb3-15"></span>
<span id="cb3-16"></span>
<span id="cb3-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 질의내용</span></span>
<span id="cb3-18">question <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"대한민국의 수도는 어디인가요?"</span></span>
<span id="cb3-19"></span>
<span id="cb3-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 질의</span></span>
<span id="cb3-21">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.invoke(question)</span>
<span id="cb3-22">response</span>
<span id="cb3-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># AIMessage(content='대한민국의 수도는 서울입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 16, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BgLBMjx3jC0X772uUgb5BnYMd5x8c', 'finish_reason': 'stop', 'logprobs': None}, id='run-dbfc16ce-51ce-43c8-a01e-8d8bfc2debe1-0', usage_metadata={'input_tokens': 16, 'output_tokens': 8, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})</span></span>
<span id="cb3-24"></span>
<span id="cb3-25">response.content</span>
<span id="cb3-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 출력: '대한민국의 수도는 서울입니다.'</span></span>
<span id="cb3-27">response.response_metadata</span>
<span id="cb3-28"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 출력: {'token_usage': {'completion_tokens': 8, 'prompt_tokens': 16, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BgLBMjx3jC0X772uUgb5BnYMd5x8c', 'finish_reason': 'stop', 'logprobs': None}</span></span></code></pre></div>


</section>

 ]]></description>
  <category>RAG</category>
  <guid>kk3225.netlify.app/docs/blog/posts/RAG/2-1.settings_api_issue.html</guid>
  <pubDate>Mon, 02 Jun 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>LangChain 환경설정</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/RAG/2-0.settings.html</link>
  <description><![CDATA[ 




<section id="환경설정" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 환경설정</h1>
<section id="windows-환경-설정" class="level2" data-number="1.1">
<h2 data-number="1.1"><span class="header-section-number">1.1</span> Windows 환경 설정</h2>
<section id="git-설치" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1"><span class="header-section-number">1.1.1</span> git 설치</h3>
<ul>
<li>실습 코드를 GitHub에서 다운로드하고 버전 관리를 위해 필요</li>
<li>64-bit Git for Windows Setup 다운로드: <a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></li>
<li><code>add a git bash profile to windows terminal</code> 옵션 선택</li>
<li>powershell 관리자 권한으로 실행</li>
<li>다음의 명령어를 입력하여 정상 동작하는지 확인</li>
</ul>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--version</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># or</span></span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span></span></code></pre></div>
</section>
<section id="powershell-policy-적용" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2"><span class="header-section-number">1.1.2</span> PowerShell Policy 적용</h3>
<ul>
<li>Windows에서 PowerShell 스크립트 실행을 허용하기 위해 필요</li>
<li>기본적으로 Windows는 보안상 외부 스크립트 실행을 제한하는데, <code>pyenv</code>와 <code>poetry</code> 같은 도구들이 PowerShell 스크립트를 사용하므로 이 제한을 해제해야 함</li>
<li>Window 키 - PowerShell 을 반드시 관리자 권한으로 실행</li>
<li>다음의 명령어를 입력하여 Policy 를 적용</li>
</ul>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">Set-ExecutionPolicy</span> RemoteSigned <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-Scope</span> CurrentUser <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-Force</span></span></code></pre></div>
<ul>
<li>적용이 완료된 후 Windows PowerShell 을 껐다가 킨다</li>
<li>아래의 진행을 위하여 Windows PowerShell 실행시 “관리자 권한으로 실행”</li>
</ul>
</section>
<section id="pyenv-설치" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3"><span class="header-section-number">1.1.3</span> pyenv 설치</h3>
<ul>
<li>pyenv 설치</li>
</ul>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> clone https://github.com/pyenv-win/pyenv-win.git <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$env</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">:USERPROFILE\.pyenv"</span></span></code></pre></div>
<ul>
<li>여러 Python 버전을 관리하기 위한 도구</li>
<li>pyenv는 배포자가 만든 가상환경이 아니라, Python 버전 관리 도구</li>
<li>LangChain은 특정 Python 버전(3.11)에서 최적으로 동작하며, 시스템에 설치된 기본 Python과 충돌 없이 원하는 버전을 사용할 수 있게 해줌</li>
<li><strong>주의</strong>: pyenv는 Python 인터프리터 버전만 관리하며, 가상환경과 패키지 관리는 Poetry가 담당</li>
<li>pyenv: Python 인터프리터 버전 관리 (3.8, 3.9, 3.11 등)</li>
<li>가상환경 도구: venv, virtualenv, Poetry, conda 등이 패키지 격리 담당</li>
<li>실제 작업 흐름:
<ul>
<li>pyenv로 Python 3.11 설치 및 선택</li>
<li>Poetry로 해당 Python 버전 기반의 가상환경 생성 + 패키지 관리</li>
</ul></li>
</ul>
</section>
<section id="환경변수-추가" class="level3" data-number="1.1.4">
<h3 data-number="1.1.4"><span class="header-section-number">1.1.4</span> 환경변수 추가</h3>
<ul>
<li>pyenv가 시스템 어디서든 실행될 수 있도록 PATH 환경변수에 pyenv 경로를 추가해야 터미널에서 <code>pyenv</code> 명령어를 사용할 수 있음</li>
</ul>
<p>아래의 내용을 복사하여 붙혀넣기 후 실행</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[System.Environment]::SetEnvironmentVariable</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PYENV'</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$env</span>:USERPROFILE + <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\.pyenv\pyenv-win</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\"</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">, "</span>User<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">")</span></span>
<span id="cb4-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">[System.Environment]::SetEnvironmentVariable('PYENV_ROOT', </span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$env</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">:USERPROFILE + "</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\.</span>pyenv<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\p</span>yenv-win<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">)</span></span>
<span id="cb4-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[System.Environment]::SetEnvironmentVariable</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PYENV_HOME'</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$env</span>:USERPROFILE + <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\.pyenv\pyenv-win</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\"</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">, "</span>User<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">")</span></span></code></pre></div>
<p>아래의 내용을 복사하여 붙혀넣기 후 실행</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb5-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">[System.Environment]::SetEnvironmentVariable</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PATH'</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$env</span>:USERPROFILE + <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\.pyenv\pyenv-win\bin;"</span> + <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$env</span>:USERPROFILE + <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"\.pyenv\pyenv-win\shims;"</span> + <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">[</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">System.Environment</span><span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">]</span>::GetEnvironmentVariable<span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PATH'</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">)</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User"</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
<p><em>현재의 Windows PowerShell 을 종료 후 다시 실행</em></p>
<ul>
<li><code>pyenv</code> 를 입력하여 정상 동작하는지 확인</li>
</ul>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb6-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pyenv</span></span></code></pre></div>
</section>
<section id="파이썬-설치" class="level3" data-number="1.1.5">
<h3 data-number="1.1.5"><span class="header-section-number">1.1.5</span> 파이썬 설치</h3>
<ul>
<li>LangChain과 관련 패키지들이 안정적으로 동작하는 Python 3.11 버전을 설치</li>
<li>최신 버전보다는 검증된 안정 버전을 사용하여 호환성 문제를 방지</li>
<li>파이썬 3.11 버전 설치</li>
</ul>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb7-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pyenv</span> install 3.11</span></code></pre></div>
<ul>
<li>3.11 버전의 python 설정</li>
</ul>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pyenv</span> global 3.11 <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 시스템의 기본 Python 버전을 3.11로 설정</span></span></code></pre></div>
<ul>
<li>파이썬 버전 확인</li>
</ul>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb9-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">python</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--version</span></span></code></pre></div>
<ul>
<li>3.11.9 버전이 설치되어 있나 확인 (혹은 3.11.11 버전으로 설치되어도 무방)</li>
</ul>
</section>
<section id="poetry-설치" class="level3" data-number="1.1.6">
<h3 data-number="1.1.6"><span class="header-section-number">1.1.6</span> Poetry 설치</h3>
<ul>
<li>LangChain 실습을 위해 수 많은 패키지를 설치해야하는데 각 패키지들의 dependency 관리가 매우 복잡</li>
<li>Poetry는 패키지 의존성을 자동으로 해결하고 가상환경을 관리해주어 패키지 충돌 문제를 방지</li>
<li>배포자가 편의를 위해 Poetry를 사용하여 dependency 관리가 끝난 자료 배포</li>
<li>Poetry가 conda보다 더 정밀한 패키지 의존성 관리 제공</li>
<li>현대적인 Python 패키지 관리 방식</li>
<li><strong>conda vs pyenv+Poetry 비교</strong>:
<ul>
<li><code>conda</code>: Python 버전 관리 + 패키지 관리 통합 도구 (주로 데이터 사이언스용)</li>
<li><code>pyenv + Poetry</code>: Python 버전 관리(pyenv) + 패키지 관리(Poetry) 분리</li>
<li>Poetry는 <code>pyproject.toml</code>과 <code>poetry.lock</code> 파일로 더 정밀한 의존성 관리 제공</li>
</ul></li>
<li>아래의 명령어를 실행하여 Poetry 패키지 관리 도구를 설치</li>
</ul>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb10-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">pip3</span> install poetry==1.8.5</span></code></pre></div>
</section>
<section id="실습코드-실행" class="level3" data-number="1.1.7">
<h3 data-number="1.1.7"><span class="header-section-number">1.1.7</span> 실습코드 실행</h3>
<ul>
<li>LangChain 학습을 위한 예제 코드와 실습 자료를 다운로드하여 실제 개발 환경을 구축</li>
<li><a href="https://github.com/teddylee777/langchain-kr">실습코드 링크</a></li>
<li>도큐먼트(Documents) 폴더로 이동</li>
</ul>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb11-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> ~/Documents</span></code></pre></div>
<ul>
<li>아래의 명령어를 실행하여 소스코드를 받는다</li>
</ul>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb12-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> clone https://github.com/teddylee777/langchain-kr.git</span></code></pre></div>
<ul>
<li>아래의 명령어를 실행하여 langchain-kr 디렉토리로 이동</li>
</ul>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb13-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> langchain-kr</span></code></pre></div>
<ul>
<li>파이썬 가상환경 설정</li>
</ul>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb14-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">poetry</span> shell</span></code></pre></div>
<ul>
<li>파이썬 패키지 일괄 업데이트</li>
</ul>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb15-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">poetry</span> update</span></code></pre></div>
</section>
<section id="visual-studio-code-설치" class="level3" data-number="1.1.8">
<h3 data-number="1.1.8"><span class="header-section-number">1.1.8</span> Visual Studio Code 설치</h3>
<ul>
<li>Python 개발과 Jupyter 노트북 실행에 최적화된 통합 개발 환경(IDE)을 제공</li>
<li>코드 편집, 디버깅, 패키지 관리를 한 곳에서 할 수 있음</li>
<li>Visual Studio Code 다운로드</li>
<li><a href="https://code.visualstudio.com/download">다운로드 링크: https://code.visualstudio.com/download</a></li>
<li>다운로드 받은 Visual Studio Code 를 설치 (Applications 폴더에 복사)</li>
<li>왼쪽 install extensions 클릭
<ul>
<li>“python” 검색 후 설치</li>
<li>“jupyter” 검색 후 설치</li>
</ul></li>
<li>Visual Studio Code 껐다가 재실행</li>
<li>우측 상단 “select kernel”
<ul>
<li>python environment 클릭 - 설치한 가상환경이 안뜬다면 Visual Studio Code 껐다가 재실행</li>
</ul></li>
</ul>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden" data-render-id="quarto-int-sidebar-title">Kwangmin Kim</span> <span class="hidden" data-render-id="quarto-int-navbar-title">Kwangmin Kim</span> <span class="hidden" data-render-id="quarto-int-navbar:Home">Home</span> <span class="hidden" data-render-id="quarto-int-navbar:/index.html">/index.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Blog">Blog</span> <span class="hidden" data-render-id="quarto-int-navbar:/docs/blog/index.html">/docs/blog/index.html</span> <span class="hidden" data-render-id="quarto-int-navbar:Me">Me</span> <span class="hidden" data-render-id="quarto-int-navbar:/about.html">/about.html</span> <span class="hidden" data-render-id="quarto-int-navbar:https://github.com/kmink3225">https://github.com/kmink3225</span> <span class="hidden" data-render-id="quarto-int-navbar:https://www.linkedin.com/in/kwangmin-kim-a5241b200/">https://www.linkedin.com/in/kwangmin-kim-a5241b200/</span></p>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden" data-render-id="quarto-metatitle">Kwangmin Kim - LangChain 환경설정</span> <span class="hidden" data-render-id="quarto-twittercardtitle">Kwangmin Kim - LangChain 환경설정</span> <span class="hidden" data-render-id="quarto-ogcardtitle">Kwangmin Kim - LangChain 환경설정</span> <span class="hidden" data-render-id="quarto-metasitename">Kwangmin Kim</span> <span class="hidden" data-render-id="quarto-twittercarddesc">LangChain 실습을 위한 Python 개발 환경 설정 가이드</span> <span class="hidden" data-render-id="quarto-ogcardddesc">LangChain 실습을 위한 Python 개발 환경 설정 가이드</span></p>
</div>
</section>
</section>
</section>

 ]]></description>
  <category>RAG</category>
  <guid>kk3225.netlify.app/docs/blog/posts/RAG/2-0.settings.html</guid>
  <pubDate>Sun, 01 Jun 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Data Science Content List</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Data_Science/content.list.html</link>
  <description><![CDATA[ 




<section id="문제-정의-모델-선택-역량" class="level2" data-number="1">

<section id="비즈니스-문제-분석" class="level3" data-number="1.1">

<ul>
<li>문제 유형 분류 (분류/회귀/생성/검색/최적화)</li>
<li>ROI 계산 및 성공 지표 정의</li>
<li>데이터 가용성 vs 모델 요구사항 분석</li>
<li>기술적 제약사항 파악 (지연시간, 정확도, 비용)</li>
</ul>
</section>
<section id="모델-생태계-이해" class="level3" data-number="1.2">

<ul>
<li>Hugging Face Hub 활용: 모델 탐색, 벤치마크 해석</li>
<li>Foundation Models 맵핑: GPT-4, Claude, Llama, Mistral 등 특성</li>
<li>Computer Vision: CLIP, SAM, YOLO, ViT 계열</li>
<li>테이블형 데이터: AutoML vs 전통 ML 판단 기준</li>
</ul>
</section>
<section id="모델-성능-평가" class="level3" data-number="1.3">

<ul>
<li>벤치마크 해석 (BLEU, ROUGE, MMLU, HellaSwag 등)</li>
<li>도메인별 평가 지표 설계</li>
<li>A/B 테스트 설계 원칙</li>
<li>비용-성능 트레이드오프 분석</li>
</ul>
</section>
</section>
<section id="fine-tuning-api-활용---langchain" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="fine-tuning-api-활용---langchain"><span class="header-section-number">2</span> Fine-tuning &amp; API 활용 - LangChain</h2>
<section id="llm-fine-tuning-전략" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="llm-fine-tuning-전략"><span class="header-section-number">2.1</span> LLM Fine-tuning 전략</h3>
<ul>
<li>Parameter-Efficient Fine-tuning: LoRA, QLoRA, Adapter</li>
<li>Instruction Tuning: 태스크별 프롬프트 데이터셋 구축</li>
<li>RLHF 개념: 인간 피드백 활용 방법론</li>
<li>도메인 적응: 의료, 법률, 금융 등 특화 모델 구축</li>
</ul>
</section>
<section id="api-활용-및-최적화" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="api-활용-및-최적화"><span class="header-section-number">2.2</span> API 활용 및 최적화</h3>
<ul>
<li>OpenAI API: GPT-4, Fine-tuning, Assistants API</li>
<li>Anthropic Claude: Constitutional AI, Function Calling</li>
<li>오픈소스 API: Ollama, vLLM, Text Generation Inference</li>
<li>멀티모달 API: GPT-4V, Claude-3, Gemini 활용</li>
</ul>
</section>
<section id="프롬프트-엔지니어링" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="프롬프트-엔지니어링"><span class="header-section-number">2.3</span> 프롬프트 엔지니어링</h3>
<ul>
<li>Few-shot Learning 전략</li>
<li>Chain-of-Thought, Tree-of-Thought</li>
<li>프롬프트 최적화 도구 (DSPy, Guidance)</li>
<li>프롬프트 보안 (Jailbreaking 방지)</li>
</ul>
</section>
</section>
<section id="시스템-통합-아키텍처---langchain" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="시스템-통합-아키텍처---langchain"><span class="header-section-number">3</span> 시스템 통합 &amp; 아키텍처 - LangChain</h2>
<section id="ai-애플리케이션-아키텍처" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="ai-애플리케이션-아키텍처"><span class="header-section-number">3.1</span> AI 애플리케이션 아키텍처</h3>
<ul>
<li>RAG 시스템 설계: Vector DB, Embedding, Retrieval 전략</li>
<li>Agent Framework: LangChain, CrewAI, AutoGen</li>
<li>워크플로우 엔진: 복잡한 AI 태스크 체이닝</li>
<li>멀티모달 파이프라인: 텍스트+이미지+음성 통합</li>
</ul>
</section>
<section id="벡터-데이터베이스-검색" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="벡터-데이터베이스-검색"><span class="header-section-number">3.2</span> 벡터 데이터베이스 &amp; 검색</h3>
<ul>
<li>Vector DB: Pinecone, Weaviate, Chroma, FAISS</li>
<li>Embedding 전략: 텍스트, 이미지, 코드 임베딩</li>
<li>하이브리드 검색: 키워드 + 시맨틱 검색 결합</li>
<li>검색 성능 최적화: 인덱싱, 캐싱 전략</li>
</ul>
</section>
<section id="모델-서빙-인프라" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="모델-서빙-인프라"><span class="header-section-number">3.3</span> 모델 서빙 &amp; 인프라</h3>
<ul>
<li>모델 서빙: TorchServe, TensorFlow Serving, vLLM</li>
<li>로드 밸런싱: 모델별 트래픽 분산</li>
<li>캐싱 전략: 응답 캐시, 임베딩 캐시</li>
<li>비용 최적화: GPU 사용량, API 호출 최적화</li>
</ul>
</section>
</section>
<section id="운영-mlops---langchain" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="운영-mlops---langchain"><span class="header-section-number">4</span> 운영 &amp; MLOps - LangChain</h2>
<section id="모델-모니터링" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="모델-모니터링"><span class="header-section-number">4.1</span> 모델 모니터링</h3>
<ul>
<li>성능 드리프트: 입력 분포 변화 감지</li>
<li>출력 품질 모니터링: 응답 길이, 독성 탐지, 할루시네이션</li>
<li>사용자 피드백: 만족도, 정확도 추적</li>
<li>비용 모니터링: 토큰 사용량, API 비용 추적</li>
</ul>
</section>
<section id="ab-테스트-실험" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="ab-테스트-실험"><span class="header-section-number">4.2</span> A/B 테스트 &amp; 실험</h3>
<ul>
<li>모델 비교: 다양한 모델/프롬프트 성능 비교</li>
<li>점진적 롤아웃: Canary 배포, Blue-Green 배포</li>
<li>실험 설계: 통계적 유의성, 표본 크기 계산</li>
<li>결과 분석: 비즈니스 메트릭 vs 기술 메트릭</li>
</ul>
</section>
<section id="거버넌스-윤리" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="거버넌스-윤리"><span class="header-section-number">4.3</span> 거버넌스 &amp; 윤리</h3>
<ul>
<li>AI 안전성: Content Filtering, Bias 탐지</li>
<li>데이터 프라이버시: PII 마스킹, GDPR 준수</li>
<li>모델 해석성: LIME, SHAP 등 설명 가능 AI</li>
<li>규제 준수: AI Act, 금융/의료 규제 대응</li>
</ul>
</section>
</section>
<section id="고급-통합-자동화---langchain-일부-커버" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="고급-통합-자동화---langchain-일부-커버"><span class="header-section-number">5</span> 고급 통합 &amp; 자동화 - LangChain 일부 커버</h2>
<section id="automl-모델-자동화" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="automl-모델-자동화"><span class="header-section-number">5.1</span> AutoML &amp; 모델 자동화</h3>
<ul>
<li>AutoML 플랫폼: H2O.ai, DataRobot, AutoGluon</li>
<li>하이퍼파라미터 최적화: Optuna, Ray Tune</li>
<li>뉴럴 아키텍처 서치: 모델 구조 자동 탐색</li>
<li>모델 압축: Pruning, Quantization, Distillation</li>
</ul>
</section>
<section id="고급-ai-패턴" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="고급-ai-패턴"><span class="header-section-number">5.2</span> 고급 AI 패턴</h3>
<ul>
<li>Multi-Agent Systems: 협업하는 AI 에이전트</li>
<li>Tool-Using AI: 외부 도구/API 활용하는 AI</li>
<li>Self-Improving Systems: 피드백 기반 자동 개선</li>
<li>Federated Learning: 분산 학습 시스템</li>
</ul>
</section>
</section>
<section id="실습-프로젝트-로드맵" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="실습-프로젝트-로드맵"><span class="header-section-number">6</span> 실습 프로젝트 로드맵</h2>
<section id="초급" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="초급"><span class="header-section-number">6.1</span> 초급</h3>
<ol type="1">
<li><strong>문서 QA 시스템</strong>: RAG + OpenAI API</li>
<li><strong>이미지 분류 API</strong>: Pre-trained Vision 모델 + FastAPI</li>
</ol>
</section>
<section id="중급" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="중급"><span class="header-section-number">6.2</span> 중급</h3>
<ol start="3" type="1">
<li><strong>커스텀 챗봇</strong>: Fine-tuned LLM + 벡터DB</li>
<li><strong>멀티모달 검색</strong>: 텍스트+이미지 통합 검색</li>
</ol>
</section>
<section id="고급" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="고급"><span class="header-section-number">6.3</span> 고급</h3>
<ol start="5" type="1">
<li><strong>AI 에이전트 시스템</strong>: 복잡한 태스크 자동화</li>
<li><strong>A/B 테스트 플랫폼</strong>: 모델 성능 비교 시스템</li>
</ol>


</section>
</section>

 ]]></description>
  <category>Data Science</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Data_Science/content.list.html</guid>
  <pubDate>Sat, 31 May 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>RAG과 LangChain 소개</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/RAG/1.intro_rag.html</link>
  <description><![CDATA[ 




<section id="lang-chain-소개" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Lang Chain 소개</h1>
<section id="langchain이란" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="langchain이란"><span class="header-section-number">1.1</span> LangChain이란?</h2>
<ul>
<li><strong>정의</strong>: LLM(Large Language Model) 기반 애플리케이션 개발을 위한 오픈소스 프레임워크</li>
<li><strong>주요 목적</strong>: 복잡한 LLM 애플리케이션을 쉽게 구축할 수 있도록 지원</li>
</ul>
</section>
<section id="langchain의-핵심-기능" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="langchain의-핵심-기능"><span class="header-section-number">1.2</span> LangChain의 핵심 기능</h2>
<ul>
<li><strong>체인(Chain)</strong>: 여러 컴포넌트를 연결하여 복잡한 워크플로우 구성</li>
<li><strong>프롬프트 템플릿</strong>: 동적으로 프롬프트 생성 및 관리</li>
<li><strong>메모리</strong>: 대화 히스토리 및 컨텍스트 유지</li>
<li><strong>에이전트</strong>: 도구 사용 및 의사결정 자동화</li>
<li><strong>문서 로더</strong>: 다양한 형식의 문서 처리</li>
<li><strong>벡터 스토어</strong>: 임베딩 기반 검색 시스템</li>
</ul>
</section>
<section id="langchain-사용-사례" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="langchain-사용-사례"><span class="header-section-number">1.3</span> LangChain 사용 사례</h2>
<ul>
<li><strong>챗봇</strong>: 문맥을 이해하는 대화형 AI 시스템</li>
<li><strong>문서 QA</strong>: 문서 기반 질의응답 시스템<br>
</li>
<li><strong>데이터 분석</strong>: 자연어로 데이터 분석 수행</li>
<li><strong>코드 생성</strong>: 자연어 명령으로 코드 자동 생성</li>
<li><strong>RAG 시스템</strong>: 검색 기반 답변 생성 시스템</li>
</ul>
</section>
</section>
<section id="rag-소개" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> RAG 소개</h1>
<section id="rag가-인기-있게-된-이유" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="rag가-인기-있게-된-이유"><span class="header-section-number">2.1</span> RAG가 인기 있게 된 이유</h2>
<ul>
<li><strong>LLM의 한계 극복</strong>: 학습 데이터 시점 이후 정보 부족 문제 해결</li>
<li><strong>실시간 정보 활용</strong>: 최신 정보를 동적으로 검색하여 활용</li>
<li><strong>도메인 특화</strong>: 특정 분야의 전문 지식 기반 답변 생성</li>
<li><strong>비용 효율성</strong>: 전체 모델 재학습 없이 지식 확장 가능</li>
<li><strong>신뢰성 향상</strong>: 검색된 문서 기반으로 답변의 근거 제공</li>
</ul>
</section>
<section id="chat-gpt-도래-및-성공" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="chat-gpt-도래-및-성공"><span class="header-section-number">2.2</span> Chat GPT 도래 및 성공</h2>
<ul>
<li><strong>2022년 11월 출시</strong>: OpenAI ChatGPT 공개 후 폭발적 인기</li>
<li><strong>사용자 급증</strong>: 출시 2개월 만에 1억 사용자 돌파</li>
<li><strong>산업 변화</strong>: AI 기반 대화형 인터페이스의 새로운 표준 제시</li>
<li><strong>기술 혁신</strong>: Transformer 기반 대화형 AI의 상용화 성공</li>
<li><strong>생성형 AI 붐</strong>: GPT 성공으로 생성형 AI 시장 급성장</li>
</ul>
</section>
<section id="chat-gpt의-문제점" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="chat-gpt의-문제점"><span class="header-section-number">2.3</span> Chat GPT의 문제점</h2>
<ul>
<li><strong>할루시네이션(Hallucination)</strong>: 그럴듯하지만 잘못된 정보 생성</li>
<li><strong>지식 컷오프</strong>: 학습 데이터 시점 이후 정보 부족</li>
<li><strong>일관성 부족</strong>: 같은 질문에 다른 답변 제공 가능</li>
<li><strong>도메인 특화 한계</strong>: 전문 분야 지식의 정확도 부족</li>
<li><strong>출처 불명</strong>: 답변 근거가 되는 정보 출처 제공 불가</li>
</ul>
</section>
<section id="rag-적용시-chat-gpt의-문제점-해결-방안들" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="rag-적용시-chat-gpt의-문제점-해결-방안들"><span class="header-section-number">2.4</span> RAG 적용시 Chat GPT의 문제점 해결 방안들</h2>
<ul>
<li><strong>실시간 정보 검색</strong>: 최신 문서에서 관련 정보 검색하여 제공</li>
<li><strong>근거 기반 답변</strong>: 검색된 문서를 바탕으로 답변 생성</li>
<li><strong>도메인 지식 확장</strong>: 특정 분야 문서 데이터베이스 구축</li>
<li><strong>일관성 개선</strong>: 동일한 문서 소스 기반으로 일관된 답변</li>
<li><strong>출처 추적</strong>: 답변에 사용된 문서 출처 명시</li>
</ul>
</section>
<section id="rag-기대-효과" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="rag-기대-효과"><span class="header-section-number">2.5</span> RAG 기대 효과</h2>
<ul>
<li><strong>정확도 향상</strong>: 검증된 문서 기반으로 답변 품질 개선</li>
<li><strong>신뢰성 확보</strong>: 출처가 명확한 근거 기반 답변 제공</li>
<li><strong>전문성 강화</strong>: 도메인 특화 지식 기반 전문 상담 가능</li>
<li><strong>비용 절감</strong>: 모델 재학습 없이 지식 업데이트</li>
<li><strong>확장성</strong>: 새로운 문서 추가만으로 지식 확장 가능</li>
</ul>
</section>
<section id="rag-적용-방법" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="rag-적용-방법"><span class="header-section-number">2.6</span> RAG 적용 방법</h2>
<p>Chat GPT의 할루시네이션을 줄이고 방대한 지식 기반으로 답변하는 도메인 특화 chatbot 구축 가능</p>
<p>즉, RAG란 chat gpt에게 잘 정제된 데이터를 제공하여 더 정확하고 신뢰할 수 있는 답변을 제공하는 방법이다.</p>
<p><strong>주요 과제들:</strong> - Chat GPT의 RAG 과정은 비공개되어 user가 통제할 수 없는 부분이기 때문에 사용자들은 문서를 chat gpt가 잘 검색할 수 있는 형태로 변경하는 것이 중요 - 어려운 점은 각 문서마다 파일 형식이 다르고 이를 gpt가 처리가능한 형태로 전처리하는 과정이 공수가 많이 들어감 - 고유의 RAG를 만들어줘야 함</p>
</section>
<section id="rag-process" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="rag-process"><span class="header-section-number">2.7</span> RAG Process</h2>
<p><strong>기본 워크플로우:</strong></p>
<pre><code>query -&gt; RAG(document -&gt; chunk -&gt; embedding -&gt; vector store (DB) -&gt; Retriever) -&gt; Prompt Engineering -&gt; LLM</code></pre>
<p><strong>세부 단계:</strong> 1. <strong>문서 수집</strong>: 도메인 특화 문서 데이터 수집 2. <strong>청킹(Chunking)</strong>: 문서를 검색 가능한 단위로 분할 3. <strong>임베딩</strong>: 텍스트를 벡터로 변환 4. <strong>벡터 스토어</strong>: 임베딩 벡터를 데이터베이스에 저장 5. <strong>검색(Retrieval)</strong>: 쿼리와 유사한 문서 청크 검색 6. <strong>프롬프트 엔지니어링</strong>: 검색 결과를 포함한 프롬프트 구성 7. <strong>답변 생성</strong>: LLM이 최종 답변 생성</p>
<p>이 고유의 RAG를 만들어주는 것이 중요하지만 매우 고되고 어려운 과정이다. 내가 구현하려고 하는 답변 기능이 안되는 이유는 정말 수백가지에 달하기 때문이다.</p>
<p>하지만 분명한건 RAG를 잘 적용하여 원하는 기능을 구현하는 사례들이 많이 나오고 있고 효과적인 방법론들이 존재한다:</p>
<p><strong>고급 RAG 기법들:</strong> - <strong>코사인 유사도 최적화</strong>: 벡터 검색 정확도 개선 - <strong>HyDE Retrieval</strong>: 가상 문서 생성을 통한 검색 성능 향상 - <strong>FT Embedding</strong>: 도메인 특화 임베딩 모델 파인튜닝 - <strong>Chunk Embedding 실험</strong>: 최적 청킹 전략 탐색 - <strong>Reranking</strong>: 검색 결과 재순위화 - <strong>Classification Step</strong>: 쿼리 유형 분류를 통한 검색 최적화 - <strong>Prompt Engineering</strong>: 효과적인 프롬프트 설계 - <strong>Tool Use</strong>: 외부 도구 활용 확장 - <strong>Query Expansion</strong>: 쿼리 확장 및 개선</p>
</section>
<section id="rag-구현-난이도" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="rag-구현-난이도"><span class="header-section-number">2.8</span> RAG 구현 난이도</h2>
<p>RAG 구현은 사실상 LLM을 Tuning하는 것과 같다.</p>
<p><strong>LLM Tuning 방법 난이도 비교:</strong> - <strong>Prompt Engineering</strong> (매우 쉬움): 프롬프트만 수정하여 성능 개선 - <strong>RAG</strong> (쉬움): 외부 지식 소스 연결하여 답변 품질 향상 - <strong>PEFT</strong> (어려움): Parameter-Efficient Fine-Tuning 적용 - <strong>Full Fine Tuning</strong> (매우 어려움): 전체 모델 파라미터 재학습</p>
<p><strong>RAG의 장점:</strong> - 상대적으로 구현 난이도가 낮음 - 기존 모델 파라미터 수정 불필요 - 지식 업데이트가 용이함 - 비용 효율적인 성능 개선 방법</p>
</section>
<section id="rag-구현-방법" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="rag-구현-방법"><span class="header-section-number">2.9</span> RAG 구현 방법</h2>
<section id="기본-rag-파이프라인-구축" class="level3" data-number="2.9.1">
<h3 data-number="2.9.1" class="anchored" data-anchor-id="기본-rag-파이프라인-구축"><span class="header-section-number">2.9.1</span> 기본 RAG 파이프라인 구축</h3>
<p><strong>문서 처리:</strong> - 다양한 형식(PDF, DOCX, TXT, HTML) 문서 로딩 - 텍스트 추출 및 전처리 - 의미 있는 단위로 청킹 분할</p>
<p><strong>벡터화 및 저장:</strong> - OpenAI Embeddings 또는 오픈소스 임베딩 모델 사용 - FAISS, Chroma, Pinecone 등 벡터 데이터베이스 구축 - 효율적인 유사도 검색 인덱스 생성</p>
</section>
<section id="검색-시스템-구현" class="level3" data-number="2.9.2">
<h3 data-number="2.9.2" class="anchored" data-anchor-id="검색-시스템-구현"><span class="header-section-number">2.9.2</span> 검색 시스템 구현</h3>
<p><strong>검색 전략:</strong> - 코사인 유사도 기반 벡터 검색 - 키워드 기반 하이브리드 검색 - 의미적 유사도와 키워드 매칭 결합</p>
<p><strong>검색 최적화:</strong> - Top-K 검색 결과 개수 조정 - 검색 임계값(threshold) 설정 - 문서 메타데이터 활용 필터링</p>
</section>
<section id="프롬프트-엔지니어링" class="level3" data-number="2.9.3">
<h3 data-number="2.9.3" class="anchored" data-anchor-id="프롬프트-엔지니어링"><span class="header-section-number">2.9.3</span> 프롬프트 엔지니어링</h3>
<p><strong>프롬프트 구조:</strong> - 시스템 메시지: 역할 및 지침 명시 - 컨텍스트: 검색된 문서 내용 포함 - 질문: 사용자 쿼리 - 답변 형식: 원하는 출력 형태 지정</p>
<p><strong>프롬프트 개선:</strong> - Few-shot 예시 추가 - 체인 오브 생각(Chain of Thought) 적용 - 답변 검증 및 출처 표기 요구</p>
</section>
<section id="평가-및-개선" class="level3" data-number="2.9.4">
<h3 data-number="2.9.4" class="anchored" data-anchor-id="평가-및-개선"><span class="header-section-number">2.9.4</span> 평가 및 개선</h3>
<p><strong>성능 평가:</strong> - 답변 정확도 측정 - 검색 정밀도(Precision) 및 재현율(Recall) - 사용자 만족도 조사</p>
<p><strong>지속적 개선:</strong> - A/B 테스트를 통한 파라미터 최적화 - 사용자 피드백 기반 모델 업데이트 - 새로운 문서 데이터 정기 추가</p>


</section>
</section>
</section>

 ]]></description>
  <category>RAG</category>
  <guid>kk3225.netlify.app/docs/blog/posts/RAG/1.intro_rag.html</guid>
  <pubDate>Sat, 31 May 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>개발 환경의 숨은 암초, PATH 환경변수 오염</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Engineering/Conda/path_pollution.html</link>
  <description><![CDATA[ 




<section id="들어가며-개발자를-괴롭히는-path-문제" class="level2">
<h2 class="anchored" data-anchor-id="들어가며-개발자를-괴롭히는-path-문제">들어가며: 개발자를 괴롭히는 PATH 문제</h2>
<ul>
<li>나는 생화학, 수학, 통계 전공을 한터라 컴퓨터 공학을 전공하는 것이 아니었기 때문에 환경변수를 관리하지 않고 업무를 했고 그 결과 누적된 문제들이 얽혀 프로그램 오류를 찾아내는데 많은 시간을 소비하였다.</li>
<li>개발 환경을 설정하다 보면 예상치 못한 문제에 직면하게 된다. 특히 여러 도구와 언어를 함께 사용할 때, PATH 환경변수 오염은 마치 숨은 암초처럼 개발자를 괴롭힌다.</li>
<li>이 글에서는 복잡하게 꼬여버린 PATH 환경변수 문제의 진단부터 해결, 그리고 예방까지의 과정을 상세히 공유하고자 한다.</li>
<li><code>'conda.bat' is not recognized</code>, <code>reticulate 오류</code>, <code>Quarto 렌더링 실패</code> 등 겉보기엔 서로 다른 문제들이 사실은 하나의 거대한 PATH 오염에서 비롯된 것임을 밝혀내는 여정을 함께 따라가보자.</li>
</ul>
</section>
<section id="문제-상황-총체적-난국-오염된-path" class="level2">
<h2 class="anchored" data-anchor-id="문제-상황-총체적-난국-오염된-path">문제 상황: 총체적 난국, 오염된 PATH</h2>
<p>모든 문제의 시작은 처참하게 오염된 PATH 환경변수였다. 마치 뒤죽박죽 엉킨 실타래처럼, PATH는 다음과 같은 심각한 문제들을 안고 있었다.</p>
<section id="치명적인-경로-손상" class="level3">
<h3 class="anchored" data-anchor-id="치명적인-경로-손상">치명적인 경로 손상</h3>
<p>가장 심각한 문제는 Conda 환경 경로를 포함한 여러 경로가 완전히 깨져버린 것이다.</p>
<ul>
<li><code>miniconda3\\envs\\blog</code> 가 <code>miniconda3vlog</code> 로</li>
<li><code>mingw-w64\\bin</code> 가 <code>mingw-w6in</code> 로</li>
<li><code>usr\\bin</code> 가 <code>usin</code> 로</li>
<li><code>Library\\bin</code> 가 <code>Librarin</code> 로</li>
</ul>
<p>이러한 손상은 시스템이 정상적으로 실행 파일을 찾는 것을 불가능하게 만들었다.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예시: Git Bash에서 확인한 깨진 PATH의 일부</span></span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Users\\kmkim\\AppData\\Local\\miniconda3vlog</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 깨진 경로 (envs\\blog → vlog)</span></span>
<span id="cb1-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Users\\kmkim\\AppData\\Local\\miniconda3vlog\\Library\\mingw-w6in</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 심각하게 깨진 경로 (mingw-w64\\bin → mingw-w6in)</span></span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Users\\kmkim\\AppData\\Local\\miniconda3vlog\\Library\\usin</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>              <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 깨진 경로 (usr\\bin → usin)</span></span>
<span id="cb1-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Users\\kmkim\\AppData\\Local\\miniconda3vlog\\Librarin</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 깨진 경로 (Library\\bin → Librarin)</span></span>
<span id="cb1-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Users\\kmkim\\AppData\\Local\\miniconda3vlog\\Scripts</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 깨진 경로</span></span>
<span id="cb1-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Users\\kmkim\\AppData\\Local\\miniconda3vloin</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 완전히 깨진 경로</span></span></code></pre></div>
</section>
<section id="끝없는-경로-중복" class="level3">
<h3 class="anchored" data-anchor-id="끝없는-경로-중복">끝없는 경로 중복</h3>
<p>마치 복사-붙여넣기를 반복한 듯, 동일한 경로가 5번에서 10번 이상 중복되어 PATH를 극도로 길고 비효율적으로 만들었다.</p>
<ul>
<li>PowerShell 관련 경로는 10번 이상 반복</li>
<li>ffmpeg, MySQL, R tools 등 거의 모든 경로가 중복</li>
</ul>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예시: 중복된 경로들</span></span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\ffmpeg</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                                                             <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ⚠️ 중복 (시스템/사용자 모두 존재)</span></span>
<span id="cb2-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\ffmpeg\\</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                                                            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 슬래시 중복</span></span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Program</span> Files<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\\</span>PowerShell<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\\</span>7<span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                                         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ⚠️ 중복</span></span>
<span id="cb2-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\\Program</span> Files<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\\</span>PowerShell<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\\</span>7<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\\</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">;</span>                                        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ❌ 슬래시 중복</span></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... 기타 수많은 중복 경로 ...</span></span></code></pre></div>
</section>
<section id="일관성-없는-슬래시-사용" class="level3">
<h3 class="anchored" data-anchor-id="일관성-없는-슬래시-사용">일관성 없는 슬래시 사용</h3>
<p>경로 마지막에 슬래시(<code>/</code> 또는 <code>\\</code>)가 있거나 없는 경우가 혼재하여, 같은 경로가 다른 것으로 인식될 여지를 남겼다.</p>
<ul>
<li><code>C:\\path</code> 와 <code>C:\\path\\</code> 가 동시에 존재</li>
</ul>
</section>
<section id="사용자-path와-시스템-path의-혼란" class="level3">
<h3 class="anchored" data-anchor-id="사용자-path와-시스템-path의-혼란">사용자 PATH와 시스템 PATH의 혼란</h3>
<p>개인용 도구의 경로가 시스템 전체에 적용되는 시스템 PATH에 섞여 있었고, 그 반대의 경우도 존재하여 관리를 어렵게 만들었다.</p>
</section>
</section>
<section id="해결-과정-path-대청소" class="level2">
<h2 class="anchored" data-anchor-id="해결-과정-path-대청소">해결 과정: PATH 대청소</h2>
<p>엉망진창이 된 PATH를 정상으로 되돌리기 위한 대청소 작전은 다음과 같이 진행되었다.</p>
<section id="단계-path-현황-파악" class="level3">
<h3 class="anchored" data-anchor-id="단계-path-현황-파악">1단계: PATH 현황 파악</h3>
<p>가장 먼저 현재 PATH 상태를 정확히 파악하는 것이 중요했다.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">where</span> python  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Python 실행 파일 위치 확인</span></span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">where</span> conda   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Conda 실행 파일 위치 확인</span></span>
<span id="cb3-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">$PATH</span>    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># (Git Bash 등에서) 전체 PATH 문자열 확인</span></span></code></pre></div>
<p>PowerShell에서는 다음과 같이 사용자 PATH와 시스템 PATH를 각각 확인할 수 있다.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode powershell code-with-copy"><code class="sourceCode powershell"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 사용자 PATH (개인 도구 및 설정)</span></span>
<span id="cb4-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span>Environment<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]::</span>GetEnvironmentVariable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Path"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 시스템 PATH (모든 사용자 및 시스템 전역 도구)</span></span>
<span id="cb4-5"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">[</span>Environment<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">]::</span>GetEnvironmentVariable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">(</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Path"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Machine"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">)</span></span></code></pre></div>
</section>
<section id="단계-사용자-path와-시스템-path-분리-및-재정렬" class="level3">
<h3 class="anchored" data-anchor-id="단계-사용자-path와-시스템-path-분리-및-재정렬">2단계: 사용자 PATH와 시스템 PATH 분리 및 재정렬</h3>
<p>진단 결과를 바탕으로, 각 경로의 성격에 맞게 사용자 PATH와 시스템 PATH로 명확히 분리했다.</p>
<ul>
<li><strong>사용자 PATH</strong>: 개인적으로 설치한 프로그램(Conda, VS Code, Quarto 등) 및 사용자별 도구</li>
<li><strong>시스템 PATH</strong>: Windows 기본 구성 요소, 모든 사용자에게 필요한 프로그램(Git, PowerShell 등)</li>
</ul>
</section>
<section id="단계-오류-수정-및-중복-제거" class="level3">
<h3 class="anchored" data-anchor-id="단계-오류-수정-및-중복-제거">3단계: 오류 수정 및 중복 제거</h3>
<ul>
<li><strong>깨진 경로 복구</strong>: <code>miniconda3vlog</code> 와 같이 손상된 부분을 원래의 <code>miniconda3\\envs\\blog\\Scripts</code> 등으로 수정했다.</li>
<li><strong>중복 경로 통합</strong>: 반복되는 경로들을 하나만 남기고 모두 제거했다. 슬래시 유무로 인한 중복도 통일했다.</li>
<li><strong>불필요한 경로 삭제</strong>: 예를 들어 Java JDK의 <code>bin\\server</code> 같이 실제 실행에 필요 없는 하위 경로를 제거했다.</li>
</ul>
</section>
<section id="단계-conda-환경-우선순위-조정" class="level3">
<h3 class="anchored" data-anchor-id="단계-conda-환경-우선순위-조정">4단계: Conda 환경 우선순위 조정</h3>
<p>여러 Python/Conda 환경이 존재할 때, 특정 프로젝트(예: <code>blog</code>)의 환경이 기본 Conda 환경보다 우선적으로 인식되도록 PATH 순서를 조정했다.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode diff code-with-copy"><code class="sourceCode diff"><span id="cb5-1"># 수정 전 (일반 Conda가 우선될 수 있음)</span>
<span id="cb5-2">C:\Users\kmkim\AppData\Local\miniconda3\Scripts</span>
<span id="cb5-3">C:\Users\kmkim\AppData\Local\miniconda3\envs\blog\Scripts</span>
<span id="cb5-4"></span>
<span id="cb5-5"># 수정 후 (blog 환경 스크립트 최우선)</span>
<span id="cb5-6"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">+ C:\Users\kmkim\AppData\Local\miniconda3\envs\blog\Scripts</span></span>
<span id="cb5-7">  C:\Users\kmkim\AppData\Local\miniconda3\Scripts</span>
<span id="cb5-8">  C:\Users\kmkim\AppData\Local\miniconda3\condabin</span>
<span id="cb5-9">  C:\Users\kmkim\AppData\Local\miniconda3</span></code></pre></div>
</section>
</section>
<section id="개선-후-평화를-되찾은-path" class="level2">
<h2 class="anchored" data-anchor-id="개선-후-평화를-되찾은-path">개선 후: 평화를 되찾은 PATH</h2>
<p>대대적인 정리 작업 끝에, PATH는 다음과 같이 깔끔하게 정돈되었다.</p>
<section id="사용자-path-개인-도구" class="level3">
<h3 class="anchored" data-anchor-id="사용자-path-개인-도구">사용자 PATH (개인 도구)</h3>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\miniconda3\envs\blog\Scripts</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ 최우선 (특정 Conda 환경)</span></span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\miniconda3\Scripts</span>            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ 일반 Conda 스크립트</span></span>
<span id="cb6-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\miniconda3\condabin</span>          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Conda 실행 파일 경로</span></span>
<span id="cb6-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\miniconda3</span>                   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Conda 기본 경로</span></span>
<span id="cb6-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\Programs\Quarto\bin</span>         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Quarto</span></span>
<span id="cb6-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\Programs\Microsoft</span> VS Code<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\b</span>in <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ VS Code</span></span>
<span id="cb6-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\Programs\cursor\resources\app\bin</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Cursor</span></span>
<span id="cb6-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\scoop\shims</span>                                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Scoop 패키지</span></span>
<span id="cb6-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Users\kmkim\AppData\Local\Microsoft\WindowsApps</span>       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Windows Store 앱</span></span>
<span id="cb6-10"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\ffmpeg</span>                                                 <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ 사용자 ffmpeg</span></span>
<span id="cb6-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\R\rtools43\usr\bin</span>                                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ R 도구</span></span></code></pre></div>
</section>
<section id="시스템-path-전역-도구" class="level3">
<h3 class="anchored" data-anchor-id="시스템-path-전역-도구">시스템 PATH (전역 도구)</h3>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Windows\system32</span>                                       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Windows 기본</span></span>
<span id="cb7-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Windows</span>                                               <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Windows 기본</span></span>
<span id="cb7-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Windows\System32\Wbem</span>                                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ WMI</span></span>
<span id="cb7-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Windows\System32\WindowsPowerShell\v1.0</span>             <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ 구 PowerShell</span></span>
<span id="cb7-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Windows\System32\OpenSSH</span>                            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ SSH</span></span>
<span id="cb7-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Program</span> Files<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\P</span>owerShell<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\7</span>                          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ 신 PowerShell</span></span>
<span id="cb7-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Program</span> Files<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\G</span>it<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\c</span>md                               <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Git</span></span>
<span id="cb7-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\ProgramData\chocolatey\bin</span>                          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Chocolatey</span></span>
<span id="cb7-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Program</span> Files<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\J</span>ava<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\o</span>penjdk-23.0.1_windows-x64_bin<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\j</span>dk-23.0.1<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\b</span>in <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Java</span></span>
<span id="cb7-10"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Program</span> Files<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\M</span>ATLAB<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\R</span>2022b<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\b</span>in                     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ MATLAB</span></span>
<span id="cb7-11"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">C:\Program</span> Files <span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">(</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">x86</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">)</span><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">\Microsoft</span> SDKs<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\A</span>zure<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\C</span>LI2<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\w</span>bin  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✅ Azure CLI</span></span></code></pre></div>
</section>
</section>
<section id="개선-효과-숫자로-보는-변화" class="level2">
<h2 class="anchored" data-anchor-id="개선-효과-숫자로-보는-변화">개선 효과: 숫자로 보는 변화</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>항목</th>
<th>개선 전</th>
<th>개선 후</th>
<th>개선율</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>총 PATH 항목 수</strong></td>
<td>~80개</td>
<td>~20개</td>
<td><strong>75% 감소</strong></td>
</tr>
<tr class="even">
<td><strong>중복 제거</strong></td>
<td>대량 중복</td>
<td>중복 없음</td>
<td><strong>100% 해결</strong></td>
</tr>
<tr class="odd">
<td><strong>깨진 경로</strong></td>
<td>5개 이상</td>
<td>0개</td>
<td><strong>100% 해결</strong></td>
</tr>
<tr class="even">
<td><strong>Python 인식</strong></td>
<td>실패</td>
<td>성공</td>
<td><strong>✅ 해결</strong></td>
</tr>
<tr class="odd">
<td><strong>Quarto 렌더링</strong></td>
<td>실패</td>
<td>성공</td>
<td><strong>✅ 해결</strong></td>
</tr>
</tbody>
</table>
</section>
<section id="최종-결과-평화로운-개발-환경" class="level2">
<h2 class="anchored" data-anchor-id="최종-결과-평화로운-개발-환경">최종 결과: 평화로운 개발 환경</h2>
<p>PATH 정리가 완료되자, 이전에 발생했던 모든 문제들이 거짓말처럼 사라졌다.</p>
<p><strong>이전</strong>: - <code>'conda.bat' is not recognized as an internal or external command...</code> - <code>Reticulate: Python N/A</code> - <code>Quarto failed to render (exit code: N)</code></p>
<p><strong>현재</strong>: - <code>conda activate blog</code> (정상 작동) - <code>python --version</code> (원하는 버전 출력) - <code>quarto preview</code> (성공적인 문서 미리보기)</p>
</section>
<section id="주요-오염-원인-분석" class="level2">
<h2 class="anchored" data-anchor-id="주요-오염-원인-분석">주요 오염 원인 분석</h2>
<p>이러한 대규모 PATH 오염은 왜 발생했을까? 몇 가지 가능한 원인들을 추정해볼 수 있다.</p>
<ol type="1">
<li><p><strong>설치 프로그램의 무분별한 PATH 수정</strong>: 일부 프로그램 설치 시, 기존 PATH를 정확히 파싱하지 못하거나, 잘못된 형식으로 경로를 추가/덮어쓰면서 문제가 누적될 수 있다. <code>bash     # 문제 패턴 예시     C:\Users\kmkim\AppData\Local\miniconda3vlog  # ← 'envs\blog'가 'vlog'로 깨짐     C:\R\rtools43\\usr\bin\                      # ← 백슬래시 중복</code></p></li>
<li><p><strong>빈번한 프로그램 설치/제거/업데이트</strong>: 다양한 버전의 Java, Python/Conda, PowerShell 등을 설치하고 제거하는 과정에서 PATH 항목이 정리되지 않고 계속 누적되어 중복과 꼬임을 유발한다.</p></li>
<li><p><strong>Conda 환경 관리 중 오류</strong>: Conda 환경을 생성하거나 삭제하는 도중 프로세스가 중단되거나, 특정 환경(예: 한글 경로)에서 인코딩 문제가 발생하면 PATH가 손상될 수 있다. <code>bash     # 정상적이라면: C:\...\miniconda3\envs\blog     # 실제 발생: C:\...\miniconda3vlog, C:\...\miniconda3\Library\usin 등</code></p></li>
<li><p><strong>Windows PATH 길이 제한 (구버전)</strong>: 과거 Windows 버전에서는 PATH 문자열의 최대 길이가 약 2048자로 제한되었다. 경로가 과도하게 길어지면 잘리면서 중간 부분이 손상될 수 있다.</p></li>
<li><p><strong>다양한 개발 도구의 독립적인 PATH 수정</strong>: MATLAB, R, Python, Java, Git, VS Code, Quarto 등 수많은 개발 도구들이 각자의 방식으로 PATH를 수정하면서 예기치 않은 충돌이나 꼬임이 발생할 수 있다.</p></li>
</ol>
</section>
<section id="예방-조치-건강한-path-유지를-위한-습관" class="level2">
<h2 class="anchored" data-anchor-id="예방-조치-건강한-path-유지를-위한-습관">예방 조치: 건강한 PATH 유지를 위한 습관</h2>
<p>향후 유사한 문제를 예방하기 위해 다음과 같은 습관을 들이는 것이 좋다.</p>
<ol type="1">
<li><p><strong>중요 작업 전 PATH 백업</strong>: 새로운 개발 도구를 설치하거나 환경 설정을 크게 변경하기 전에는 현재 PATH 상태를 백업한다. <code>powershell     $env:PATH | Out-File path_backup_YYYYMMDD.txt</code></p></li>
<li><p><strong>설치 프로그램 사용 시 신중함 유지</strong>:</p>
<ul>
<li>한 번에 하나의 프로그램만 설치하고, 설치 후 PATH 변경 사항 및 정상 작동 여부를 확인한다.</li>
<li>가능하다면 “Add to PATH” 옵션을 해제하고 수동으로 필요한 경로만 추가하는 것을 고려한다.</li>
<li>설치 후에는 시스템을 재부팅하여 변경사항이 완전히 적용되도록 한다.</li>
</ul></li>
<li><p><strong>정기적인 PATH 점검 및 정리</strong>: 주기적으로 PATH를 점검하여 불필요하거나 중복된 경로, 깨진 경로가 있는지 확인하고 정리한다. <code>powershell     # PowerShell에서 중복 없는 정렬된 PATH 목록 확인     $env:PATH -split ';' | Sort-Object | Get-Unique</code></p></li>
</ol>
</section>
<section id="교훈-모든-것은-path로-통한다" class="level2">
<h2 class="anchored" data-anchor-id="교훈-모든-것은-path로-통한다">교훈: 모든 것은 PATH로 통한다</h2>
<p>이번 PATH 오염 사태를 통해 얻은 교훈은 다음과 같다.</p>
<ul>
<li><strong>환경변수 오염은 소리 없는 암살자</strong>: 눈에 잘 보이지 않지만 시스템 전반의 안정성과 프로그램 작동에 치명적인 영향을 미칠 수 있다.</li>
<li><strong>PATH 순서의 중요성</strong>: 시스템은 PATH에 등록된 순서대로 실행 파일을 찾는다. 원하는 버전이나 환경의 도구가 먼저 실행되도록 순서를 올바르게 설정해야 한다.</li>
<li><strong>사용자 PATH와 시스템 PATH의 명확한 분리</strong>: 역할에 맞게 경로를 분리해야 충돌을 예방하고 관리가 용이해진다.</li>
<li><strong>복잡한 개발 스택일수록 PATH 관리는 필수</strong>: 특히 Quarto, R, Python처럼 여러 언어와 도구가 연동되는 환경에서는 깨끗하고 정확한 PATH 설정이 무엇보다 중요하다.</li>
</ul>
<p>결국, 겉으로 드러난 수많은 오류 메시지들은 “근본 원인”인 PATH 오염이 해결되자 모두 사라졌다. 복잡한 문제일수록 기본으로 돌아가 시스템의 가장 기초적인 설정부터 점검하는 자세가 필요함을 다시 한번 깨닫게 되었다.</p>


</section>

 ]]></description>
  <category>Engineering</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Engineering/Conda/path_pollution.html</guid>
  <pubDate>Wed, 30 Apr 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>데이터 플랫폼 리소스 계획 및 구현</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Engineering/data_engineering/2.IaaS.html</link>
  <description><![CDATA[ 




<section id="azure-sql을-사용하여-iaas-솔루션-배포" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="azure-sql을-사용하여-iaas-솔루션-배포"><span class="header-section-number">1</span> Azure SQL을 사용하여 IaaS 솔루션 배포</h2>
<section id="introduction" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1.1</span> <a href="https://learn.microsoft.com/en-us/training/modules/deploy-iaas-solutions-with-azure-sql/1-introduction">Introduction</a></h3>
<p>데이터베이스 시스템의 성능 최적화를 위한 주요 고려사항:</p>
<ul>
<li>데이터베이스 워크로드 성능 보장
<ul>
<li>가상 머신의 적절한 크기 선택이 필수적
<ul>
<li>CPU, 메모리, IOPS 등 리소스 요구사항 분석</li>
<li>워크로드 특성에 맞는 VM 시리즈 선택</li>
</ul></li>
<li>스토리지 구성의 최적화
<ul>
<li>Premium SSD, Ultra Disk 등 적절한 스토리지 타입 선택</li>
<li>데이터, 로그, 템프DB 파일의 효율적인 배치</li>
</ul></li>
<li>네트워크 설정 최적화
<ul>
<li>대역폭 요구사항에 맞는 네트워크 구성</li>
<li>보안 및 접근성 고려</li>
</ul></li>
</ul></li>
<li>고가용성 구성
<ul>
<li>비즈니스 요구사항에 맞는 가용성 수준 결정</li>
<li>Always On 가용성 그룹, 장애 조치 클러스터 등 적절한 솔루션 선택</li>
<li>백업 및 복구 전략 수립</li>
</ul></li>
<li>Azure VM에서의 SQL Server 배포 이점
<ul>
<li>기존 온프레미스 환경의 손쉬운 클라우드 마이그레이션</li>
<li>최소한의 아키텍처 변경으로 신속한 전환 가능</li>
<li>기존 라이선스 및 구성의 재사용 가능</li>
</ul></li>
<li>성공적인 마이그레이션을 위한 핵심 요소
<ul>
<li>상세한 마이그레이션 계획 수립</li>
<li>적절한 배포 옵션 선택</li>
<li>철저한 테스트 및 검증 절차</li>
</ul></li>
</ul>
<section id="자유도의-차이-iaas자유도가-높음-vs-paas자유도가-중간-vs-saas자유도가-낮음" class="level4">
<h4 class="anchored" data-anchor-id="자유도의-차이-iaas자유도가-높음-vs-paas자유도가-중간-vs-saas자유도가-낮음">자유도의 차이: IaaS(자유도가 높음) vs PaaS(자유도가 중간) vs SaaS(자유도가 낮음)</h4>
<ul>
<li>Software as a Service (SaaS)
<ul>
<li><strong>관리 수준</strong>: 완전 관리형으로 모든 것이 서비스 제공업체에 의해 관리됨</li>
<li><strong>유지보수</strong>: 서비스 제공업체가 모든 유지보수 담당</li>
<li><strong>확장성</strong>: 자동 확장, 사용자는 구독 수준만 선택</li>
<li><strong>비용</strong>: 구독 기반 과금, 사용량에 따른 요금제</li>
<li><strong>유연성</strong>: 매우 제한적, 제공되는 기능만 사용 가능</li>
<li><strong>적합 사례</strong>: 표준화된 소프트웨어 필요 시 (예: Office 365, Salesforce)</li>
</ul></li>
<li>Azure SQL Database (PaaS)
<ul>
<li><strong>관리 수준</strong>: 완전 관리형 서비스로 Microsoft가 OS, 하드웨어, 백업, 고가용성 등을 관리</li>
<li><strong>유지보수</strong>: 자동 패치 및 업그레이드</li>
<li><strong>확장성</strong>: 자동 확장 기능 지원</li>
<li><strong>비용</strong>: 사용한 리소스에 따라 비용 지불, 일반적으로 관리 오버헤드가 적음</li>
<li><strong>제한사항</strong>: 일부 고급 SQL Server 기능 사용 불가(CLR, SQL Agent 등)</li>
<li><strong>적합 사례</strong>: 새 애플리케이션 개발, 관리 오버헤드 최소화가 필요한 경우</li>
</ul></li>
<li>IaaS SQL Server (Azure VM)
<ul>
<li><strong>관리 수준</strong>: 셀프 관리형으로 사용자가 OS, 소프트웨어 업데이트, 백업 등 직접 관리</li>
<li><strong>유지보수</strong>: 수동 패치 및 업그레이드</li>
<li><strong>확장성</strong>: 수동 확장, VM 크기 변경 필요</li>
<li><strong>비용</strong>: VM 인프라에 대한 비용 지불, 관리 오버헤드가 더 많음</li>
<li><strong>유연성</strong>: 모든 SQL Server 기능 사용 가능(SSAS, SSIS, SSRS 등)</li>
<li><strong>적합 사례</strong>: 기존 온프레미스 SQL Server 마이그레이션, 특정 버전/기능 필요 시</li>
</ul></li>
<li>주요 차이점
<ul>
<li><strong>제어 수준</strong>: IaaS는 더 많은 제어를 제공하지만 더 많은 관리 책임이 따름</li>
<li><strong>호환성</strong>: IaaS는 온프레미스 SQL Server와 100% 호환, PaaS는 일부 제한</li>
<li><strong>운영 비용</strong>: PaaS는 일반적으로 운영 비용이 더 낮음</li>
</ul></li>
</ul>
</section>
</section>
<section id="azure에서-sql-server를-배포하기-위한-iaas-옵션-설명" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="azure에서-sql-server를-배포하기-위한-iaas-옵션-설명"><span class="header-section-number">1.2</span> <a href="https://learn.microsoft.com/en-us/training/modules/deploy-iaas-solutions-with-azure-sql/2-explain-iaas-options-deploy-azure">Azure에서 SQL Server를 배포하기 위한 IaaS 옵션 설명</a></h3>
<ul>
<li><p>Azure VM에서 SQL Server를 실행해야 하는 주요 시나리오들:</p>
<ol type="1">
<li>이전 버전의 SQL Server가 필요한 경우</li>
</ol>
<ul>
<li>일부 애플리케이션은 특정 이전 버전의 SQL Server에서만 작동</li>
<li>공급업체가 지원하는 특정 SQL Server 버전을 사용해야 하는 경우</li>
<li>이런 경우 VM에 원하는 버전을 직접 설치하여 실행하는 것이 가장 좋은 방법</li>
</ul>
<ol start="2" type="1">
<li>여러 SQL Server 서비스를 함께 사용해야 하는 경우</li>
</ol>
<ul>
<li>SQL Server 데이터베이스 엔진과 함께 Analysis Services(분석 서비스)나 Integration Services(통합 서비스), Reporting Services(보고 서비스)를 같이 사용해야 할 때</li>
<li>이들을 한 VM에서 함께 실행하면 라이선스 비용을 절약할 수 있음</li>
<li>Azure에서 일부 서비스는 PaaS로 제공되지만, 비용 효율성을 위해 VM에서 함께 실행하는 것이 유리할 수 있음</li>
</ul>
<ol start="3" type="1">
<li>애플리케이션 호환성 문제가 있는 경우</li>
</ol>
<ul>
<li>일부 애플리케이션은 여러 데이터베이스 간의 쿼리(교차 데이터베이스 쿼리)가 필요</li>
<li>Azure SQL Database는 이를 지원하지 않아 VM 사용이 필요</li>
<li>데이터베이스와 다른 서비스들이 특별한 방식으로 함께 동작해야 하는 경우</li>
</ul></li>
<li><p>IaaS(Infrastructure as a Service)의 장점과 특징:</p>
<ul>
<li>관리자의 세밀한 시스템 제어
<ul>
<li>Azure가 서버 하드웨어와 네트워크를 관리하지만, 관리자는 다음을 직접 제어 가능:
<ul>
<li>가상 스토리지 설정</li>
<li>가상 네트워크 구성</li>
<li>SQL Server 설치 및 설정</li>
<li>추가 소프트웨어 설치</li>
</ul></li>
</ul></li>
<li>인프라 구성의 높은 자유도
<ul>
<li>OS 레벨부터 완전한 제어 가능</li>
<li>커스텀 설정 및 튜닝의 자유로움</li>
</ul></li>
<li>세부적인 구성 계획의 중요성
<ul>
<li>성능 요구사항에 맞는 리소스 할당</li>
<li>확장성을 고려한 아키텍처 설계</li>
<li>비용 효율적인 리소스 사용 계획</li>
</ul></li>
</ul></li>
</ul>
<section id="azure-서비스-control-granularity제어-정밀도-비교" class="level4">
<h4 class="anchored" data-anchor-id="azure-서비스-control-granularity제어-정밀도-비교">Azure 서비스 Control Granularity(제어 정밀도) 비교</h4>
<ul>
<li>IaaS, PaaS, SaaS의 제어 수준 차이
<ul>
<li>IaaS: 가장 높은 제어 수준 제공</li>
<li>PaaS: 중간 수준의 제어 제공</li>
<li>SaaS: 가장 제한된 제어 수준</li>
</ul></li>
<li>각 서비스 별 관리 책임
<ul>
<li>SaaS: 사용자는 보안과 데이터 관리만 담당</li>
<li>PaaS: 클라우드 제공업체가 OS와 기본 소프트웨어 관리</li>
<li>IaaS: 사용자가 OS 패치, 네트워크, 스토리지 구성 등 대부분 관리</li>
</ul></li>
<li>Azure IaaS에서의 책임 분담
<ul>
<li>Microsoft 담당:
<ul>
<li>물리적 서버</li>
<li>스토리지</li>
<li>물리적 네트워킹</li>
</ul></li>
<li>사용자 담당:
<ul>
<li>OS 관리</li>
<li>SQL Server 인스턴스 구성</li>
<li>추가 소프트웨어 설치/관리</li>
</ul></li>
</ul></li>
<li>IaaS가 필요한 특수 상황
<ul>
<li>특정 SQL Server/Windows 버전 조합이 필요한 경우</li>
<li>SQL Server와 함께 추가 소프트웨어 설치가 필요한 경우</li>
<li>CLR, 복제 등 특수 기능 사용이 필요한 경우</li>
<li>기존 Active Directory 인증이 필요한 경우</li>
<li>OS 직접 접근이 필요한 애플리케이션 운영 시</li>
</ul></li>
<li>IaaS의 장점
<ul>
<li>높은 유연성과 제어 가능성</li>
<li>기존 온프레미스 환경과 유사한 구성 가능</li>
<li>클라우드의 이점과 기존 기능의 동시 활용</li>
<li>특수한 요구사항 수용 가능</li>
</ul></li>
</ul>
</section>
<section id="sql-server-iaas-agent-extensionsql-server-iaas-에이전트-확장" class="level4">
<h4 class="anchored" data-anchor-id="sql-server-iaas-agent-extensionsql-server-iaas-에이전트-확장">SQL Server IaaS Agent Extension(SQL Server IaaS 에이전트 확장)</h4>
<ul>
<li>Azure Marketplace에서 SQL Server VM을 배포할 때, 프로세스의 일부로 IaaS Agent Extension이 설치된다.</li>
<li>확장(Extension)은 VM 배포 후 실행되는 코드로, 일반적으로 배포 후 구성을 수행한다.</li>
<li>예를 들어 백신 소프트웨어 설치나 Windows 기능 활성화 등이 있다.</li>
<li>SQL Server IaaS Agent Extension은 관리 부담을 줄일 수 있는 다음과 같은 주요 기능을 제공한다:
<ul>
<li>자동 백업</li>
<li>자동 패치 적용</li>
<li>Azure Key Vault 통합</li>
<li>Microsoft Defender for Cloud 통합</li>
<li>포털에서 디스크 사용량 확인</li>
<li>유연한 라이선싱</li>
<li>유연한 버전/에디션 선택</li>
<li>SQL 모범 사례 평가</li>
</ul></li>
</ul>
<p>이러한 기능 외에도, 이 확장을 통해 SQL Server의 구성 및 스토리지 사용량 정보를 확인할 수 있다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kk3225.netlify.app/images/azure/IaaS Agent Extension.PNG" class="img-fluid figure-img"></p>
<figcaption>IaaS Agent Extension</figcaption>
</figure>
</div>
</section>
<section id="sql-server-라이선싱-모델" class="level4">
<h4 class="anchored" data-anchor-id="sql-server-라이선싱-모델">SQL Server 라이선싱 모델</h4>
<ul>
<li>Azure VM에서 SQL Server 라이선스 사용 방법은 크게 두 가지</li>
</ul>
<ol type="1">
<li>종량제(Pay as you Go) 방식
<ul>
<li>Azure Marketplace에서 SQL Server가 설치된 VM 이미지 사용</li>
<li>사용한 시간만큼 VM 비용 + SQL Server 라이선스 비용 지불</li>
</ul></li>
<li>기존 라이선스 사용(BYOL) 방식
<ul>
<li>Software Assurance(SA) 프로그램 참여 고객만 가능</li>
<li>기존 보유한 SQL Server 라이선스를 Azure VM에 적용</li>
<li>VM 구현 후 10일 이내에 Microsoft에 라이선스 사용 보고 필요</li>
<li>SQL Server를 직접 설치하거나 커스텀 이미지 업로드 가능</li>
</ul></li>
</ol>
<p>비용 절감을 위한 추가 옵션: - Windows Server 라이선스도 기존 것 사용 가능 (Azure Hybrid Benefit) - VM을 1-3년 예약 구매 시 추가 할인 - 선불 결제 없이 월별 청구 가능 - 장기 사용 예정인 대형 VM에 특히 유리</p>
</section>
<section id="azure-vm-제품군-종류" class="level4">
<h4 class="anchored" data-anchor-id="azure-vm-제품군-종류">Azure VM 제품군 종류</h4>
<p>Azure VM은 다양한 제품군(시리즈)을 제공하며, 각각 특정 용도에 최적화되어 있다.</p>
<ol type="1">
<li>범용(General Purpose)
<ul>
<li>CPU와 메모리의 균형잡힌 구성</li>
<li>테스트/개발 환경, 소/중규모 DB 서버, 중소 트래픽 웹서버에 적합</li>
</ul></li>
<li>컴퓨팅 최적화(Compute Optimized)
<ul>
<li>높은 CPU 대 메모리 비율</li>
<li>중규모 웹서버, 네트워크 어플라이언스, 배치 처리에 적합</li>
<li>기본적인 머신러닝 워크로드 지원</li>
</ul></li>
<li>메모리 최적화(Memory Optimized)
<ul>
<li>높은 메모리 대 CPU 비율 (최대 4TB RAM)</li>
<li>대부분의 데이터베이스 워크로드에 적합</li>
</ul></li>
<li>스토리지 최적화(Storage Optimized)
<ul>
<li>고속 로컬 NVMe 임시 스토리지 제공</li>
<li>Cassandra 등 스케일아웃 데이터 워크로드에 적합</li>
<li>SQL Server 사용 시 Always On 가용성 그룹 등 데이터 보호 구성 필요</li>
</ul></li>
<li>GPU 최적화
<ul>
<li>비디오 렌더링/처리</li>
<li>GPU 기반 대규모 병렬 머신러닝 워크로드에 적합</li>
</ul></li>
<li>FPGA 가속
<ul>
<li>컴퓨팅 집약적 워크로드용</li>
<li>높은 스토리지 처리량과 네트워크 대역폭 제공</li>
</ul></li>
<li>고성능 컴퓨팅(HPC)
<ul>
<li>수천 개 CPU 코어로 수평 확장 가능</li>
<li>RDMA 네트워킹을 통한 낮은 지연시간 제공</li>
</ul></li>
</ol>
<ul>
<li>VM 크기 선택 방법
<ul>
<li>Azure 포털의 VM 생성 블레이드에서 ‘모든 크기 보기’ 선택</li>
<li>각 크기별 상세 정보 확인 가능:
<ul>
<li>vCPU 수</li>
<li>RAM 용량</li>
<li>데이터 디스크 수</li>
<li>최대 IOPS</li>
<li>임시 스토리지 용량</li>
<li>프리미엄 스토리지 지원 여부</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="azure-marketplace" class="level4">
<h4 class="anchored" data-anchor-id="azure-marketplace">Azure Marketplace</h4>
<p>Azure Marketplace는 Azure에서 제공하는 리소스 스토어로, 미리 만들어진 템플릿을 사용해 쉽게 리소스를 생성할 수 있다.</p>
<ul>
<li>주요 특징:
<ul>
<li>간단한 설정: 기본 정보만 입력하면 빠르게 리소스 생성 가능</li>
<li>빠른 구축: 몇 분 안에 리소스 사용 가능</li>
<li>다양한 옵션: SQL Server, Windows Server 등 다양한 제품 제공</li>
<li>사전 구성: OLTP, Data Warehouse 등 용도에 맞는 설정 제공</li>
</ul></li>
<li>장점
<ul>
<li>쉽고 빠른 시작 가능</li>
<li>직관적인 인터페이스</li>
<li>상세 설정 없이도 사용 가능</li>
</ul></li>
<li>단점
<ul>
<li>반복 작업이 어려움</li>
<li>자동화하기 불편함</li>
</ul></li>
</ul>
</section>
<section id="sql-server-configuration" class="level4">
<h4 class="anchored" data-anchor-id="sql-server-configuration">SQL Server configuration</h4>
<p>Azure VM에서 SQL Server를 설치할 때 다음과 같은 기본적인 설정들을 할 수 있다:</p>
<ul>
<li>보안 설정: 방화벽 규칙, 접근 권한 등을 설정</li>
<li>네트워크 설정: 가상 네트워크, 서브넷 등을 구성<br>
</li>
<li>SQL 인증: 사용자 계정과 비밀번호 설정</li>
<li>SQL 인스턴스: 데이터베이스 엔진 설정</li>
</ul>
</section>
</section>
<section id="understand-hybrid-scenarios" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="understand-hybrid-scenarios"><span class="header-section-number">1.3</span> <a href="https://learn.microsoft.com/en-us/training/modules/deploy-iaas-solutions-with-azure-sql/3-understand-hybrid-scenarios">Understand hybrid scenarios</a></h3>
<ul>
<li>하이브리드 인프라의 필요성
<ul>
<li>온프레미스/로컬 데이터센터의 SQL Server 인프라 투자 활용 가능</li>
<li>클라우드와 온프레미스의 장점을 모두 활용 가능</li>
<li>운영 복원력 향상과 비용 절감 효과</li>
</ul></li>
<li>하이브리드 인프라의 장점
<ul>
<li>클라우드 전환에 신중한 조직을 위한 좋은 시작점</li>
<li>물리적/가상화된 SQL Server 온프레미스 배포를 클라우드로 확장 가능</li>
<li>온프레미스와 클라우드 서비스의 상호 보완적 운영</li>
<li>IaaS 서비스(스토리지, SQL Server VM 등) 활용 가능</li>
</ul></li>
<li>하이브리드 구현 범위
<ul>
<li>온프레미스와 클라우드 간 하이브리드</li>
<li>여러 클라우드 서비스 간 하이브리드 구현 가능</li>
<li>다양한 SQL Server 하이브리드 시나리오 적용 가능</li>
</ul></li>
</ul>
<section id="sql-server를-위한-하이브리드-시나리오" class="level4">
<h4 class="anchored" data-anchor-id="sql-server를-위한-하이브리드-시나리오">SQL Server를 위한 하이브리드 시나리오</h4>
<p>SQL Server를 위한 하이브리드 솔루션을 배포할 때 고려할 수 있는 몇 가지 전략</p>
</section>
<section id="재해-복구" class="level4">
<h4 class="anchored" data-anchor-id="재해-복구">재해 복구</h4>
<p>재해 복구는 SQL Server를 하이브리드로 운영할 때 가장 많이 사용되는 방식</p>
<ul>
<li>주요 특징
<ul>
<li>재난 상황에서도 비즈니스 연속성 보장</li>
<li>여러 데이터 센터에 분산 배치 가능</li>
<li>Azure VM을 활용해 비용 효율적인 DR 구축</li>
</ul></li>
<li>운영 방식
<ul>
<li>일상적인 처리는 온프레미스 서버 사용</li>
<li>재해 발생 시 Azure로 전환(장애 조치)</li>
<li>여러 지역에 걸쳐 백업 가능</li>
</ul></li>
</ul>
</section>
<section id="sql-server-백업" class="level4">
<h4 class="anchored" data-anchor-id="sql-server-백업">SQL Server 백업</h4>
<p>SQL Server의 데이터를 안전하게 보관하기 위한 백업 전략</p>
<ul>
<li>백업 방식
<ul>
<li>Azure Storage에 직접 백업 (URL 사용)</li>
<li>Azure 파일 공유 활용 (SMB 프로토콜)</li>
</ul></li>
<li>주요 이점
<ul>
<li>현장 백업 실패 시에도 데이터 보호</li>
<li>Azure VM에서 백업 데이터 복원 테스트 가능</li>
<li>클라우드의 안정적인 스토리지 활용</li>
</ul></li>
</ul>
</section>
<section id="azure-arc-지원-sql-server" class="level4">
<h4 class="anchored" data-anchor-id="azure-arc-지원-sql-server">Azure Arc 지원 SQL Server</h4>
<p>여러 환경의 SQL Server를 Azure에서 통합 관리할 수 있게 해주는 서비스</p>
<ul>
<li>지원 환경
<ul>
<li>온프레미스</li>
<li>데이터 센터</li>
<li>엣지 환경</li>
<li>멀티클라우드</li>
</ul></li>
<li>주요 기능
<ul>
<li>모든 SQL Server 배포 현황 파악</li>
<li>구성/사용 패턴/보안 평가</li>
<li>실시간 보안 경고</li>
<li>취약점 보고</li>
</ul></li>
</ul>
</section>
<section id="보안-고려사항" class="level4">
<h4 class="anchored" data-anchor-id="보안-고려사항">보안 고려사항</h4>
<p>하이브리드 SQL 환경을 안전하게 운영하기 위한 보안 요소</p>
<ul>
<li>기본 요구사항
<ul>
<li>Active Directory와 DNS 설정 (온프레미스/Azure 모두)</li>
<li>안전한 양방향 통신 구축</li>
</ul></li>
<li>연결 방식
<ul>
<li>사이트 간(S2S) VPN</li>
<li>ExpressRoute</li>
</ul></li>
<li>ExpressRoute 특징
<ul>
<li>장점
<ul>
<li>최고 수준의 보안</li>
<li>최소 지연 시간</li>
<li>공용 인터넷과 분리된 전용 채널</li>
</ul></li>
<li>단점
<ul>
<li>높은 비용</li>
<li>멀티클라우드 환경에서 제한적 사용</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="explore-performance-and-security" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="explore-performance-and-security"><span class="header-section-number">1.4</span> <a href="https://learn.microsoft.com/en-us/training/modules/deploy-iaas-solutions-with-azure-sql/4-explore-performance-and-security">Explore performance and security</a></h3>
<ul>
<li>Azure 에코시스템은 Azure 가상 머신의 SQL Server 인스턴스에 대한 다양한 성능 및 보안 옵션을 제공한다</li>
<li>각 옵션은 워크로드의 용량 및 성능 요구사항을 충족하는 다양한 디스크 유형과 같은 기능을 제공한다.</li>
</ul>
<section id="스토리지-고려사항" class="level4">
<h4 class="anchored" data-anchor-id="스토리지-고려사항">스토리지 고려사항</h4>
<ul>
<li>SQL Server는 Azure VM이나 온프레미스 환경에서 모두 고성능을 위해 우수한 스토리지 성능이 필수적</li>
<li>Azure는 다양한 스토리지 솔루션을 제공하는데, SQL Server 워크로드는 주로 Azure 관리 디스크를 사용</li>
<li>Azure 관리 디스크는 VM에 제공되는 블록 수준 스토리지로, 높은 가용성과 확장성을 제공</li>
</ul>
<p>Azure 관리 디스크의 주요 특징:</p>
<ul>
<li>스토리지 유형
<ul>
<li>Blob, 파일, 큐, 테이블 등 다양한 유형 제공</li>
<li>SQL Server는 주로 관리 디스크 사용</li>
<li>장애 조치 클러스터는 파일 스토리지 사용 가능</li>
<li>백업은 blob 스토리지 활용</li>
</ul></li>
<li>관리 디스크의 장점
<ul>
<li>99.999%의 높은 가용성</li>
<li>지역당 구독당 최대 50,000개 VM 디스크 지원</li>
<li>가용성 집합/영역과의 통합으로 높은 복원력</li>
</ul></li>
<li>암호화 옵션
<ul>
<li>Azure 서버 측 암호화: 스토리지 서비스 레벨의 암호화</li>
<li>Azure 디스크 암호화: VM 내부의 OS/데이터 디스크 암호화</li>
<li>두 옵션 모두 Azure Key Vault 통합 지원</li>
</ul></li>
</ul>
<p>VM에 연결되는 디스크 유형:</p>
<ol type="1">
<li>운영 체제 디스크
<ul>
<li>부팅 볼륨 포함</li>
<li>Windows: C: 드라이브</li>
<li>Linux: /dev/sda1</li>
</ul></li>
<li>임시 디스크
<ul>
<li>임시 스토리지용</li>
<li>페이지/스왑 파일 등 비영구 데이터 저장</li>
<li>Windows: D:&nbsp;드라이브</li>
<li>Linux: /dev/sdb1</li>
<li>중요 데이터 저장 금지</li>
</ul></li>
<li>데이터 디스크
<ul>
<li>VM에 추가되는 관리 디스크</li>
<li>Windows: Storage Spaces로 풀링 가능</li>
<li>Linux: 논리 볼륨 관리로 풀링 가능</li>
<li>IOPS와 스토리지 용량 확장 가능</li>
</ul></li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 15%">
<col style="width: 20%">
<col style="width: 16%">
<col style="width: 17%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Ultra Disk</th>
<th>Premium SSD v2</th>
<th>Premium SSD</th>
<th>Standard SSD</th>
<th>Standard HDD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Disk type</td>
<td>SSD</td>
<td>SSD</td>
<td>SSD</td>
<td>SSD</td>
<td>HDD</td>
</tr>
<tr class="even">
<td>Best for</td>
<td>IO-intensive workloads</td>
<td>Performance-sensitive workloads</td>
<td>Performance-sensitive workloads</td>
<td>Lightweight workloads</td>
<td>Backups, non-critical workloads</td>
</tr>
<tr class="odd">
<td>Max disk size</td>
<td>65,536 GiB</td>
<td>64,000 GiB</td>
<td>32,767 GiB</td>
<td>32,767 GiB</td>
<td>32,767 GiB</td>
</tr>
<tr class="even">
<td>Max throughput</td>
<td>10,000 MB/s</td>
<td>1,200 MB/s</td>
<td>900 MB/s</td>
<td>750 MB/s</td>
<td>500 MB/s</td>
</tr>
<tr class="odd">
<td>Max IOPS</td>
<td>160,000</td>
<td>80,000</td>
<td>20,000</td>
<td>6,000</td>
<td>2,000</td>
</tr>
</tbody>
</table>
<p>Azure SQL Server의 스토리지 구성에 대한 모범 사례를 살펴보면, 성능 최적화를 위해 여러 디스크를 적절히 구성하는 것이 중요. 특히 IOPS와 스토리지 용량을 효과적으로 관리하기 위해서는 프리미엄 디스크를 풀링하여 사용하는 것이 권장됨</p>
<p>각 데이터 유형별 스토리지 구성 권장사항:</p>
<ul>
<li>데이터 파일
<ul>
<li>프리미엄 디스크의 자체 풀에 저장</li>
<li>읽기 캐싱 기능 활성화</li>
<li>높은 IOPS와 처리량 확보</li>
</ul></li>
<li>트랜잭션 로그 파일
<ul>
<li>별도의 디스크 풀에 저장</li>
<li>캐싱 기능 비활성화 (캐싱의 이점 없음)</li>
<li>안정적인 쓰기 성능 보장</li>
</ul></li>
<li>TempDB
<ul>
<li>두 가지 옵션 중 선택:
<ol type="1">
<li>자체 디스크 풀에 저장</li>
<li>VM의 임시 디스크 활용 (물리 서버와 직접 연결되어 낮은 지연시간 제공)</li>
</ol></li>
</ul></li>
</ul>
<p>성능 요구사항에 따른 디스크 선택: - 일반적인 워크로드: 프리미엄 SSD (밀리초 단위의 지연시간) - 미션 크리티컬 워크로드: Ultra SSD (더 낮은 지연시간 필요시)</p>
</section>
<section id="보안-고려사항-1" class="level4">
<h4 class="anchored" data-anchor-id="보안-고려사항-1">보안 고려사항</h4>
<p>Azure는 가상 머신에서 실행되는 SQL Server의 규정 준수 솔루션을 위해 다양한 보안 도구와 기능을 제공합니다.</p>
<p>주요 보안 도구:</p>
<ol type="1">
<li>SQL용 Microsoft Defender
<ul>
<li>취약성 평가 및 보안 경고 기능 제공</li>
<li>SQL Server 인스턴스와 데이터베이스의 잠재적 취약점 식별</li>
<li>보안 위험 감지 및 해결 방안 제시</li>
<li>보안 상태 모니터링 및 개선을 위한 실행 가능한 단계 제공</li>
</ul></li>
<li>Azure Security Center
<ul>
<li>통합 보안 관리 시스템</li>
<li>하이브리드 클라우드 워크로드 전반의 보안 상태 모니터링</li>
<li>공격 노출 감소 및 위협 대응 기능</li>
<li>보안 개선 기회 식별 및 제안</li>
</ul></li>
</ol>
</section>
<section id="성능-최적화-방안" class="level4">
<h4 class="anchored" data-anchor-id="성능-최적화-방안">성능 최적화 방안</h4>
<p>Azure VM의 SQL Server는 온프레미스 환경과 유사한 성능 최적화 기능을 제공합니다.</p>
<p>주요 성능 최적화 기능:</p>
<ol type="1">
<li>테이블 파티셔닝
<ul>
<li>대규모 테이블의 효율적 관리</li>
<li>쿼리 성능 향상</li>
<li>유지보수 작업 효율화</li>
</ul>
구현 단계:
<ul>
<li>파일 그룹 생성</li>
<li>파티션 함수 정의</li>
<li>파티션 스키마 생성</li>
<li>테이블 파티션 설정</li>
</ul></li>
<li>데이터 압축 압축 유형:
<ul>
<li>행 압축
<ul>
<li>기본적인 압축 방식</li>
<li>최소 저장 공간 사용</li>
<li>낮은 시스템 부하</li>
</ul></li>
<li>페이지 압축
<ul>
<li>행 압축 포함</li>
<li>접두사 압축과 사전 압축 기술 적용</li>
<li>높은 압축률 제공</li>
</ul></li>
<li>컬럼스토어 아카이브 압축
<ul>
<li>XPRESS 압축 알고리즘 사용</li>
<li>자주 접근하지 않는 보관 데이터에 적합</li>
<li>높은 CPU 사용률</li>
</ul></li>
</ul></li>
<li>추가 최적화 옵션
<ul>
<li>백업 압축 기능 활성화</li>
<li>즉각적인 파일 초기화 설정</li>
<li>데이터베이스 자동 증가 제한 설정</li>
<li>자동 축소/자동 닫기 기능 비활성화</li>
<li>시스템 데이터베이스 데이터 디스크 이전</li>
<li>로그 및 추적 파일 데이터 디스크 이전</li>
</ul></li>
</ol>
<pre><code>-- Partition function
CREATE PARTITION FUNCTION PartitionByMonth (datetime2)
    AS RANGE RIGHT
    -- The boundary values defined is the first day of each month, where the table will be partitioned into 13 partitions
    FOR VALUES ('20210101', '20210201', '20210301',
      '20210401', '20210501', '20210601', '20210701',
      '20210801', '20210901', '20211001', '20211101', 
      '20211201');

-- The partition scheme below will use the partition function created above, and assign each partition to a specific filegroup.
CREATE PARTITION SCHEME PartitionByMonthSch
    AS PARTITION PartitionByMonth
    TO (FILEGROUP1, FILEGROUP2, FILEGROUP3, FILEGROUP4,
        FILEGROUP5, FILEGROUP6, FILEGROUP7, FILEGROUP8,
        FILEGROUP9, FILEGROUP10, FILEGROUP11, FILEGROUP12);

-- Creates a partitioned table called Order that applies PartitionByMonthSch partition scheme to partition the OrderDate column  
CREATE TABLE Order ([Id] int PRIMARY KEY, OrderDate datetime2)  
    ON PartitionByMonthSch (OrderDate) ;  
GO
</code></pre>
</section>
<section id="데이터-압축" class="level4">
<h4 class="anchored" data-anchor-id="데이터-압축">데이터 압축</h4>
<p>SQL Server의 데이터 압축은 데이터베이스의 성능과 저장 공간을 최적화하는 중요한 기능입니다.</p>
<p>데이터 압축의 기본 구조: - SQL Server는 8KB 크기의 페이지 단위로 데이터를 저장 - 압축을 통해 한 페이지에 더 많은 데이터를 저장 가능</p>
<p>데이터 압축의 주요 효과: 1. 물리적 IO 감소 - 쿼리 실행 시 읽어야 할 페이지 수가 줄어듦 - 디스크 읽기/쓰기 작업이 감소</p>
<ol start="2" type="1">
<li>메모리 사용 효율성 향상
<ul>
<li>버퍼 풀의 메모리를 더 효율적으로 사용</li>
<li>동일한 메모리로 더 많은 데이터 처리 가능</li>
</ul></li>
</ol>
<p>데이터 압축의 주요 특징과 장단점은 다음과 같습니다:</p>
<ol type="1">
<li><p>주요 이점</p>
<ul>
<li>물리적 IO 감소</li>
<li>버퍼 풀의 효율적인 메모리 사용</li>
<li>저장 공간 절약</li>
<li>대부분의 경우 전반적인 성능 향상</li>
</ul></li>
<li><p>잠재적 단점</p>
<ul>
<li>CPU 사용량 증가</li>
<li>압축/해제 과정에서의 추가 처리 시간</li>
</ul></li>
<li><p>구현 특성</p>
<ul>
<li>개체 수준에서 구현 가능</li>
<li>개별 인덱스나 테이블 단위로 압축 가능</li>
<li>파티션 단위로도 압축 설정 가능</li>
<li>sp_estimate_data_compression_savings 프로시저로 압축 효과 예측 가능</li>
</ul></li>
<li><p>압축 유형별 특징</p>
<p>행 압축:</p>
<ul>
<li>기본적인 압축 방식으로 최소한의 시스템 부하</li>
<li>각 열의 값을 최소 필요 공간으로 저장</li>
<li>숫자 데이터는 가변 길이로 저장</li>
<li>고정 길이 문자열을 가변 길이로 변환</li>
</ul>
<p>페이지 압축:</p>
<ul>
<li>행 압축을 포함한 고급 압축 방식</li>
<li>접두사 압축으로 중복 데이터 제거</li>
<li>사전 압축으로 반복 값을 포인터로 대체</li>
<li>데이터 중복성이 높을수록 압축률 증가</li>
</ul>
<p>컬럼스토어 아카이브 압축:</p>
<ul>
<li>XPRESS 압축 알고리즘 사용</li>
<li>자주 접근하지 않는 보관용 데이터에 적합</li>
<li>높은 압축률 제공</li>
<li>CPU 사용량이 상대적으로 높음</li>
</ul></li>
</ol>
</section>
<section id="추가-옵션" class="level4">
<h4 class="anchored" data-anchor-id="추가-옵션">추가 옵션</h4>
<p>다음은 프로덕션 워크로드에 대해 고려해야 할 추가 SQL Server 기능 및 작업 목록:</p>
<ul>
<li>백업 압축 활성화</li>
<li>데이터 파일에 대한 즉각적인 파일 초기화 활성화</li>
<li>데이터베이스 자동 증가 제한</li>
<li>데이터베이스에 대한 자동 축소/자동 닫기 비활성화</li>
<li>시스템 데이터베이스를 포함한 모든 데이터베이스를 데이터 디스크로 이동</li>
<li>SQL Server 오류 로그 및 추적 파일 디렉터리를 데이터 디스크로 이동</li>
<li>최대 SQL Server 메모리 제한 설정</li>
<li>메모리의 페이지 잠금 활성화</li>
<li>OLTP 중심 환경을 위한 임시 워크로드 최적화 활성화</li>
<li>쿼리 스토어 활성화</li>
<li>DBCC CHECKDB, 인덱스 재구성, 인덱스 재구축 및 통계 업데이트 작업을 실행하도록 SQL Server Agent 작업 예약</li>
<li>트랜잭션 로그 파일의 상태 및 크기 모니터링 및 관리</li>
</ul>
</section>
</section>
</section>
<section id="explain-high-availability-and-disaster-recovery-options" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="explain-high-availability-and-disaster-recovery-options"><span class="header-section-number">2</span> <a href="https://learn.microsoft.com/en-us/training/modules/deploy-iaas-solutions-with-azure-sql/5-explain-high-availability-and-disaster-recovery-options">Explain high availability and disaster recovery options</a></h2>
<p>Azure 플랫폼의 고가용성 옵션:</p>
<ol type="1">
<li>기본 제공 고가용성
<ul>
<li>VM과 PaaS 워크로드에 기본적으로 제공</li>
</ul></li>
<li>추가 고가용성 옵션
<ul>
<li>가용성 영역(Availability Zones)</li>
<li>가용성 집합(Availability Sets)</li>
</ul></li>
<li>주요 보호 기능
<ul>
<li>계획된 유지보수 활동으로부터 보호</li>
<li>잠재적인 하드웨어 장애로부터 보호</li>
<li>더 높은 수준의 가용성 제공</li>
</ul></li>
</ol>
<section id="high-availability-options" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="high-availability-options"><span class="header-section-number">2.1</span> High availability options</h3>
<p>SQL Server 고가용성 솔루션의 Azure VM 지원:</p>
<ul>
<li>Azure 전용 솔루션
<ul>
<li>전체 HADR 시스템이 Azure에서 실행</li>
<li>완전한 클라우드 기반 운영 가능</li>
</ul></li>
<li>하이브리드 구성
<ul>
<li>일부는 Azure에서 실행</li>
<li>일부는 온프레미스에서 실행</li>
<li>유연한 구성 가능</li>
</ul></li>
<li>Azure 환경의 장점
<ul>
<li>예산에 맞춘 단계적 마이그레이션 가능</li>
<li>HADR 요구사항에 따른 유연한 구성</li>
<li>부분 또는 완전 마이그레이션 선택 가능</li>
</ul></li>
</ul>
<section id="availability-zones" class="level4">
<h4 class="anchored" data-anchor-id="availability-zones">Availability Zones</h4>
<section id="가용성-영역-개요" class="level5">
<h5 class="anchored" data-anchor-id="가용성-영역-개요">가용성 영역 개요</h5>
<ul>
<li>한 지역 내의 고유한 물리적 위치</li>
<li>각 영역은 독립적인 전원, 냉각, 네트워킹을 갖춘 데이터센터로 구성</li>
<li>지원되는 Azure 지역마다 3개의 가용성 영역 제공</li>
</ul>
</section>
<section id="가용성-영역-특징" class="level5">
<h5 class="anchored" data-anchor-id="가용성-영역-특징">가용성 영역 특징</h5>
<ul>
<li>VM 생성 시 배치할 영역 지정 가능</li>
<li>여러 VM을 다른 영역에 분산 배포하여 데이터센터 장애 대비</li>
<li>Microsoft는 한 번에 하나의 영역만 업데이트 (업데이트 도메인 사용)</li>
<li>VM 에코시스템을 3개 영역에 분산 가능</li>
</ul>
</section>
<section id="가용성-영역-장점" class="level5">
<h5 class="anchored" data-anchor-id="가용성-영역-장점">가용성 영역 장점</h5>
<ul>
<li>가동 시간 99.99% 보장 (연간 최대 52.60분 다운타임)</li>
<li>애플리케이션에 가장 높은 수준의 가용성 제공</li>
<li>docs.microsoft.com에서 지원 지역 확인 가능</li>
</ul>
</section>
<section id="가용성-영역-배포" class="level5">
<h5 class="anchored" data-anchor-id="가용성-영역-배포">가용성 영역 배포</h5>
<ul>
<li>Zone 1, 2, 3 중 선택하여 배포 가능</li>
<li>물리적 데이터센터의 논리적 표현</li>
<li>구독별로 Zone 번호가 다른 데이터센터를 나타낼 수 있음</li>
</ul>
</section>
<section id="사용-조건" class="level5">
<h5 class="anchored" data-anchor-id="사용-조건">사용 조건</h5>
<ul>
<li>해당 지역에서 가용성 영역 지원 필요</li>
<li>애플리케이션이 최소한의 영역 간 지연 시간 지원 필요</li>
</ul>
</section>
</section>
<section id="availability-sets" class="level4">
<h4 class="anchored" data-anchor-id="availability-sets">Availability Sets</h4>
<section id="가용성-집합-개요" class="level5">
<h5 class="anchored" data-anchor-id="가용성-집합-개요">가용성 집합 개요</h5>
<ul>
<li>가용성 영역과의 차이점
<ul>
<li>가용성 영역: 지역의 데이터 센터에 워크로드 분산</li>
<li>가용성 집합: 데이터 센터 내의 서버와 랙에 워크로드 분산</li>
</ul></li>
</ul>
</section>
<section id="주요-특징" class="level5">
<h5 class="anchored" data-anchor-id="주요-특징">주요 특징</h5>
<ul>
<li>VM 분산 배치 보장
<ul>
<li>Always On 가용성 그룹 멤버 VM들이 서로 다른 물리적 호스트에서 실행되도록 보장</li>
<li>Azure의 대부분 워크로드가 가상화되어 있어 효과적</li>
</ul></li>
</ul>
</section>
<section id="성능-및-사용-조건" class="level5">
<h5 class="anchored" data-anchor-id="성능-및-사용-조건">성능 및 사용 조건</h5>
<ul>
<li>가용성 보장
<ul>
<li>최대 99.95%의 가용성 제공</li>
</ul></li>
<li>사용 시나리오
<ul>
<li>가용성 영역을 사용할 수 없는 지역</li>
<li>애플리케이션이 영역 내 지연 시간을 허용할 수 없는 경우</li>
</ul></li>
</ul>
</section>
</section>
<section id="always-on-availability-groups-ag" class="level4">
<h4 class="anchored" data-anchor-id="always-on-availability-groups-ag">Always On availability groups (AG)</h4>
<ul>
<li>구현 범위
<ul>
<li>Azure 가상 머신에서 실행되는 두 개 이상(최대 9개)의 SQL Server 인스턴스 간</li>
<li>온프레미스 데이터 센터와 Azure 간 구현 가능</li>
</ul></li>
<li>작동 방식
<ul>
<li>데이터베이스 트랜잭션이 기본 복제본에 커밋</li>
<li>동기식 또는 비동기식으로 모든 보조 복제본으로 전송</li>
</ul></li>
<li>가용성 모드 선택 기준
<ul>
<li>서버 간 물리적 거리에 따라 결정</li>
<li>비동기식 가용성 모드 권장 상황:
<ul>
<li>워크로드가 낮은 지연 시간 요구</li>
<li>보조 복제본이 지리적으로 분산된 경우</li>
</ul></li>
<li>동기식 커밋 모드 권장 상황:
<ul>
<li>복제본이 동일한 Azure 지역 내 위치</li>
<li>애플리케이션이 일정 수준의 지연 시간 허용 가능</li>
</ul></li>
</ul></li>
<li>동기식 모드 특징
<ul>
<li>각 트랜잭션이 하나 이상의 보조 복제본에 커밋된 후 애플리케이션 진행</li>
</ul></li>
<li>장점
<ul>
<li>단일 가용성 그룹이 동기식과 비동기식 가용성 모드 모두 지원</li>
<li>고가용성과 재해 복구 동시 제공</li>
<li>장애 조치 단위는 데이터베이스 그룹(전체 인스턴스가 아님)</li>
</ul></li>
<li>재해 복구 기능
<ul>
<li>Azure 지역 전체에 걸쳐 최대 9개의 데이터베이스 복제본 구현 가능</li>
<li>분산 가용성 그룹을 통한 아키텍처 확장 가능</li>
<li>기본 지역 외 다른 위치에 데이터베이스 실행 가능한 복사본 보장</li>
<li>자연 재해와 인위적 재해로부터 데이터 생태계 보호</li>
</ul></li>
<li>구성 예시
<ul>
<li>Windows Server 장애 조치 클러스터에서 실행</li>
<li>하나의 기본 복제본과 4개의 보조 복제본 구성 가능</li>
<li>모든 복제본이 동기식이거나, 동기식과 비동기식 복제본 조합 가능</li>
<li>장애 조치 단위는 데이터베이스 그룹(인스턴스가 아님)</li>
<li>장애 조치 클러스터 인스턴스는 인스턴스 수준 HA 제공(재해 복구는 제공하지 않음)</li>
</ul></li>
</ul>
</section>
<section id="sql-server-failover-cluster-instances" class="level4">
<h4 class="anchored" data-anchor-id="sql-server-failover-cluster-instances">SQL Server Failover Cluster instances</h4>
<ul>
<li>SQL Server 장애 조치 클러스터 인스턴스(FCI) 개요
<ul>
<li>전체 인스턴스 보호를 위한 솔루션</li>
<li>단일 지역에서 전체 인스턴스에 대한 고가용성 제공</li>
<li>단독으로는 재해 복구 기능 제공하지 않음
<ul>
<li>가용성 그룹이나 로그 전달과 같은 기능과 결합 필요</li>
</ul></li>
<li>공유 스토리지 요구사항 존재
<ul>
<li>Azure에서 공유 파일 스토리지 사용 가능</li>
<li>Windows Server의 Storage Spaces Direct 활용 가능</li>
</ul></li>
</ul></li>
<li>Azure 환경에서의 FCI 고려사항
<ul>
<li>새로운 배포에서는 가용성 그룹이 선호됨
<ul>
<li>FCI의 공유 스토리지 요구사항이 배포 복잡성 증가</li>
</ul></li>
<li>온프레미스 솔루션 마이그레이션 시 FCI 필요 가능성
<ul>
<li>기존 애플리케이션 지원을 위한 요구사항 고려</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="disaster-recovery-options" class="level4">
<h4 class="anchored" data-anchor-id="disaster-recovery-options">Disaster Recovery options</h4>
<ul>
<li>Azure 플랫폼 기본 특성
<ul>
<li>기본적으로 99.9%의 가동 시간 제공</li>
<li>재해 발생 가능성 여전히 존재</li>
<li>애플리케이션 가동 시간에 영향을 미칠 수 있음</li>
</ul></li>
<li>재해 복구 계획의 중요성
<ul>
<li>마이그레이션 수행 시 적절한 계획 수립 필요</li>
<li>데이터 및 서비스 연속성 보장</li>
</ul></li>
<li>Azure의 SQL Server 보호 방법 (두 가지 구성 요소)
<ul>
<li>Azure 플랫폼 옵션
<ul>
<li>지역 복제 스토리지 (백업용)</li>
<li>Azure Site Recovery (포괄적인 재해 복구 솔루션)</li>
</ul></li>
<li>SQL Server 전용 기능
<ul>
<li>가용성 그룹(Availability Groups)</li>
<li>네이티브 백업 기능</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="native-sql-server-backups" class="level4">
<h4 class="anchored" data-anchor-id="native-sql-server-backups">Native SQL Server backups</h4>
<ul>
<li>백업의 중요성
<ul>
<li>모든 데이터베이스 관리자에게 있어 생명줄과 같은 역할</li>
<li>클라우드 솔루션에서도 동일하게 중요</li>
</ul></li>
<li>Azure VM의 SQL Server 백업 특징
<ul>
<li>백업 시기와 저장 위치에 대한 세밀한 제어 가능</li>
<li>SQL 에이전트 작업을 통한 Azure blob 스토리지 직접 백업 지원</li>
<li>URL을 통한 백업 연결 방식 제공</li>
</ul></li>
<li>Azure 스토리지 옵션
<ul>
<li>지역 중복 스토리지(GRS) 제공</li>
<li>읽기 액세스 지역 중복 스토리지(RA-GRS) 제공</li>
<li>지리적으로 분산된 환경에서 백업 파일 안전 보장</li>
</ul></li>
<li>자동화 옵션
<ul>
<li>Azure SQL VM 서비스 제공자를 통한 자동 백업 관리 가능</li>
<li>플랫폼 수준의 백업 자동화 지원</li>
</ul></li>
</ul>
</section>
<section id="azure-backup-for-sql-server" class="level4">
<h4 class="anchored" data-anchor-id="azure-backup-for-sql-server">Azure Backup for SQL Server</h4>
<ul>
<li>기본 구성 요소
<ul>
<li>가상 머신에 에이전트 설치 필요</li>
<li>SQL Server 데이터베이스의 자동 백업 관리</li>
<li>Azure 서비스와 에이전트 간 통신</li>
</ul></li>
<li>주요 기능
<ul>
<li>지정된 RPO/RTO 메트릭 충족 관리</li>
<li>백업 모니터링을 위한 중앙 집중식 인터페이스 제공</li>
<li>장기 데이터 보존 지원</li>
<li>자동화된 백업 관리 기능</li>
<li>추가적인 데이터 보호 기능</li>
</ul></li>
<li>비용 및 가치
<ul>
<li>직접 백업보다 높은 비용</li>
<li>SQL Server용 Azure 리소스 공급자보다 비용 증가</li>
<li>더 포괄적인 엔터프라이즈 백업 솔루션 제공</li>
<li>완벽한 백업 기능 세트 제공</li>
</ul></li>
</ul>
</section>
<section id="azure-site-recovery" class="level4">
<h4 class="anchored" data-anchor-id="azure-site-recovery">Azure Site Recovery</h4>
<ul>
<li>개요
<ul>
<li>Azure 가상 머신의 블록 수준 복제를 수행하는 저비용 솔루션</li>
<li>재해 복구 전략을 테스트하고 검증할 수 있는 다양한 기능 제공</li>
</ul></li>
<li>적합한 사용 환경
<ul>
<li>상태가 없는 환경(예: 웹 서버)에 가장 적합</li>
<li>트랜잭션 데이터베이스 가상 머신에는 덜 적합</li>
</ul></li>
<li>SQL Server와 함께 사용 시 고려사항
<ul>
<li>더 높은 복구 지점 설정 필요 (잠재적 데이터 손실 의미)</li>
<li>RTO(복구 시간 목표)가 본질적으로 RPO(복구 지점 목표)가 됨</li>
</ul></li>
<li>작동 프로세스
<ul>
<li>VM이 Azure Site Recovery에 등록</li>
<li>데이터가 캐시로 지속적으로 복제</li>
<li>캐시가 대상 스토리지 계정으로 복제</li>
<li>장애 조치(failover) 중에 가상 머신이 대상 환경에 추가</li>
</ul></li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>Engineering</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Engineering/data_engineering/2.IaaS.html</guid>
  <pubDate>Wed, 02 Apr 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Azure 가상 머신의 SQL Server</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Engineering/data_engineering/1.azure_server_based_db_management.html</link>
  <description><![CDATA[ 




<section id="microsoft-intelligent-data-platform-역할-설명" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="microsoft-intelligent-data-platform-역할-설명"><span class="header-section-number">1</span> <a href="https://learn.microsoft.com/ko-kr/training/modules/prepare-to-maintain-sql-databases-azure/2-describe-azure-data-platform-roles">Microsoft Intelligent Data Platform 역할 설명</a></h2>
<p>Microsoft는 클라우드(Microsoft Intelligent Data Platform 서비스 활용) 데이터 관련 업무를 위한 5가지 주요 역할을 정의하고 있다:</p>
<ol type="1">
<li>Azure 데이터베이스 관리자
<ul>
<li>Azure 데이터 서비스와 SQL Server 기반 데이터 플랫폼 솔루션 관리 (데이터 관리, 모니터링, 보안 및 개인정보 보호 설계)</li>
<li>T-SQL을 활용한 일상적인 운영 및 관리 작업 수행</li>
</ul></li>
<li>Azure 데이터 분석가
<ul>
<li>Microsoft Power BI를 사용</li>
<li>확장 가능한 데이터 모델을 설계 및 구축하고, 데이터를 정리 및 변환하며, 이해하기 쉬운 데이터 시각화</li>
</ul></li>
<li>Azure 데이터 분석가
<ul>
<li>Power BI를 활용한 데이터 모델링 및 시각화</li>
<li>데이터 정제/변환을 통한 비즈니스 인사이트 도출</li>
</ul></li>
<li>Azure 데이터 과학자
<ul>
<li>Azure Machine Learning 기반 ML 워크로드 구현</li>
<li>데이터 과학/머신러닝 지식 활용</li>
</ul></li>
<li>Azure 인공지능 엔지니어
<ul>
<li>Cognitive Services, ML, Knowledge Mining 활용</li>
<li>자연어처리, 음성, 컴퓨터 비전, 봇 등 AI 솔루션 구현</li>
</ul></li>
</ol>
</section>
<section id="azure-vm의-sql-server" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="azure-vm의-sql-server"><span class="header-section-number">2</span> <a href="https://learn.microsoft.com/ko-kr/training/modules/prepare-to-maintain-sql-databases-azure/3-understand-sql-server-azure-virtual-machine">Azure VM의 SQL Server</a></h2>
<section id="azure-가상-머신의-sql-server-특징-백업-고가용성" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="azure-가상-머신의-sql-server-특징-백업-고가용성"><span class="header-section-number">2.1</span> Azure 가상 머신의 SQL Server: 특징, 백업, 고가용성</h3>
<ul>
<li>Azure 가상 머신에서 실행되는 SQL Server(IaaS)는 온프레미스 SQL Server와 동등</li>
<li>가상 머신에서 SQL Server를 선택하는 주요 이유:</li>
</ul>
<ol type="1">
<li><strong>애플리케이션 호환성</strong>: 특정 버전의 SQL Server가 필요하거나 PaaS와 호환되지 않는 설치 요구사항이 있는 경우</li>
<li><strong>다양한 SQL Server 서비스 활용</strong>: SQL Server Analysis Services(SSAS), Integration Services(SSIS), Reporting Services(SSRS)를 데이터베이스 엔진과 함께 실행할 수 있음</li>
</ol>
</section>
<section id="백업-솔루션" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="백업-솔루션"><span class="header-section-number">2.2</span> 백업 솔루션</h3>
<p>최근 SQL Server 릴리스에서는 다음 두 가지 주요 백업 기능을 제공: - <strong>URL로 백업</strong>: Azure Blob Storage 서비스에 데이터베이스를 백업 * Azure Blob Storage란? * Blob (Binary Large Object): 이미지, 오디오, 비디오, 문서 등과 같은 대용량 비정형 데이터를 저장하는 데 사용되는 데이터 형식 * Azure의 클라우드 기반 스토리지 서비스 * 비교적 저렴한 비용으로 높은 가용성, 내구성, 확장성을 제공 * 데이터 암호화, 보안, 백업 등 다양한 기능 제공 * <strong>Azure Backup</strong>: SQL Server VM을 위한 포괄적인 엔터프라이즈 백업 솔루션</p>
</section>
<section id="배포-옵션" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="배포-옵션"><span class="header-section-number">2.3</span> 배포 옵션</h3>
<ul>
<li>Azure의 모든 리소스는 Azure Resource Manager를 통해 관리되고 배포</li>
<li>최종적으로 JSON 문서인 Azure Resource Manager 템플릿으로 변환됨</li>
<li>대규모 배포에는 선언적 접근 방식이 권장됨</li>
</ul>
</section>
<section id="azure-스토리지-개요" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="azure-스토리지-개요"><span class="header-section-number">2.4</span> Azure 스토리지 개요</h3>
<p>SQL Server 운영 환경에서는 다음 4가지 스토리지 유형 제공:</p>
<ul>
<li><strong>Standard HDD</strong>: 비용 절감을 위해 사용, 데이터베이스 백업에는 표준 스토리지를 사용</li>
<li><strong>Standard SSD</strong>: 비교적 빠른 속도와 비교적 저렴한 비용</li>
<li><strong>Premium SSD</strong>: 5-10ms 지연 시간</li>
<li><strong>Ultra Disk</strong>: 1-2ms 지연 시간(최적화 시 1ms 미만 가능)</li>
</ul>
</section>
<section id="azure의-high-availability" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="azure의-high-availability"><span class="header-section-number">2.5</span> Azure의 High Availability</h3>
<ul>
<li>Azure 플랫폼은 fault tolerance을 갖추고 있으며 서비스 중단과 일시적 오류로부터 빠르게 복구됨</li>
<li>Premium SSD 또는 Ultra Disk를 사용하는 단일 인스턴스 Azure 가상 머신의 경우 최소 99.9%(1년의 0.01%인 약 9시간 정도의 가동 중단 리스크)의 가동 시간을 보장</li>
<li>가용성 집합, 가용성 영역, 부하 분산 기술을 통해 high availability을 제공</li>
</ul>
</section>
<section id="azure-arc-지원-sql-server" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="azure-arc-지원-sql-server"><span class="header-section-number">2.6</span> Azure Arc 지원 SQL Server</h3>
<ul>
<li>Azure Arc는 Azure 관리 기능을 온프레미스, 다른 클라우드 또는 엣지에서 실행되는 SQL Server 인스턴스로 확장</li>
<li>Azure Arc를 통해 기존 SQL Server를 Azure로 이전하지 않고도 일관된 정책 적용, 규정 준수, Azure Monitor 및 Security Center 활용이 가능</li>
<li>중앙 집중식 관리, 자동 업데이트, 백업 및 복원, 재해 복구와 같은 고급 기능을 활용할 수 있으며, Azure의 머신러닝과 AI 기능도 기존 데이터에 적용 가능</li>
</ul>
</section>
</section>
<section id="클라우드-기반-azure-sql-database-설계" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="클라우드-기반-azure-sql-database-설계"><span class="header-section-number">3</span> <a href="https://learn.microsoft.com/ko-kr/training/modules/prepare-to-maintain-sql-databases-azure/4-design-azure-sql-database-for-cloud-native-applications">클라우드 기반 Azure SQL Database 설계</a></h2>
<p>Azure SQL Database는 PaaS(Platform as a Service) 형태로 제공되는 고확장성 데이터베이스 서비스로, 최소한의 유지 관리로 특정 워크로드에 최적화되어 있다. 개발자에게 유연성과 세분화된 배포 옵션을 제공하여 새로운 애플리케이션 개발에 적합하다.</p>
<section id="구매-모델" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="구매-모델"><span class="header-section-number">3.1</span> 구매 모델</h3>
<section id="vcore-기반-모델" class="level4">
<h4 class="anchored" data-anchor-id="vcore-기반-모델">1. vCore 기반 모델</h4>
<ul>
<li>컴퓨팅과 스토리지 리소스를 독립적으로 확장 가능</li>
<li>서비스 Tier:
<ul>
<li><strong>범용(General Purpose)</strong>: 덜 집약적인 작업용, 프로비저닝 및 서버리스 컴퓨팅 계층 제공</li>
<li><strong>비즈니스 크리티컬(Business Critical)</strong>: In-Memory OLTP, 읽기 전용 복제본, 로컬 SSD 지원
<ul>
<li>OLTP: In-Memory OLTP(Online Transaction Processing)는 Microsoft SQL Server에서 제공하는 메모리 최적화 기술</li>
<li>이 기술은 데이터베이스 테이블과 저장 프로시저를 메인 메모리(RAM)에 저장하여 디스크 I/O 작업을 최소화함으로써 트랜잭션 처리 성능을 크게 향상</li>
<li>주요 특징
<ul>
<li>데이터를 디스크가 아닌 메모리에 저장하여 액세스 속도 향상</li>
<li>락(lock)이나 래치(latch) 없는 동시성 제어 메커니즘으로 경합 감소</li>
<li>높은 처리량과 낮은 지연 시간이 필요한 트랜잭션 중심 애플리케이션에 적합</li>
</ul></li>
</ul></li>
<li><strong>하이퍼스케일(Hyperscale)</strong>: 수평적 확장 기능, 대규모 데이터 처리에 적합</li>
</ul></li>
</ul>
</section>
<section id="dtu-기반-모델" class="level4">
<h4 class="anchored" data-anchor-id="dtu-기반-모델">2. DTU 기반 모델</h4>
<ul>
<li>컴퓨팅과 스토리지가 DTU 수준에 종속
<ul>
<li>DTU(Database Transaction Unit): Azure SQL Database에서 사용하는 성능 측정 단위</li>
<li>Microsoft가 개발한 이 단위는 CPU, 메모리, 데이터 I/O 및 트랜잭션 로그 I/O의 혼합된 측정값으로, 데이터베이스 성능을 단일 값으로 표현</li>
<li>DTU 기반 구매 모델에서는 데이터베이스에 특정 DTU 레벨을 할당하며, 이 레벨은 해당 데이터베이스가 사용할 수 있는 컴퓨팅 및 스토리지 리소스의 양을 결정 (DTU 계층에 따라 성능과 비용이 증가)</li>
<li>이 모델은 vCore 모델과 달리 컴퓨팅과 스토리지가 함께 묶여 있어, 스토리지만 늘리고 싶어도 DTU 수준을 전체적으로 올려야 하는 단점이 있다.</li>
</ul></li>
<li>Basic, Standard, and Premium 세 가지 서비스 tier 제공</li>
<li>스토리지 한도 도달 시 컴퓨팅 사용률과 무관하게 DTU 증가 필요</li>
</ul>
</section>
</section>
<section id="서버리스-컴퓨팅" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="서버리스-컴퓨팅"><span class="header-section-number">3.2</span> 서버리스 컴퓨팅</h3>
<ul>
<li>자동 확장 및 일시 중지 기능을 제공하여 개발/테스트 환경의 비용 절감에 효과적</li>
<li>워크로드에 따라 동적으로 확장되며 비활성 상태일 때는 자동으로 일시 중지되어 스토리지 비용만 발생</li>
</ul>
</section>
<section id="배포-모델" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="배포-모델"><span class="header-section-number">3.3</span> 배포 모델</h3>
<section id="단일-데이터베이스" class="level4">
<h4 class="anchored" data-anchor-id="단일-데이터베이스">1.단일 데이터베이스</h4>
<ul>
<li>각 데이터베이스를 개별적으로 관리</li>
<li>동일 서버에 배포되어도 각 데이터베이스는 전용 리소스 보유</li>
<li>Azure 포털을 통한 리소스 모니터링 가능</li>
</ul>
</section>
<section id="탄력적-풀" class="level4">
<h4 class="anchored" data-anchor-id="탄력적-풀">2.탄력적 풀</h4>
<ul>
<li>여러 데이터베이스가 리소스를 공유하는 모델</li>
<li>개별 데이터베이스 스케일링이 불필요해 관리 용이</li>
<li>SaaS 애플리케이션에 비용 효율적</li>
<li>사용률이 낮은 멀티테넌트 환경에 적합</li>
</ul>
</section>
</section>
<section id="주요-기능" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="주요-기능"><span class="header-section-number">3.4</span> 주요 기능</h3>
<section id="네트워크-옵션" class="level4">
<h4 class="anchored" data-anchor-id="네트워크-옵션">네트워크 옵션</h4>
<p>방화벽 규칙, 가상 네트워크 엔드포인트, Private Link 등으로 액세스 제어가 가능</p>
</section>
<section id="백업-및-복원" class="level4">
<h4 class="anchored" data-anchor-id="백업-및-복원">백업 및 복원</h4>
<p>Azure는 SQL Database 및 SQL Managed Instance에 대한 원활한 백업 및 복원 기능을 제공</p>
<ul>
<li><strong>지속적 백업(seamless backup)</strong>: 정기적인 백업과 지역 중복 스토리지, 전체 백업은 매주 수행되고, 차등 백업은 12~24시간마다 수행되며, 트랜잭션 로그 백업은 5~10분마다 수행됨</li>
<li><strong>지역 복원(geo-restore)</strong>: 다른 지리적 지역으로 복원 가능, 덜 엄격한 재해 복구 시나리오에 특히 유용</li>
<li><strong>시점 복원(PITR, point-in-time restore)</strong>: 특정 시점 복원 가능, 1-35일 보존 기간 설정 가능, 실제로 지정하지 않으면 기본 구성은 7일</li>
<li><strong>장기 보존(LTR, long-term retention)</strong>: 최대 10년까지 보존 정책 설정, 이 옵션은 기본적으로 사용하지 않도록 설정</li>
</ul>
</section>
<section id="자동-튜닝" class="level4">
<h4 class="anchored" data-anchor-id="자동-튜닝">자동 튜닝</h4>
<p>머신러닝 기반으로 쿼리 성능을 자동 최적화 - 비용 많은 쿼리 식별 - 실행 계획 최적화 - 인덱스 추가/제거 기능</p>
</section>
<section id="탄력적-쿼리-및-작업" class="level4">
<h4 class="anchored" data-anchor-id="탄력적-쿼리-및-작업">탄력적 쿼리 및 작업</h4>
<ul>
<li>여러 데이터베이스에 걸친 쿼리 실행과 유지 관리 작업 자동화를 지원</li>
<li>여러 데이터베이스를 연결하는 T-SQL 쿼리를 실행 가능하고 이 기능은 변경할 수 없는 세 부분 및 네 부분으로 된 이름을 사용하는 애플리케이션에 유용</li>
<li>마이그레이션을 허용하기 때문에 이식성이 향상</li>
<li>다음 분할 전략을 지원
<ul>
<li>수직 분할: 데이터베이스 간 쿼리라고도 합니다. 데이터는 여러 데이터베이스 간에 세로로 분할 (컬럼 단위 분할도 가능).</li>
<li>가로 분할: 데이터는 여러 확장된 데이터베이스에 행을 분산하기 위해 수평(행또는 record 단위)으로 분할</li>
</ul></li>
</ul>
</section>
<section id="microsoft-fabric-통합" class="level4">
<h4 class="anchored" data-anchor-id="microsoft-fabric-통합">Microsoft Fabric 통합</h4>
<ul>
<li>Microsoft 생태계와 완벽하게 통합되어 데이터 워크플로 간소화, 협업 강화, 고급 분석 지원 등의 이점을 제공</li>
<li>Microsoft Fabric은 모든 데이터 및 분석 요구 사항을 위한 통합 플랫폼
<ul>
<li>Microsoft의 SaaS(Software as a Service) 분석 제품군</li>
<li>Power BI, Azure Synapse Analytics, Azure Data Factory 등의 Microsoft 서비스를 하나의 통합된 환경으로 결합</li>
</ul></li>
<li>주요 특징:
<ul>
<li>데이터 수집, 처리, 저장, 분석, 시각화를 위한 end-to-end 솔루션</li>
<li>공통 데이터 저장소인 OneLake를 중심으로 구축</li>
<li>다양한 워크로드 지원: 데이터 엔지니어링, 데이터 과학, 실시간 분석, BI 등</li>
<li>통합된 거버넌스 및 보안 모델</li>
<li>Microsoft 365와 긴밀한 통합</li>
<li>Fabric은 SQL Database와 같은 여러 데이터 서비스를 통합하여 조직이 데이터 사일로를 제거하고 더 효율적으로 데이터를 활용하도록 지원</li>
</ul></li>
</ul>
</section>
</section>
</section>
<section id="azure-sql-managed-instance" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="azure-sql-managed-instance"><span class="header-section-number">4</span> <a href="https://learn.microsoft.com/ko-kr/training/modules/prepare-to-maintain-sql-databases-azure/5-explore-azure-sql-database-managed-instance">Azure SQL Managed Instance</a></h2>
<p>Azure SQL Managed Instance는 Azure SQL Database와 많은 공통 코드를 공유하는 완전 관리형 PaaS 솔루션으로 SQL Server 잘 작동하는 완전 관리형 데이터베이스 서비스</p>
<section id="주요-이점" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="주요-이점"><span class="header-section-number">4.1</span> 주요 이점</h3>
<ul>
<li>자동 백업 및 패치</li>
<li>기본 제공 고가용성(99.99% 가동시간 보장, 년간 52분 가동 중단 시간 허용 리스크)</li>
<li>보안 및 성능 도구</li>
<li>통합 감사 기능</li>
<li>SQL Server 설치 및 패치 불필요로 유지 관리 감소</li>
</ul>
</section>
<section id="sql-database와의-차별점" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="sql-database와의-차별점"><span class="header-section-number">4.2</span> SQL Database와의 차별점</h3>
<p>SQL Database가 단일 데이터베이스 중심인 반면, SQL Managed Instance는 다음을 지원: - 데이터베이스 간 쿼리 - CLR(Common Language Runtime, 공통 언어 런타임) - 다양한 .NET 언어(C#, Visual Basic .NET 등)로 작성된 코드를 SQL Server 내에서 실행 가능 - 스토어드 프로시저, 트리거, 사용자 정의 함수, 사용자 정의 형식, 사용자 정의 집계 등을 .NET 언어로 작성 가능 - T-SQL로 구현하기 어려운 복잡한 비즈니스 로직, 문자열 처리, 수학 계산 등을 효율적으로 처리 가능 - T-SQL(Transact-SQL): Microsoft SQL Server에서 사용되는, SQL(Structured Query Language)의 확장 버전 - 외부 리소스(파일 시스템, 네트워크 등)에 접근하는 코드 실행 가능 - 시스템 데이터베이스 액세스 - SQL 에이전트 기능 - Microsoft SQL Server의 작업 자동화 서비스 - 작업 예약, 작업 모니터링, 작업 로깅 등 다양한 기능 제공</p>
</section>
<section id="하이브리드-라이선스-옵션" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="하이브리드-라이선스-옵션"><span class="header-section-number">4.3</span> 하이브리드 라이선스 옵션</h3>
<ul>
<li>Active Software Assurance가 있는 기존 라이선스를 활용해 PaaS(SQL Database 및 SQL Managed Instance) 비용 절감(최대 40%)
<ul>
<li>Enterprise Edition: 코어당 비즈니스 크리티컬 vCore 1개 또는 범용 vCore 8개</li>
<li>Standard Edition: 코어당 범용 vCore 1개</li>
</ul></li>
</ul>
</section>
<section id="connectivity-architecture" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="connectivity-architecture"><span class="header-section-number">4.4</span> Connectivity Architecture</h3>
<ul>
<li>SQL Managed Instance에 대한 연결은 TDS 엔드포인트를 통한 연결
<ul>
<li>TDS(Tabular Data Stream)는 Microsoft SQL Server 및 Sybase에서 클라이언트와 데이터베이스 서버 간의 통신에 사용되는 네트워크 프로토콜</li>
</ul></li>
<li>고가용성 방식으로 배포된 게이트웨이 구성 요소</li>
<li>자동화된 백업(지역 중복 및 자동 복제)</li>
<li>자동 장애 조치 그룹 지원</li>
</ul>
</section>
<section id="migration-options" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="migration-options"><span class="header-section-number">4.5</span> Migration Options</h3>
<ol type="1">
<li><strong>Log 재생 서비스</strong>: 온라인 마이그레이션, 세부 제어 가능</li>
<li><strong>Azure Data Studio 확장</strong>: 준비 상태 평가, 리소스 추천, 중소규모 DB에 적합</li>
<li><strong>Managed Instance 링크</strong>: 분산 가용성 그룹 사용, 즉시 데이터 복제</li>
<li><strong>네이티브 백업 및 복원</strong>: 간단한 마이그레이션 방법</li>
<li><strong>트랜잭션 복제</strong>: 대규모 DB의 온/오프라인 마이그레이션에 적합</li>
</ol>
</section>
<section id="machine-learning-services" class="level3" data-number="4.6">
<h3 data-number="4.6" class="anchored" data-anchor-id="machine-learning-services"><span class="header-section-number">4.6</span> Machine Learning Services</h3>
<ul>
<li>Python 및 R 패키지 지원</li>
<li>데이터 이동 없이 기계 학습 모델 학습 및 배포</li>
<li>T-SQL 저장 프로시저를 통한 모델 배포</li>
<li>scikit-learn, PyTorch, TensorFlow 등 오픈소스 라이브러리 지원</li>
<li>T-SQL PREDICT 함수로 예측 가속화</li>
<li><code>sp_configure 'external scripts enabled', 1;</code> 명령으로 활성화</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Engineering</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Engineering/data_engineering/1.azure_server_based_db_management.html</guid>
  <pubDate>Tue, 01 Apr 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Azure SQL Database 관리</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Engineering/data_engineering/0.azure_dba_intro.html</link>
  <description><![CDATA[ 




<section id="한눈에-보기" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 한눈에 보기</h1>
<ul>
<li>관련 서비스: Azure SQL Database, Azure SQL Managed Instance, Azure Virtual Machines의 SQL Server</li>
<li>역할: 데이터 분석가, 데이터 엔지니어, 데이터베이스 관리자</li>
<li>주제: 데이터베이스 관리</li>
</ul>
<section id="데이터베이스와-관리-시스템의-이해" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="데이터베이스와-관리-시스템의-이해"><span class="header-section-number">1.1</span> 데이터베이스와 관리 시스템의 이해</h2>
<section id="데이터베이스의-기본-개념" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="데이터베이스의-기본-개념"><span class="header-section-number">1.1.1</span> 데이터베이스의 기본 개념</h3>
<p>데이터베이스는 데이터를 체계적으로 저장하고 관리하는 시스템이다. 데이터의 저장, 검색, 갱신을 효율적으로 수행할 수 있는 기능을 제공한다.</p>
</section>
<section id="데이터베이스-관리-시스템dbms" class="level3" data-number="1.1.2">
<h3 data-number="1.1.2" class="anchored" data-anchor-id="데이터베이스-관리-시스템dbms"><span class="header-section-number">1.1.2</span> 데이터베이스 관리 시스템(DBMS)</h3>
<p>DBMS(Database Management System)는 데이터베이스를 운영하고 관리하는 소프트웨어 시스템으로, 다음과 같은 핵심 기능을 제공한다:</p>
<ul>
<li>데이터베이스 생성 및 스키마 관리</li>
<li>데이터 입력, 수정, 삭제 기능</li>
<li>데이터 무결성 유지</li>
<li>보안 및 접근 제어</li>
</ul>
</section>
<section id="데이터베이스-관리자dba의-역할" class="level3" data-number="1.1.3">
<h3 data-number="1.1.3" class="anchored" data-anchor-id="데이터베이스-관리자dba의-역할"><span class="header-section-number">1.1.3</span> 데이터베이스 관리자(DBA)의 역할</h3>
<p>DBA(Database Administrator)는 데이터베이스의 전반적인 운영을 책임지는 전문가로서 다음과 같은 업무를 하는 사람이다:</p>
<ul>
<li>데이터베이스 설계 및 구현</li>
<li>성능 최적화 및 모니터링</li>
<li>보안 관리 및 백업/복구</li>
<li>사용자 권한 관리</li>
</ul>
</section>
</section>
<section id="azure-클라우드-환경에서의-데이터베이스-관리" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="azure-클라우드-환경에서의-데이터베이스-관리"><span class="header-section-number">1.2</span> Azure 클라우드 환경에서의 데이터베이스 관리</h2>
<section id="azure-데이터베이스-서비스의-중요성" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="azure-데이터베이스-서비스의-중요성"><span class="header-section-number">1.2.1</span> Azure 데이터베이스 서비스의 중요성</h3>
<ul>
<li>현대 비즈니스 운영에서 클라우드 플랫폼 활용은 필수적</li>
<li>Azure는 안정적이고 확장 가능한 데이터베이스 서비스 제공</li>
<li>Microsoft와의 협업을 통한 지속적인 서비스 개선</li>
</ul>
</section>
<section id="azure-서비스-모델" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="azure-서비스-모델"><span class="header-section-number">1.2.2</span> Azure 서비스 모델</h3>
<p>Azure는 세 가지 주요 서비스 모델을 제공한다:</p>
<ol type="1">
<li>Infrastructure as a Service (IaaS)
<ul>
<li>가상 머신, 스토리지, 네트워킹 제공</li>
<li>사용자가 직접 패치 및 소프트웨어 관리</li>
<li>높은 수준의 커스터마이징 가능</li>
</ul></li>
<li>Platform as a Service (PaaS)
<ul>
<li>클라우드 제공업체가 더 많은 관리 작업 담당</li>
<li>사용자는 애플리케이션과 데이터에 집중 가능</li>
<li>관리 부담 감소</li>
</ul></li>
<li>Software as a Service (SaaS)
<ul>
<li>완전히 관리되는 소프트웨어 애플리케이션 제공</li>
<li>사용자는 서비스만 이용</li>
<li>설치, 유지보수, 업그레이드가 모두 자동화</li>
</ul></li>
</ol>


</section>
</section>
</section>

 ]]></description>
  <category>Engineering</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Engineering/data_engineering/0.azure_dba_intro.html</guid>
  <pubDate>Mon, 31 Mar 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>Hugging Face: PLM 생태계의 중심</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/27.plm_hugging_face.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>Hugging Face는 현재 <strong>NLP 분야의 사실상 표준</strong>이 된 라이브러리이자 플랫폼이다. PyTorch와 TensorFlow 모두를 지원하며, 수만 개의 사전 학습 모델을 제공하는 거대한 생태계를 구축했다.</p>
<section id="핵심-가치-제안" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="핵심-가치-제안"><span class="header-section-number">1.1</span> 핵심 가치 제안</h2>
<ul>
<li><strong>접근성 혁명</strong>: 몇 줄의 코드로 최신 PLM 사용 가능</li>
<li><strong>표준화</strong>: 모든 모델이 동일한 API로 통일</li>
<li><strong>완전한 워크플로우</strong>: 전처리부터 배포까지 원스톱 지원</li>
<li><strong>거대한 커뮤니티</strong>: 전 세계 개발자들이 모델과 데이터셋 공유</li>
</ul>
</section>
<section id="주요-구성-요소" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="주요-구성-요소"><span class="header-section-number">1.2</span> 주요 구성 요소</h2>
<ul>
<li><strong>Transformers 라이브러리</strong>: 핵심 모델 구현체</li>
<li><strong>Model Hub</strong>: 10만+ 사전 학습 모델 저장소</li>
<li><strong>Datasets</strong>: 표준화된 데이터셋 라이브러리</li>
<li><strong>Tokenizers</strong>: 고성능 토큰화 라이브러리</li>
<li><strong>Accelerate</strong>: 분산 학습 및 최적화 도구</li>
<li><strong>Gradio</strong>: 빠른 데모 및 프로토타입 구축</li>
<li><strong>Spaces</strong>: 모델 배포 및 공유 플랫폼</li>
</ul>
</section>
<section id="실무에서의-강력함" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="실무에서의-강력함"><span class="header-section-number">1.3</span> 실무에서의 강력함</h2>
<p><strong>Before Hugging Face</strong> (2019년 이전):</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 복잡한 모델 구현과 전처리 필요</span></span>
<span id="cb1-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> CustomBERTModel(nn.Module):</span>
<span id="cb1-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb1-4">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 수백 줄의 구현 코드...</span></span>
<span id="cb1-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">pass</span></span>
<span id="cb1-6">    </span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 토크나이저 직접 구현</span></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 체크포인트 로딩 코드 작성</span></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 모델마다 다른 API</span></span></code></pre></div>
<p><strong>After Hugging Face</strong>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3줄로 끝</span></span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pipeline</span>
<span id="cb2-3">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment-analysis"</span>)</span>
<span id="cb2-4">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"이 영화 정말 재밌었어!"</span>)</span></code></pre></div>
<p>이러한 <strong>코드 단순화</strong>는 NLP 기술의 민주화를 이끌었으며, 연구자뿐만 아니라 일반 개발자들도 쉽게 최신 AI 기술을 활용할 수 있게 만들었다.</p>
</section>
</section>
<section id="hugging-face-생태계-전체-구조" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Hugging Face 생태계 전체 구조</h1>
<section id="플랫폼-아키텍처" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="플랫폼-아키텍처"><span class="header-section-number">2.1</span> 플랫폼 아키텍처</h2>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    A[Hugging Face Hub] --&gt; B[Models]
    A --&gt; C[Datasets] 
    A --&gt; D[Spaces]
    
    B --&gt; E[Transformers Library]
    C --&gt; F[Datasets Library]
    D --&gt; G[Gradio/Streamlit]
    
    E --&gt; H[PyTorch]
    E --&gt; I[TensorFlow]
    E --&gt; J[JAX]
    
    K[사용자] --&gt; L[Pipeline API]
    K --&gt; M[AutoModel API]
    K --&gt; N[Trainer API]
    
    L --&gt; E
    M --&gt; E
    N --&gt; E
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
<section id="핵심-라이브러리들" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="핵심-라이브러리들"><span class="header-section-number">2.2</span> 핵심 라이브러리들</h2>
<section id="transformers-라이브러리" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="transformers-라이브러리"><span class="header-section-number">2.2.1</span> 1. Transformers 라이브러리</h3>
<p><strong>역할</strong>: 모든 트랜스포머 기반 모델의 통합 구현체</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 지원하는 주요 모델들</span></span>
<span id="cb3-2">models <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb3-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BERT"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"GPT-2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"T5"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BART"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RoBERTa"</span>,</span>
<span id="cb3-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ALBERT"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DistilBERT"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ELECTRA"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DeBERTa"</span>,</span>
<span id="cb3-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"GPT-Neo"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"GPT-J"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"OPT"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"BLOOM"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LLaMA"</span></span>
<span id="cb3-6">]</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 지원하는 태스크들</span></span>
<span id="cb3-9">tasks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb3-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-classification"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"token-classification"</span>,</span>
<span id="cb3-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question-answering"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-generation"</span>,</span>
<span id="cb3-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"summarization"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"translation"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fill-mask"</span></span>
<span id="cb3-13">]</span></code></pre></div>
</section>
<section id="model-hub의-규모" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="model-hub의-규모"><span class="header-section-number">2.2.2</span> 2. Model Hub의 규모</h3>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2024년 기준 통계</span></span>
<span id="cb4-2">hub_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb4-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'total_models'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>,</span>
<span id="cb4-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'organizations'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>,</span>
<span id="cb4-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'downloads_per_month'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'10억+'</span>,</span>
<span id="cb4-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'supported_languages'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>,</span>
<span id="cb4-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'korean_models'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb4-8">}</span></code></pre></div>
</section>
<section id="지원하는-프레임워크" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="지원하는-프레임워크"><span class="header-section-number">2.2.3</span> 3. 지원하는 프레임워크</h3>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 멀티 프레임워크 지원</span></span>
<span id="cb5-2">frameworks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb5-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'PyTorch'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'기본 지원, 가장 많은 모델'</span>,</span>
<span id="cb5-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'TensorFlow'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'TF 2.x 완전 지원'</span>,</span>
<span id="cb5-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'JAX/Flax'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Google 연구팀 협업'</span>,</span>
<span id="cb5-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ONNX'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'추론 최적화 지원'</span></span>
<span id="cb5-7">}</span></code></pre></div>
</section>
</section>
</section>
<section id="토큰화와-전처리" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> 토큰화와 전처리</h1>
<section id="토크나이저의-중요성" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="토크나이저의-중요성"><span class="header-section-number">3.1</span> 토크나이저의 중요성</h2>
<p><strong>핵심 원칙</strong>: 모델과 토크나이저는 항상 쌍으로 사용해야 한다.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 올바른 사용법 ✅</span></span>
<span id="cb6-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer, AutoModel</span>
<span id="cb6-3"></span>
<span id="cb6-4">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span></span>
<span id="cb6-5">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb6-6">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModel.from_pretrained(model_name)</span></code></pre></div>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 잘못된 사용법 ❌ - 다른 모델의 토크나이저 사용</span></span>
<span id="cb7-2">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bert-base-uncased"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 영어</span></span>
<span id="cb7-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModel.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 한국어</span></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># → 완전히 다른 vocabulary로 인한 성능 저하</span></span></code></pre></div>
</section>
<section id="토큰화-과정-상세-분석" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="토큰화-과정-상세-분석"><span class="header-section-number">3.2</span> 토큰화 과정 상세 분석</h2>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BertTokenizer</span>
<span id="cb8-2"></span>
<span id="cb8-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 한국어 BERT 토크나이저</span></span>
<span id="cb8-4">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>)</span>
<span id="cb8-5"></span>
<span id="cb8-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 단계별 토큰화 과정</span></span>
<span id="cb8-7">text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"안녕하세요. 자연어 처리를 공부합니다."</span></span>
<span id="cb8-8"></span>
<span id="cb8-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1단계: 텍스트를 토큰으로 분할</span></span>
<span id="cb8-10">tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.tokenize(text)</span>
<span id="cb8-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"토큰화: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tokens<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb8-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ['안녕', '##하', '##세요', '.', '자연어', '처리를', '공부', '##합니다', '.']</span></span>
<span id="cb8-13"></span>
<span id="cb8-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2단계: 토큰을 ID로 변환</span></span>
<span id="cb8-15">token_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.convert_tokens_to_ids(tokens)</span>
<span id="cb8-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"토큰 ID: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>token_ids<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb8-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [2374, 8910, 4567, 119, 15234, 9876, 3456, 7890, 119]</span></span>
<span id="cb8-18"></span>
<span id="cb8-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3단계: 특수 토큰 추가 및 패딩</span></span>
<span id="cb8-20">encoded <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(text, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>)</span>
<span id="cb8-21"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"최종 인코딩: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>encoded<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb8-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># {'input_ids': tensor([[101, 2374, 8910, ..., 102]]), </span></span>
<span id="cb8-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  'attention_mask': tensor([[1, 1, 1, ..., 1]])}</span></span></code></pre></div>
</section>
<section id="다양한-토크나이저-종류" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="다양한-토크나이저-종류"><span class="header-section-number">3.3</span> 다양한 토크나이저 종류</h2>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. WordPiece (BERT 계열)</span></span>
<span id="cb9-2">wordpiece_tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>)</span>
<span id="cb9-3">result1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> wordpiece_tokenizer.tokenize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"자연어처리"</span>)</span>
<span id="cb9-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"WordPiece: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result1<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ['자연어', '##처리']</span></span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. BPE (GPT 계열)</span></span>
<span id="cb9-7">bpe_tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GPT2Tokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"skt/kogpt2-base-v2"</span>)</span>
<span id="cb9-8">result2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> bpe_tokenizer.tokenize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"자연어처리"</span>)</span>
<span id="cb9-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"BPE: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result2<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ['자연어', '처리']</span></span>
<span id="cb9-10"></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. SentencePiece (T5, ALBERT 계열)</span></span>
<span id="cb9-12">sp_tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> T5Tokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"KETI-AIR/ke-t5-base"</span>)</span>
<span id="cb9-13">result3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sp_tokenizer.tokenize(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"자연어처리"</span>)</span>
<span id="cb9-14"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"SentencePiece: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result3<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ['▁자연어', '처리']</span></span></code></pre></div>
</section>
<section id="토크나이저-성능-최적화" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="토크나이저-성능-최적화"><span class="header-section-number">3.4</span> 토크나이저 성능 최적화</h2>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 배치 처리로 성능 향상</span></span>
<span id="cb10-2">texts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"문장 1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"문장 2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"문장 3"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb10-3"></span>
<span id="cb10-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 느린 방법 ❌</span></span>
<span id="cb10-5">slow_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb10-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> text <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> texts:</span>
<span id="cb10-7">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(text)</span>
<span id="cb10-8">    slow_results.append(result)</span>
<span id="cb10-9"></span>
<span id="cb10-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 빠른 방법 ✅ (10-100배 빠름)</span></span>
<span id="cb10-11">fast_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(texts, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-12"></span>
<span id="cb10-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Fast Tokenizer 사용 (Rust 구현)</span></span>
<span id="cb10-14">fast_tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb10-15">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>, </span>
<span id="cb10-16">    use_fast<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Rust 기반 고속 토크나이저</span></span>
<span id="cb10-17">)</span></code></pre></div>
</section>
</section>
<section id="모델-로딩과-활용" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> 모델 로딩과 활용</h1>
<section id="automodel-계열의-강력함" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="automodel-계열의-강력함"><span class="header-section-number">4.1</span> AutoModel 계열의 강력함</h2>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer, AutoModel, AutoModelForSequenceClassification</span>
<span id="cb11-2"></span>
<span id="cb11-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 자동으로 적절한 모델 클래스 선택</span></span>
<span id="cb11-4">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span></span>
<span id="cb11-5"></span>
<span id="cb11-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 범용 인코더</span></span>
<span id="cb11-7">encoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModel.from_pretrained(model_name)</span>
<span id="cb11-8"></span>
<span id="cb11-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 분류용 모델 (분류 헤드 자동 추가)</span></span>
<span id="cb11-10">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb11-11">    model_name, </span>
<span id="cb11-12">    num_labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb11-13">)</span>
<span id="cb11-14"></span>
<span id="cb11-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 질의응답용 모델</span></span>
<span id="cb11-16">qa_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForQuestionAnswering.from_pretrained(model_name)</span></code></pre></div>
</section>
<section id="모델-설정-커스터마이징" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="모델-설정-커스터마이징"><span class="header-section-number">4.2</span> 모델 설정 커스터마이징</h2>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BertConfig, BertForSequenceClassification</span>
<span id="cb12-2"></span>
<span id="cb12-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 설정 불러오기 및 수정</span></span>
<span id="cb12-4">config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertConfig.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>)</span>
<span id="cb12-5">config.num_labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 분류 클래스 수 변경</span></span>
<span id="cb12-6">config.dropout <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 드롭아웃 비율 조정</span></span>
<span id="cb12-7">config.attention_probs_dropout_prob <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span></span>
<span id="cb12-8"></span>
<span id="cb12-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 수정된 설정으로 모델 생성</span></span>
<span id="cb12-10">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BertForSequenceClassification.from_pretrained(</span>
<span id="cb12-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>,</span>
<span id="cb12-12">    config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config</span>
<span id="cb12-13">)</span>
<span id="cb12-14"></span>
<span id="cb12-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모델 구조 확인</span></span>
<span id="cb12-16"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(model)</span></code></pre></div>
</section>
<section id="메모리-효율적-모델-로딩" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="메모리-효율적-모델-로딩"><span class="header-section-number">4.3</span> 메모리 효율적 모델 로딩</h2>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 절반 정밀도 사용 (메모리 50% 절약)</span></span>
<span id="cb13-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModel.from_pretrained(</span>
<span id="cb13-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>,</span>
<span id="cb13-4">    torch_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float16</span>
<span id="cb13-5">)</span>
<span id="cb13-6"></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. CPU 오프로딩 (큰 모델용)</span></span>
<span id="cb13-8">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModel.from_pretrained(</span>
<span id="cb13-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"microsoft/DialoGPT-large"</span>,</span>
<span id="cb13-10">    device_map<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"auto"</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 자동으로 GPU/CPU 배치</span></span>
<span id="cb13-11">    low_cpu_mem_usage<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb13-12">)</span>
<span id="cb13-13"></span>
<span id="cb13-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 8비트 양자화 (메모리 75% 절약)</span></span>
<span id="cb13-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BitsAndBytesConfig</span>
<span id="cb13-16"></span>
<span id="cb13-17">quantization_config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> BitsAndBytesConfig(load_in_8bit<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb13-18">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModel.from_pretrained(</span>
<span id="cb13-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"facebook/opt-6.7b"</span>,</span>
<span id="cb13-20">    quantization_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>quantization_config</span>
<span id="cb13-21">)</span></code></pre></div>
</section>
</section>
<section id="pipeline-api-즉시-사용-가능한-nlp" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Pipeline API: 즉시 사용 가능한 NLP</h1>
<section id="기본-pipeline-사용법" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="기본-pipeline-사용법"><span class="header-section-number">5.1</span> 기본 Pipeline 사용법</h2>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pipeline</span>
<span id="cb14-2"></span>
<span id="cb14-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 감정 분석</span></span>
<span id="cb14-4">sentiment_analyzer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(</span>
<span id="cb14-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment-analysis"</span>,</span>
<span id="cb14-6">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base-en-ko-cased"</span>,</span>
<span id="cb14-7">    return_all_scores<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb14-8">)</span>
<span id="cb14-9"></span>
<span id="cb14-10">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sentiment_analyzer(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"이 영화 정말 재밌었어!"</span>)</span>
<span id="cb14-11"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result)</span>
<span id="cb14-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [{'label': 'POSITIVE', 'score': 0.9998}]</span></span>
<span id="cb14-13"></span>
<span id="cb14-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 텍스트 생성</span></span>
<span id="cb14-15">generator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(</span>
<span id="cb14-16">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-generation"</span>,</span>
<span id="cb14-17">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"skt/kogpt2-base-v2"</span>,</span>
<span id="cb14-18">    max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb14-19">    do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb14-20">    temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span></span>
<span id="cb14-21">)</span>
<span id="cb14-22"></span>
<span id="cb14-23">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> generator(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"인공지능의 미래는"</span>)</span>
<span id="cb14-24"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'generated_text'</span>])</span>
<span id="cb14-25"></span>
<span id="cb14-26"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 질의응답</span></span>
<span id="cb14-27">qa_pipeline <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(</span>
<span id="cb14-28">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question-answering"</span>,</span>
<span id="cb14-29">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span></span>
<span id="cb14-30">)</span>
<span id="cb14-31"></span>
<span id="cb14-32">context <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"파이썬은 1991년 귀도 반 로섬이 개발한 프로그래밍 언어다."</span></span>
<span id="cb14-33">question <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"파이썬을 개발한 사람은 누구인가?"</span></span>
<span id="cb14-34"></span>
<span id="cb14-35">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> qa_pipeline(question<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>question, context<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>context)</span>
<span id="cb14-36"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"답: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'answer'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, 신뢰도: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
</section>
<section id="고급-pipeline-설정" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="고급-pipeline-설정"><span class="header-section-number">5.2</span> 고급 Pipeline 설정</h2>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 배치 처리 파이프라인</span></span>
<span id="cb15-2">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(</span>
<span id="cb15-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-classification"</span>,</span>
<span id="cb15-4">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>,</span>
<span id="cb15-5">    device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPU 사용</span></span>
<span id="cb15-6">    batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 배치 크기</span></span>
<span id="cb15-7">    max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>,</span>
<span id="cb15-8">    truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb15-9">)</span>
<span id="cb15-10"></span>
<span id="cb15-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 대량 텍스트 처리</span></span>
<span id="cb15-12">texts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"텍스트 1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"텍스트 2"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb15-13">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier(texts)</span>
<span id="cb15-14"></span>
<span id="cb15-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 커스텀 전처리 함수</span></span>
<span id="cb15-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> preprocess_function(examples):</span>
<span id="cb15-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 커스텀 전처리 로직</span></span>
<span id="cb15-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> tokenizer(examples, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb15-19"></span>
<span id="cb15-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 파이프라인에 커스텀 함수 적용</span></span>
<span id="cb15-21">custom_pipeline <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(</span>
<span id="cb15-22">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-classification"</span>,</span>
<span id="cb15-23">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model,</span>
<span id="cb15-24">    tokenizer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer,</span>
<span id="cb15-25">    preprocessing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>preprocess_function</span>
<span id="cb15-26">)</span></code></pre></div>
</section>
<section id="실무용-pipeline-최적화" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="실무용-pipeline-최적화"><span class="header-section-number">5.3</span> 실무용 Pipeline 최적화</h2>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> OptimizedPipeline:</span>
<span id="cb16-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, model_name, task, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>):</span>
<span id="cb16-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pipeline <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(</span>
<span id="cb16-4">            task,</span>
<span id="cb16-5">            model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_name,</span>
<span id="cb16-6">            device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb16-7">            batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>,</span>
<span id="cb16-8">            return_all_scores<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb16-9">        )</span>
<span id="cb16-10">        </span>
<span id="cb16-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> batch_predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, texts, batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>):</span>
<span id="cb16-12">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""대량 텍스트 효율적 처리"""</span></span>
<span id="cb16-13">        results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb16-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(texts), batch_size):</span>
<span id="cb16-15">            batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> texts[i:i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>batch_size]</span>
<span id="cb16-16">            batch_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pipeline(batch)</span>
<span id="cb16-17">            results.extend(batch_results)</span>
<span id="cb16-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> results</span>
<span id="cb16-19">    </span>
<span id="cb16-20">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict_with_confidence(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text, threshold<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>):</span>
<span id="cb16-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""신뢰도 기반 예측"""</span></span>
<span id="cb16-22">        result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pipeline(text, return_all_scores<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb16-23">        max_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(result[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">lambda</span> x: x[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>])</span>
<span id="cb16-24">        </span>
<span id="cb16-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> max_score[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> threshold:</span>
<span id="cb16-26">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> max_score</span>
<span id="cb16-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb16-28">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"label"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UNCERTAIN"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"score"</span>: max_score[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'score'</span>]}</span>
<span id="cb16-29"></span>
<span id="cb16-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 사용 예시</span></span>
<span id="cb16-31">classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OptimizedPipeline(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-classification"</span>)</span>
<span id="cb16-32">results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier.batch_predict([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"텍스트1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"텍스트2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"텍스트3"</span>])</span></code></pre></div>
</section>
</section>
<section id="파인튜닝과-학습" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> 파인튜닝과 학습</h1>
<section id="trainer-api-활용" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="trainer-api-활용"><span class="header-section-number">6.1</span> Trainer API 활용</h2>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Trainer, TrainingArguments</span>
<span id="cb17-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer, AutoModelForSequenceClassification</span>
<span id="cb17-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb17-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.utils.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Dataset</span>
<span id="cb17-5"></span>
<span id="cb17-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 데이터셋 준비</span></span>
<span id="cb17-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> CustomDataset(Dataset):</span>
<span id="cb17-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, texts, labels, tokenizer, max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>):</span>
<span id="cb17-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.texts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> texts</span>
<span id="cb17-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> labels</span>
<span id="cb17-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer</span>
<span id="cb17-12">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_length</span>
<span id="cb17-13">    </span>
<span id="cb17-14">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__len__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb17-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.texts)</span>
<span id="cb17-16">    </span>
<span id="cb17-17">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, idx):</span>
<span id="cb17-18">        text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.texts[idx])</span>
<span id="cb17-19">        encoding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer(</span>
<span id="cb17-20">            text,</span>
<span id="cb17-21">            truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb17-22">            padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_length'</span>,</span>
<span id="cb17-23">            max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_length,</span>
<span id="cb17-24">            return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span></span>
<span id="cb17-25">        )</span>
<span id="cb17-26">        </span>
<span id="cb17-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb17-28">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>: encoding[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>].flatten(),</span>
<span id="cb17-29">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>: encoding[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>].flatten(),</span>
<span id="cb17-30">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'labels'</span>: torch.tensor(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.labels[idx], dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">long</span>)</span>
<span id="cb17-31">        }</span>
<span id="cb17-32"></span>
<span id="cb17-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 모델과 토크나이저 준비</span></span>
<span id="cb17-34">model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span></span>
<span id="cb17-35">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb17-36">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb17-37">    model_name,</span>
<span id="cb17-38">    num_labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb17-39">)</span>
<span id="cb17-40"></span>
<span id="cb17-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 학습 설정</span></span>
<span id="cb17-42">training_args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TrainingArguments(</span>
<span id="cb17-43">    output_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'./results'</span>,</span>
<span id="cb17-44">    num_train_epochs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,</span>
<span id="cb17-45">    per_device_train_batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>,</span>
<span id="cb17-46">    per_device_eval_batch_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>,</span>
<span id="cb17-47">    warmup_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>,</span>
<span id="cb17-48">    weight_decay<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>,</span>
<span id="cb17-49">    logging_dir<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'./logs'</span>,</span>
<span id="cb17-50">    logging_steps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb17-51">    evaluation_strategy<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"epoch"</span>,</span>
<span id="cb17-52">    save_strategy<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"epoch"</span>,</span>
<span id="cb17-53">    load_best_model_at_end<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb17-54">    metric_for_best_model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eval_accuracy"</span>,</span>
<span id="cb17-55">    greater_is_better<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb17-56">)</span>
<span id="cb17-57"></span>
<span id="cb17-58"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 4. 평가 함수</span></span>
<span id="cb17-59"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score, precision_recall_fscore_support</span>
<span id="cb17-60"></span>
<span id="cb17-61"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> compute_metrics(eval_pred):</span>
<span id="cb17-62">    predictions, labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eval_pred</span>
<span id="cb17-63">    predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> predictions.argmax(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb17-64">    </span>
<span id="cb17-65">    accuracy <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> accuracy_score(labels, predictions)</span>
<span id="cb17-66">    precision, recall, f1, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> precision_recall_fscore_support(</span>
<span id="cb17-67">        labels, predictions, average<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'weighted'</span></span>
<span id="cb17-68">    )</span>
<span id="cb17-69">    </span>
<span id="cb17-70">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb17-71">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'accuracy'</span>: accuracy,</span>
<span id="cb17-72">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'f1'</span>: f1,</span>
<span id="cb17-73">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'precision'</span>: precision,</span>
<span id="cb17-74">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'recall'</span>: recall</span>
<span id="cb17-75">    }</span>
<span id="cb17-76"></span>
<span id="cb17-77"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5. 학습 실행</span></span>
<span id="cb17-78">trainer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Trainer(</span>
<span id="cb17-79">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model,</span>
<span id="cb17-80">    args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>training_args,</span>
<span id="cb17-81">    train_dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_dataset,</span>
<span id="cb17-82">    eval_dataset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>eval_dataset,</span>
<span id="cb17-83">    compute_metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>compute_metrics</span>
<span id="cb17-84">)</span>
<span id="cb17-85"></span>
<span id="cb17-86">trainer.train()</span></code></pre></div>
</section>
<section id="효율적-파인튜닝-기법" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="효율적-파인튜닝-기법"><span class="header-section-number">6.2</span> 효율적 파인튜닝 기법</h2>
<section id="lora-low-rank-adaptation" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="lora-low-rank-adaptation"><span class="header-section-number">6.2.1</span> LoRA (Low-Rank Adaptation)</h3>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> peft <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LoraConfig, get_peft_model, TaskType</span>
<span id="cb18-2"></span>
<span id="cb18-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LoRA 설정</span></span>
<span id="cb18-4">lora_config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LoraConfig(</span>
<span id="cb18-5">    task_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>TaskType.SEQ_CLS,</span>
<span id="cb18-6">    inference_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb18-7">    r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 랭크</span></span>
<span id="cb18-8">    lora_alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>,</span>
<span id="cb18-9">    lora_dropout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb18-10">    target_modules<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"query"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 적용할 레이어</span></span>
<span id="cb18-11">)</span>
<span id="cb18-12"></span>
<span id="cb18-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LoRA 적용</span></span>
<span id="cb18-14">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_peft_model(model, lora_config)</span>
<span id="cb18-15"></span>
<span id="cb18-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 학습 가능한 파라미터 수 확인</span></span>
<span id="cb18-17">model.print_trainable_parameters()</span>
<span id="cb18-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 학습 가능한 파라미터: 294,912 (전체의 0.27%)</span></span></code></pre></div>
</section>
<section id="gradient-checkpointing-메모리-절약" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="gradient-checkpointing-메모리-절약"><span class="header-section-number">6.2.2</span> Gradient Checkpointing (메모리 절약)</h3>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 메모리 사용량을 절반으로 줄임 (속도는 약간 느려짐)</span></span>
<span id="cb19-2">model.gradient_checkpointing_enable()</span>
<span id="cb19-3"></span>
<span id="cb19-4">training_args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TrainingArguments(</span>
<span id="cb19-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... 기타 설정</span></span>
<span id="cb19-6">    gradient_checkpointing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb19-7">    dataloader_pin_memory<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 메모리 절약</span></span>
<span id="cb19-8">    remove_unused_columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb19-9">)</span></code></pre></div>
</section>
<section id="deepspeed-통합-대규모-모델" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3" class="anchored" data-anchor-id="deepspeed-통합-대규모-모델"><span class="header-section-number">6.2.3</span> DeepSpeed 통합 (대규모 모델)</h3>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># deepspeed_config.json</span></span>
<span id="cb20-2">deepspeed_config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb20-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train_batch_size"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>,</span>
<span id="cb20-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gradient_accumulation_steps"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb20-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp16"</span>: {</span>
<span id="cb20-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"enabled"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb20-7">    },</span>
<span id="cb20-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"zero_optimization"</span>: {</span>
<span id="cb20-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"stage"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb20-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"offload_optimizer"</span>: {</span>
<span id="cb20-11">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"device"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cpu"</span>,</span>
<span id="cb20-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pin_memory"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb20-13">        }</span>
<span id="cb20-14">    }</span>
<span id="cb20-15">}</span>
<span id="cb20-16"></span>
<span id="cb20-17">training_args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> TrainingArguments(</span>
<span id="cb20-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... 기타 설정</span></span>
<span id="cb20-19">    deepspeed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>deepspeed_config,</span>
<span id="cb20-20">    fp16<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb20-21">)</span></code></pre></div>
</section>
</section>
</section>
<section id="실무-활용-사례와-베스트-프랙티스" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> 실무 활용 사례와 베스트 프랙티스</h1>
<section id="한국어-모델-선택-가이드" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="한국어-모델-선택-가이드"><span class="header-section-number">7.1</span> 한국어 모델 선택 가이드</h2>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 태스크별 추천 한국어 모델</span></span>
<span id="cb21-2">korean_models <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb21-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 범용 인코더</span></span>
<span id="cb21-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'general_encoder'</span>: [</span>
<span id="cb21-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>,           <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 가장 안정적</span></span>
<span id="cb21-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/roberta-large"</span>,       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 높은 성능</span></span>
<span id="cb21-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"monologg/kobert"</span>,          <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 경량화</span></span>
<span id="cb21-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beomi/kcbert-base"</span>         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 댓글/리뷰 특화</span></span>
<span id="cb21-9">    ],</span>
<span id="cb21-10">    </span>
<span id="cb21-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 텍스트 생성</span></span>
<span id="cb21-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'text_generation'</span>: [</span>
<span id="cb21-13">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"skt/kogpt2-base-v2"</span>,       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 일반적 용도</span></span>
<span id="cb21-14">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kakaobrain/kogpt"</span>,         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 고품질 생성</span></span>
<span id="cb21-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"EleutherAI/polyglot-ko-12.8b"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 대규모 모델</span></span>
<span id="cb21-16">    ],</span>
<span id="cb21-17">    </span>
<span id="cb21-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 요약</span></span>
<span id="cb21-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'summarization'</span>: [</span>
<span id="cb21-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eenzeenee/t5-base-korean-summarization"</span>,</span>
<span id="cb21-21">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"psyche/KoT5-summarization"</span></span>
<span id="cb21-22">    ],</span>
<span id="cb21-23">    </span>
<span id="cb21-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 번역</span></span>
<span id="cb21-25">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'translation'</span>: [</span>
<span id="cb21-26">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Helsinki-NLP/opus-mt-ko-en"</span>,   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 한→영</span></span>
<span id="cb21-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Helsinki-NLP/opus-mt-en-ko"</span>    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 영→한</span></span>
<span id="cb21-28">    ]</span>
<span id="cb21-29">}</span></code></pre></div>
</section>
<section id="성능-벤치마킹" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="성능-벤치마킹"><span class="header-section-number">7.2</span> 성능 벤치마킹</h2>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb22-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb22-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pipeline</span>
<span id="cb22-4"></span>
<span id="cb22-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> benchmark_model(model_name, texts, task<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text-classification"</span>):</span>
<span id="cb22-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""모델 성능 벤치마크"""</span></span>
<span id="cb22-7">    </span>
<span id="cb22-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPU 메모리 초기화</span></span>
<span id="cb22-9">    torch.cuda.empty_cache()</span>
<span id="cb22-10">    </span>
<span id="cb22-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모델 로드 시간</span></span>
<span id="cb22-12">    start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb22-13">    pipe <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipeline(task, model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>model_name, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb22-14">    load_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb22-15">    </span>
<span id="cb22-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 추론 시간 (단일)</span></span>
<span id="cb22-17">    start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb22-18">    single_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipe(texts[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb22-19">    single_inference_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb22-20">    </span>
<span id="cb22-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 추론 시간 (배치)</span></span>
<span id="cb22-22">    start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb22-23">    batch_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pipe(texts)</span>
<span id="cb22-24">    batch_inference_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb22-25">    </span>
<span id="cb22-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPU 메모리 사용량</span></span>
<span id="cb22-27">    memory_usage <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cuda.max_memory_allocated() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GB</span></span>
<span id="cb22-28">    </span>
<span id="cb22-29">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb22-30">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'model'</span>: model_name,</span>
<span id="cb22-31">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'load_time'</span>: load_time,</span>
<span id="cb22-32">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'single_inference_time'</span>: single_inference_time,</span>
<span id="cb22-33">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'batch_inference_time'</span>: batch_inference_time,</span>
<span id="cb22-34">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'throughput'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(texts) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> batch_inference_time,</span>
<span id="cb22-35">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'memory_usage_gb'</span>: memory_usage</span>
<span id="cb22-36">    }</span>
<span id="cb22-37"></span>
<span id="cb22-38"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 벤치마크 실행</span></span>
<span id="cb22-39">test_texts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"테스트 문장"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb22-40">models_to_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb22-41">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>,</span>
<span id="cb22-42">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"monologg/distilkobert"</span>,</span>
<span id="cb22-43">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"beomi/kcbert-base"</span></span>
<span id="cb22-44">]</span>
<span id="cb22-45"></span>
<span id="cb22-46"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> models_to_test:</span>
<span id="cb22-47">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> benchmark_model(model, test_texts)</span>
<span id="cb22-48">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
</section>
<section id="프로덕션-배포-전략" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="프로덕션-배포-전략"><span class="header-section-number">7.3</span> 프로덕션 배포 전략</h2>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 모델 최적화 및 저장</span></span>
<span id="cb23-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ProductionModel:</span>
<span id="cb23-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, model_path):</span>
<span id="cb23-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_path)</span>
<span id="cb23-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForSequenceClassification.from_pretrained(</span>
<span id="cb23-6">            model_path,</span>
<span id="cb23-7">            torch_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.float16,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 반정밀도</span></span>
<span id="cb23-8">            return_dict<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb23-9">        )</span>
<span id="cb23-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 평가 모드</span></span>
<span id="cb23-11">        </span>
<span id="cb23-12">    <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@torch.no_grad</span>()</span>
<span id="cb23-13">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, texts):</span>
<span id="cb23-14">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""추론 전용 메서드"""</span></span>
<span id="cb23-15">        inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer(</span>
<span id="cb23-16">            texts,</span>
<span id="cb23-17">            padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb23-18">            truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb23-19">            return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>,</span>
<span id="cb23-20">            max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span></span>
<span id="cb23-21">        )</span>
<span id="cb23-22">        </span>
<span id="cb23-23">        outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>inputs)</span>
<span id="cb23-24">        predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.functional.softmax(outputs.logits, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb23-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> predictions.cpu().numpy()</span>
<span id="cb23-26"></span>
<span id="cb23-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. API 서버 예시 (FastAPI)</span></span>
<span id="cb23-28"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastapi <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> FastAPI</span>
<span id="cb23-29"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb23-30"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> List</span>
<span id="cb23-31"></span>
<span id="cb23-32">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> FastAPI()</span>
<span id="cb23-33">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ProductionModel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./trained_model"</span>)</span>
<span id="cb23-34"></span>
<span id="cb23-35"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> PredictionRequest(BaseModel):</span>
<span id="cb23-36">    texts: List[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>]</span>
<span id="cb23-37"></span>
<span id="cb23-38"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.post</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/predict"</span>)</span>
<span id="cb23-39"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">async</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict(request: PredictionRequest):</span>
<span id="cb23-40">    predictions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(request.texts)</span>
<span id="cb23-41">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb23-42">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"predictions"</span>: predictions.tolist(),</span>
<span id="cb23-43">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model_info"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>,</span>
<span id="cb23-44">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"timestamp"</span>: time.time()</span>
<span id="cb23-45">    }</span>
<span id="cb23-46"></span>
<span id="cb23-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 도커 컨테이너화</span></span>
<span id="cb23-48">dockerfile_content <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb23-49"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">FROM python:3.9-slim</span></span>
<span id="cb23-50"></span>
<span id="cb23-51"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">WORKDIR /app</span></span>
<span id="cb23-52"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">COPY requirements.txt .</span></span>
<span id="cb23-53"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">RUN pip install -r requirements.txt</span></span>
<span id="cb23-54"></span>
<span id="cb23-55"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">COPY . .</span></span>
<span id="cb23-56"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">EXPOSE 8000</span></span>
<span id="cb23-57"></span>
<span id="cb23-58"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]</span></span>
<span id="cb23-59"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div>
</section>
<section id="모니터링-및-로깅" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="모니터링-및-로깅"><span class="header-section-number">7.4</span> 모니터링 및 로깅</h2>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> logging</span>
<span id="cb24-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datetime <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datetime</span>
<span id="cb24-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb24-4"></span>
<span id="cb24-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ModelMonitor:</span>
<span id="cb24-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, model_name):</span>
<span id="cb24-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_name</span>
<span id="cb24-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.logger <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._setup_logger()</span>
<span id="cb24-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.prediction_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb24-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.error_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb24-11">        </span>
<span id="cb24-12">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _setup_logger(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb24-13">        logger <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logging.getLogger(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>model_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb24-14">        handler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logging.FileHandler(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model_logs_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>model_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.log"</span>)</span>
<span id="cb24-15">        formatter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> logging.Formatter(</span>
<span id="cb24-16">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%(asctime)s</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%(name)s</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%(levelname)s</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"> - </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%(message)s</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb24-17">        )</span>
<span id="cb24-18">        handler.setFormatter(formatter)</span>
<span id="cb24-19">        logger.addHandler(handler)</span>
<span id="cb24-20">        logger.setLevel(logging.INFO)</span>
<span id="cb24-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> logger</span>
<span id="cb24-22">    </span>
<span id="cb24-23">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> log_prediction(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, input_text, prediction, confidence, latency):</span>
<span id="cb24-24">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""예측 결과 로깅"""</span></span>
<span id="cb24-25">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.prediction_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb24-26">        </span>
<span id="cb24-27">        log_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb24-28">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"timestamp"</span>: datetime.now().isoformat(),</span>
<span id="cb24-29">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input_length"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(input_text),</span>
<span id="cb24-30">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prediction"</span>: prediction,</span>
<span id="cb24-31">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"confidence"</span>: confidence,</span>
<span id="cb24-32">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"latency_ms"</span>: latency <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>,</span>
<span id="cb24-33">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prediction_id"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.prediction_count</span>
<span id="cb24-34">        }</span>
<span id="cb24-35">        </span>
<span id="cb24-36">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.logger.info(json.dumps(log_data))</span>
<span id="cb24-37">        </span>
<span id="cb24-38">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 낮은 신뢰도 경고</span></span>
<span id="cb24-39">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> confidence <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>:</span>
<span id="cb24-40">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.logger.warning(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Low confidence prediction: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>confidence<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb24-41">    </span>
<span id="cb24-42">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> log_error(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, error_msg, input_text):</span>
<span id="cb24-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""오류 로깅"""</span></span>
<span id="cb24-44">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.error_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb24-45">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.logger.error(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>error_msg<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, Input: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>input_text[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">..."</span>)</span>
<span id="cb24-46">    </span>
<span id="cb24-47">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> get_stats(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb24-48">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""통계 정보 반환"""</span></span>
<span id="cb24-49">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb24-50">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"total_predictions"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.prediction_count,</span>
<span id="cb24-51">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"total_errors"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.error_count,</span>
<span id="cb24-52">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"error_rate"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.error_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.prediction_count, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb24-53">        }</span>
<span id="cb24-54"></span>
<span id="cb24-55"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 사용 예시</span></span>
<span id="cb24-56">monitor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ModelMonitor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sentiment_classifier"</span>)</span>
<span id="cb24-57"></span>
<span id="cb24-58"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> monitored_predict(text):</span>
<span id="cb24-59">    start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time()</span>
<span id="cb24-60">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">try</span>:</span>
<span id="cb24-61">        result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict([text])[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb24-62">        latency <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time</span>
<span id="cb24-63">        </span>
<span id="cb24-64">        prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> result.argmax()</span>
<span id="cb24-65">        confidence <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> result.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()</span>
<span id="cb24-66">        </span>
<span id="cb24-67">        monitor.log_prediction(text, prediction, confidence, latency)</span>
<span id="cb24-68">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"prediction"</span>: prediction, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"confidence"</span>: confidence}</span>
<span id="cb24-69">        </span>
<span id="cb24-70">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="cb24-71">        monitor.log_error(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(e), text)</span>
<span id="cb24-72">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">raise</span></span></code></pre></div>
</section>
</section>
<section id="한국어-nlp-특화-고려사항" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> 한국어 NLP 특화 고려사항</h1>
<section id="한국어-토큰화의-특수성" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="한국어-토큰화의-특수성"><span class="header-section-number">8.1</span> 한국어 토큰화의 특수성</h2>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 한국어 형태소 분석기와 조합</span></span>
<span id="cb25-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> konlpy.tag <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Mecab</span>
<span id="cb25-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer</span>
<span id="cb25-4"></span>
<span id="cb25-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> KoreanPreprocessor:</span>
<span id="cb25-6">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, model_name):</span>
<span id="cb25-7">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb25-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mecab <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Mecab()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 형태소 분석기</span></span>
<span id="cb25-9">    </span>
<span id="cb25-10">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> preprocess_korean(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text):</span>
<span id="cb25-11">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""한국어 특화 전처리"""</span></span>
<span id="cb25-12">        </span>
<span id="cb25-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 정규화</span></span>
<span id="cb25-14">        text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text.strip()</span>
<span id="cb25-15">        text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.sub(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'[ㄱ-ㅎㅏ-ㅣ]+'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>, text)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 자음/모음만 있는 경우 제거</span></span>
<span id="cb25-16">        text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.sub(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'\s+'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>, text)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연속 공백 제거</span></span>
<span id="cb25-17">        </span>
<span id="cb25-18">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 이모지/특수문자 처리</span></span>
<span id="cb25-19">        text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> re.sub(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'[^\w\s가-힣]'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span>, text)</span>
<span id="cb25-20">        </span>
<span id="cb25-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. 형태소 분석 (선택적)</span></span>
<span id="cb25-22">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># morphs = self.mecab.morphs(text)</span></span>
<span id="cb25-23">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># text = ' '.join(morphs)</span></span>
<span id="cb25-24">        </span>
<span id="cb25-25">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> text</span>
<span id="cb25-26">    </span>
<span id="cb25-27">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> tokenize_korean(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text):</span>
<span id="cb25-28">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""한국어 토큰화"""</span></span>
<span id="cb25-29">        preprocessed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.preprocess_korean(text)</span>
<span id="cb25-30">        tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tokenizer(</span>
<span id="cb25-31">            preprocessed,</span>
<span id="cb25-32">            max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>,</span>
<span id="cb25-33">            truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb25-34">            padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb25-35">            return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span></span>
<span id="cb25-36">        )</span>
<span id="cb25-37">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> tokens</span>
<span id="cb25-38"></span>
<span id="cb25-39"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 사용 예시</span></span>
<span id="cb25-40">preprocessor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KoreanPreprocessor(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"klue/bert-base"</span>)</span>
<span id="cb25-41">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> preprocessor.tokenize_korean(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"안녕하세요!!! 😊 테스트입니다ㅋㅋㅋ"</span>)</span></code></pre></div>
</section>
<section id="한국어-데이터-증강" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="한국어-데이터-증강"><span class="header-section-number">8.2</span> 한국어 데이터 증강</h2>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> random</span>
<span id="cb26-2"></span>
<span id="cb26-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> KoreanDataAugmentation:</span>
<span id="cb26-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb26-5">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 유의어 사전 (실제로는 더 큰 사전 필요)</span></span>
<span id="cb26-6">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.synonyms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb26-7">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"좋다"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"훌륭하다"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"멋지다"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"괜찮다"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나쁘지않다"</span>],</span>
<span id="cb26-8">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나쁘다"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"별로다"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"안좋다"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"형편없다"</span>],</span>
<span id="cb26-9">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"크다"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"거대하다"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"큰"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"대형의"</span>],</span>
<span id="cb26-10">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"작다"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"소형의"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"작은"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"미니"</span>]</span>
<span id="cb26-11">        }</span>
<span id="cb26-12">    </span>
<span id="cb26-13">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> synonym_replacement(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb26-14">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""유의어 치환"""</span></span>
<span id="cb26-15">        words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text.split()</span>
<span id="cb26-16">        new_words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> words.copy()</span>
<span id="cb26-17">        </span>
<span id="cb26-18">        random_word_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>([word <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> words <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.synonyms]))</span>
<span id="cb26-19">        random.shuffle(random_word_list)</span>
<span id="cb26-20">        </span>
<span id="cb26-21">        num_replaced <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb26-22">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> random_word <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> random_word_list:</span>
<span id="cb26-23">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> num_replaced <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> n:</span>
<span id="cb26-24">                synonyms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.synonyms[random_word]</span>
<span id="cb26-25">                synonym <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> random.choice(synonyms)</span>
<span id="cb26-26">                new_words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [synonym <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> word <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> random_word <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span> word <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> word <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> new_words]</span>
<span id="cb26-27">                num_replaced <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb26-28">        </span>
<span id="cb26-29">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>.join(new_words)</span>
<span id="cb26-30">    </span>
<span id="cb26-31">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> random_insertion(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>):</span>
<span id="cb26-32">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""임의 삽입"""</span></span>
<span id="cb26-33">        words <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text.split()</span>
<span id="cb26-34">        </span>
<span id="cb26-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n):</span>
<span id="cb26-36">            new_word <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._get_random_synonym()</span>
<span id="cb26-37">            random_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> random.randint(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(words))</span>
<span id="cb26-38">            words.insert(random_idx, new_word)</span>
<span id="cb26-39">        </span>
<span id="cb26-40">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">' '</span>.join(words)</span>
<span id="cb26-41">    </span>
<span id="cb26-42">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> _get_random_synonym(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb26-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""임의 유의어 선택"""</span></span>
<span id="cb26-44">        word <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> random.choice(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.synonyms.keys()))</span>
<span id="cb26-45">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> random.choice(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.synonyms[word])</span>
<span id="cb26-46"></span>
<span id="cb26-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 사용 예시</span></span>
<span id="cb26-48">augmenter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KoreanDataAugmentation()</span>
<span id="cb26-49">original <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"이 영화는 정말 좋다"</span></span>
<span id="cb26-50">augmented <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> augmenter.synonym_replacement(original)</span>
<span id="cb26-51"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"원본: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>original<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb26-52"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"증강: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>augmented<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
</section>
</section>
<section id="결론" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> 결론</h1>
<p>Hugging Face는 <strong>NLP 분야의 게임체인저</strong>로서, 연구와 실무 사이의 간격을 혁신적으로 줄였다.</p>
<section id="핵심-성과" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="핵심-성과"><span class="header-section-number">9.1</span> 핵심 성과</h2>
<ul>
<li><strong>기술 민주화</strong>: 복잡한 PLM을 몇 줄의 코드로 사용 가능하게 만듦</li>
<li><strong>표준화</strong>: 모든 모델이 동일한 API로 통일되어 학습 곡선 단축</li>
<li><strong>생태계 구축</strong>: 10만+ 모델과 데이터셋을 공유하는 거대한 커뮤니티 형성</li>
<li><strong>개발 가속화</strong>: 프로토타입부터 프로덕션까지 전체 워크플로우 지원</li>
</ul>
</section>
<section id="실무에서의-가치" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="실무에서의-가치"><span class="header-section-number">9.2</span> 실무에서의 가치</h2>
<p><strong>Before Hugging Face</strong> 시대에는 새로운 모델을 사용하려면 논문을 읽고, 코드를 직접 구현하며, 체크포인트를 찾아 헤매야 했다. <strong>After Hugging Face</strong> 시대에는 <code>pipeline("task", model="model_name")</code>만으로 최신 기술을 바로 활용할 수 있다.</p>
<p>이러한 접근성 향상은 단순한 편의성을 넘어서, <strong>AI 기술의 진입 장벽을 낮춰 더 많은 개발자들이 NLP 분야에 참여할 수 있게</strong> 만들었다. 스타트업부터 대기업까지, 연구자부터 실무 개발자까지 모든 레벨에서 혜택을 받고 있다.</p>
</section>
<section id="미래-전망" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="미래-전망"><span class="header-section-number">9.3</span> 미래 전망</h2>
<p>Hugging Face는 계속해서 발전하고 있다:</p>
<ul>
<li><strong>더 큰 모델들</strong>: LLaMA, Falcon 등 오픈소스 대규모 모델 지원 확대</li>
<li><strong>멀티모달</strong>: 텍스트, 이미지, 음성을 통합하는 모델들</li>
<li><strong>효율성</strong>: 양자화, 프루닝, LoRA 등 효율적 학습/추론 기법</li>
<li><strong>AutoML</strong>: 자동 모델 선택과 하이퍼파라미터 튜닝</li>
<li><strong>Edge 배포</strong>: 모바일과 임베디드 환경 지원 강화</li>
</ul>
</section>
<section id="실무진을-위한-조언" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="실무진을-위한-조언"><span class="header-section-number">9.4</span> 실무진을 위한 조언</h2>
<ol type="1">
<li><strong>Pipeline부터 시작</strong>: 복잡한 구현보다는 Pipeline API로 빠른 프로토타입 제작</li>
<li><strong>한국어 모델 활용</strong>: KLUE 등 검증된 한국어 모델 우선 고려</li>
<li><strong>단계적 접근</strong>: API → 파인튜닝 → 커스텀 모델 순으로 점진적 발전</li>
<li><strong>커뮤니티 활용</strong>: Model Hub의 평가와 리뷰를 참고한 현명한 모델 선택</li>
<li><strong>성능 모니터링</strong>: 프로덕션 환경에서는 반드시 성능과 품질 추적</li>
</ol>
<p>Hugging Face는 <strong>“연구실의 최신 기술을 현실의 문제 해결에 바로 적용”</strong>할 수 있게 해주는 강력한 도구다. 이제 중요한 것은 기술 자체가 아니라, <strong>어떤 문제를 해결할 것인가</strong>와 <strong>어떻게 사용자에게 가치를 제공할 것인가</strong>이다. Hugging Face는 그 여정을 위한 최고의 동반자가 될 것이다.</p>


</section>
</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/27.plm_hugging_face.html</guid>
  <pubDate>Sun, 26 Jan 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>PLM: Pre-trained Language Model</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/26.plm.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>사전 학습 언어 모델(PLM)은 지속적으로 발전하고 있지만, <strong>무조건 최신 모델이 항상 정답은 아니다</strong>. 기업의 규모, 프로젝트의 특성, 예산 제약, 성능 요구사항에 따라 적절한 모델을 선택하는 것이 실무에서는 더욱 중요하다.</p>
<section id="모델-발전의-딜레마" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="모델-발전의-딜레마"><span class="header-section-number">1.1</span> 모델 발전의 딜레마</h2>
<p>기술적으로는 LSTM → BERT → T5 → ChatGPT로 발전할수록 성능이 향상되지만, 실무에서는 다음과 같은 현실적 제약이 있다:</p>
<ul>
<li><strong>비용과 리소스</strong>: 최신 모델일수록 막대한 컴퓨팅 비용과 인프라 필요</li>
<li><strong>개발 복잡성</strong>: 고성능 모델은 구현과 튜닝의 난이도가 높음</li>
<li><strong>운영 효율성</strong>: 실시간 서비스에서는 지연시간이 비즈니스 성패를 좌우</li>
<li><strong>도메인 적합성</strong>: 범용 모델보다 특화된 작은 모델이 더 효과적인 경우 존재</li>
</ul>
</section>
<section id="현실적-선택-기준" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="현실적-선택-기준"><span class="header-section-number">1.2</span> 현실적 선택 기준</h2>
<ol type="1">
<li><strong>스타트업/중소기업</strong>: 1.3B 이하 오픈소스 모델(BERT, KoGPT)이 현실적 마지노선</li>
<li><strong>중견기업</strong>: 하이브리드 접근법(API + 자체 모델)으로 비용 효율성 추구</li>
<li><strong>대기업</strong>: 자체 인프라와 전문 인력을 바탕으로 최신 모델 적용</li>
</ol>
</section>
<section id="효과적인-전략들" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="효과적인-전략들"><span class="header-section-number">1.3</span> 효과적인 전략들</h2>
<ul>
<li><strong>API 활용</strong>: ChatGPT API로 데이터 생성 후 작은 모델 학습</li>
<li><strong>모델 조합</strong>: 검색엔진 + ChatGPT + 프롬프트 엔지니어링</li>
<li><strong>단계적 접근</strong>: 작은 모델로 시작해서 필요에 따라 확장</li>
<li><strong>도메인 특화</strong>: 범용성보다는 특정 문제에 최적화</li>
</ul>
<p>결국, 문제의 복잡도와 요구사항에 맞는 적절한 모델을 선택하는 것이 성공의 핵심이다.</p>
</section>
</section>
<section id="nlp-모델-발전-과정" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> NLP 모델 발전 과정</h1>
<pre><code>RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa (Facebook, 2019)
|   ├── ALBERT (Google, 2019)
|   ├── DistilBERT (Hugging Face, 2019)
|   └── ELECTRA (Google, 2020)
|
└── 후속 발전 모델들
    ├── T5, XLNet, DeBERTa
    └── GPT-2/3/4, ChatGPT, PaLM 등</code></pre>
</section>
<section id="실무에서의-모델-선택-전략" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> 실무에서의 모델 선택 전략</h1>
<section id="성능-vs-현실-사이의-간극" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="성능-vs-현실-사이의-간극"><span class="header-section-number">3.1</span> 성능 vs 현실 사이의 간극</h2>
<p>PLM 기술은 매년 눈부신 발전을 보이고 있다. 논문에서는 항상 더 큰 모델이 더 좋은 성능을 보여주고, 최신 모델들이 이전 모델들의 단점을 보완하며 SOTA를 경신한다. 하지만 실무에서는 이야기가 다르다.</p>
<section id="기술-발전과-현실적-제약" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="기술-발전과-현실적-제약"><span class="header-section-number">3.1.1</span> 기술 발전과 현실적 제약</h3>
<p><strong>기술적 우수성과 실용성은 별개의 문제다</strong>. T5가 BERT보다 우수하고, ChatGPT가 T5보다 뛰어나다고 해서 모든 프로젝트에 ChatGPT를 써야 하는 것은 아니다. 다음과 같은 현실적 제약들이 존재한다:</p>
<ul>
<li><strong>컴퓨팅 비용</strong>: GPT-4 API 호출 비용 vs 자체 BERT 모델 운영 비용</li>
<li><strong>지연시간</strong>: 실시간 챗봇에서 3초 응답 vs 100ms 응답의 차이</li>
<li><strong>데이터 보안</strong>: 민감한 데이터를 외부 API로 전송할 수 없는 경우</li>
<li><strong>커스터마이징</strong>: 도메인 특화 요구사항에 대한 대응 가능성</li>
<li><strong>안정성</strong>: 서비스 중단 없이 24/7 운영 가능한지</li>
</ul>
</section>
<section id="모델별-현실적-접근성" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="모델별-현실적-접근성"><span class="header-section-number">3.1.2</span> 모델별 현실적 접근성</h3>
<pre><code>[ 기업 규모별 현실적 모델 선택 ]

스타트업 (직원 ~50명)
├── BERT, KoGPT: 무료 오픈소스, 자체 서버 운영 가능
├── OpenAI API: 초기 프로토타입용, 월 예산 ~$1,000
└── 하이브리드: API로 데이터 생성 → 작은 모델 학습

중견기업 (직원 ~500명)  
├── DistilBERT, ALBERT: 효율성 최적화된 모델
├── T5-Small/Base: 적당한 성능과 비용의 균형
├── API + 자체모델: 복잡한 태스크는 API, 단순한 것은 자체 모델
└── 클라우드 GPU: AWS/GCP의 관리형 서비스 활용

대기업 (직원 1,000명+)
├── T5-Large, GPT-3.5 수준: 자체 인프라로 운영
├── 전용 하드웨어: A100 클러스터, TPU 등
├── 자체 모델 개발: 도메인 특화 대규모 모델
└── 하이브리드 전략: 용도별로 다양한 모델 조합</code></pre>
</section>
</section>
<section id="프로젝트-특성별-모델-선택" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="프로젝트-특성별-모델-선택"><span class="header-section-number">3.2</span> 프로젝트 특성별 모델 선택</h2>
<section id="문서-분류-프로젝트-사례" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="문서-분류-프로젝트-사례"><span class="header-section-number">3.2.1</span> 문서 분류 프로젝트 사례</h3>
<p><strong>상황</strong>: 고객 문의사항을 10개 카테고리로 자동 분류하는 시스템</p>
<p><strong>옵션별 비교</strong>:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 옵션 1: BERT-Base (110M)</span></span>
<span id="cb3-2">장점: </span>
<span id="cb3-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 분류 태스크에 최적화된 구조</span>
<span id="cb3-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 빠른 추론 속도 (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">ms</span>)</span>
<span id="cb3-5"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 완전한 온프레미스 운영 가능</span>
<span id="cb3-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 충분한 성능 (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%+</span> 정확도)</span>
<span id="cb3-7"></span>
<span id="cb3-8">단점:</span>
<span id="cb3-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 새로운 카테고리 추가 시 재학습 필요</span>
<span id="cb3-10"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 복잡한 추론이나 설명 생성 불가</span>
<span id="cb3-11"></span>
<span id="cb3-12">비용: 월 $<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span> (AWS t3.medium 인스턴스)</span></code></pre></div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 옵션 2: GPT-4 API</span></span>
<span id="cb4-2">장점:</span>
<span id="cb4-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Few<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>shot learning으로 빠른 적응</span>
<span id="cb4-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 분류 근거까지 자연어로 설명 가능</span>
<span id="cb4-5"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 새 카테고리 추가가 프롬프트 수정만으로 가능</span>
<span id="cb4-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 복잡한 경계 케이스도 잘 처리</span>
<span id="cb4-7"></span>
<span id="cb4-8">단점:</span>
<span id="cb4-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 높은 API 비용 (요청당 $<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.03</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.06</span>)</span>
<span id="cb4-10"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 외부 의존성으로 인한 서비스 리스크</span>
<span id="cb4-11"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 응답 속도 변동성 (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">ms</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">s</span>)</span>
<span id="cb4-12"></span>
<span id="cb4-13">비용: 월 $<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000</span> (일 <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">건</span> 처리 시)</span></code></pre></div>
</section>
<section id="실제-선택-기준" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="실제-선택-기준"><span class="header-section-number">3.2.2</span> 실제 선택 기준</h3>
<p><strong>언제 작은 모델을 선택해야 하는가?</strong></p>
<ol type="1">
<li><strong>명확한 태스크 정의</strong>: 감정 분석, 개체명 인식 등 잘 정의된 문제</li>
<li><strong>빠른 응답 필요</strong>: 실시간 추천, 챗봇 등</li>
<li><strong>대용량 배치 처리</strong>: 비용 효율성이 핵심인 경우 (단순 반복 작업)
<ul>
<li>예: 일일 수백만 건의 뉴스 기사 분류</li>
<li>예: 고객 리뷰의 감정 분석 (긍정/부정/중립)</li>
<li>예: 이메일 스팸 필터링</li>
<li>이유: API 비용($0.03/건 × 100만건 = $30,000/일) vs 자체 모델($100/월)</li>
</ul></li>
<li><strong>데이터 보안</strong>: 금융, 의료 등 민감한 정보</li>
<li><strong>예산 제약</strong>: 스타트업의 MVP(Minimum Viable Product) 단계</li>
</ol>
<p><strong>언제 큰 모델을 선택해야 하는가?</strong></p>
<ol type="1">
<li><strong>복잡한 추론</strong>: 다단계 논리적 사고가 필요한 경우</li>
<li><strong>유연성 중요</strong>: 요구사항이 자주 변하는 환경</li>
<li><strong>높은 품질 요구</strong>: 고객 대면 서비스, 브랜드 이미지가 중요한 경우</li>
<li><strong>다양한 태스크</strong>: 하나의 모델로 여러 기능을 처리해야 하는 경우</li>
<li><strong>소량 고품질 처리</strong>: 일일 수천~수만 건의 프리미엄 서비스 (고품질의 창의적 작업)
<ul>
<li>예: 법률 문서 분석 및 요약</li>
<li>예: 개인 맞춤형 투자 조언 생성</li>
<li>예: 고급 마케팅 콘텐츠 작성</li>
</ul></li>
<li><strong>충분한 예산</strong>: ROI가 명확하게 보장되는 경우</li>
</ol>
</section>
</section>
<section id="현실적-하이브리드-전략" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="현실적-하이브리드-전략"><span class="header-section-number">3.3</span> 현실적 하이브리드 전략</h2>
<section id="계층적-모델-활용" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="계층적-모델-활용"><span class="header-section-number">3.3.1</span> 계층적 모델 활용</h3>
<p>많은 기업들이 실제로 사용하는 전략은 <strong>단일 모델이 아닌 계층적 접근법</strong>이다. 태스크의 복잡도에 따라 적절한 모델을 라우팅하는 방식이다.</p>
<p><strong>핵심은 복잡도 분류 모델(라우터)</strong>이다. 이 작은 모델이 전체 시스템의 효율성을 결정한다:</p>
<p><strong>복잡도별 태스크 분류:</strong></p>
<ul>
<li><strong>Simple (단순)</strong>: 정형화된 정보 검색, 단순 분류
<ul>
<li>FAQ 검색, 카테고리 분류, 키워드 추출</li>
<li>BERT, DistilBERT 등 가벼운 모델로 충분</li>
</ul></li>
<li><strong>Medium (중간)</strong>: 텍스트 변환, 기본적인 생성
<ul>
<li>문서 요약, 번역, 제품 설명 생성, 이메일 자동 응답</li>
<li>템플릿 기반 보고서 작성, 간단한 QA</li>
<li>T5, BART 등 encoder-decoder 모델 적합</li>
</ul></li>
<li><strong>Complex (복잡)</strong>: 창의적 사고, 복합적 추론
<ul>
<li>마케팅 콘텐츠 창작, 코드 생성, 복잡한 분석</li>
<li>다단계 논리 추론, 개인화된 조언</li>
<li>GPT-4, Claude 등 대규모 모델 필요</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1단계: 질문 복잡도 분류 모델 (라우터)</span></span>
<span id="cb5-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ComplexityClassifier:</span>
<span id="cb5-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb5-4">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 가벼운 BERT 모델로 빠른 분류 (10-20ms)</span></span>
<span id="cb5-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DistilBERT_for_classification()</span>
<span id="cb5-6">        </span>
<span id="cb5-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict_complexity(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, query):</span>
<span id="cb5-8">        features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.extract_features(query)</span>
<span id="cb5-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.predict(features)</span>
<span id="cb5-10">    </span>
<span id="cb5-11">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> extract_features(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, query):</span>
<span id="cb5-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> {</span>
<span id="cb5-13">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'length'</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(query.split()),</span>
<span id="cb5-14">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'question_words'</span>: count_wh_words(query),</span>
<span id="cb5-15">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'conjunctions'</span>: count_conjunctions(query),</span>
<span id="cb5-16">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'domain_keywords'</span>: check_domain_keywords(query),</span>
<span id="cb5-17">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sentiment_complexity'</span>: analyze_sentiment_depth(query)</span>
<span id="cb5-18">        }</span>
<span id="cb5-19"></span>
<span id="cb5-20"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> smart_routing(user_query):</span>
<span id="cb5-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1단계: 빠른 분류기로 복잡도 판단</span></span>
<span id="cb5-22">    classifier <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ComplexityClassifier()</span>
<span id="cb5-23">    complexity <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier.predict_complexity(user_query)</span>
<span id="cb5-24">    </span>
<span id="cb5-25">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> complexity <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>:</span>
<span id="cb5-26">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 단순 반복의 간단한 질문은 BERT 기반 FAQ 검색</span></span>
<span id="cb5-27">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예: "운영시간이 언제인가요?", "배송비는 얼마인가요?"</span></span>
<span id="cb5-28">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> faq_bert_model.search(user_query)</span>
<span id="cb5-29">    </span>
<span id="cb5-30">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">elif</span> complexity <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"medium"</span>:</span>
<span id="cb5-31">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 중간 복잡도는 T5 모델 사용</span></span>
<span id="cb5-32">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예: 제품 설명 요약, 기본적인 문서 생성, 간단한 QA</span></span>
<span id="cb5-33">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> t5_model.generate_response(user_query)</span>
<span id="cb5-34">    </span>
<span id="cb5-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># complex</span></span>
<span id="cb5-36">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 복잡한 질문만 GPT-4 API 호출</span></span>
<span id="cb5-37">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예: 창의적 글쓰기, 복잡한 분석, 다단계 추론</span></span>
<span id="cb5-38">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> openai_api.complete(user_query)</span></code></pre></div>
<p><strong>복잡도 분류 모델의 학습 데이터 예시:</strong></p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 학습 데이터셋 구축</span></span>
<span id="cb6-2">training_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb6-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Simple (단순) - 정형화된 질문</span></span>
<span id="cb6-4">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"운영시간이 언제인가요?"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>),</span>
<span id="cb6-5">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"배송비는 얼마인가요?"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>), </span>
<span id="cb6-6">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"환불 정책을 알려주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>),</span>
<span id="cb6-7">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"계정을 삭제하고 싶어요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>),</span>
<span id="cb6-8">    </span>
<span id="cb6-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Medium (중간) - 변환/생성이 필요한 질문</span></span>
<span id="cb6-10">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"이 제품의 장단점을 요약해주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"medium"</span>),</span>
<span id="cb6-11">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"고객 불만사항을 정중한 답변으로 작성해주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"medium"</span>),</span>
<span id="cb6-12">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"이 기사를 3문장으로 요약해주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"medium"</span>),</span>
<span id="cb6-13">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"영어를 한국어로 번역해주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"medium"</span>),</span>
<span id="cb6-14">    </span>
<span id="cb6-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Complex (복잡) - 창의적/분석적 사고 필요</span></span>
<span id="cb6-16">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"우리 회사에 맞는 마케팅 전략을 제안해주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complex"</span>),</span>
<span id="cb6-17">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"이 데이터를 분석해서 인사이트를 도출해주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complex"</span>),</span>
<span id="cb6-18">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"소설의 첫 장을 써주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complex"</span>),</span>
<span id="cb6-19">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"복잡한 법률 문제를 분석해주세요"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complex"</span>)</span>
<span id="cb6-20">]</span>
<span id="cb6-21"></span>
<span id="cb6-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 분류기 성능 최적화 포인트</span></span>
<span id="cb6-23">accuracy_requirements <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb6-24">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'simple_recall'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 단순 질문을 놓치면 안됨 (비용 증가)</span></span>
<span id="cb6-25">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'complex_precision'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.90</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 복잡한 질문을 잘못 분류하면 품질 저하</span></span>
<span id="cb6-26">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'medium_balance'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span>   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 중간 복잡도는 어느쪽으로 가도 큰 문제없음</span></span>
<span id="cb6-27">}</span></code></pre></div>
<p><strong>라우터 모델의 실제 운영 고려사항:</strong></p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">class</span> ProductionComplexityClassifier:</span>
<span id="cb7-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb7-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DistilBERT()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 20MB, 추론 10-15ms</span></span>
<span id="cb7-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.fallback_rules <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.load_rule_based_backup()</span>
<span id="cb7-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.confidence_threshold <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span></span>
<span id="cb7-6">        </span>
<span id="cb7-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> predict_with_confidence(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, query):</span>
<span id="cb7-8">        prediction, confidence <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.model.predict_proba(query)</span>
<span id="cb7-9">        </span>
<span id="cb7-10">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 확신이 낮으면 안전한 쪽(더 큰 모델)으로</span></span>
<span id="cb7-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> confidence <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.confidence_threshold:</span>
<span id="cb7-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"medium"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 애매하면 중간 모델로</span></span>
<span id="cb7-13">            </span>
<span id="cb7-14">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 키워드 기반 안전장치</span></span>
<span id="cb7-15">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.check_safety_keywords(query):</span>
<span id="cb7-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complex"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 민감한 키워드는 무조건 큰 모델</span></span>
<span id="cb7-17">            </span>
<span id="cb7-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> prediction</span>
<span id="cb7-19">    </span>
<span id="cb7-20">    <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> check_safety_keywords(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, query):</span>
<span id="cb7-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 법률, 의료, 금융 등 민감한 영역은 큰 모델로</span></span>
<span id="cb7-22">        sensitive_keywords <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'법률'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'의료'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'투자'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'세금'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'계약'</span>]</span>
<span id="cb7-23">                 <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">any</span>(keyword <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> query <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> keyword <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sensitive_keywords)</span></code></pre></div>
<p><strong>라우터 시스템의 비용 효율성 분석:</strong></p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 월 100,000건 처리 시 비용 비교</span></span>
<span id="cb8-2">routing_costs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb8-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 라우터 없이 모든 요청을 GPT-4로 처리</span></span>
<span id="cb8-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'all_gpt4'</span>: {</span>
<span id="cb8-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'api_cost'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100000</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.03</span>,  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># $3,000</span></span>
<span id="cb8-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'router_cost'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,</span>
<span id="cb8-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'total'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3000</span></span>
<span id="cb8-8">    },</span>
<span id="cb8-9">    </span>
<span id="cb8-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 라우터 사용 (70% simple, 20% medium, 10% complex)</span></span>
<span id="cb8-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'with_router'</span>: {</span>
<span id="cb8-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'simple_cost'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70000</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.001</span>,   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># BERT 자체 호스팅: $70</span></span>
<span id="cb8-13">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'medium_cost'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20000</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>,    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># T5 자체 호스팅: $200  </span></span>
<span id="cb8-14">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'complex_cost'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.03</span>,   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPT-4 API: $300</span></span>
<span id="cb8-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'router_cost'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100000</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0005</span>, <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># DistilBERT: $50</span></span>
<span id="cb8-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'total'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">620</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 80% 비용 절약!</span></span>
<span id="cb8-17">    }</span>
<span id="cb8-18">}</span>
<span id="cb8-19"></span>
<span id="cb8-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 성능 vs 비용 트레이드오프</span></span>
<span id="cb8-21">performance_metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb8-22">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'accuracy'</span>: {</span>
<span id="cb8-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'all_gpt4'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>,        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모든 요청 고품질</span></span>
<span id="cb8-24">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'with_router'</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.92</span>      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 라우팅 오류로 약간 감소</span></span>
<span id="cb8-25">    },</span>
<span id="cb8-26">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latency'</span>: {</span>
<span id="cb8-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'all_gpt4'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'800ms'</span>,     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모든 요청이 느림</span></span>
<span id="cb8-28">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'with_router'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'200ms'</span>   <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 70%는 빠른 응답</span></span>
<span id="cb8-29">    },</span>
<span id="cb8-30">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cost_per_query'</span>: {</span>
<span id="cb8-31">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'all_gpt4'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0.03'</span>,</span>
<span id="cb8-32">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'with_router'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$0.006'</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5배 저렴</span></span>
<span id="cb8-33">    }</span>
<span id="cb8-34">}</span></code></pre></div>
</section>
<section id="api를-활용한-데이터-생성-전략" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="api를-활용한-데이터-생성-전략"><span class="header-section-number">3.3.2</span> API를 활용한 데이터 생성 전략</h3>
<p><strong>ChatGPT API로 학습 데이터 생성하기</strong>:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. 고품질 데이터 생성 (일회성 비용)</span></span>
<span id="cb9-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> generate_training_data():</span>
<span id="cb9-3">    prompts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb9-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"고객 불만사항 100개를 생성해줘. 다양한 톤과 상황을 포함해서."</span>,</span>
<span id="cb9-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"제품 문의사항 50개를 생성해줘. 기술적 질문과 일반적 질문을 섞어서."</span>,</span>
<span id="cb9-6">    ]</span>
<span id="cb9-7">    </span>
<span id="cb9-8">    training_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb9-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> prompt <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> prompts:</span>
<span id="cb9-10">        response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> openai.Completion.create(</span>
<span id="cb9-11">            model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4"</span>,</span>
<span id="cb9-12">            prompt<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>prompt,</span>
<span id="cb9-13">            max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span></span>
<span id="cb9-14">        )</span>
<span id="cb9-15">        training_data.append(response.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].text)</span>
<span id="cb9-16">    </span>
<span id="cb9-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> training_data</span>
<span id="cb9-18"></span>
<span id="cb9-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. 생성된 데이터로 작은 모델 학습</span></span>
<span id="cb9-20"><span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">def</span> train_custom_model(training_data):</span>
<span id="cb9-21">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># BERT나 DistilBERT를 fine-tuning</span></span>
<span id="cb9-22">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModel.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bert-base-multilingual-cased"</span>)</span>
<span id="cb9-23">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... 학습 코드</span></span>
<span id="cb9-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">return</span> model</span></code></pre></div>
<p><strong>이 방식의 장점</strong>: - 초기에만 API 비용 발생 (월 $500-1000) - 이후 자체 모델로 무제한 사용 가능 - 도메인 특화된 고품질 데이터 확보 - 완전한 통제권과 커스터마이징 가능</p>
</section>
<section id="단계별-모델-도입-전략" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="단계별-모델-도입-전략"><span class="header-section-number">3.3.3</span> 단계별 모델 도입 전략</h3>
<p>실무에서는 처음부터 완벽한 시스템을 구축하려 하지 말고, 단계적으로 접근하는 것이 현명하다.</p>
<p><strong>Phase 1: MVP 단계 (Minimum Viable Produc, 최소 기능 제품)</strong></p>
<pre><code>목표: 빠른 검증과 프로토타입, 핵심 기능만 구현
모델: OpenAI API 또는 Hugging Face 사전 학습 모델
특징: 완벽함보다는 속도, 시장 반응 테스트가 우선
전략: 일단 돌아가는 것을 만든 후 사용자 피드백 수집
기간: 1-2개월
예산: $1,000-5,000

MVP 예시:
- 고객 문의 자동 분류: OpenAI API로 빠른 프로토타입
- 기본 챗봇: Hugging Face ChatBot 모델 + 간단한 인터페이스
- 문서 요약 도구: GPT-3.5 API + 웹 인터페이스</code></pre>
<p><strong>Phase 2: 확장 단계 (Product-Market Fit 달성 후)</strong></p>
<pre><code>목표: 비용 최적화와 성능 개선
모델: 자체 학습한 BERT/T5 + API 하이브리드
특징: 사용량 증가에 따른 비용 압박, 성능 요구사항 명확화
전략: 대부분은 자체 모델, 복잡한 것만 API 활용
기간: 3-6개월  
예산: $5,000-20,000

확장 단계 예시:
- 80% 질문은 자체 BERT 모델로 처리
- 20% 복잡한 질문만 GPT-4 API 사용
- 도메인 특화 데이터로 모델 fine-tuning</code></pre>
<p><strong>Phase 3: 성숙 단계 (스케일업)</strong></p>
<pre><code>목표: 완전한 커스터마이징과 독립성
모델: 도메인 특화 대규모 모델 + 자체 인프라
특징: 대규모 사용자, 차별화된 서비스 필요
전략: 핵심 기술의 내재화, 경쟁 우위 확보
기간: 6개월+
예산: $50,000+

성숙 단계 예시:
- 자체 개발한 도메인 특화 LLM
- 전용 GPU 클러스터 운영
- A/B 테스트 기반 지속적 모델 개선</code></pre>
</section>
</section>
<section id="의사결정-프레임워크" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="의사결정-프레임워크"><span class="header-section-number">3.4</span> 의사결정 프레임워크</h2>
<section id="모델-선택-체크리스트" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="모델-선택-체크리스트"><span class="header-section-number">3.4.1</span> 모델 선택 체크리스트</h3>
<p><strong>1. 기술적 요구사항</strong> - [ ] 정확도 임계값: 90%? 95%? 99%? - [ ] 응답 속도: 실시간(&lt;100ms)? 준실시간(&lt;1s)? 배치? - [ ] 동시 사용자 수: 10명? 1,000명? 10,000명? - [ ] 데이터 민감도: 공개 가능? 제한적? 극비?</p>
<p><strong>2. 비즈니스 제약사항</strong> - [ ] 월 예산: $100? $1,000? $10,000? - [ ] 개발 기간: 1주? 1개월? 6개월? - [ ] 팀 역량: 연구원 있음? 엔지니어만? 외주? - [ ] 인프라: 클라우드? 온프레미스? 하이브리드?</p>
<p><strong>3. 전략적 고려사항</strong> - [ ] 확장성: 현재만? 향후 10배 성장? - [ ] 차별화: 경쟁사 대비 핵심 요소? - [ ] 종속성: 외부 의존 허용? 독립성 필요? - [ ] 유지보수: 지속적 개선? 일회성 구축?</p>
</section>
<section id="실무진을-위한-가이드라인" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="실무진을-위한-가이드라인"><span class="header-section-number">3.4.2</span> 실무진을 위한 가이드라인</h3>
<p><strong>“이럴 때는 이 모델을”</strong></p>
<pre><code>📱 모바일 앱의 실시간 챗봇 (단순)
→ DistilBERT + 사전 정의된 답변 세트
이유: 빠른 응답, 낮은 배터리 소모, 오프라인 가능

🏪 이커머스 상품 검색 (단순)
→ BERT + Elasticsearch
이유: 정확한 의미 검색, 확장성, 비용 효율성

📋 고객 지원 티켓 분류 (단순→복잡)
→ BERT → 복잡한 경우만 GPT-4 API
이유: 대부분은 단순 분류, 어려운 케이스만 고급 모델

📰 뉴스 요약 서비스 (중간)
→ T5 또는 BART
이유: 정형화된 요약 패턴, 일관된 품질, 중간 수준의 이해력

📧 이메일 자동 응답 (중간)
→ T5 + 템플릿 시스템
이유: 기본 구조는 정해져 있고, 내용만 상황에 맞게 생성

🌐 다국어 번역 서비스 (중간)
→ T5 multilingual 또는 mBART
이유: 언어 쌍별 모델보다 효율적, 준수한 품질

✍️ 마케팅 콘텐츠 생성 (복잡)
→ GPT-4 API
이유: 창의성과 품질이 ROI에 직결

🏥 의료 텍스트 분석 (단순)
→ 도메인 특화 BERT (BioBERT)
이유: 전문성, 규제 준수, 설명 가능성

💰 금융 리스크 분석 (단순)
→ 자체 학습 모델 (데이터 보안)
이유: 규제, 보안, 실시간 대량 처리</code></pre>
<p>실무에서는 <strong>기술적 완벽함보다 비즈니스 목표 달성</strong>이 우선이다. 최고의 모델이 아니라 <strong>현재 상황에서 최적인 모델</strong>을 선택하는 것이 성공의 열쇠다.</p>
</section>
</section>
</section>
<section id="결론" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> 결론</h1>
<ul>
<li>PLM 기술의 발전은 놀랍지만, 실무에서는 <strong>기술적 우수성과 현실적 제약 사이의 균형</strong>을 맞추는 것이 핵심이다.</li>
<li>단순한 분류 문제에 수십억 파라미터의 모델을 사용하는 것은 비효율적이다. 반대로 복잡한 추론이 필요한 곳에 작은 모델만 고집하는 것도 기회 손실이다.</li>
<li>중요한 것은 <strong>문제의 본질을 이해하고, 제약 조건을 명확히 하며, 단계적으로 접근하는 것</strong>이다. 오늘은 BERT로 시작해서 내일은 T5로, 필요하다면 GPT-4로 발전시켜 나가는 것이 현실적인 전략이다.</li>
<li>결국 가장 좋은 모델은 <strong>가장 비싼 모델이 아니라, 주어진 상황에서 목표를 가장 효과적으로 달성하는 모델</strong>이다. 기술은 수단이지 목적이 아니라는 점을 항상 기억해</li>
</ul>


</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/26.plm.html</guid>
  <pubDate>Sat, 25 Jan 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>T5: Text-to-Text Transfer Transformer</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/25.plm_T5.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>T5(Text-to-Text Transfer Transformer)는 2019년 Google Research에서 발표한 혁신적인 사전 학습 언어 모델이다. 기존 모델들이 태스크별로 다른 출력 형식을 사용했던 것과 달리, 모든 자연어 처리 태스크를 <strong>텍스트-투-텍스트</strong> 형식으로 통일하여 처리하는 획기적인 프레임워크를 제시했다.</p>
<p>주요 특징과 혁신 사항은 다음과 같다:</p>
<ul>
<li><strong>Text-to-Text 통합 프레임워크</strong>:
<ul>
<li>분류, 회귀, 생성 등 모든 NLP 태스크를 텍스트 생성 문제로 변환</li>
<li>“classify: 이 리뷰는 긍정적입니다” → “positive” 형태로 출력</li>
<li>태스크별 특수 헤드가 불필요한 완전히 통일된 접근법</li>
<li>인덱스 예측 대신 자연어 텍스트 생성을 통한 문제 해결</li>
</ul></li>
<li><strong>Encoder-Decoder 아키텍처</strong>:
<ul>
<li>BERT의 양방향 이해 능력과 GPT의 생성 능력을 결합</li>
<li>원본 Transformer와 동일한 구조로 검증된 안정성</li>
<li>Cross-attention을 통한 효과적인 정보 전달</li>
<li>입력 길이와 출력 길이의 독립적 처리</li>
</ul></li>
<li><strong>혁신적인 사전 학습 방식</strong>:
<ul>
<li><strong>Span Corruption</strong>: 연속된 토큰들을 마스킹하고 복원</li>
<li>다양한 사전 학습 목표의 체계적 비교 연구</li>
<li>C4(Colossal Clean Crawled Corpus) 데이터셋 활용</li>
<li>750GB의 필터링된 고품질 텍스트로 학습</li>
</ul></li>
<li><strong>확장성과 성능</strong>:
<ul>
<li>T5-Small(60M)부터 T5-11B(11B)까지 다양한 크기</li>
<li>GLUE, SuperGLUE에서 SOTA 달성</li>
<li>CNN/DailyMail 요약에서 뛰어난 성능</li>
<li>WMT 번역 태스크에서 경쟁력 있는 결과</li>
</ul></li>
<li><strong>현대 LLM의 설계 철학 확립</strong>:
<ul>
<li>모든 문제를 생성 태스크로 해결하는 접근법</li>
<li>Instruction following의 기초 마련</li>
<li>현재 ChatGPT, GPT-4 등 대화형 AI의 설계 원리</li>
<li>Fine-tuning 시 추가 레이어 불필요</li>
</ul></li>
</ul>
<p>T5는 단순한 성능 향상을 넘어 <strong>모든 NLP 태스크를 통합하는 새로운 패러다임</strong>을 제시했으며, 현재 대규모 언어 모델들의 설계 철학에 결정적 영향을 미쳤다.</p>
</section>
<section id="nlp-모델-발전-과정" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> NLP 모델 발전 과정</h1>
<pre><code>RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa
|   └── ALBERT
|
├── BERT 변형 모델들
|   ├── RoBERTa (Facebook, 2019)
|   ├── ALBERT (Google, 2019)
|   ├── DistilBERT (Hugging Face, 2019)
|   └── ELECTRA (Google, 2020)
|
└── 후속 발전 모델들
    ├── T5, XLNet, DeBERTa
    └── GPT-2/3/4, ChatGPT, PaLM 등</code></pre>
</section>
<section id="t5-이전-모델들의-한계점" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> T5 이전 모델들의 한계점</h1>
<section id="기존-언어-모델의-문제점" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="기존-언어-모델의-문제점"><span class="header-section-number">3.1</span> 기존 언어 모델의 문제점</h2>
<p><strong>태스크별 다른 출력 형식의 혼재</strong>: - 텍스트 분류: 클래스 인덱스 예측 (0, 1, 2…) - 개체명 인식: BIO 태깅 (B-PER, I-LOC, O…) - 질의응답: 시작/끝 위치 예측 (start_idx, end_idx) - 텍스트 생성: 토큰 시퀀스 생성 - 각 태스크마다 다른 출력 헤드와 손실 함수 필요</p>
<p><strong>모델 아키텍처의 태스크별 특화</strong>: - BERT: 분류/이해 태스크에 특화된 encoder-only 구조 - GPT: 생성 태스크에 특화된 decoder-only 구조 - 하나의 모델로 모든 태스크를 효과적으로 처리하기 어려움 - 태스크 전환 시 아키텍처 변경 또는 별도 모델 필요</p>
<p><strong>Fine-tuning의 복잡성</strong>: - 태스크별로 다른 추가 레이어 설계 필요 - 출력 형식에 맞는 특수 헤드(classification head, regression head 등) 구현 - 태스크별 다른 손실 함수와 평가 메트릭 - 모델 개발과 유지보수의 복잡성 증가</p>
<p><strong>통합적 학습의 어려움</strong>: - 여러 태스크를 동시에 학습하기 위한 복잡한 멀티태스크 설정 - 태스크 간 간섭(interference) 문제 - 태스크별 가중치 조정의 어려움 - 새로운 태스크 추가 시 전체 시스템 재설계 필요</p>
<p><strong>자연어 이해와 생성의 분리</strong>: - 이해 모델(BERT)과 생성 모델(GPT)이 별도로 발전 - 통합된 프레임워크의 부재로 인한 효율성 저하 - 인간의 언어 처리와 다른 분절된 접근법</p>
</section>
</section>
<section id="t5-text-to-text-transfer-transformer" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> T5 (Text-to-Text Transfer Transformer)</h1>
<section id="개요와-기본-개념" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="개요와-기본-개념"><span class="header-section-number">4.1</span> 개요와 기본 개념</h2>
<p>T5는 <strong>모든 자연어 처리 태스크를 텍스트-투-텍스트 문제로 통일</strong>한 혁신적인 언어 모델이다. 2019년 Google Research에서 발표된 T5는 “Text-to-Text Transfer Transformer”의 줄임말로, 입력과 출력 모두 텍스트 형태로 처리하는 완전히 새로운 패러다임을 제시했다.</p>
<section id="핵심-아이디어" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="핵심-아이디어"><span class="header-section-number">4.1.1</span> 핵심 아이디어</h3>
<ul>
<li><strong>통일된 프레임워크</strong>: 모든 NLP 태스크를 “텍스트 입력 → 텍스트 출력” 형태로 변환</li>
<li><strong>자연어 기반 출력</strong>: 숫자나 인덱스 대신 자연어 텍스트로 답변 생성</li>
<li><strong>태스크 무관한 아키텍처</strong>: 하나의 모델 구조로 모든 문제 해결</li>
<li><strong>인간친화적 접근</strong>: 인간이 이해하기 쉬운 형태의 입출력</li>
</ul>
</section>
</section>
<section id="text-to-text-프레임워크" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="text-to-text-프레임워크"><span class="header-section-number">4.2</span> Text-to-Text 프레임워크</h2>
<section id="기본-원리" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="기본-원리"><span class="header-section-number">4.2.1</span> 기본 원리</h3>
<p><strong>“모든 텍스트 처리 문제를 텍스트 생성 문제로 변환”</strong></p>
<pre><code>기존 방식: 입력 텍스트 → 특수 출력 (클래스 ID, 확률, 위치 등)
T5 방식: 입력 텍스트 → 출력 텍스트</code></pre>
</section>
<section id="태스크별-변환-예시" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="태스크별-변환-예시"><span class="header-section-number">4.2.2</span> 태스크별 변환 예시</h3>
<p><strong>1. 텍스트 분류</strong></p>
<pre><code>기존: "This movie is great!" → [1] (긍정 클래스)
T5: "sentiment: This movie is great!" → "positive"</code></pre>
<p><strong>2. 번역</strong></p>
<pre><code>기존: "Hello world" → sequence of token IDs
T5: "translate English to German: Hello world" → "Hallo Welt"</code></pre>
<p><strong>3. 질의응답</strong></p>
<pre><code>기존: Question + Context → [start_pos, end_pos]
T5: "question: What is the capital? context: France's capital is Paris" → "Paris"</code></pre>
<p><strong>4. 요약</strong></p>
<pre><code>기존: Long text → Abstract representation → Summary
T5: "summarize: [long article text]" → "Brief summary text"</code></pre>
<p><strong>5. 문법 오류 수정</strong></p>
<pre><code>T5: "grammar: She are going to school" → "She is going to school"</code></pre>
<p><strong>6. 자연어 추론</strong></p>
<pre><code>T5: "nli premise: A man is sleeping hypothesis: A person is resting" → "entailment"</code></pre>
</section>
<section id="prefix-기반-태스크-식별" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="prefix-기반-태스크-식별"><span class="header-section-number">4.2.3</span> Prefix 기반 태스크 식별</h3>
<p><strong>태스크별 접두사(Prefix) 사용</strong>: - <code>translate English to German:</code> - 영독 번역 - <code>summarize:</code> - 텍스트 요약<br>
- <code>question:</code> - 질의응답 - <code>sentiment:</code> - 감정 분석 - <code>cola sentence:</code> - 문법성 판단</p>
<p>이 접두사를 통해 모델이 수행할 태스크를 명확히 지시할 수 있다.</p>
</section>
</section>
<section id="아키텍처-상세" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="아키텍처-상세"><span class="header-section-number">4.3</span> 아키텍처 상세</h2>
<section id="encoder-decoder-구조" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="encoder-decoder-구조"><span class="header-section-number">4.3.1</span> Encoder-Decoder 구조</h3>
<p>T5는 원본 Transformer와 동일한 encoder-decoder 구조를 사용한다.</p>
<pre><code>Input Text (with task prefix)
    ↓
Encoder (Bidirectional Self-Attention)
├── Multi-Head Self-Attention
├── Feed-Forward Network  
└── Layer Normalization
    ↓
Encoder Representations
    ↓
Decoder (Causal Self-Attention + Cross-Attention)
├── Masked Multi-Head Self-Attention
├── Cross-Attention (to Encoder)
├── Feed-Forward Network
└── Layer Normalization
    ↓
Output Text</code></pre>
</section>
<section id="주요-구성-요소" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="주요-구성-요소"><span class="header-section-number">4.3.2</span> 주요 구성 요소</h3>
<p><strong>Encoder</strong>: - 입력 텍스트의 양방향 문맥 이해 - BERT와 유사한 구조로 전체 입력 동시 처리 - Self-attention을 통한 풍부한 표현 학습 - 태스크 prefix를 포함한 전체 입력 인코딩</p>
<p><strong>Decoder</strong>: - 출력 텍스트의 순차적 생성 - GPT와 유사한 causal masking 적용 - Cross-attention으로 encoder 정보 활용 - 자연어 형태의 답변 생성</p>
<p><strong>Position Encoding</strong>: - 상대적 위치 인코딩(Relative Position Encoding) 사용 - 절대 위치 대신 토큰 간 상대적 거리 정보 활용 - 더 긴 시퀀스에 대한 일반화 능력 향상</p>
</section>
</section>
<section id="사전-학습-방법론" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="사전-학습-방법론"><span class="header-section-number">4.4</span> 사전 학습 방법론</h2>
<section id="span-corruption-목표" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="span-corruption-목표"><span class="header-section-number">4.4.1</span> Span Corruption 목표</h3>
<p><strong>기본 개념</strong>: T5의 주요 사전 학습 목표는 “Span Corruption”이다.</p>
<pre><code>원본: "The quick brown fox jumps over the lazy dog"
마스킹: "The quick &lt;X&gt; jumps over &lt;Y&gt; dog"
목표: "&lt;X&gt; brown fox &lt;Y&gt; the lazy"</code></pre>
<p><strong>작동 방식</strong>: 1. <strong>Span 선택</strong>: 연속된 토큰들을 임의로 선택 (평균 3개 토큰) 2. <strong>마스킹</strong>: 선택된 span을 특수 토큰으로 대체 (<code>&lt;X&gt;</code>, <code>&lt;Y&gt;</code>, <code>&lt;Z&gt;</code> 등) 3. <strong>복원</strong>: 디코더가 마스킹된 부분을 순차적으로 생성</p>
<p><strong>BERT MLM과의 차이점</strong>: - BERT: 개별 토큰 마스킹 → 각 위치별 독립 예측 - T5: 연속 span 마스킹 → 순차적 생성으로 복원 - T5가 더 자연스러운 텍스트 생성 능력 학습</p>
</section>
<section id="c4-데이터셋" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="c4-데이터셋"><span class="header-section-number">4.4.2</span> C4 데이터셋</h3>
<p><strong>Colossal Clean Crawled Corpus (C4)</strong>: - Common Crawl에서 추출한 웹 텍스트 - 750GB의 정제된 영어 텍스트 - 품질 필터링과 중복 제거 적용 - 다양한 도메인과 스타일 포함</p>
<p><strong>전처리 과정</strong>: 1. <strong>언어 식별</strong>: 영어 텍스트만 선별 2. <strong>품질 필터링</strong>: 문법적으로 올바른 문장 선택 3. <strong>중복 제거</strong>: 동일하거나 유사한 내용 제거 4. <strong>독성 콘텐츠 제거</strong>: 부적절한 내용 필터링</p>
</section>
<section id="다양한-사전-학습-목표-비교" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="다양한-사전-학습-목표-비교"><span class="header-section-number">4.4.3</span> 다양한 사전 학습 목표 비교</h3>
<p>T5 논문에서는 여러 사전 학습 방식을 체계적으로 비교했다:</p>
<p><strong>1. BERT-style (Mask Language Model)</strong>: - 개별 토큰을 [MASK]로 대체 - 각 위치에서 원래 토큰 예측</p>
<p><strong>2. Prefix LM</strong>: - 문장의 앞부분을 보고 뒷부분 예측 - GPT와 유사한 방식</p>
<p><strong>3. Span Corruption (T5의 선택)</strong>: - 연속된 토큰 span을 마스킹 - 순차적 생성으로 복원</p>
<p><strong>실험 결과</strong>: Span Corruption이 downstream 태스크에서 가장 좋은 성능을 보였다.</p>
</section>
</section>
<section id="모델-크기와-변형" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="모델-크기와-변형"><span class="header-section-number">4.5</span> 모델 크기와 변형</h2>
<section id="t5-모델-크기별-구성" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="t5-모델-크기별-구성"><span class="header-section-number">4.5.1</span> T5 모델 크기별 구성</h3>
<table class="table">
<thead>
<tr class="header">
<th>모델</th>
<th>파라미터</th>
<th>레이어</th>
<th>d_model</th>
<th>d_ff</th>
<th>Heads</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>T5-Small</td>
<td>60M</td>
<td>6</td>
<td>512</td>
<td>2,048</td>
<td>8</td>
</tr>
<tr class="even">
<td>T5-Base</td>
<td>220M</td>
<td>12</td>
<td>768</td>
<td>3,072</td>
<td>12</td>
</tr>
<tr class="odd">
<td>T5-Large</td>
<td>770M</td>
<td>24</td>
<td>1,024</td>
<td>4,096</td>
<td>16</td>
</tr>
<tr class="even">
<td>T5-3B</td>
<td>3B</td>
<td>24</td>
<td>1,024</td>
<td>16,384</td>
<td>32</td>
</tr>
<tr class="odd">
<td>T5-11B</td>
<td>11B</td>
<td>24</td>
<td>1,024</td>
<td>65,536</td>
<td>128</td>
</tr>
</tbody>
</table>
</section>
<section id="scaling-laws-검증" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="scaling-laws-검증"><span class="header-section-number">4.5.2</span> Scaling Laws 검증</h3>
<p>T5는 모델 크기, 데이터 크기, 계산량에 따른 성능 변화를 체계적으로 연구: - 모델이 클수록 거의 모든 태스크에서 성능 향상 - 데이터 양 증가도 지속적인 성능 개선 효과 - 계산 자원 투입 대비 예측 가능한 성능 향상</p>
</section>
</section>
<section id="성능-및-벤치마크" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="성능-및-벤치마크"><span class="header-section-number">4.6</span> 성능 및 벤치마크</h2>
<section id="glue-benchmark" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="glue-benchmark"><span class="header-section-number">4.6.1</span> GLUE Benchmark</h3>
<p><strong>General Language Understanding Evaluation</strong>: - CoLA(문법성): 83.6 (Matthews correlation) - SST-2(감정): 97.5% (accuracy)<br>
- MRPC(패러프레이즈): 93.4% (F1) - QQP(질문 유사성): 89.9% (F1) - MNLI(자연어 추론): 90.6% (accuracy) - QNLI(질의응답): 95.9% (accuracy) - RTE(텍스트 함의): 93.1% (accuracy) - WNLI(대명사 해소): 94.4% (accuracy)</p>
<p><strong>평균 GLUE 점수</strong>: 88.9 (당시 SOTA)</p>
</section>
<section id="superglue-benchmark" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="superglue-benchmark"><span class="header-section-number">4.6.2</span> SuperGLUE Benchmark</h3>
<p>더 어려운 태스크들에서도 우수한 성능: - BoolQ: 87.7% - CB: 96.9%<br>
- COPA: 84.0% - MultiRC: 88.1% - ReCoRD: 94.1% - RTE: 93.1% - WiC: 77.8% - WSC: 95.2%</p>
</section>
<section id="생성-태스크-성능" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="생성-태스크-성능"><span class="header-section-number">4.6.3</span> 생성 태스크 성능</h3>
<p><strong>CNN/DailyMail 요약</strong>: - ROUGE-1: 43.5 - ROUGE-2: 21.0 - ROUGE-L: 40.7</p>
<p><strong>WMT English-German 번역</strong>: - BLEU: 27.5 (당시 경쟁력 있는 수준)</p>
<p><strong>SQuAD 질의응답</strong>: - Exact Match: 85.8% - F1 Score: 90.0%</p>
</section>
</section>
<section id="t5의-혁신과-영향" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="t5의-혁신과-영향"><span class="header-section-number">4.7</span> T5의 혁신과 영향</h2>
<section id="지속적-학습continual-learning-지원" class="level3" data-number="4.7.1">
<h3 data-number="4.7.1" class="anchored" data-anchor-id="지속적-학습continual-learning-지원"><span class="header-section-number">4.7.1</span> 지속적 학습(Continual Learning) 지원</h3>
<p>T5는 새로운 태스크를 추가할 때 기존 지식을 유지하면서 학습할 수 있는 구조를 제공한다: - <strong>태스크 접두사 확장</strong>: 새로운 prefix만 추가하면 새로운 태스크 처리 가능 - <strong>Catastrophic Forgetting 완화</strong>: 통일된 출력 형식으로 태스크 간 간섭 최소화 - <strong>점진적 능력 확장</strong>: 기존 능력을 손상시키지 않고 새로운 능력 획득</p>
</section>
<section id="다국어-확장과-mt5" class="level3" data-number="4.7.2">
<h3 data-number="4.7.2" class="anchored" data-anchor-id="다국어-확장과-mt5"><span class="header-section-number">4.7.2</span> 다국어 확장과 mT5</h3>
<p><strong>Multilingual T5 (mT5)</strong>: - 101개 언어 지원 - 언어 간 지식 전이 효과 확인 - 저자원 언어에서도 우수한 성능 - Cross-lingual 태스크에서 획기적 성과</p>
</section>
<section id="효율성-개선-모델들" class="level3" data-number="4.7.3">
<h3 data-number="4.7.3" class="anchored" data-anchor-id="효율성-개선-모델들"><span class="header-section-number">4.7.3</span> 효율성 개선 모델들</h3>
<p><strong>T5 기반 파생 모델들</strong>: - <strong>UL2</strong>: Unified Language Learner, 다양한 denoising 목표 통합 - <strong>PaLM</strong>: T5의 스케일링 연장선, 540B 파라미터 - <strong>Flan-T5</strong>: Instruction tuning으로 성능 향상 - <strong>T5X</strong>: 더 효율적인 구현과 학습 방법</p>
</section>
</section>
<section id="현대-llm에-미친-영향" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="현대-llm에-미친-영향"><span class="header-section-number">4.8</span> 현대 LLM에 미친 영향</h2>
<section id="instruction-following의-기초" class="level3" data-number="4.8.1">
<h3 data-number="4.8.1" class="anchored" data-anchor-id="instruction-following의-기초"><span class="header-section-number">4.8.1</span> Instruction Following의 기초</h3>
<p>T5의 prefix 기반 태스크 지시는 현재 instruction following의 원형이다:</p>
<pre><code>T5: "translate English to Korean: Hello" → "안녕하세요"
GPT-4: "Translate this to Korean: Hello" → "안녕하세요"</code></pre>
</section>
<section id="통합-모델-아키텍처의-확산" class="level3" data-number="4.8.2">
<h3 data-number="4.8.2" class="anchored" data-anchor-id="통합-모델-아키텍처의-확산"><span class="header-section-number">4.8.2</span> 통합 모델 아키텍처의 확산</h3>
<p><strong>현재 주요 모델들의 T5 영향</strong>: - <strong>ChatGPT/GPT-4</strong>: 모든 태스크를 대화/생성으로 통일 - <strong>PaLM, LaMDA</strong>: T5의 encoder-decoder 구조 활용 - <strong>BART, Pegasus</strong>: Text-to-Text 패러다임 적용 - <strong>UL2</strong>: T5의 denoising 방식 확장</p>
</section>
<section id="멀티모달-ai로의-확장" class="level3" data-number="4.8.3">
<h3 data-number="4.8.3" class="anchored" data-anchor-id="멀티모달-ai로의-확장"><span class="header-section-number">4.8.3</span> 멀티모달 AI로의 확장</h3>
<p>T5의 Text-to-Text 프레임워크는 멀티모달로 자연스럽게 확장:</p>
<pre><code>Vision-Language: 이미지 → 텍스트 설명
Speech-to-Text: 음성 → 텍스트 전사  
Text-to-Code: 자연어 → 프로그래밍 코드</code></pre>
</section>
</section>
</section>
<section id="결론" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> 결론</h1>
<p>T5는 자연어 처리 분야에서 <strong>패러다임 통합</strong>을 이뤄낸 혁신적인 모델로, 2019년 발표 이후 NLP 연구와 산업 응용의 방향을 근본적으로 바꿨다.</p>
<section id="t5의-핵심-기여" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="t5의-핵심-기여"><span class="header-section-number">5.1</span> T5의 핵심 기여</h2>
<p><strong>프레임워크 통합</strong>: - 모든 NLP 태스크를 하나의 일관된 Text-to-Text 형태로 통일 - 태스크별 특수 아키텍처의 필요성을 제거하고 범용성 확보 - 인간이 이해하기 쉬운 자연어 입출력으로 해석 가능성 향상</p>
<p><strong>아키텍처 검증</strong>: - Encoder-Decoder 구조의 효과성을 대규모로 검증 - Span Corruption을 통한 효율적인 사전 학습 방법 제시 - 모델 크기와 성능 간 예측 가능한 관계(Scaling Laws) 확립</p>
<p><strong>실용적 혁신</strong>: - Fine-tuning 시 추가 레이어가 불필요한 완전 통합 모델 - 새로운 태스크 추가 시 prefix만 변경하면 되는 확장성 - 다국어, 멀티모달로의 자연스러운 확장 가능성</p>
</section>
<section id="후속-발전에-미친-영향" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="후속-발전에-미친-영향"><span class="header-section-number">5.2</span> 후속 발전에 미친 영향</h2>
<p>T5의 등장은 <strong>“생성으로 모든 것을 해결한다”</strong>는 새로운 AI 패러다임의 출발점이었다.</p>
<p><strong>직접적 영향</strong>: - mT5, UL2, Flan-T5 등 직접적 개선 모델들 - BART, Pegasus 등 동시대 모델들의 설계 방향 제시 - Instruction tuning 연구의 기초 프레임워크 제공</p>
<p><strong>간접적 영향</strong>: - <strong>ChatGPT/GPT-4</strong>: 모든 태스크를 대화 생성으로 통일하는 접근법 - <strong>Large Language Models</strong>: 모든 문제를 텍스트 생성으로 해결하는 철학 - <strong>Multimodal AI</strong>: Vision-Language, Speech-Text 등 다양한 모달리티 통합</p>
<p><strong>산업적 응용</strong>: - 구글 검색, 번역, Gmail 스마트 컴포즈 등에 T5 기술 활용 - Hugging Face 등 오픈소스 생태계의 핵심 모델 - 다양한 도메인별 특화 모델의 기반 아키텍처</p>
</section>
<section id="현재적-의미와-미래-전망" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="현재적-의미와-미래-전망"><span class="header-section-number">5.3</span> 현재적 의미와 미래 전망</h2>
<p>T5는 단순한 성능 향상을 넘어 <strong>AI가 문제를 해결하는 방식의 근본적 변화</strong>를 제시했다.</p>
<p><strong>현재 상황</strong>: - 현재 대부분의 대규모 언어 모델이 T5의 설계 철학을 따름 - 모든 AI 태스크를 생성 문제로 변환하는 접근법이 표준이 됨 - Instruction following, Few-shot learning의 기초 프레임워크 역할</p>
<p><strong>미래 전망</strong>: - <strong>Unified AI Systems</strong>: 언어, 시각, 음성을 통합하는 멀티모달 AI의 기초 - <strong>Personalized AI</strong>: 개인별 맞춤형 AI 어시스턴트의 핵심 아키텍처 - <strong>Domain-Specific AI</strong>: 의료, 법률, 과학 등 전문 분야 AI의 기반 모델 - <strong>Interactive AI</strong>: 실시간 대화와 협업이 가능한 AI 시스템</p>
<p><strong>장기적 영향</strong>: T5가 제시한 “모든 문제를 텍스트 생성으로 해결”하는 패러다임은 AGI(Artificial General Intelligence) 구현의 중요한 단계로 평가된다. 인간의 언어 사용 방식을 모방하여 다양한 문제를 일관된 방식으로 해결하는 접근법은 더욱 인간다운 AI 시스템 구축의 기초가 되고 있다.</p>
<p>T5의 등장은 자연어 처리를 넘어 <strong>인공지능 전반의 설계 철학을 바꾼 역사적 전환점</strong>이었으며, 현재 우리가 경험하고 있는 생성형 AI 혁명의 이론적 토대를 마련했다.</p>


</section>
</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/25.plm_T5.html</guid>
  <pubDate>Fri, 24 Jan 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>BART: Bidirectional and Auto-Regressive Transformers</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/24.plm_BART.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>BART(Bidirectional and Auto-Regressive Transformers)는 2019년 Facebook AI Research에서 발표한 혁신적인 사전 학습 언어 모델이다. 기존 BERT의 이해 능력과 GPT의 생성 능력을 하나의 모델에서 통합한 encoder-decoder 구조를 통해 자연어 이해(NLU)와 자연어 생성(NLG) 모두에서 탁월한 성능을 보여준다.</p>
<p>주요 특징과 혁신 사항은 다음과 같다:</p>
<ul>
<li><strong>Encoder-Decoder 통합 구조</strong>:
<ul>
<li>BERT 스타일의 bidirectional encoder로 입력 텍스트의 풍부한 표현 학습</li>
<li>GPT 스타일의 autoregressive decoder로 순차적 텍스트 생성</li>
<li>양방향 이해와 일방향 생성의 최적 결합</li>
<li>Cross-attention을 통한 encoder-decoder 간 정보 전달</li>
</ul></li>
<li><strong>다양한 노이즈 함수를 활용한 사전 학습</strong>:
<ul>
<li><strong>Denoising Autoencoder</strong>: 손상된 텍스트를 원본으로 복원하는 방식으로 학습</li>
<li><strong>Token Masking</strong>: BERT와 유사하지만 더 다양한 마스킹 패턴 적용</li>
<li><strong>Token Deletion</strong>: 임의 토큰 삭제 후 복원</li>
<li><strong>Text Infilling</strong>: 연속된 토큰 스팬을 하나의 마스크로 대체</li>
<li><strong>Sentence Permutation</strong>: 문장 순서 무작위 셔플 후 원래 순서 복원</li>
<li><strong>Document Rotation</strong>: 문서의 시작점을 임의로 회전시킨 후 복원</li>
</ul></li>
<li><strong>범용적 생성 능력</strong>:
<ul>
<li>텍스트 요약, 기계번역, 질의응답, 대화 생성 등 다양한 생성 태스크에 적용</li>
<li>Fine-tuning을 통한 태스크별 최적화</li>
<li>긴 텍스트 생성에서의 일관성과 품질 향상</li>
</ul></li>
<li><strong>성능과 효율성</strong>:
<ul>
<li>BART-Base: 140M 파라미터, BART-Large: 400M 파라미터</li>
<li>CNN/DailyMail 요약 태스크에서 SOTA 달성</li>
<li>WMT 기계번역에서 경쟁력 있는 성능</li>
<li>ConvAI2 대화 생성에서 뛰어난 성능</li>
</ul></li>
</ul>
<p>BART는 단일 모델로 이해와 생성을 모두 잘 수행할 수 있는 가능성을 보여주었으며, 이후 T5, PEGASUS 등 encoder-decoder 기반 모델들의 발전에 중요한 영향을 미쳤다.</p>
</section>
<section id="nlp-모델-발전-과정" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> NLP 모델 발전 과정</h1>
<pre><code>RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa
|   └── ALBERT
|
├── BERT 변형 모델들
|   ├── RoBERTa (Facebook, 2019)
|   ├── ALBERT (Google, 2019)
|   ├── DistilBERT (Hugging Face, 2019)
|   └── ELECTRA (Google, 2020)
|
└── 후속 발전 모델들
    ├── T5, XLNet, DeBERTa
    └── GPT-2/3/4, ChatGPT, PaLM 등</code></pre>
</section>
<section id="bart-이전-모델들의-한계점" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> BART 이전 모델들의 한계점</h1>
<section id="기존-언어-모델의-문제점" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="기존-언어-모델의-문제점"><span class="header-section-number">3.1</span> 기존 언어 모델의 문제점</h2>
<p><strong>BERT의 한계</strong>: - Encoder-only 구조로 인한 생성 능력 부족 - Masked Language Model은 이해에는 강하지만 자연스러운 텍스트 생성에는 부적합 - 순차적 디코딩이 불가능하여 autoregressive 생성 태스크에 활용 어려움 - 긴 텍스트 생성 시 일관성과 품질 저하</p>
<p><strong>GPT의 한계</strong>: - Decoder-only 구조로 인한 양방향 문맥 이해 부족 - Causal masking으로 인해 미래 정보 활용 불가 - 이해 태스크에서 BERT 대비 상대적으로 낮은 성능 - 입력 문맥의 전체적 이해보다 순차적 예측에 집중</p>
<p><strong>Seq2Seq 모델의 한계</strong>: - 사전 학습 없이 태스크별 학습으로 인한 데이터 효율성 문제 - 작은 규모의 모델로 인한 표현력 한계 - Transfer learning의 혜택을 충분히 활용하지 못함 - 복잡한 언어 패턴 학습의 어려움</p>
<p><strong>통합적 접근의 필요성</strong>: - NLU와 NLG를 모두 잘 수행하는 단일 모델의 부재 - 이해와 생성 태스크를 위해 별도 모델 필요 - 효율적인 전이 학습을 위한 범용적 사전 학습 방법 부족</p>
</section>
</section>
<section id="bart-bidirectional-and-auto-regressive-transformers" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> BART (Bidirectional and Auto-Regressive Transformers)</h1>
<section id="개요와-기본-개념" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="개요와-기본-개념"><span class="header-section-number">4.1</span> 개요와 기본 개념</h2>
<ul>
<li>BART는 <strong>양방향 인코더와 자기회귀 디코더를 결합한 혁신적인 언어 모델</strong></li>
<li>2019년 Facebook AI Research에서 발표되었다.</li>
<li>기존 BERT의 강력한 이해 능력과 GPT의 뛰어난 생성 능력을 하나의 모델에서 통합</li>
<li>자연어 이해(NLU)와 자연어 생성(NLG) 모두에서 탁월한 성능을 보여준다.</li>
<li>모델 크기는 BART-Base (140M), BART-Large (400M) 두 가지가 있다.</li>
</ul>
<section id="핵심-아이디어" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="핵심-아이디어"><span class="header-section-number">4.1.1</span> 핵심 아이디어</h3>
<ul>
<li><strong>최고의 결합</strong>: BERT의 bidirectional encoder + GPT의 autoregressive decoder</li>
<li><strong>Denoising 사전 학습</strong>: 다양한 노이즈로 손상된 텍스트를 원본으로 복원하며 학습</li>
<li><strong>범용성</strong>: 하나의 모델로 분류, 생성, 번역, 요약 등 다양한 태스크 수행</li>
<li><strong>효율성</strong>: Encoder-decoder 구조의 장점을 최대한 활용</li>
</ul>
</section>
</section>
<section id="아키텍처-상세" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="아키텍처-상세"><span class="header-section-number">4.2</span> 아키텍처 상세</h2>
<section id="encoder-decoder-구조" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="encoder-decoder-구조"><span class="header-section-number">4.2.1</span> Encoder-Decoder 구조</h3>
<pre><code>입력 텍스트 (노이즈 추가)
    ↓
BERT-style Bidirectional Encoder
├── Multi-Head Self-Attention (양방향)
├── Feed-Forward Network
└── Layer Normalization
    ↓
Encoder 표현 (풍부한 문맥 정보)
    ↓
GPT-style Autoregressive Decoder
├── Masked Multi-Head Self-Attention (인과적)
├── Cross-Attention (Encoder 참조)
├── Feed-Forward Network
└── Layer Normalization
    ↓
복원된 원본 텍스트</code></pre>
</section>
<section id="핵심-구성-요소" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="핵심-구성-요소"><span class="header-section-number">4.2.2</span> 핵심 구성 요소</h3>
<p><strong>Bidirectional Encoder</strong>: - BERT와 동일한 구조로 양방향 문맥 처리 - 입력 시퀀스의 모든 위치를 동시에 참조 - 풍부한 표현 학습으로 깊은 이해 능력 제공 - 손상된 입력에서도 robust한 표현 추출</p>
<p><strong>Autoregressive Decoder</strong>: - GPT와 유사한 구조로 순차적 생성 - 이전 생성 토큰들만 참조하는 causal masking - Cross-attention을 통해 encoder 정보 활용 - 자연스럽고 일관성 있는 텍스트 생성</p>
<p><strong>Cross-Attention 메커니즘</strong>: - Decoder의 각 층에서 encoder 출력 참조 - Query는 decoder, Key와 Value는 encoder에서 생성 - 입력 문맥 정보를 생성 과정에 효과적으로 반영 - Attention visualization으로 해석 가능성 제공</p>
</section>
</section>
<section id="사전-학습-방법론" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="사전-학습-방법론"><span class="header-section-number">4.3</span> 사전 학습 방법론</h2>
<section id="denoising-autoencoder-패러다임" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="denoising-autoencoder-패러다임"><span class="header-section-number">4.3.1</span> Denoising Autoencoder 패러다임</h3>
<p><strong>기본 원리</strong>: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BBART%7D(%5Ctext%7Bcorrupt%7D(x))%20=%20x"></p>
<ul>
<li>원본 텍스트 x에 다양한 노이즈 함수 적용</li>
<li>손상된 입력에서 원본 복원을 학습 목표로 설정</li>
<li>모델이 언어의 구조와 의미를 깊이 이해하도록 유도</li>
<li>다양한 downstream 태스크에 효과적으로 전이</li>
</ul>
</section>
<section id="다양한-노이즈-함수" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="다양한-노이즈-함수"><span class="header-section-number">4.3.2</span> 다양한 노이즈 함수</h3>
<p><strong>1. Token Masking</strong></p>
<pre><code>원본: "The quick brown fox jumps over the lazy dog"
마스킹: "The quick [MASK] fox jumps [MASK] the lazy dog"</code></pre>
<ul>
<li>BERT의 MLM과 유사하지만 더 유연한 패턴</li>
<li>임의의 토큰을 [MASK]로 대체</li>
<li>문맥을 통한 단어 의미 추론 능력 학습</li>
</ul>
<p><strong>2. Token Deletion</strong></p>
<pre><code>원본: "The quick brown fox jumps over the lazy dog"
삭제: "The brown fox jumps the lazy dog"</code></pre>
<ul>
<li>임의의 토큰들을 완전히 제거</li>
<li>모델이 누락된 정보를 추론하여 복원</li>
<li>압축된 정보에서 전체 의미 재구성 능력 향상</li>
</ul>
<p><strong>3. Text Infilling</strong></p>
<pre><code>원본: "The quick brown fox jumps over the lazy dog"
Infilling: "The quick [MASK] jumps over [MASK] dog"</code></pre>
<ul>
<li>연속된 토큰 스팬을 하나의 [MASK]로 대체</li>
<li>다양한 길이의 스팬을 무작위로 선택</li>
<li>긴 구문의 의미와 구조 학습에 효과적</li>
</ul>
<p><strong>4. Sentence Permutation</strong></p>
<pre><code>원본: "First sentence. Second sentence. Third sentence."
셔플: "Third sentence. First sentence. Second sentence."</code></pre>
<ul>
<li>문장 순서를 무작위로 섞은 후 원래 순서 복원</li>
<li>문서 구조와 논리적 흐름 이해 능력 향상</li>
<li>긴 텍스트의 일관성 유지 학습</li>
</ul>
<p><strong>5. Document Rotation</strong></p>
<pre><code>원본: "A B C D E F G H"
회전: "D E F G H A B C" (토큰 D부터 시작)</code></pre>
<ul>
<li>문서의 시작점을 임의로 설정한 후 원래 시작점 찾기</li>
<li>문서 전체의 구조적 이해 능력 향상</li>
<li>시작과 끝의 구분 없이 전체 맥락 파악</li>
</ul>
</section>
<section id="노이즈-함수-조합-및-효과" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="노이즈-함수-조합-및-효과"><span class="header-section-number">4.3.3</span> 노이즈 함수 조합 및 효과</h3>
<p><strong>Text Infilling + Sentence Permutation (최적 조합)</strong>: - BART에서 가장 효과적인 것으로 확인된 조합 - Text infilling: 지역적 언어 이해 능력 - Sentence permutation: 전역적 문서 구조 이해 - 두 방식의 시너지로 최고 성능 달성</p>
<p><strong>다른 조합들과의 비교</strong>: - Token masking only: BERT와 유사한 성능 - Token deletion only: 정보 손실로 인한 성능 저하 - 모든 노이즈 함수 조합: 과도한 복잡성으로 최적화 어려움</p>
</section>
</section>
<section id="학습-과정" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="학습-과정"><span class="header-section-number">4.4</span> 학습 과정</h2>
<section id="사전-학습-세부사항" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="사전-학습-세부사항"><span class="header-section-number">4.4.1</span> 사전 학습 세부사항</h3>
<p><strong>데이터셋</strong>: - 16GB의 diverse text corpus 사용 - Book corpus, English Wikipedia, CC-News, OpenWebText - 도메인 다양성을 통한 robust한 표현 학습</p>
<p><strong>학습 설정</strong>: - 모델 크기: BART-Base (140M), BART-Large (400M) - Batch size: 8,000 sequences - Learning rate: 3e-4 (Adam optimizer) - 500,000 스텝 학습 (약 250 epochs)</p>
<p><strong>토큰화</strong>: - GPT-2 스타일의 BPE (Byte Pair Encoding) - 50,265개의 vocabulary - Subword 단위로 효율적 처리</p>
</section>
<section id="fine-tuning-전략" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="fine-tuning-전략"><span class="header-section-number">4.4.2</span> Fine-tuning 전략</h3>
<p><strong>Generation Tasks</strong>: - 전체 encoder-decoder 구조 그대로 사용 - Task-specific 출력 형식에 맞게 조정 - 요약, 번역, 질의응답 등에 직접 적용</p>
<p><strong>Classification Tasks</strong>: - Encoder 출력을 classification head에 연결 - [CLS] 토큰 또는 전체 시퀀스 평균 사용 - BERT와 유사한 방식으로 fine-tuning</p>
</section>
</section>
<section id="주요-특징과-혁신" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="주요-특징과-혁신"><span class="header-section-number">4.5</span> 주요 특징과 혁신</h2>
<section id="양방향-이해-순차적-생성" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="양방향-이해-순차적-생성"><span class="header-section-number">4.5.1</span> 1. 양방향 이해 + 순차적 생성</h3>
<p><strong>Encoder의 양방향 처리</strong>: - 입력의 모든 위치를 동시에 참조 - 문맥의 완전한 이해를 통한 rich representation - BERT 수준의 깊은 언어 이해 능력</p>
<p><strong>Decoder의 순차적 생성</strong>: - 이전 토큰들만 참조하는 autoregressive 생성 - 자연스럽고 일관성 있는 출력 생성 - GPT 수준의 유창한 텍스트 생성 능력</p>
</section>
<section id="유연한-입력-출력-매핑" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="유연한-입력-출력-매핑"><span class="header-section-number">4.5.2</span> 2. 유연한 입력-출력 매핑</h3>
<p><strong>다양한 태스크 형태</strong>: - Sequence-to-Sequence: 번역, 요약, 질의응답 - Sequence-to-Label: 분류, 개체명 인식 - Conditional Generation: 조건부 텍스트 생성</p>
<p><strong>길이 변화 처리</strong>: - 입력보다 짧은 출력: 요약, 압축 - 입력보다 긴 출력: 확장, 상세화 - 동일 길이 출력: 번역, 패러프레이징</p>
</section>
<section id="robust한-표현-학습" class="level3" data-number="4.5.3">
<h3 data-number="4.5.3" class="anchored" data-anchor-id="robust한-표현-학습"><span class="header-section-number">4.5.3</span> 3. Robust한 표현 학습</h3>
<p><strong>노이즈에 강한 인코딩</strong>: - 다양한 노이즈 함수로 훈련되어 robust함 - 불완전한 입력에서도 의미 추출 가능 - 실제 사용 환경의 noisy input에 효과적</p>
<p><strong>Transfer Learning 효과</strong>: - 사전 학습의 풍부한 언어 지식 활용 - 적은 양의 태스크별 데이터로도 high performance - Domain adaptation에 효과적</p>
</section>
</section>
<section id="성능-및-벤치마크" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="성능-및-벤치마크"><span class="header-section-number">4.6</span> 성능 및 벤치마크</h2>
<section id="텍스트-요약" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="텍스트-요약"><span class="header-section-number">4.6.1</span> 텍스트 요약</h3>
<p><strong>CNN/DailyMail 데이터셋</strong>: - ROUGE-1: 44.16 (당시 SOTA) - ROUGE-2: 21.28 - ROUGE-L: 40.90 - 기존 모델들 대비 평균 2-3점 향상</p>
<p><strong>XSum 데이터셋</strong>: - ROUGE-1: 45.14 - ROUGE-2: 22.27 - ROUGE-L: 37.25 - Abstractive summarization에서 특히 강점</p>
</section>
<section id="기계번역" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="기계번역"><span class="header-section-number">4.6.2</span> 기계번역</h3>
<p><strong>WMT16 English-German</strong>: - BLEU: 35.0 (Transformer baseline 대비 +2.3) - 특히 긴 문장에서 품질 향상 확인 - Encoder-decoder 구조의 장점 활용</p>
<p><strong>WMT16 English-French</strong>: - BLEU: 41.5 - Cross-attention을 통한 정확한 alignment - 문맥 정보 활용도 개선</p>
</section>
<section id="대화-생성" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="대화-생성"><span class="header-section-number">4.6.3</span> 대화 생성</h3>
<p><strong>ConvAI2 데이터셋</strong>: - Perplexity: 16.3 (당시 최고 성능) - F1 score: 20.3 - 일관성 있는 긴 대화 생성 능력</p>
</section>
<section id="독해-및-질의응답" class="level3" data-number="4.6.4">
<h3 data-number="4.6.4" class="anchored" data-anchor-id="독해-및-질의응답"><span class="header-section-number">4.6.4</span> 독해 및 질의응답</h3>
<p><strong>SQuAD 1.1</strong>: - F1: 88.8 - EM: 84.9 - BERT와 경쟁적 성능 달성</p>
<p><strong>SQuAD 2.0</strong>: - F1: 86.1 - EM: 83.2 - 답변 생성의 자연스러움 향상</p>
</section>
</section>
</section>
<section id="결론" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> 결론</h1>
<p>BART는 자연어 처리 분야에서 <strong>이해와 생성을 통합한 새로운 패러다임</strong>을 제시한 혁신적인 모델이다. 2019년 Facebook AI Research에서 발표된 이후, encoder-decoder 기반 사전 학습 모델의 가능성을 보여주며 NLP 분야에 중요한 영향을 미쳤다.</p>
<section id="bart의-핵심-기여" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="bart의-핵심-기여"><span class="header-section-number">5.1</span> BART의 핵심 기여</h2>
<ul>
<li><p><strong>이해와 생성의 통합</strong>: BERT의 양방향 이해 능력과 GPT의 순차적 생성 능력을 하나의 모델에서 효과적으로 결합하여, 단일 모델로 다양한 NLP 태스크를 해결할 수 있는 가능성을 제시했다.</p></li>
<li><p><strong>혁신적인 사전 학습 방법</strong>: 다양한 노이즈 함수를 활용한 denoising autoencoder 방식으로 언어의 구조와 의미를 깊이 학습하여, 기존 MLM보다 더 robust하고 효과적인 표현을 학습할 수 있음을 보여주었다.</p></li>
<li><p><strong>Encoder-Decoder 사전 학습의 효과성</strong>: Transformer의 전체 encoder-decoder 구조를 사전 학습에 활용하여, sequence-to-sequence 태스크에서 탁월한 성능을 달성할 수 있음을 입증했다.</p></li>
<li><p><strong>유연한 적용성</strong>: 텍스트 요약, 기계번역, 질의응답, 대화 생성 등 다양한 생성 태스크뿐만 아니라 분류 태스크에서도 경쟁력 있는 성능을 보여주었다.</p></li>
</ul>
</section>
<section id="nlp-발전에-미친-영향" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="nlp-발전에-미친-영향"><span class="header-section-number">5.2</span> NLP 발전에 미친 영향</h2>
<p><strong>Encoder-Decoder 모델의 부흥</strong>: BART의 성공은 이후 T5, PEGASUS, mT5 등 다양한 encoder-decoder 기반 사전 학습 모델들의 개발을 촉진했다. 특히 생성 태스크에서 encoder-decoder 구조의 우수성을 입증했다.</p>
<p><strong>사전 학습 방법의 다양화</strong>: 단순한 token masking을 넘어 text infilling, sentence permutation 등 다양한 노이즈 함수를 활용한 사전 학습 방법의 중요성을 보여주었다. 이는 이후 모델들에서 더욱 창의적인 사전 학습 방법들이 개발되는 계기가 되었다.</p>
<p><strong>생성 태스크의 성능 향상</strong>: 텍스트 요약, 기계번역 등 생성 태스크에서 기존 모델들을 크게 앞서는 성능을 보여주어, 실용적인 NLP 응용 분야의 발전을 가속화했다.</p>
<p><strong>통합 모델의 가능성</strong>: 하나의 모델로 이해와 생성을 모두 잘 수행할 수 있다는 가능성을 보여주어, 범용 언어 모델 개발의 방향성을 제시했다.</p>
</section>
<section id="실용적-활용과-파급-효과" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="실용적-활용과-파급-효과"><span class="header-section-number">5.3</span> 실용적 활용과 파급 효과</h2>
<p><strong>산업 응용</strong>: BART는 뉴스 요약, 문서 번역, 챗봇 개발 등 다양한 산업 분야에서 실제로 활용되기 시작했다. 특히 자동 요약 시스템에서는 BART 기반 모델들이 널리 사용되고 있다.</p>
<p><strong>연구 도구</strong>: 연구자들이 다양한 sequence-to-sequence 태스크를 실험할 수 있는 강력한 baseline을 제공하여, NLP 연구의 효율성을 높였다.</p>
<p><strong>오픈 소스 생태계</strong>: Hugging Face Transformers 등을 통해 쉽게 사용할 수 있게 되어, 학계와 산업계 모두에서 광범위하게 활용되고 있다.</p>
</section>
<section id="한계와-개선-영역" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="한계와-개선-영역"><span class="header-section-number">5.4</span> 한계와 개선 영역</h2>
<p><strong>계산 복잡도</strong>: Encoder-decoder 구조로 인해 encoder-only나 decoder-only 모델에 비해 더 많은 계산 자원이 필요하다. 특히 inference 시에 decoder의 순차적 생성으로 인한 속도 제약이 있다.</p>
<p><strong>긴 시퀀스 처리</strong>: Transformer의 quadratic attention complexity로 인해 매우 긴 문서 처리에는 여전히 한계가 있다. 메모리 사용량과 계산 시간이 시퀀스 길이에 따라 급격히 증가한다.</p>
<p><strong>도메인 특화</strong>: 특정 도메인에 특화된 성능을 위해서는 여전히 상당한 양의 domain-specific 데이터와 fine-tuning이 필요하다.</p>
<p><strong>해석 가능성</strong>: 복잡한 encoder-decoder 구조로 인해 모델의 의사결정 과정을 이해하고 해석하기가 어렵다.</p>
</section>
<section id="미래-발전-방향" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="미래-발전-방향"><span class="header-section-number">5.5</span> 미래 발전 방향</h2>
<p><strong>효율성 개선</strong>: Sparse attention, linear attention 등을 활용한 더 효율적인 BART 변형들이 개발될 것이다. 또한 model compression과 knowledge distillation을 통한 경량화 연구도 활발해질 것이다.</p>
<p><strong>다중 모달 확장</strong>: 텍스트뿐만 아니라 이미지, 음성 등 다양한 모달리티를 함께 처리할 수 있는 multimodal BART의 개발이 진행될 것이다.</p>
<p><strong>도메인 특화</strong>: 의료, 법률, 과학 등 특정 도메인에 특화된 BART 모델들이 개발되어 전문 분야에서의 활용도가 높아질 것이다.</p>
<p><strong>Few-shot Learning</strong>: GPT-3와 같이 few-shot learning 능력을 갖춘 대규모 BART 모델들이 개발되어, 적은 데이터로도 새로운 태스크에 적응할 수 있게 될 것이다.</p>
<p><strong>실시간 응용</strong>: 더 빠른 inference를 위한 최적화 기술들이 개발되어, 실시간 번역, 실시간 요약 등의 응용이 가능해질 것이다.</p>
</section>
<section id="역사적-의미와-전망" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="역사적-의미와-전망"><span class="header-section-number">5.6</span> 역사적 의미와 전망</h2>
<p>BART는 NLP 역사에서 <strong>이해와 생성의 통합</strong>이라는 중요한 이정표를 세웠다. BERT가 이해 태스크에서, GPT가 생성 태스크에서 각각 혁신을 가져왔다면, BART는 이 두 능력을 하나의 모델에서 효과적으로 결합할 수 있음을 보여주었다.</p>
<p>이는 현재 우리가 목표로 하는 <strong>범용 인공지능(AGI)</strong>의 관점에서도 중요한 의미를 가진다. 인간이 언어를 이해하고 생성하는 능력을 하나의 통합된 시스템에서 수행하듯이, AI도 이해와 생성을 분리하지 않고 통합적으로 처리할 수 있어야 한다.</p>
<p>앞으로 BART의 핵심 아이디어들은 더욱 발전되어, 인간 수준의 언어 이해와 생성 능력을 갖춘 AI 시스템 개발의 중요한 기초가 될 것이다. 특히 대화형 AI, 창작 보조 도구, 자동 번역 시스템 등에서 BART의 영향은 계속해서 확대될 것으로 예상된다.</p>
<p>BART는 단순한 기술적 개선을 넘어, AI가 언어를 통해 인간과 더욱 자연스럽고 효과적으로 소통할 수 있는 미래를 열어가는 중요한 발걸음이었다.</p>


</section>
</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/24.plm_BART.html</guid>
  <pubDate>Thu, 23 Jan 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>GPT: Generative Pre-trained Transformer</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/23.plm_GPT.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>GPT(Generative Pre-trained Transformer)는 2018년 OpenAI에서 발표한 혁신적인 생성형 사전 학습 언어 모델이다. 기존의 이해 중심 모델들과 달리 텍스트 생성에 특화되어 강력한 언어 생성 능력을 보여주었으며, 현재 ChatGPT로 이어지는 생성형 AI 혁명의 출발점이 되었다.</p>
<p>주요 특징과 혁신 사항은 다음과 같다:</p>
<ul>
<li><strong>생성형 언어 모델링</strong>:
<ul>
<li>Transformer 디코더 구조를 사용하여 순차적 텍스트 생성에 최적화</li>
<li>Causal Self-Attention으로 이전 토큰들만을 참조하는 일방향 처리</li>
<li>Next Token Prediction을 통한 자기회귀적 텍스트 생성</li>
</ul></li>
<li><strong>혁신적인 사전 학습 방식</strong>:
<ul>
<li><strong>Next Token Prediction</strong>: 이전 토큰들을 바탕으로 다음 토큰을 예측하는 단순하면서도 강력한 학습 목표</li>
<li>대규모 텍스트 데이터에서 언어의 패턴과 구조를 학습</li>
<li>문맥을 이해하고 일관성 있는 긴 텍스트 생성 능력 획득</li>
</ul></li>
<li><strong>확장성과 성능 향상</strong>:
<ul>
<li>GPT-1(117M) → GPT-2(1.5B) → GPT-3(175B) → GPT-4(추정 1T+)로 모델 크기 확장</li>
<li>데이터 양과 모델 크기 증가만으로도 성능이 지속적으로 향상됨을 입증</li>
<li>Scaling Laws를 통한 성능 예측 가능성 제시</li>
</ul></li>
<li><strong>In-Context Learning과 Few-Shot 능력</strong>:
<ul>
<li>별도 Fine-tuning 없이도 예시만으로 새로운 태스크 수행</li>
<li>Prompt Engineering을 통한 다양한 응용 가능성</li>
<li>Zero-shot, One-shot, Few-shot Learning의 강력한 성능</li>
</ul></li>
<li><strong>생성형 AI 패러다임 확립</strong>:
<ul>
<li>단순한 분류/이해를 넘어선 창조적 텍스트 생성</li>
<li>ChatGPT, GPT-4 등으로 이어지는 대화형 AI의 기반 마련</li>
<li>코드 생성, 창작, 번역, 요약 등 광범위한 생성 태스크에서 인간 수준 성능</li>
</ul></li>
</ul>
<p>GPT의 등장은 자연어 처리를 이해 중심에서 생성 중심으로 패러다임을 전환시켰으며, 현재 우리가 경험하고 있는 생성형 AI 시대의 기초를 마련했다.</p>
</section>
<section id="nlp-모델-발전-과정" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> NLP 모델 발전 과정</h1>
<pre><code>RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa
|   └── ALBERT
|
├── BERT 변형 모델들
|   ├── RoBERTa (Facebook, 2019)
|   ├── ALBERT (Google, 2019)
|   ├── DistilBERT (Hugging Face, 2019)
|   └── ELECTRA (Google, 2020)
|
└── 후속 발전 모델들
    ├── T5, XLNet, DeBERTa
    └── ChatGPT, PaLM, Claude, Gemini 등</code></pre>
</section>
<section id="gpt-이전-모델들의-한계점" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> GPT 이전 모델들의 한계점</h1>
<section id="기존-언어-모델의-문제점" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="기존-언어-모델의-문제점"><span class="header-section-number">3.1</span> 기존 언어 모델의 문제점</h2>
<ul>
<li><strong>일방향성의 한계</strong>:
<ul>
<li>기존 RNN 기반 언어 모델은 순차적 처리로 인한 병렬화 불가</li>
<li>긴 시퀀스에서의 그래디언트 소실 문제</li>
<li>문맥 정보의 제한적 활용</li>
</ul></li>
<li><strong>제한적인 전이 학습</strong>:
<ul>
<li>태스크별로 별도의 모델 아키텍처 필요</li>
<li>사전 학습된 표현의 활용도 제한</li>
<li>Fine-tuning 과정에서 많은 라벨 데이터 요구</li>
</ul></li>
<li><strong>생성 능력의 부족</strong>:
<ul>
<li>주로 분류나 이해 태스크에 집중</li>
<li>창조적이고 일관성 있는 텍스트 생성의 어려움</li>
<li>다양한 도메인과 스타일에 대한 적응력 부족</li>
</ul></li>
</ul>
</section>
</section>
<section id="gpt-generative-pre-trained-transformer" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> GPT (Generative Pre-trained Transformer)</h1>
<section id="개요와-기본-개념" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="개요와-기본-개념"><span class="header-section-number">4.1</span> 개요와 기본 개념</h2>
<ul>
<li>GPT는 <strong>생성형 사전 학습 트랜스포머</strong>로, 2018년 OpenAI에서 발표한 혁신적인 언어 모델이다.</li>
<li>기존의 이해 중심 모델들과 달리 <strong>텍스트 생성</strong>에 특화되어 설계되었으며, 현재 ChatGPT로까지 이어지는 생성형 AI 혁명의 시발점이 되었다.</li>
</ul>
<section id="핵심-아이디어" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="핵심-아이디어"><span class="header-section-number">4.1.1</span> 핵심 아이디어</h3>
<ul>
<li><strong>단순함의 힘</strong>: Next Token Prediction이라는 단순한 목표로 복잡한 언어 능력 학습</li>
<li><strong>확장성</strong>: 모델 크기와 데이터 양을 늘리는 것만으로도 성능 향상 가능</li>
<li><strong>범용성</strong>: 하나의 모델로 다양한 생성 태스크 수행</li>
</ul>
</section>
</section>
<section id="아키텍처-상세" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="아키텍처-상세"><span class="header-section-number">4.2</span> 아키텍처 상세</h2>
<section id="transformer-디코더-기반-구조" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="transformer-디코더-기반-구조"><span class="header-section-number">4.2.1</span> Transformer 디코더 기반 구조</h3>
<pre><code>입력 토큰들 → 토큰 임베딩 + 위치 임베딩
    ↓
Transformer 디코더 블록 × N
├── Masked Multi-Head Self-Attention
├── Layer Normalization
├── Feed-Forward Network
└── Layer Normalization
    ↓
출력 Linear Layer → 다음 토큰 확률 분포</code></pre>
</section>
<section id="핵심-구성-요소" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="핵심-구성-요소"><span class="header-section-number">4.2.2</span> 핵심 구성 요소</h3>
<ul>
<li><strong>Causal Self-Attention</strong>:
<ul>
<li>이전 위치의 토큰들만 참조 가능 (미래 정보 차단)</li>
<li>순차적 생성 과정에서 정보 누출 방지</li>
<li>문장을 왼쪽부터 오른쪽으로 읽으면서, 현재 단어를 이해할 때 이미 본 단어들만 참고할 수 있다</li>
<li>예: “나는 오늘 학교에 갔다”에서 “학교”를 처리할 때, “나는”, “오늘”만 참고 가능하고 “갔다”는 참고 불가</li>
<li>이렇게 하는 이유는 텍스트 생성 시 다음 단어를 예측해야 하는데, 미래 단어를 미리 알면 부정행위가 되기 때문</li>
<li>Attention score matrix에서 상삼각 부분을 -∞로 마스킹</li>
<li>Softmax 적용 후 미래 위치의 attention weight가 0이 됨</li>
<li>결과적으로 현재 위치 이전의 토큰들만 정보 제공</li>
<li>참고: Self-Attention
<ul>
<li>한 문장 내에서 각 단어가 다른 모든 단어들과 얼마나 관련이 있는지를 계산하는 메커니즘</li>
<li>문장: “그 강아지는 공원에서 뛰어다니며 즐거워했다”</li>
<li>각 단어를 처리할 때:
<ul>
<li>“강아지”를 이해하려면 → “뛰어다니며”, “즐거워했다”와 연결해서 생각</li>
<li>“뛰어다니며”를 이해하려면 → “강아지”, “공원에서”와 연결해서 생각</li>
<li>“즐거워했다”를 이해하려면 → “강아지”와 강하게 연결해서 생각</li>
</ul></li>
<li>핵심: 각 단어가 문장의 다른 모든 단어들을 “쳐다보면서” 관련성을 파악</li>
</ul></li>
</ul></li>
<li><strong>위치 인코딩</strong>:
<ul>
<li>Transformer는 본질적으로 순서를 모르는 구조이므로, 토큰의 위치 정보를 별도로 주입해야 한다.</li>
<li>학습 가능한 절대 위치 임베딩 사용</li>
<li>토큰의 순서 정보를 모델에 제공</li>
<li>단어 카드를 무작위로 섞어놓으면 문장의 의미가 바뀌는 것처럼, AI도 단어의 순서를 알아야 함</li>
<li>“강아지가 고양이를 쫓았다”와 “고양이가 강아지를 쫓았다”는 완전히 다른 의미</li>
<li>각 위치(1번째, 2번째, 3번째…)에 고유한 “위치 ID카드”를 부여하는 개념</li>
<li>학습 가능한 위치 임베딩 사용 (고정된 삼각함수 대신)</li>
<li>각 위치마다 별도의 벡터를 학습하여 토큰 임베딩에 더함</li>
<li>최대 시퀀스 길이까지만 위치 정보 제공 가능</li>
</ul></li>
<li><strong>Layer Normalization</strong>:
<ul>
<li>딥러닝에서 학습을 안정화하고 빠르게 만드는 정규화 기법</li>
<li>각 서브레이어 이후 정규화 적용</li>
<li>요리할 때 재료들의 크기를 비슷하게 맞춰서 골고루 익도록 하는 것과 유사</li>
<li>신경망 각 층에서 데이터의 분포가 너무 치우치거나 분산되지 않도록 조정</li>
<li>마치 각 층마다 “데이터 정리정돈”을 해주는 역할</li>
<li>학습 안정성과 수렴 속도 향상</li>
<li>Pre-LN(Pre Layer Normalization) 구조로 깊은 네트워크 학습 가능
<ul>
<li>각 Transformer 블록 내부의 서브레이어(attention, feedforward) 이후에 적용</li>
<li>Post-LN 구조: 서브레이어 입력 전에 정규화 (원래 Transformer는 Post-LN)</li>
<li>깊은 네트워크에서도 gradient가 잘 전달되어 학습이 안정적</li>
<li>정규화 없이는 깊은 네트워크에서 gradient vanishing/exploding 문제 발생</li>
<li>학습 속도가 빨라지고 더 높은 학습률 사용 가능</li>
<li>각 층의 입력 분포가 안정적이어서 일관된 학습 가능</li>
</ul></li>
</ul></li>
</ul>
</section>
</section>
<section id="학습-방법" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="학습-방법"><span class="header-section-number">4.3</span> 학습 방법</h2>
<section id="사전-학습-pre-training" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="사전-학습-pre-training"><span class="header-section-number">4.3.1</span> 사전 학습 (Pre-training)</h3>
<p><strong>목표</strong>: Next Token Prediction <img src="https://latex.codecogs.com/png.latex?%20P(w_t%20%7C%20w_1,%20w_2,%20...,%20w_%7Bt-1%7D)%20=%20%5Ctext%7Bsoftmax%7D(W_o%20%5Ccdot%20h_t)%20"></p>
<ul>
<li><p><strong>데이터</strong>: 대규모 인터넷 텍스트 (CommonCrawl, WebText, Books, Wikipedia 등)</p></li>
<li><p><strong>손실 함수</strong>: Cross-Entropy Loss <img src="https://latex.codecogs.com/png.latex?%20%5Cmathcal%7BL%7D%20=%20-%5Csum_%7Bt=1%7D%5E%7BT%7D%20%5Clog%20P(w_t%20%7C%20w_1,%20...,%20w_%7Bt-1%7D)%20"></p></li>
<li><p><strong>학습 과정</strong>:</p>
<ol type="1">
<li>입력 시퀀스의 각 위치에서 다음 토큰 예측</li>
<li>실제 토큰과 예측 분포 간의 크로스 엔트로피 최소화</li>
<li>자기회귀적 생성을 통한 언어 패턴 학습</li>
</ol></li>
</ul>
</section>
<section id="fine-tuning" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="fine-tuning"><span class="header-section-number">4.3.2</span> Fine-tuning</h3>
<p><strong>기존 방식</strong>: * 태스크별 특수 토큰 추가 (예: <code>[CLS]</code>, <code>[SEP]</code>) * 출력 레이어만 태스크에 맞게 수정 * 적은 양의 라벨 데이터로 추가 학습</p>
<p><strong>GPT-3 이후</strong>: * <strong>In-Context Learning</strong>: Fine-tuning 없이 예시만으로 태스크 수행 * <strong>Prompt Engineering</strong>: 적절한 프롬프트 설계를 통한 성능 최적화 * <strong>Few-Shot Learning</strong>: 소수 예시로 새로운 태스크 학습</p>
</section>
</section>
<section id="gpt-버전별-발전-과정" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="gpt-버전별-발전-과정"><span class="header-section-number">4.4</span> GPT 버전별 발전 과정</h2>
<section id="gpt-1-2018년-6월" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="gpt-1-2018년-6월"><span class="header-section-number">4.4.1</span> GPT-1 (2018년 6월)</h3>
<ul>
<li><strong>모델 크기</strong>: 117M 파라미터</li>
<li><strong>데이터</strong>: BooksCorpus (7,000권의 책)</li>
<li><strong>혁신 사항</strong>:
<ul>
<li>Transformer 디코더 기반 언어 모델 최초 제안</li>
<li>Unsupervised Pre-training + Supervised Fine-tuning 패러다임 확립</li>
<li>다양한 NLP 태스크에서 기존 모델 대비 성능 향상</li>
</ul></li>
</ul>
</section>
<section id="gpt-2-2019년-2월" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="gpt-2-2019년-2월"><span class="header-section-number">4.4.2</span> GPT-2 (2019년 2월)</h3>
<ul>
<li><strong>모델 크기</strong>: 1.5B 파라미터 (Small: 117M, Medium: 345M, Large: 762M, XL: 1.5B)</li>
<li><strong>데이터</strong>: WebText (800만 개 웹페이지, 40GB)</li>
<li><strong>혁신 사항</strong>:
<ul>
<li>모델 크기 대폭 확장 (10배 증가)</li>
<li>Zero-shot 태스크 수행 능력 확인</li>
<li>고품질 텍스트 생성으로 인한 오남용 우려 (초기 공개 제한)</li>
<li>“더 큰 모델이 더 좋은 성능”이라는 스케일링 법칙 입증</li>
</ul></li>
</ul>
</section>
<section id="gpt-3-2020년-5월" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="gpt-3-2020년-5월"><span class="header-section-number">4.4.3</span> GPT-3 (2020년 5월)</h3>
<ul>
<li><strong>모델 크기</strong>: 175B 파라미터</li>
<li><strong>데이터</strong>: 570GB 텍스트 (CommonCrawl, WebText2, Books1/2, Wikipedia)</li>
<li><strong>혁신 사항</strong>:
<ul>
<li><strong>In-Context Learning</strong>: Fine-tuning 없이 예시만으로 태스크 수행</li>
<li><strong>Few-Shot Learning</strong>: 소수 예시로 새로운 태스크 학습</li>
<li>인간 수준의 텍스트 생성 품질</li>
<li>코딩, 수학, 추론 등 다양한 도메인에서 놀라운 성능</li>
<li>API 형태로 서비스 제공하여 생성형 AI 생태계 구축</li>
</ul></li>
</ul>
</section>
<section id="gpt-4-2023년-3월" class="level3" data-number="4.4.4">
<h3 data-number="4.4.4" class="anchored" data-anchor-id="gpt-4-2023년-3월"><span class="header-section-number">4.4.4</span> GPT-4 (2023년 3월)</h3>
<ul>
<li><strong>모델 크기</strong>: 공개되지 않음 (추정 1T+ 파라미터)</li>
<li><strong>데이터</strong>: 다중 모달 데이터 (텍스트 + 이미지)</li>
<li><strong>혁신 사항</strong>:
<ul>
<li><strong>다중 모달 능력</strong>: 텍스트와 이미지 동시 처리</li>
<li>더욱 향상된 추론 능력과 안전성</li>
<li>긴 컨텍스트 처리 능력 (32K 토큰)</li>
<li>전문 시험에서 인간 수준 또는 그 이상의 성능</li>
</ul></li>
</ul>
</section>
</section>
<section id="gpt의-핵심-혁신" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="gpt의-핵심-혁신"><span class="header-section-number">4.5</span> GPT의 핵심 혁신</h2>
<section id="스케일링-법칙-scaling-laws" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="스케일링-법칙-scaling-laws"><span class="header-section-number">4.5.1</span> 스케일링 법칙 (Scaling Laws)</h3>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BLoss%7D%20%5Cpropto%20N%5E%7B-%5Calpha%7D"></p>
<ul>
<li>모델 크기(N), 데이터 양, 계산량이 증가할수록 성능 향상</li>
<li>예측 가능한 성능 개선 곡선</li>
<li>“더 크면 더 좋다”는 단순하지만 강력한 원리</li>
</ul>
</section>
<section id="창발적-능력-emergent-abilities" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="창발적-능력-emergent-abilities"><span class="header-section-number">4.5.2</span> 창발적 능력 (Emergent Abilities)</h3>
<ul>
<li><strong>특정 임계점</strong>을 넘으면 갑자기 나타나는 새로운 능력들</li>
<li><strong>In-Context Learning</strong>: GPT-3에서 처음 관찰</li>
<li><strong>Chain-of-Thought Reasoning</strong>: 단계별 추론 능력</li>
<li><strong>코드 생성</strong>: 프로그래밍 언어 이해와 생성</li>
</ul>
</section>
<section id="인간-피드백-강화-학습-rlhf" class="level3" data-number="4.5.3">
<h3 data-number="4.5.3" class="anchored" data-anchor-id="인간-피드백-강화-학습-rlhf"><span class="header-section-number">4.5.3</span> 인간 피드백 강화 학습 (RLHF)</h3>
<p><strong>InstructGPT와 ChatGPT에 도입</strong>: 1. <strong>Supervised Fine-tuning</strong>: 고품질 대화 데이터로 학습 2. <strong>Reward Model</strong>: 인간 선호도 기반 보상 모델 학습 3. <strong>PPO</strong>: 보상 모델을 사용한 강화 학습</p>
</section>
<section id="prompt-engineering의-발전" class="level3" data-number="4.5.4">
<h3 data-number="4.5.4" class="anchored" data-anchor-id="prompt-engineering의-발전"><span class="header-section-number">4.5.4</span> Prompt Engineering의 발전</h3>
<ul>
<li><strong>Zero-shot</strong>: 예시 없이 태스크 수행</li>
<li><strong>Few-shot</strong>: 소수 예시로 태스크 학습</li>
<li><strong>Chain-of-Thought</strong>: 단계별 추론 과정 명시</li>
<li><strong>Constitutional AI</strong>: 원칙 기반 행동 유도</li>
</ul>
</section>
</section>
<section id="gpt의-강점과-한계" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="gpt의-강점과-한계"><span class="header-section-number">4.6</span> GPT의 강점과 한계</h2>
<section id="강점" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="강점"><span class="header-section-number">4.6.1</span> 강점</h3>
<ul>
<li><strong>뛰어난 생성 능력</strong>: 일관성 있고 창의적인 텍스트 생성</li>
<li><strong>범용성</strong>: 하나의 모델로 다양한 태스크 수행</li>
<li><strong>적응성</strong>: 프롬프트만으로 새로운 태스크 수행</li>
<li><strong>확장성</strong>: 모델 크기 증가로 성능 향상 가능</li>
</ul>
</section>
<section id="한계" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="한계"><span class="header-section-number">4.6.2</span> 한계</h3>
<ul>
<li><strong>사실성 문제</strong>: 할루시네이션 (거짓 정보 생성)</li>
<li><strong>편향성</strong>: 학습 데이터의 편향 반영</li>
<li><strong>해석 가능성</strong>: 내부 동작 원리의 불투명성</li>
<li><strong>계산 비용</strong>: 대규모 모델의 높은 추론 비용</li>
</ul>
</section>
</section>
<section id="현재적-의미와-영향" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="현재적-의미와-영향"><span class="header-section-number">4.7</span> 현재적 의미와 영향</h2>
<p>GPT는 단순한 기술 발전을 넘어 <strong>인간-AI 상호작용의 패러다임</strong>을 바꾸었다:</p>
<ul>
<li><strong>ChatGPT 현상</strong>: 일반 대중의 AI 접근성 혁신</li>
<li><strong>생성형 AI 생태계</strong>: 수많은 응용 서비스와 스타트업 등장</li>
<li><strong>업무 방식 변화</strong>: 글쓰기, 코딩, 창작 등 지식 작업의 혁신</li>
<li><strong>교육 패러다임 변화</strong>: AI 활용 능력의 중요성 대두</li>
</ul>
</section>
</section>
<section id="결론" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> 결론</h1>
<ul>
<li>GPT는 자연어 처리 분야에서 <strong>생성형 AI 혁명</strong>의 출발점이 된 가장 중요한 혁신 중 하나다.</li>
<li>2018년 첫 발표 이후 현재까지 NLP 연구와 실용 AI의 패러다임을 완전히 바꾸어 놓았다.</li>
</ul>
<section id="gpt의-핵심-기여" class="level3" data-number="5.0.1">
<h3 data-number="5.0.1" class="anchored" data-anchor-id="gpt의-핵심-기여"><span class="header-section-number">5.0.1</span> GPT의 핵심 기여</h3>
<ul>
<li><strong>생성형 언어 모델의 확립</strong>: 이해 중심에서 생성 중심으로 NLP 패러다임 전환, Next Token Prediction이라는 단순한 목표로 복잡한 언어 능력 획득</li>
<li><strong>스케일링 법칙의 입증</strong>: 모델 크기와 데이터 양 증가만으로도 성능이 예측 가능하게 향상됨을 보여주어 대규모 AI 개발의 방향 제시</li>
<li><strong>In-Context Learning의 발견</strong>: Fine-tuning 없이도 예시만으로 새로운 태스크를 수행할 수 있는 혁신적 능력으로 AI 활용 방식을 근본적으로 변화</li>
<li><strong>창발적 능력의 관찰</strong>: 특정 규모를 넘으면 갑자기 나타나는 추론, 코딩, 창작 등의 고차원적 능력으로 AI 발전의 새로운 가능성 제시</li>
</ul>
</section>
<section id="생성형-ai-생태계의-탄생" class="level3" data-number="5.0.2">
<h3 data-number="5.0.2" class="anchored" data-anchor-id="생성형-ai-생태계의-탄생"><span class="header-section-number">5.0.2</span> 생성형 AI 생태계의 탄생</h3>
<p>GPT의 등장은 단순한 기술 발전을 넘어 완전히 새로운 <strong>생성형 AI 생태계</strong>를 만들어냈다:</p>
<ul>
<li><strong>ChatGPT 현상</strong>: 2022년 ChatGPT 출시로 일반 대중이 AI와 자연어로 대화하는 새로운 경험 제공, 전 세계적인 AI 관심과 활용 폭발적 증가</li>
<li><strong>산업 생태계 변화</strong>: 수많은 GPT 기반 서비스와 스타트업 등장, 기존 산업의 디지털 전환 가속화</li>
<li><strong>생산성 혁신</strong>: 글쓰기, 코딩, 번역, 요약 등 지식 작업의 자동화 및 보조 도구로 활용되어 업무 효율성 획기적 향상</li>
<li><strong>창작과 교육 변화</strong>: AI와의 협업을 통한 새로운 창작 방식 등장, 교육 방법과 평가 체계의 근본적 재고</li>
</ul>
</section>
<section id="기술적-영향과-후속-발전" class="level3" data-number="5.0.3">
<h3 data-number="5.0.3" class="anchored" data-anchor-id="기술적-영향과-후속-발전"><span class="header-section-number">5.0.3</span> 기술적 영향과 후속 발전</h3>
<p>GPT가 확립한 기술적 기반은 이후 모든 언어 AI 발전의 토대가 되었다:</p>
<ul>
<li><strong>아키텍처 표준화</strong>: Transformer 디코더 기반 구조가 생성형 언어 모델의 표준이 됨</li>
<li><strong>훈련 방법론</strong>: Next Token Prediction과 RLHF(인간 피드백 강화 학습)가 대화형 AI 개발의 핵심 방법론으로 자리잡음</li>
<li><strong>다중 모달 확장</strong>: GPT-4의 텍스트-이미지 처리 능력을 시작으로 멀티모달 AI 발전의 기반 마련</li>
<li><strong>경쟁 모델들의 등장</strong>: Google의 Gemini, Anthropic의 Claude, Meta의 Llama 등 다양한 대안 모델들의 개발 촉진</li>
</ul>
</section>
<section id="사회적-변화와-도전-과제" class="level3" data-number="5.0.4">
<h3 data-number="5.0.4" class="anchored" data-anchor-id="사회적-변화와-도전-과제"><span class="header-section-number">5.0.4</span> 사회적 변화와 도전 과제</h3>
<p>GPT는 기술적 혁신을 넘어 사회 전반에 깊은 영향을 미치고 있다:</p>
</section>
<section id="긍정적-영향" class="level3" data-number="5.0.5">
<h3 data-number="5.0.5" class="anchored" data-anchor-id="긍정적-영향"><span class="header-section-number">5.0.5</span> 긍정적 영향</h3>
<ul>
<li><strong>접근성 혁신</strong>: 복잡한 기술 지식 없이도 자연어로 AI 활용 가능</li>
<li><strong>창의성 증진</strong>: AI와의 협업을 통한 새로운 아이디어 창출과 표현 방식 확장</li>
<li><strong>교육 개인화</strong>: 맞춤형 학습 지원과 즉시 피드백 제공</li>
<li><strong>언어 장벽 해소</strong>: 실시간 번역과 다국어 소통 지원</li>
</ul>
</section>
<section id="해결-과제" class="level3" data-number="5.0.6">
<h3 data-number="5.0.6" class="anchored" data-anchor-id="해결-과제"><span class="header-section-number">5.0.6</span> 해결 과제</h3>
<ul>
<li><strong>진실성과 신뢰성</strong>: 할루시네이션 문제와 잘못된 정보 생성 위험</li>
<li><strong>윤리적 책임</strong>: AI 생성 콘텐츠의 책임 소재와 저작권 문제</li>
<li><strong>사회적 불평등</strong>: AI 접근성 격차와 일자리 대체 우려</li>
<li><strong>안전성 확보</strong>: 악용 방지와 AI 정렬(Alignment) 문제</li>
</ul>
</section>
<section id="미래-전망과-발전-방향" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="미래-전망과-발전-방향"><span class="header-section-number">5.1</span> 미래 전망과 발전 방향</h2>
<p>GPT가 열어놓은 생성형 AI의 미래는 다음과 같은 방향으로 발전할 것으로 예상된다:</p>
<section id="기술적-발전" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="기술적-발전"><span class="header-section-number">5.1.1</span> 기술적 발전</h3>
<ul>
<li><strong>더 큰 규모</strong>: 수조 파라미터 규모의 모델과 더욱 방대한 학습 데이터</li>
<li><strong>효율성 개선</strong>: 추론 속도 향상과 계산 비용 감소를 위한 최적화 기술</li>
<li><strong>전문화</strong>: 도메인별 특화 모델과 개인화된 AI 어시스턴트</li>
<li><strong>다중 모달</strong>: 텍스트, 이미지, 음성, 비디오를 통합한 범용 AI</li>
</ul>
</section>
<section id="응용-분야-확장" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="응용-분야-확장"><span class="header-section-number">5.1.2</span> 응용 분야 확장</h3>
<ul>
<li><strong>과학 연구</strong>: 논문 작성, 가설 생성, 실험 설계 지원</li>
<li><strong>의료 분야</strong>: 진단 보조, 치료법 연구, 의료 문서 작성</li>
<li><strong>법률 서비스</strong>: 계약서 분석, 판례 검색, 법률 문서 작성</li>
<li><strong>예술과 미디어</strong>: 소설, 시나리오, 음악 창작의 새로운 방법론</li>
</ul>
</section>
</section>
<section id="역사적-의미" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="역사적-의미"><span class="header-section-number">5.2</span> 역사적 의미</h2>
<p>GPT의 등장은 <strong>인공지능 역사의 중요한 전환점</strong>이다. 1950년대 튜링 테스트 제안, 1980년대 신경망 부흥, 2010년대 딥러닝 혁명에 이어, GPT는 <strong>AI가 인간과 자연스럽게 소통할 수 있는 시대</strong>를 열었다.</p>
<p>특히 ChatGPT의 대중적 성공은 AI를 전문가들만의 도구에서 일반인도 일상적으로 사용하는 기술로 바꾸어 놓았다. 이는 개인용 컴퓨터나 인터넷의 등장에 비견될 만한 기술적, 사회적 변화를 의미한다.</p>
<p>GPT로 시작된 생성형 AI 시대는 이제 막 시작되었으며, 향후 인간의 창조적 활동, 학습 방식, 의사소통 패턴까지 근본적으로 변화시킬 것이다. 이러한 변화의 중심에서 GPT는 <strong>AI와 인간이 협력하는 새로운 시대의 출발점</strong>으로 역사에 기록될 것이다.</p>


</section>
</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/23.plm_GPT.html</guid>
  <pubDate>Wed, 22 Jan 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>BERT: Bidirectional Encoder Representations from Transformers</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/22.ptm_BERT.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>BERT(Bidirectional Encoder Representations from Transformers)는 2018년 Google에서 발표한 혁신적인 사전 학습 언어 모델이다. 기존의 일방향 언어 모델들과 달리 양방향 문맥을 동시에 고려하여 깊은 언어 이해 능력을 획득했다.</p>
<p>주요 특징과 혁신 사항은 다음과 같다:</p>
<ul>
<li><strong>양방향 문맥 포착</strong>:
<ul>
<li>기존 GPT, ELMo와 달리 좌우 문맥을 동시에 고려</li>
<li>Transformer 인코더 구조를 사용하여 Self-Attention으로 모든 위치 간 관계 학습</li>
<li>단어의 의미를 문맥에 따라 동적으로 결정</li>
</ul></li>
<li><strong>혁신적인 사전 학습 방식</strong>:
<ul>
<li><strong>Masked Language Model (MLM)</strong>: 입력 토큰의 15%를 마스킹하고 원래 단어 예측</li>
<li><strong>Next Sentence Prediction (NSP)</strong>: 두 문장 간의 연속성 판단</li>
<li>대규모 무라벨 텍스트 데이터로 언어의 일반적 패턴 학습</li>
</ul></li>
<li><strong>Transfer Learning 패러다임 확립</strong>:
<ul>
<li>Pre-training + Fine-tuning 방식으로 다양한 NLP 태스크 해결</li>
<li>태스크별 최소한의 아키텍처 변경만으로 최고 성능 달성</li>
<li>텍스트 분류, 개체명 인식, 질의응답, 감정 분석 등 광범위한 적용</li>
</ul></li>
<li><strong>모델 구조와 성능</strong>:
<ul>
<li>BERT-Base: 12층 Transformer 인코더, 110M 파라미터</li>
<li>BERT-Large: 24층 Transformer 인코더, 340M 파라미터</li>
<li>11개 NLP 태스크에서 기존 최고 성능 대폭 개선</li>
</ul></li>
</ul>
<p>BERT의 등장은 자연어 처리 분야의 패러다임을 바꾸었으며, 이후 RoBERTa, ALBERT, DistilBERT 등 수많은 후속 모델들의 기반이 되었다.</p>
</section>
<section id="nlp-모델-발전-과정" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> NLP 모델 발전 과정</h1>
<pre><code>RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa
|   └── ALBERT
|
├── BERT 변형 모델들
|   ├── RoBERTa (Facebook, 2019)
|   ├── ALBERT (Google, 2019)
|   ├── DistilBERT (Hugging Face, 2019)
|   └── ELECTRA (Google, 2020)
|
└── 후속 발전 모델들
    ├── T5, XLNet, DeBERTa
    └── GPT-2/3/4, ChatGPT, PaLM 등</code></pre>
</section>
<section id="bert-이전-모델들의-한계점" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> BERT 이전 모델들의 한계점</h1>
<section id="기존-언어-모델의-문제점" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="기존-언어-모델의-문제점"><span class="header-section-number">3.1</span> 기존 언어 모델의 문제점</h2>
<section id="일방향성-문제" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="일방향성-문제"><span class="header-section-number">3.1.1</span> 일방향성 문제</h3>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPT-1의 일방향 예측 방식</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"The man went to the [MASK]"</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 오직 "The man went to the" 부분만 보고 다음 단어 예측</span></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 뒤의 문맥 정보 활용 불가</span></span></code></pre></div>
</section>
<section id="elmo의-한계" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="elmo의-한계"><span class="header-section-number">3.1.2</span> ELMo의 한계</h3>
<ul>
<li>BiLSTM을 사용하여 양방향 문맥 고려 시도</li>
<li>하지만 forward LSTM과 backward LSTM이 별도로 학습</li>
<li>진정한 의미의 양방향 문맥 통합 부족</li>
<li>계산 효율성 문제 (순차 처리 필요)</li>
</ul>
</section>
<section id="문맥-독립적-임베딩의-한계" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="문맥-독립적-임베딩의-한계"><span class="header-section-number">3.1.3</span> 문맥 독립적 임베딩의 한계</h3>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Word2Vec, GloVe의 문제점</span></span>
<span id="cb3-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"I went to the bank to deposit money"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 은행</span></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"I sat by the river bank"</span>              <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 강가</span></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 같은 "bank"이지만 다른 의미, 하지만 같은 벡터 표현</span></span></code></pre></div>
</section>
</section>
</section>
<section id="bert의-핵심-아이디어와-혁신" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> BERT의 핵심 아이디어와 혁신</h1>
<section id="양방향-문맥의-진정한-활용" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="양방향-문맥의-진정한-활용"><span class="header-section-number">4.1</span> 양방향 문맥의 진정한 활용</h2>
<ul>
<li>BERT는 Transformer 인코더의 Self-Attention 메커니즘을 활용하여 문장 내 모든 단어가 서로 상호작용할 수 있도록 설계되었다.</li>
</ul>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># BERT의 양방향 문맥 활용 예시</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"The man went to the [MASK] to buy milk"</span></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [MASK] 예측 시 좌측 문맥: "The man went to the"</span></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 우측 문맥: "to buy milk"</span></span>
<span id="cb4-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 양쪽 모든 정보를 동시에 고려하여 "store" 예측</span></span></code></pre></div>
</section>
<section id="masked-language-model-mlm" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="masked-language-model-mlm"><span class="header-section-number">4.2</span> Masked Language Model (MLM)</h2>
<section id="mlm의-동작-원리" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="mlm의-동작-원리"><span class="header-section-number">4.2.1</span> MLM의 동작 원리</h3>
<ul>
<li>입력 토큰의 15%를 랜덤하게 선택하여 마스킹</li>
<li>마스킹된 토큰의 원래 단어를 예측하도록 학습</li>
<li>양방향 문맥을 자연스럽게 활용하는 학습 목표</li>
</ul>
</section>
<section id="마스킹-전략-15-토큰-중" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="마스킹-전략-15-토큰-중"><span class="header-section-number">4.2.2</span> 마스킹 전략 (15% 토큰 중)</h3>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 마스킹 규칙 적용 예시</span></span>
<span id="cb5-2">original_sentence <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The quick brown fox jumps over the lazy dog"</span></span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 80%: [MASK] 토큰으로 대체</span></span>
<span id="cb5-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"The quick brown [MASK] jumps over the lazy dog"</span></span>
<span id="cb5-6"></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 10%: 랜덤 단어로 대체  </span></span>
<span id="cb5-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"The quick brown cat jumps over the lazy dog"</span></span>
<span id="cb5-9"></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 10%: 원래 단어 유지</span></span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"The quick brown fox jumps over the lazy dog"</span></span></code></pre></div>
<p>이러한 전략을 사용하는 이유: * <strong>80% [MASK]</strong>: 주요 학습 목표 * <strong>10% 랜덤 대체</strong>: 실제 토큰에 대한 robustness 향상 * <strong>10% 원래 유지</strong>: [MASK] 토큰에만 의존하지 않도록 방지</p>
</section>
</section>
<section id="next-sentence-prediction-nsp" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="next-sentence-prediction-nsp"><span class="header-section-number">4.3</span> Next Sentence Prediction (NSP)</h2>
<section id="nsp의-목적과-방법" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="nsp의-목적과-방법"><span class="header-section-number">4.3.1</span> NSP의 목적과 방법</h3>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연속된 문장 쌍 (IsNext = True)</span></span>
<span id="cb6-2">Sentence A: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The man went to the store."</span></span>
<span id="cb6-3">Sentence B: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"He bought milk and bread."</span></span>
<span id="cb6-4">Label: IsNext</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 무관한 문장 쌍 (IsNext = False)  </span></span>
<span id="cb6-7">Sentence A: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The man went to the store."</span></span>
<span id="cb6-8">Sentence B: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The weather is nice today."</span></span>
<span id="cb6-9">Label: NotNext</span></code></pre></div>
</section>
<section id="nsp의-한계와-후속-연구" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="nsp의-한계와-후속-연구"><span class="header-section-number">4.3.2</span> NSP의 한계와 후속 연구</h3>
<ul>
<li>RoBERTa 연구에서 NSP가 성능 향상에 크게 기여하지 않음을 발견</li>
<li>너무 쉬운 태스크로 실제 문장 관계 이해에 제한적</li>
<li>후속 모델들에서는 NSP 대신 다른 학습 목표 사용</li>
</ul>
</section>
</section>
</section>
<section id="bert의-구조와-아키텍처" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> BERT의 구조와 아키텍처</h1>
<section id="transformer-인코더-기반-설계" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="transformer-인코더-기반-설계"><span class="header-section-number">5.1</span> Transformer 인코더 기반 설계</h2>
<section id="bert의-전체-구조" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="bert의-전체-구조"><span class="header-section-number">5.1.1</span> BERT의 전체 구조</h3>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># BERT 아키텍처 개요</span></span>
<span id="cb7-2">Input: [CLS] token_1 token_2 ... token_n [SEP] token_n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> ... [SEP] [PAD] ...</span>
<span id="cb7-3">       <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span></span>
<span id="cb7-4">       v</span>
<span id="cb7-5">Embedding Layer (Token <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Position <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Segment)</span>
<span id="cb7-6">       <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span></span>
<span id="cb7-7">       v</span>
<span id="cb7-8">Transformer Encoder Layers × N</span>
<span id="cb7-9">       <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span></span>
<span id="cb7-10">       v</span>
<span id="cb7-11">Output: contextualized representations <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span> tokens</span></code></pre></div>
</section>
<section id="모델-크기별-사양" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="모델-크기별-사양"><span class="header-section-number">5.1.2</span> 모델 크기별 사양</h3>
<table class="table">
<colgroup>
<col style="width: 9%">
<col style="width: 16%">
<col style="width: 19%">
<col style="width: 25%">
<col style="width: 19%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>모델</th>
<th>레이어 수</th>
<th>Hidden Size</th>
<th>Attention Heads</th>
<th>파라미터 수</th>
<th>용도</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BERT-Base</td>
<td>12</td>
<td>768</td>
<td>12</td>
<td>110M</td>
<td>일반적 사용, 연구</td>
</tr>
<tr class="even">
<td>BERT-Large</td>
<td>24</td>
<td>1024</td>
<td>16</td>
<td>340M</td>
<td>대규모 태스크, 최고 성능</td>
</tr>
</tbody>
</table>
</section>
<section id="입력-표현-input-representation" class="level3" data-number="5.1.3">
<h3 data-number="5.1.3" class="anchored" data-anchor-id="입력-표현-input-representation"><span class="header-section-number">5.1.3</span> 입력 표현 (Input Representation)</h3>
<p>BERT는 세 가지 임베딩을 합쳐서 입력 표현을 만든다:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 임베딩 구성 요소</span></span>
<span id="cb8-2">Total_Embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Token_Embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Position_Embedding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Segment_Embedding</span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예시: "Hello world [SEP] How are you?"</span></span>
<span id="cb8-5">Token_Embedding:    [hello] [world] [SEP] [how] [are] [you] [?]</span>
<span id="cb8-6">Position_Embedding: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]     [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]     [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>]</span>
<span id="cb8-7">Segment_Embedding:  [A]     [A]     [A]   [B]   [B]   [B]   [B]</span></code></pre></div>
<section id="token-embedding" class="level4" data-number="5.1.3.1">
<h4 data-number="5.1.3.1" class="anchored" data-anchor-id="token-embedding"><span class="header-section-number">5.1.3.1</span> Token Embedding</h4>
<ul>
<li>WordPiece 토크나이저 사용 (30,000개 vocab)</li>
<li>미등록어(OOV) 문제 해결을 위한 subword 분할</li>
<li>예: “playing” → “play” + “##ing”</li>
</ul>
</section>
<section id="position-embedding" class="level4" data-number="5.1.3.2">
<h4 data-number="5.1.3.2" class="anchored" data-anchor-id="position-embedding"><span class="header-section-number">5.1.3.2</span> Position Embedding</h4>
<ul>
<li>각 토큰의 위치 정보 인코딩</li>
<li>Transformer의 순서 정보 부족 문제 해결</li>
<li>학습 가능한 positional embedding 사용</li>
</ul>
</section>
<section id="segment-embedding" class="level4" data-number="5.1.3.3">
<h4 data-number="5.1.3.3" class="anchored" data-anchor-id="segment-embedding"><span class="header-section-number">5.1.3.3</span> Segment Embedding</h4>
<ul>
<li>두 문장을 구분하기 위한 임베딩</li>
<li>첫 번째 문장: Segment A, 두 번째 문장: Segment B</li>
<li>NSP 태스크를 위해 필수적</li>
</ul>
</section>
</section>
</section>
<section id="특수-토큰의-역할" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="특수-토큰의-역할"><span class="header-section-number">5.2</span> 특수 토큰의 역할</h2>
<section id="cls-토큰" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="cls-토큰"><span class="header-section-number">5.2.1</span> [CLS] 토큰</h3>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [CLS] 토큰 활용 예시</span></span>
<span id="cb9-2">Input:  [CLS] This movie <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> great [SEP] I love it [SEP]</span>
<span id="cb9-3">Output: [CLS_repr] [token_reprs...] </span>
<span id="cb9-4"></span>
<span id="cb9-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Classification에서 [CLS] 표현 사용</span></span>
<span id="cb9-6">classification_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Linear([CLS_repr])</span></code></pre></div>
<ul>
<li><strong>분류 태스크의 핵심</strong>: 전체 시퀀스 정보를 압축한 표현</li>
<li><strong>문장 레벨 정보 집약</strong>: Self-Attention을 통해 모든 토큰 정보 통합</li>
</ul>
</section>
<section id="sep-토큰" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="sep-토큰"><span class="header-section-number">5.2.2</span> [SEP] 토큰</h3>
<ul>
<li>문장 경계 표시</li>
<li>NSP 태스크에서 문장 구분 역할</li>
<li>다중 문장 입력 시 필수</li>
</ul>
</section>
<section id="mask-토큰" class="level3" data-number="5.2.3">
<h3 data-number="5.2.3" class="anchored" data-anchor-id="mask-토큰"><span class="header-section-number">5.2.3</span> [MASK] 토큰</h3>
<ul>
<li>MLM 학습 시에만 사용</li>
<li>Fine-tuning이나 추론 시에는 사용하지 않음</li>
</ul>
</section>
<section id="pad-토큰" class="level3" data-number="5.2.4">
<h3 data-number="5.2.4" class="anchored" data-anchor-id="pad-토큰"><span class="header-section-number">5.2.4</span> [PAD] 토큰</h3>
<ul>
<li>배치 처리를 위한 길이 통일</li>
<li>Attention mask와 함께 사용하여 실제 계산에서 제외</li>
</ul>
</section>
</section>
<section id="attention-mask-메커니즘" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="attention-mask-메커니즘"><span class="header-section-number">5.3</span> Attention Mask 메커니즘</h2>
<ul>
<li>패딩 토큰을 제외하고 실제 토큰에 대해서만 attention을 계산하도록 하는 기법</li>
</ul>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Attention Mask 예시</span></span>
<span id="cb10-2">Input tokens:    [CLS] Hello world [SEP] [PAD] [PAD]</span>
<span id="cb10-3">Attention mask:  [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]   [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb10-4"></span>
<span id="cb10-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1: 실제 토큰 (attention 계산에 포함)</span></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 0: 패딩 토큰 (attention 계산에서 제외)</span></span></code></pre></div>
<p>Attention mask의 중요성: * <strong>메모리 효율성</strong>: 불필요한 패딩 토큰 계산 방지 * <strong>성능 향상</strong>: 의미 있는 토큰에만 집중 * <strong>배치 처리 가능</strong>: 다양한 길이의 문장을 효율적으로 처리</p>
</section>
</section>
<section id="bert의-학습-과정" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> BERT의 학습 과정</h1>
<section id="사전-학습-pre-training" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="사전-학습-pre-training"><span class="header-section-number">6.1</span> 사전 학습 (Pre-training)</h2>
<section id="학습-데이터" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="학습-데이터"><span class="header-section-number">6.1.1</span> 학습 데이터</h3>
<ul>
<li><strong>BookCorpus</strong>: 11,038권의 책 (800M words)</li>
<li><strong>English Wikipedia</strong>: 2,500M words (리스트와 테이블 제외)</li>
<li>총 3.3B words의 대규모 텍스트 데이터</li>
</ul>
</section>
<section id="학습-설정" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="학습-설정"><span class="header-section-number">6.1.2</span> 학습 설정</h3>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># BERT-Base 학습 하이퍼파라미터</span></span>
<span id="cb11-2">{</span>
<span id="cb11-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"batch_size"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>,</span>
<span id="cb11-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"learning_rate"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>,</span>
<span id="cb11-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"training_steps"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1_000_000</span>,</span>
<span id="cb11-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"warmup_steps"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10_000</span>,</span>
<span id="cb11-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_sequence_length"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">512</span>,</span>
<span id="cb11-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"masked_lm_prob"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>,</span>
<span id="cb11-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"optimizer"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Adam"</span>,</span>
<span id="cb11-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hardware"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"4×4 TPU Pod (16 TPUs)"</span></span>
<span id="cb11-11">}</span></code></pre></div>
</section>
<section id="학습-시간과-비용" class="level3" data-number="6.1.3">
<h3 data-number="6.1.3" class="anchored" data-anchor-id="학습-시간과-비용"><span class="header-section-number">6.1.3</span> 학습 시간과 비용</h3>
<ul>
<li><strong>BERT-Base</strong>: 4일 (4×4 TPU Pod)</li>
<li><strong>BERT-Large</strong>: 4일 (16×4 TPU Pod)</li>
<li>당시 기준으로 수만 달러의 컴퓨팅 비용</li>
</ul>
</section>
</section>
<section id="파인튜닝-fine-tuning" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="파인튜닝-fine-tuning"><span class="header-section-number">6.2</span> 파인튜닝 (Fine-tuning)</h2>
<section id="태스크별-아키텍처-변경" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="태스크별-아키텍처-변경"><span class="header-section-number">6.2.1</span> 태스크별 아키텍처 변경</h3>
<section id="텍스트-분류-text-classification" class="level4" data-number="6.2.1.1">
<h4 data-number="6.2.1.1" class="anchored" data-anchor-id="텍스트-분류-text-classification"><span class="header-section-number">6.2.1.1</span> 텍스트 분류 (Text Classification)</h4>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 감정 분석, 스팸 분류 등</span></span>
<span id="cb12-2">Input:  [CLS] This movie <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> amazing [SEP]</span>
<span id="cb12-3">        ↓</span>
<span id="cb12-4">BERT → [CLS_representation] → Linear → Softmax → [Positive<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Negative]</span></code></pre></div>
</section>
<section id="개체명-인식-named-entity-recognition" class="level4" data-number="6.2.1.2">
<h4 data-number="6.2.1.2" class="anchored" data-anchor-id="개체명-인식-named-entity-recognition"><span class="header-section-number">6.2.1.2</span> 개체명 인식 (Named Entity Recognition)</h4>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 토큰별 분류</span></span>
<span id="cb13-2">Input:  [CLS] Barack Obama was born <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> Hawaii [SEP]</span>
<span id="cb13-3">        ↓</span>
<span id="cb13-4">BERT → [tok_reprs] → Linear → Softmax → [O B<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>PER I<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>PER O O O B<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>LOC]</span></code></pre></div>
</section>
<section id="질의응답-question-answering" class="level4" data-number="6.2.1.3">
<h4 data-number="6.2.1.3" class="anchored" data-anchor-id="질의응답-question-answering"><span class="header-section-number">6.2.1.3</span> 질의응답 (Question Answering)</h4>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SQuAD 데이터셋 예시</span></span>
<span id="cb14-2">Question: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Where was Barack Obama born?"</span></span>
<span id="cb14-3">Context:  <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Barack Obama was born in Hawaii..."</span></span>
<span id="cb14-4">        ↓</span>
<span id="cb14-5">BERT → start_logits, end_logits → Answer span: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hawaii"</span></span></code></pre></div>
</section>
<section id="문장-유사도-sentence-similarity" class="level4" data-number="6.2.1.4">
<h4 data-number="6.2.1.4" class="anchored" data-anchor-id="문장-유사도-sentence-similarity"><span class="header-section-number">6.2.1.4</span> 문장 유사도 (Sentence Similarity)</h4>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 두 문장 비교</span></span>
<span id="cb15-2">Input:  [CLS] The cat sits on mat [SEP] A cat <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">is</span> on the mat [SEP]</span>
<span id="cb15-3">        ↓</span>
<span id="cb15-4">BERT → [CLS_representation] → Linear → Similarity_score</span></code></pre></div>
</section>
</section>
<section id="파인튜닝-효율성" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="파인튜닝-효율성"><span class="header-section-number">6.2.2</span> 파인튜닝 효율성</h3>
<ul>
<li><strong>빠른 수렴</strong>: 대부분 태스크에서 2-4 epoch로 충분</li>
<li><strong>높은 성능</strong>: 기존 태스크별 모델 대비 큰 성능 향상</li>
<li><strong>적은 데이터</strong>: Transfer learning으로 적은 labeled data로도 높은 성능</li>
</ul>
</section>
</section>
</section>
<section id="bert의-성능과-영향" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> BERT의 성능과 영향</h1>
<section id="glue-벤치마크-성능" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="glue-벤치마크-성능"><span class="header-section-number">7.1</span> GLUE 벤치마크 성능</h2>
<ul>
<li>GLUE: General Language Understanding Evaluation
<ul>
<li>11개 NLP 태스크를 평가하는 벤치마크</li>
<li>텍스트 분류, 개체명 인식, 질의응답, 문장 유사도 등 다양한 태스크 포함</li>
</ul></li>
<li>BERT는 발표 당시 11개 NLP 태스크에서 기존 최고 성능을 대폭 경신했다:</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>태스크</th>
<th>기존 최고</th>
<th>BERT-Base</th>
<th>BERT-Large</th>
<th>개선 폭</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MNLI</td>
<td>86.7</td>
<td>84.6</td>
<td>86.7</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>QQP</td>
<td>89.2</td>
<td>89.2</td>
<td>89.3</td>
<td>+0.1</td>
</tr>
<tr class="odd">
<td>QNLI</td>
<td>88.1</td>
<td>90.5</td>
<td>92.7</td>
<td>+4.6</td>
</tr>
<tr class="even">
<td>SST-2</td>
<td>95.8</td>
<td>93.5</td>
<td>94.9</td>
<td>-0.9</td>
</tr>
<tr class="odd">
<td>CoLA</td>
<td>60.5</td>
<td>52.1</td>
<td>60.5</td>
<td>0.0</td>
</tr>
<tr class="even">
<td>STS-B</td>
<td>86.5</td>
<td>85.8</td>
<td>87.1</td>
<td>+0.6</td>
</tr>
<tr class="odd">
<td>MRPC</td>
<td>86.8</td>
<td>88.9</td>
<td>89.3</td>
<td>+2.5</td>
</tr>
<tr class="even">
<td>RTE</td>
<td>66.4</td>
<td>66.4</td>
<td>70.1</td>
<td>+3.7</td>
</tr>
</tbody>
</table>
</section>
<section id="squad-질의응답-성능" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="squad-질의응답-성능"><span class="header-section-number">7.2</span> SQuAD 질의응답 성능</h2>
<table class="table">
<thead>
<tr class="header">
<th>모델</th>
<th>EM</th>
<th>F1</th>
<th>특징</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BiDAF</td>
<td>67.7</td>
<td>77.3</td>
<td>기존 최고 모델</td>
</tr>
<tr class="even">
<td>BERT-Base</td>
<td>80.8</td>
<td>88.5</td>
<td>+13.1 EM 향상</td>
</tr>
<tr class="odd">
<td>BERT-Large</td>
<td>84.1</td>
<td>90.9</td>
<td>+16.4 EM 향상</td>
</tr>
<tr class="even">
<td>Human</td>
<td>82.3</td>
<td>91.2</td>
<td>인간 수준 근접</td>
</tr>
</tbody>
</table>
</section>
<section id="한국어-bert-모델들" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="한국어-bert-모델들"><span class="header-section-number">7.3</span> 한국어 BERT 모델들</h2>
<section id="kobert-sktbrain-2019" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="kobert-sktbrain-2019"><span class="header-section-number">7.3.1</span> KoBERT (SKTBrain, 2019)</h3>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># KoBERT 특징</span></span>
<span id="cb16-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 한국어 Wikipedia <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> 뉴스 데이터 학습</span>
<span id="cb16-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> SentencePiece 기반 토크나이징</span>
<span id="cb16-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">00</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">2개</span> vocab size</span>
<span id="cb16-5"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> BERT<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>Base 구조 (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">층</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">768</span> hidden)</span></code></pre></div>
</section>
<section id="koelectra-monologg-2020" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="koelectra-monologg-2020"><span class="header-section-number">7.3.2</span> KoELECTRA (Monologg, 2020)</h3>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 더 효율적인 한국어 사전학습 모델</span></span>
<span id="cb17-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> ELECTRA 아키텍처 기반</span>
<span id="cb17-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">34</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">GB</span> 한국어 텍스트 데이터</span>
<span id="cb17-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 다양한 크기: Small, Base, Large</span></code></pre></div>
</section>
<section id="klu-bert-시리즈" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="klu-bert-시리즈"><span class="header-section-number">7.3.3</span> KLU-BERT 시리즈</h3>
<div class="sourceCode" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 카카오에서 개발한 한국어 특화 모델들</span></span>
<span id="cb18-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> KLU<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>RoBERTa</span>
<span id="cb18-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> KLU<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>ALBERT  </span>
<span id="cb18-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> KLU<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>ELECTRA</span></code></pre></div>
</section>
</section>
</section>
<section id="bert의-한계점과-해결방안" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> BERT의 한계점과 해결방안</h1>
<section id="bert-vs-gpt" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="bert-vs-gpt"><span class="header-section-number">8.1</span> BERT vs GPT</h2>
<ul>
<li>BERT의 양방향성은 분명히 강력한 특징이고, 얼핏 보면 더 “이해”에 유리해 보이지만, GPT가 실제 성능에서 더 우수한 이유는 단순한 방향성의 차이를 넘는 여러 구조적, 방법론적 요소들이 작용하고 있기 때문이다.</li>
</ul>
<section id="bert와-gpt의-학습-방식-요약" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="bert와-gpt의-학습-방식-요약"><span class="header-section-number">8.1.1</span> BERT와 GPT의 학습 방식 요약</h3>
<ul>
<li><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong>
<ul>
<li>학습 방식: <strong>Masked Language Modeling (MLM)</strong></li>
<li>입력 문장에서 일부 단어를 가리고, 그 가려진 단어를 예측</li>
<li>양방향 문맥 정보를 활용 (왼쪽 + 오른쪽을 동시에 고려)</li>
<li>fine-tuning을 통해 다양한 NLP 태스크에 사용</li>
</ul></li>
<li><strong>GPT (Generative Pre-trained Transformer)</strong>
<ul>
<li>학습 방식: <strong>Auto-regressive Language Modeling</strong></li>
<li>입력 시 왼쪽에서 오른쪽으로만 예측 (순방향)</li>
<li>다음 단어를 예측하며 문장을 생성함</li>
<li>사전학습과 미세조정 없이도 다양한 태스크에서 성능을 보임 (in-context learning)</li>
</ul></li>
</ul>
</section>
<section id="bert의-한계-masked-lm의-본질적-약점" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="bert의-한계-masked-lm의-본질적-약점"><span class="header-section-number">8.1.2</span> BERT의 한계: Masked LM의 본질적 약점</h3>
<ul>
<li>Mask된 단어를 맞히는 과제는 <strong>문장 생성</strong>이나 <strong>상황 이해</strong>보다는 <strong>클로즈 테스트(cloze test)</strong>와 유사한 제한적 과제이다.</li>
<li>문장에서 단어 몇 개만 가리기 때문에, 실제로는 <strong>전체 문맥 생성 능력</strong>은 훈련되지 않음.</li>
<li>마스크된 입력은 실제 문장이 아니기 때문에, <strong>학습-추론 간 괴리(train-test discrepancy)</strong>가 발생함.</li>
<li>BERT는 <strong>단어 수준에서 잘 작동</strong>하지만, 문장 생성이나 응답 생성처럼 <strong>문맥을 흐름으로 이어가는 작업</strong>에는 약함.</li>
</ul>
</section>
<section id="gpt의-강점-자연스러운-생성과-학습-구조" class="level3" data-number="8.1.3">
<h3 data-number="8.1.3" class="anchored" data-anchor-id="gpt의-강점-자연스러운-생성과-학습-구조"><span class="header-section-number">8.1.3</span> GPT의 강점: 자연스러운 생성과 학습 구조</h3>
<ul>
<li>GPT는 학습 단계에서부터 실제 사용하는 방식과 거의 동일하게 훈련됨 → <strong>next-token prediction</strong></li>
<li>문장을 왼쪽부터 오른쪽으로 예측하면서 학습하기 때문에, <strong>문맥의 흐름에 맞는 문장 생성</strong> 능력이 매우 뛰어남.</li>
<li>특히 GPT-3부터는 <strong>few-shot, zero-shot, in-context learning</strong>이 가능해졌고, GPT-4에서는 그 능력이 폭발적으로 향상됨.
<ul>
<li>예: 예시 몇 개만 주면 태스크의 룰을 “이해하고 따라함”</li>
</ul></li>
<li>실시간 대화, 질의응답, 요약, 번역, 추론 등에서 자연스럽고 유연한 반응을 생성할 수 있음.</li>
</ul>
</section>
<section id="모델-크기와-학습-데이터-규모" class="level3" data-number="8.1.4">
<h3 data-number="8.1.4" class="anchored" data-anchor-id="모델-크기와-학습-데이터-규모"><span class="header-section-number">8.1.4</span> 모델 크기와 학습 데이터 규모</h3>
<ul>
<li>GPT는 BERT보다 훨씬 큰 모델이며, <strong>훨씬 더 많은 텍스트 데이터</strong>로 사전학습함.</li>
<li>특히 GPT-4 계열은 <strong>수조 개 단어 수준의 데이터</strong>로 사전학습되었고, 파라미터 수도 수천억 개 이상.</li>
<li>단순한 방향성보다 <strong>스케일(모델 크기와 데이터 양)</strong>이 언어 모델 성능에 미치는 영향이 훨씬 큼.</li>
</ul>
</section>
<section id="응용-범위와-범용성" class="level3" data-number="8.1.5">
<h3 data-number="8.1.5" class="anchored" data-anchor-id="응용-범위와-범용성"><span class="header-section-number">8.1.5</span> 응용 범위와 범용성</h3>
<ul>
<li>BERT는 특정 태스크(fine-tuning)를 거쳐야만 좋은 성능을 냄.</li>
<li>GPT는 prompt만 바꿔서 수많은 태스크에 바로 적용 가능 (범용성 높음).</li>
<li>따라서 실용성 면에서 GPT가 훨씬 유리함.</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 16%">
<col style="width: 35%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>요소</th>
<th>BERT</th>
<th>GPT</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>문맥 방향성</td>
<td>양방향</td>
<td>일방향</td>
</tr>
<tr class="even">
<td>학습 방식</td>
<td>마스크 단어 예측 (MLM)</td>
<td>다음 단어 예측 (Auto-regressive)</td>
</tr>
<tr class="odd">
<td>문장 생성 능력</td>
<td>약함</td>
<td>강함</td>
</tr>
<tr class="even">
<td>학습-추론 일치도</td>
<td>낮음</td>
<td>높음</td>
</tr>
<tr class="odd">
<td>범용성</td>
<td>낮음 (fine-tuning 필요)</td>
<td>높음 (prompt만으로도 작동)</td>
</tr>
<tr class="even">
<td>스케일</td>
<td>비교적 작음</td>
<td>훨씬 큼 (GPT-3, 4는 초대형)</td>
</tr>
</tbody>
</table>
<ul>
<li>즉, “양방향성”이라는 요소 하나만으로 모델의 전반적인 성능을 판단하기는 어렵고, 실제로는 <strong>학습 방식, 생성 구조, 스케일, 추론 능력</strong> 같은 요소들이 종합적으로 작용한 결과 GPT가 더 뛰어난 성능을 보이고 있다.</li>
<li>원리적으론 BERT 방식이 더 “이해 중심”처럼 보일 수 있지만, 실전에서 요구되는 <strong>언어 생성, 응답의 자연스러움, 유연성</strong>은 GPT가 더 잘 처리하는 영역이다.</li>
</ul>
</section>
</section>
<section id="계산-복잡도-문제" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="계산-복잡도-문제"><span class="header-section-number">8.2</span> 계산 복잡도 문제</h2>
<section id="문제점" class="level3" data-number="8.2.1">
<h3 data-number="8.2.1" class="anchored" data-anchor-id="문제점"><span class="header-section-number">8.2.1</span> 문제점</h3>
<ul>
<li>Transformer의 Self-Attention: O(n²) 복잡도</li>
<li>긴 시퀀스 처리 시 메모리 사용량 급증</li>
<li>실시간 서비스에는 너무 무거움</li>
</ul>
</section>
<section id="해결방안들" class="level3" data-number="8.2.2">
<h3 data-number="8.2.2" class="anchored" data-anchor-id="해결방안들"><span class="header-section-number">8.2.2</span> 해결방안들</h3>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. DistilBERT: 지식 증류를 통한 경량화</span></span>
<span id="cb19-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> BERT 성능의 <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 유지하면서 <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 크기 감소</span>
<span id="cb19-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 추론 속도 <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 향상</span>
<span id="cb19-4"></span>
<span id="cb19-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. ALBERT: 파라미터 공유</span></span>
<span id="cb19-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Factorized Embedding: 임베딩 크기 분해</span>
<span id="cb19-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Cross<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>layer Parameter Sharing: 레이어 간 파라미터 공유</span>
<span id="cb19-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">배</span> 적은 파라미터로 더 좋은 성능</span>
<span id="cb19-9"></span>
<span id="cb19-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. MobileBERT: 모바일 최적화</span></span>
<span id="cb19-11"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Teacher<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>Student 학습</span>
<span id="cb19-12"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Bottleneck 구조로 레이어 압축</span></code></pre></div>
</section>
</section>
<section id="긴-시퀀스-처리-한계" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="긴-시퀀스-처리-한계"><span class="header-section-number">8.3</span> 긴 시퀀스 처리 한계</h2>
<section id="문제점-1" class="level3" data-number="8.3.1">
<h3 data-number="8.3.1" class="anchored" data-anchor-id="문제점-1"><span class="header-section-number">8.3.1</span> 문제점</h3>
<ul>
<li>최대 512 토큰 제한</li>
<li>긴 문서 처리 불가</li>
<li>문서 레벨 태스크에서 한계</li>
</ul>
</section>
<section id="해결방안들-1" class="level3" data-number="8.3.2">
<h3 data-number="8.3.2" class="anchored" data-anchor-id="해결방안들-1"><span class="header-section-number">8.3.2</span> 해결방안들</h3>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Longformer: Sparse Attention</span></span>
<span id="cb20-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Local <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> Global Attention 패턴</span>
<span id="cb20-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span> 토큰까지 처리 가능</span>
<span id="cb20-4"></span>
<span id="cb20-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. BigBird: Random + Window + Global Attention  </span></span>
<span id="cb20-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 이론적으로 증명된 sparse attention</span>
<span id="cb20-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 더 긴 시퀀스 처리 가능</span>
<span id="cb20-8"></span>
<span id="cb20-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. LED (Longformer-Encoder-Decoder)</span></span>
<span id="cb20-10"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 긴 시퀀스 요약<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>생성 태스크 특화</span></code></pre></div>
</section>
</section>
<section id="생성-태스크-한계" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="생성-태스크-한계"><span class="header-section-number">8.4</span> 생성 태스크 한계</h2>
<section id="문제점-2" class="level3" data-number="8.4.1">
<h3 data-number="8.4.1" class="anchored" data-anchor-id="문제점-2"><span class="header-section-number">8.4.1</span> 문제점</h3>
<ul>
<li>인코더 전용 구조로 생성 태스크 부적합</li>
<li>MLM은 생성보다 이해에 특화</li>
<li>자연스러운 텍스트 생성 어려움</li>
</ul>
</section>
<section id="해결방안들-2" class="level3" data-number="8.4.2">
<h3 data-number="8.4.2" class="anchored" data-anchor-id="해결방안들-2"><span class="header-section-number">8.4.2</span> 해결방안들</h3>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. BART: 인코더-디코더 구조</span></span>
<span id="cb21-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Denoising Autoencoder 방식</span>
<span id="cb21-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 생성과 이해 모두 강화</span>
<span id="cb21-4"></span>
<span id="cb21-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. T5: Text-to-Text Transfer Transformer</span></span>
<span id="cb21-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 모든 태스크를 생성 문제로 변환</span>
<span id="cb21-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"translate English to German: Hello"</span> → <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hallo"</span></span>
<span id="cb21-8"></span>
<span id="cb21-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. UniLM: Unified Language Model</span></span>
<span id="cb21-10"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 단일 모델로 이해<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>생성 모두 수행</span></code></pre></div>
</section>
</section>
</section>
<section id="bert-변형-모델들" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> BERT 변형 모델들</h1>
<section id="roberta-2019-facebook" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="roberta-2019-facebook"><span class="header-section-number">9.1</span> RoBERTa (2019, Facebook)</h2>
<section id="주요-개선사항" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="주요-개선사항"><span class="header-section-number">9.1.1</span> 주요 개선사항</h3>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># RoBERTa 변경점</span></span>
<span id="cb22-2"><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span> NSP 제거: Next Sentence Prediction 태스크 제거</span>
<span id="cb22-3"><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.</span> 동적 마스킹: 매 epoch마다 다른 마스킹 패턴</span>
<span id="cb22-4"><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.</span> 더 큰 배치: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">K</span> 배치 크기 사용</span>
<span id="cb22-5"><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.</span> 더 많은 데이터: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">160</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">GB</span> 텍스트 데이터</span>
<span id="cb22-6"><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span> 더 긴 학습: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">K</span> steps</span></code></pre></div>
</section>
<section id="성능-향상" class="level3" data-number="9.1.2">
<h3 data-number="9.1.2" class="anchored" data-anchor-id="성능-향상"><span class="header-section-number">9.1.2</span> 성능 향상</h3>
<ul>
<li>GLUE에서 BERT-Large 대비 평균 1-2% 성능 향상</li>
<li>SQuAD 2.0에서 큰 성능 개선</li>
<li>단순한 변경으로 큰 효과 입증</li>
</ul>
</section>
</section>
<section id="albert-2019-google" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="albert-2019-google"><span class="header-section-number">9.2</span> ALBERT (2019, Google)</h2>
<section id="핵심-기술" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="핵심-기술"><span class="header-section-number">9.2.1</span> 핵심 기술</h3>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1. Factorized Embedding Parameterization</span></span>
<span id="cb23-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 기존: vocab_size × hidden_size</span></span>
<span id="cb23-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ALBERT: vocab_size × embedding_size × hidden_size</span></span>
<span id="cb23-4">E <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># embedding_size &lt;&lt; hidden_size (768)</span></span>
<span id="cb23-5"></span>
<span id="cb23-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2. Cross-layer Parameter Sharing</span></span>
<span id="cb23-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모든 레이어가 같은 파라미터 공유</span></span>
<span id="cb23-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 24층이어도 1층만큼의 파라미터만 사용</span></span>
<span id="cb23-9"></span>
<span id="cb23-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 3. SOP (Sentence Order Prediction)</span></span>
<span id="cb23-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># NSP 대신 문장 순서 예측 태스크 사용</span></span></code></pre></div>
</section>
<section id="효과" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="효과"><span class="header-section-number">9.2.2</span> 효과</h3>
<ul>
<li>BERT-Large 대비 18배 적은 파라미터</li>
<li>더 나은 성능 달성</li>
<li>훈련 시간 단축</li>
</ul>
</section>
</section>
<section id="distilbert-2019-hugging-face" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="distilbert-2019-hugging-face"><span class="header-section-number">9.3</span> DistilBERT (2019, Hugging Face)</h2>
<section id="지식-증류-knowledge-distillation" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="지식-증류-knowledge-distillation"><span class="header-section-number">9.3.1</span> 지식 증류 (Knowledge Distillation)</h3>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Teacher-Student 학습</span></span>
<span id="cb24-2">Teacher: BERT<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>Base (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">110</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">M</span> parameters)</span>
<span id="cb24-3">Student: DistilBERT (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">66</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">M</span> parameters)</span>
<span id="cb24-4"></span>
<span id="cb24-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 손실 함수</span></span>
<span id="cb24-6">Loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> α × distillation_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> β × student_loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> γ × cosine_loss</span>
<span id="cb24-7"></span>
<span id="cb24-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 결과</span></span>
<span id="cb24-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 성능 유지</span>
<span id="cb24-10"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 크기 감소  </span>
<span id="cb24-11"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 빠른 추론</span></code></pre></div>
</section>
</section>
<section id="electra-2020-google" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="electra-2020-google"><span class="header-section-number">9.4</span> ELECTRA (2020, Google)</h2>
<section id="혁신적-학습-방법" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="혁신적-학습-방법"><span class="header-section-number">9.4.1</span> 혁신적 학습 방법</h3>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Replace Token Detection (RTD)</span></span>
<span id="cb25-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># MLM: 15% 토큰만 학습</span></span>
<span id="cb25-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ELECTRA: 100% 토큰 모두 학습</span></span>
<span id="cb25-4"></span>
<span id="cb25-5">Generator (작은 모델): 토큰 생성</span>
<span id="cb25-6">Discriminator (ELECTRA): 각 토큰이 원본인지 생성된 것인지 판단</span>
<span id="cb25-7"></span>
<span id="cb25-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예시</span></span>
<span id="cb25-9">Original: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The chef cooked the meal"</span></span>
<span id="cb25-10">Generated: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The chef ate the meal"</span>  </span>
<span id="cb25-11">ELECTRA: [Original, Original, Replaced, Original, Original]</span></code></pre></div>
</section>
<section id="성능" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="성능"><span class="header-section-number">9.4.2</span> 성능</h3>
<ul>
<li>같은 컴퓨팅으로 BERT보다 높은 성능</li>
<li>특히 작은 모델에서 큰 효과</li>
</ul>
</section>
</section>
</section>
<section id="bert의-현재와-미래" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> BERT의 현재와 미래</h1>
<section id="산업계-활용-현황" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="산업계-활용-현황"><span class="header-section-number">10.1</span> 산업계 활용 현황</h2>
<section id="검색-엔진-개선" class="level3" data-number="10.1.1">
<h3 data-number="10.1.1" class="anchored" data-anchor-id="검색-엔진-개선"><span class="header-section-number">10.1.1</span> 검색 엔진 개선</h3>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Google Search (2019년부터)</span></span>
<span id="cb26-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 검색 쿼리 이해 향상</span>
<span id="cb26-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 쿼리에 BERT 적용</span>
<span id="cb26-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 특히 긴 꼬리(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">long</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>tail) 쿼리에서 큰 개선</span>
<span id="cb26-5"></span>
<span id="cb26-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Microsoft Bing</span></span>
<span id="cb26-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> BERT 기반 검색 개선</span>
<span id="cb26-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 광고 관련성 향상</span></code></pre></div>
</section>
<section id="실제-서비스-적용" class="level3" data-number="10.1.2">
<h3 data-number="10.1.2" class="anchored" data-anchor-id="실제-서비스-적용"><span class="header-section-number">10.1.2</span> 실제 서비스 적용</h3>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 챗봇/가상 비서</span></span>
<span id="cb27-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 의도(Intent) 분류</span>
<span id="cb27-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 개체명 인식(NER)  </span>
<span id="cb27-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 감정 분석</span>
<span id="cb27-5"></span>
<span id="cb27-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 콘텐츠 추천</span></span>
<span id="cb27-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 텍스트 유사도 계산</span>
<span id="cb27-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 사용자 관심사 파악</span>
<span id="cb27-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 개인화 추천</span>
<span id="cb27-10"></span>
<span id="cb27-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 문서 처리</span></span>
<span id="cb27-12"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 자동 요약</span>
<span id="cb27-13"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 문서 분류</span>
<span id="cb27-14"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 정보 추출</span></code></pre></div>
</section>
</section>
<section id="후속-모델들에-미친-영향" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="후속-모델들에-미친-영향"><span class="header-section-number">10.2</span> 후속 모델들에 미친 영향</h2>
<section id="transformer-기반-모델들" class="level3" data-number="10.2.1">
<h3 data-number="10.2.1" class="anchored" data-anchor-id="transformer-기반-모델들"><span class="header-section-number">10.2.1</span> Transformer 기반 모델들</h3>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># BERT의 영향을 받은 주요 모델들</span></span>
<span id="cb28-2">├── 인코더 계열</span>
<span id="cb28-3">│   ├── RoBERTa, ALBERT, ELECTRA</span>
<span id="cb28-4">│   ├── DeBERTa, CANINE</span>
<span id="cb28-5">│   └── 다국어: mBERT, XLM<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>R</span>
<span id="cb28-6">│</span>
<span id="cb28-7">├── 인코더<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>디코더 계열  </span>
<span id="cb28-8">│   ├── BART, T5</span>
<span id="cb28-9">│   ├── PEGASUS, ProphetNet</span>
<span id="cb28-10">│   └── mT5, ByT5</span>
<span id="cb28-11">│</span>
<span id="cb28-12">└── 디코더 계열</span>
<span id="cb28-13">    ├── GPT<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span></span>
<span id="cb28-14">    ├── PaLM, LaMDA</span>
<span id="cb28-15">    └── ChatGPT, Gemini</span></code></pre></div>
</section>
<section id="설계-원칙의-확산" class="level3" data-number="10.2.2">
<h3 data-number="10.2.2" class="anchored" data-anchor-id="설계-원칙의-확산"><span class="header-section-number">10.2.2</span> 설계 원칙의 확산</h3>
<ul>
<li><strong>Pre-training + Fine-tuning</strong>: 거의 모든 NLP 모델의 표준</li>
<li><strong>Large-scale Unsupervised Learning</strong>: 무라벨 데이터 활용</li>
<li><strong>Transfer Learning</strong>: 일반 지식을 특정 태스크로 전이</li>
<li><strong>Attention is All You Need</strong>: Transformer 아키텍처 표준화</li>
</ul>
</section>
</section>
<section id="연구-동향과-발전-방향" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="연구-동향과-발전-방향"><span class="header-section-number">10.3</span> 연구 동향과 발전 방향</h2>
<section id="효율성-개선" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="효율성-개선"><span class="header-section-number">10.3.1</span> 효율성 개선</h3>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 경량화 연구</span></span>
<span id="cb29-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Pruning: 불필요한 가중치 제거</span>
<span id="cb29-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Quantization: 낮은 정밀도 연산</span>
<span id="cb29-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Knowledge Distillation: 지식 증류</span>
<span id="cb29-5"></span>
<span id="cb29-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 아키텍처 개선</span></span>
<span id="cb29-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Sparse Attention: 희소 어텐션 패턴</span>
<span id="cb29-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Linear Attention: 선형 복잡도 어텐션</span>
<span id="cb29-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Hardware<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>aware Design: 하드웨어 최적화</span></code></pre></div>
</section>
<section id="성능-향상-1" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="성능-향상-1"><span class="header-section-number">10.3.2</span> 성능 향상</h3>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 더 나은 사전학습</span></span>
<span id="cb30-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Better Objectives: MLM 개선</span>
<span id="cb30-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Curriculum Learning: 점진적 학습</span>
<span id="cb30-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Multi<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>task Learning: 다중 태스크 학습</span>
<span id="cb30-5"></span>
<span id="cb30-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 아키텍처 혁신</span></span>
<span id="cb30-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Mixture of Experts: 전문가 혼합 모델</span>
<span id="cb30-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Retrieval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>Augmented: 검색 증강 생성</span>
<span id="cb30-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> Multimodal: 다중 모달 통합</span></code></pre></div>
</section>
<section id="응용-분야-확장" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3" class="anchored" data-anchor-id="응용-분야-확장"><span class="header-section-number">10.3.3</span> 응용 분야 확장</h3>
<div class="sourceCode" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 새로운 도메인</span></span>
<span id="cb31-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 과학 문헌: SciBERT, BioBERT</span>
<span id="cb31-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 법률 문서: LegalBERT</span>
<span id="cb31-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 금융 분야: FinBERT</span>
<span id="cb31-5"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 의료 분야: ClinicalBERT</span>
<span id="cb31-6"></span>
<span id="cb31-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 다국어 지원</span></span>
<span id="cb31-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> mBERT: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">104</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">개</span> 언어</span>
<span id="cb31-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> XLM<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>R: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">개</span> 언어  </span>
<span id="cb31-10"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> 언어별 특화 모델들</span></code></pre></div>
</section>
</section>
</section>
<section id="결론" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> 결론</h1>
<p>BERT는 자연어 처리 분야에서 가장 중요한 혁신 중 하나로, 2018년 발표 이후 NLP 연구와 응용의 패러다임을 완전히 바꾸었다.</p>
<section id="bert의-핵심-기여" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="bert의-핵심-기여"><span class="header-section-number">11.1</span> BERT의 핵심 기여</h2>
<ul>
<li><strong>양방향 문맥 이해</strong>: Self-Attention을 통한 진정한 의미의 양방향 문맥 포착으로 기존 일방향 모델의 한계 극복</li>
<li><strong>혁신적 사전 학습</strong>: MLM과 NSP를 통해 대규모 무라벨 데이터에서 언어의 깊은 패턴을 학습하는 새로운 방법 제시</li>
<li><strong>Transfer Learning 확립</strong>: Pre-training + Fine-tuning 패러다임을 통해 하나의 모델로 다양한 NLP 태스크를 효과적으로 해결</li>
<li><strong>성능 혁신</strong>: 11개 주요 NLP 태스크에서 기존 최고 성능을 대폭 경신하며 인간 수준에 근접한 성능 달성</li>
</ul>
</section>
<section id="후속-발전에-미친-영향" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="후속-발전에-미친-영향"><span class="header-section-number">11.2</span> 후속 발전에 미친 영향</h2>
<p>BERT 등장 이후 NLP 분야는 완전히 새로운 국면에 접어들었다. RoBERTa, ALBERT, ELECTRA 등의 직접적 개선 모델뿐만 아니라, T5의 텍스트-투-텍스트 프레임워크, GPT 시리즈의 생성형 AI 혁신까지 모두 BERT가 확립한 기반 위에서 발전했다.</p>
<p>특히 ChatGPT로 대표되는 현재의 대화형 AI 시스템들도 BERT가 보여준 대규모 사전 학습의 효과성과 Transfer Learning 패러다임의 연장선상에 있다.</p>
</section>
<section id="현재적-의미와-미래-전망" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="현재적-의미와-미래-전망"><span class="header-section-number">11.3</span> 현재적 의미와 미래 전망</h2>
<p>BERT는 단순한 기술적 발전을 넘어 AI가 언어를 이해하는 방식을 근본적으로 변화시켰다. 검색, 번역, 질의응답, 문서 분류 등 실생활의 다양한 영역에서 BERT 기반 기술이 활용되고 있으며, 이는 인간과 기계의 상호작용을 더욱 자연스럽게 만들고 있다.</p>
<p>앞으로도 BERT의 핵심 아이디어들은 더욱 효율적이고 강력한 언어 모델의 기초가 될 것이며, 다중 모달 AI, 개인화된 AI 어시스턴트, 전문 도메인 특화 AI 등의 발전에 계속해서 중요한 역할을 할 것이다.</p>
<p>BERT의 등장은 AI가 인간의 언어를 진정으로 이해할 수 있다는 가능성을 보여준 역사적 전환점이었으며, 이후 모든 언어 AI 기술 발전의 출발점이 되었다.</p>


</section>
</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/22.ptm_BERT.html</guid>
  <pubDate>Tue, 21 Jan 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>사전 학습 모델의 발전</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/21.ptm_overview.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>이 문서는 자연어 처리 분야에서 패러다임 전환을 이끈 <strong>사전 학습 모델(Pre-trained Model)</strong>들의 발전 과정과 핵심 원리를 탐구한다. 2015년 Google의 LSTM 사전 학습 실험부터 2023년 LLaMA까지, 각 모델이 가져온 혁신적 변화와 기술적 특징을 상세히 설명한다.</p>
<p>주요 내용은 다음과 같다:</p>
<ul>
<li><strong>사전 학습의 개념과 발전</strong>:
<ul>
<li>초기에는 Word2Vec, GloVe 같은 정적 임베딩에서 시작</li>
<li>Google의 LSTM 사전 학습 실험(2015)이 사전 학습의 효과를 입증</li>
<li>대규모 데이터로 미리 학습한 모델이 무작위 초기화보다 우수한 성능 확인</li>
</ul></li>
<li><strong>문맥 기반 임베딩의 등장</strong>:
<ul>
<li><strong>ELMo (2017)</strong>: BiLSTM 기반 양방향 문맥 임베딩의 선구자</li>
<li>동일한 단어라도 문맥에 따라 다른 벡터 표현 생성</li>
<li>“bank”가 금융기관과 강가에서 서로 다른 의미로 표현되는 혁신</li>
</ul></li>
<li><strong>Transformer 아키텍처의 혁명</strong>:
<ul>
<li><strong>Transformer (2017)</strong>: Self-Attention과 Position Encoding으로 순차 처리 방식 탈피</li>
<li>병렬 처리 가능, 장거리 의존성 포착 능력 향상</li>
<li>현대 모든 대규모 언어 모델의 기초 구조 제공</li>
</ul></li>
<li><strong>특화 모델들의 분화</strong>:
<ul>
<li><strong>GPT (2018)</strong>: Transformer 디코더 기반 생성 특화 모델</li>
<li><strong>BERT (2018)</strong>: Transformer 인코더 기반 이해 특화 모델</li>
<li><strong>BART (2019)</strong>: 인코더-디코더 결합으로 이해와 생성 모두 강화</li>
<li><strong>T5 (2020)</strong>: 모든 NLP 태스크를 텍스트-투-텍스트로 통합</li>
</ul></li>
<li><strong>최신 발전 동향</strong>:
<ul>
<li><strong>LLaMA (2023)</strong>: 효율적인 대규모 언어 모델의 새로운 표준</li>
<li><strong>UL2 (2023)</strong>: 다양한 사전 학습 방식의 융합</li>
<li><strong>FLAN (2022)</strong>: Instruction Tuning을 통한 명령어 이해 능력 강화</li>
</ul></li>
</ul>
<p>각 모델의 핵심 아이디어, 학습 방식, 활용 분야를 통해 현대 NLP 기술의 발전 궤적과 미래 방향성을 이해할 수 있다.</p>
</section>
<section id="텍스트-인코딩-및-벡터화" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 텍스트 인코딩 및 벡터화</h1>
<pre><code>RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa
|   └── ALBERT
|
├── 한국어 특화: KoBERT, KoGPT, KLU-BERT 등 (Kakao,2019~)
└── 기타 발전 모델
    ├── T5, XLNet, ELECTRA
    └── PaLM, LaMDA, Gemini, Claude 등</code></pre>
</section>
<section id="사전-학습-모델-pre-trained-model" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> 사전 학습 모델 (Pre-trained Model)</h1>
<ul>
<li>원래는 언어모델보다는 word embedding에서 사용되던 개념이었음</li>
<li>사전 훈련된 임베딩 (Word2Vec, GloVe)은 대용량 텍스트의 단어들의 동시 등장 통계로부터 훈련시키는 방법</li>
<li>미리 학습시켜 놓은 모델을 가리고 새로운 문제를 풀었었음</li>
<li>Google의 LSTM 사전학습 실험 (Semi-Supervised Sequence Learning, 2015)
<ul>
<li>LSTM 언어 모델을 사전 학습한 후에 텍스트 분류에 적용해봄</li>
<li>LSTM을 사전 학습하지 않은 상태에서 텍스트 분류를 학습한 것과 성능 비교</li>
<li>사전 학습된 LSTM이 random 초기화된 LSTM보다 성능이 좋았음</li>
</ul></li>
</ul>
<section id="elmoembeddings-from-language-models.-2017" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="elmoembeddings-from-language-models.-2017"><span class="header-section-number">3.1</span> ELMo(Embeddings from Language Models. 2017)</h2>
<ul>
<li>사전 학습된 LSTM 언어 모델 2가지를 결합하여 좋은 임베딩 벡터값을 얻는 방법론</li>
<li>사전 학습된 언어 모델이 NLP에서 좋은 성능을 얻을 수 있다는 강한 인상을 줌</li>
<li>ELMo는 문장에서 단어의 의미를 상황에 맞게 다르게 표현해주는 단어 임베딩 기법</li>
<li>예를 들어,
<ul>
<li>“He went to the bank to deposit money.”</li>
<li>“She sat by the bank of the river.”</li>
<li>여기서 bank는 같은 철자지만 의미가 전혀 다르지만 기존 방식(Word2Vec, GloVe)은 이걸 같은 의미로 취급</li>
<li>그런데 ELMo는 문맥을 보고 각각 다른 벡터로 표현</li>
</ul></li>
<li>동작 방식
<ul>
<li>문장을 왼쪽에서 읽는 모델 + 오른쪽에서 읽는 모델 두 개를 활용하여 해당 단어가 문장 속에서 어떤 의미로 쓰였는지를 분석</li>
<li>문장을 양방향으로 읽어 단어의 문맥 정보를 파악함
<ul>
<li>앞에서부터 → 순방향 LSTM</li>
<li>뒤에서부터 → 역방향 LSTM</li>
<li>순방향에서의 bank에 대한 hidden state와 역방향에서의 bank에 대한 hidden state를 결합하여 임베딩을 생성</li>
</ul></li>
<li>모든 단어의 의미는 “문맥 기반”
<ul>
<li>“bank”가 앞뒤에 어떤 단어들과 쓰였는지 보면서 이게 ’돈 관련 은행’인지, ’강가’인지 판단함</li>
</ul></li>
<li>그리고, 임베딩을 뽑음
<ul>
<li>이렇게 판단한 의미를 벡터(숫자 집합)로 표현</li>
</ul></li>
</ul></li>
<li>ELMo는 등장하자마자 기존 NLP 모델들의 정확도를 확 뛰어넘었다</li>
<li>개체명 인식(NER), 질의응답(QA), 문장 분류 등에 광범위하게 쓰였다</li>
<li>지금은 BERT, GPT 같은 트랜스포머가 주도하고 있지만, ELMo는 문맥 기반 임베딩의 출발점이었음</li>
</ul>
</section>
<section id="transformer-2017" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="transformer-2017"><span class="header-section-number">3.2</span> Transformer (2017)</h2>
<ul>
<li>기존의 RNN, LSTM과 달리 <strong>순서를 따라 처리하지 않고</strong>, 문장 전체를 <strong>한꺼번에 보고</strong> 이해할 수 있도록 만든 모델이다.</li>
<li>Transformer는 두 가지 핵심 구조
<ul>
<li><ol type="1">
<li><strong>Self-Attention</strong></li>
</ol>
<ul>
<li>문장 안에서 <strong>각 단어가 다른 단어들과 얼마나 중요한 관계가 있는지를 계산</strong>한다.</li>
<li>예를 들어, “The cat sat on the mat”에서 “sat”와 “cat” 사이의 연결이 중요하다면, 모델은 그 둘의 관계를 더 강하게 본다.</li>
</ul></li>
<li><ol start="2" type="1">
<li><strong>Position Encoding</strong></li>
</ol>
<ul>
<li>Transformer는 순서를 따라 읽지 않기 때문에, <strong>각 단어의 위치 정보</strong>를 따로 추가해줘야 한다.</li>
<li>위치 정보를 더해줘서 “첫 번째 단어”, “두 번째 단어” 등의 순서를 인식하게 한다.</li>
</ul></li>
</ul></li>
<li>Transformer의 구성요소
<ul>
<li><strong>인코더(Encoder)</strong>: 입력 문장을 이해하고 벡터로 변환함</li>
<li><strong>디코더(Decoder)</strong>: 그 벡터를 바탕으로 결과(예: 번역, 요약 등)를 생성함</li>
<li>예를 들어, 영어 문장을 프랑스어로 번역하는 경우,
<ul>
<li>인코더는 영어 문장을 이해하고</li>
<li>디코더는 그것을 프랑스어로 바꾸어 생성한다.</li>
</ul></li>
</ul></li>
<li>Transformer는 다음과 같은 이유로 혁신적이다:
<ul>
<li><strong>병렬처리 가능</strong>: RNN처럼 순서대로 처리하지 않기 때문에 연산 속도가 빠르다.</li>
<li><strong>문맥 파악 능력 향상</strong>: 문장의 멀리 떨어진 단어들 간의 관계도 잘 이해한다.</li>
<li><strong>기반 기술로 발전</strong>: BERT, GPT, T5, LLaMA 등 오늘날의 대부분의 대형 언어모델은 Transformer 기반이다.</li>
</ul></li>
<li>오늘날 대부분의 LLM은 이 구조를 바탕으로 하고 있다.</li>
<li>ELMo는 RNN 구조 기반이고,
<ul>
<li>Transformer는 그 한계를 뛰어넘기 위해 등장한 구조라는 점에서</li>
<li>이 둘의 <strong>패러다임 자체가 다르다</strong>는 것도 같이 기억해두면 좋겠다.</li>
</ul></li>
</ul>
</section>
<section id="gptgenerative-pre-trained-transformer.-2018" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="gptgenerative-pre-trained-transformer.-2018"><span class="header-section-number">3.3</span> GPT(Generative Pre-trained Transformer. 2018)</h2>
<ul>
<li>GPT는 문장을 생성하는 모델이다.</li>
<li>기존 모델들이 문장을 이해하는 데 집중했다면, GPT는 문장을 생성하는 데 집중한다.</li>
<li>OpenAI는 Google의 Transformer을 보고 STM이 사전 학습되어 사용되면 성능이 좋은 것을 확인.<br>
</li>
<li>Transformer의 디코더 구조를 분석하고 다음 단어를 예측하는 모듈에 해당하는 디코더로 사전 학습 언어 모델을 구현했다.</li>
<li>Transformer의 encoder를 버리고 decoder만 사용하여 문장을 생성하는 모델을 만들었다.</li>
<li>동작 방식
<ul>
<li>GPT는 <strong>Transformer의 디코더 구조만</strong> 사용한다.</li>
<li>즉, 문장을 생성하는 데 특화되어 있으며,</li>
<li>문장을 이해하는 인코더 구조는 없다.</li>
<li>핵심 동작 방식
<ul>
<li><strong>좌→우 방향의 언어 생성 학습</strong>
<ul>
<li>문장을 왼쪽에서 오른쪽으로 읽으면서,</li>
<li>다음에 올 단어를 예측하는 방식으로 학습한다.</li>
<li>예:
<ul>
<li>입력: “I want to eat”</li>
<li>목표: 다음 단어가 무엇일까? → “pizza”</li>
<li>이런 식으로 엄청나게 많은 문장 데이터를 통해 <strong>패턴을 학습</strong>한다.</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>사전학습 후 활용</strong>
<ul>
<li>대규모 텍스트로 먼저 학습(Pre-training)</li>
<li>이후 별도 작업(챗봇, 작문, 번역 등)에 맞게 사용(Fine-tuning or Prompting)</li>
</ul></li>
</ul></li>
<li>특징
<ul>
<li><strong>텍스트 생성 능력</strong>이 매우 뛰어남</li>
<li>다양한 태스크를 <strong>명시적 미세조정 없이 프롬프트만으로 해결 가능</strong>
<ul>
<li>이게 GPT 계열 모델의 큰 장점이다 (Few-shot, Zero-shot, etc.)</li>
</ul></li>
<li><strong>문장 완성, 요약, 번역, 창작, 대화 등</strong>
<ul>
<li>생성형 작업에 모두 강하다</li>
</ul></li>
</ul></li>
<li><strong>GPT는 문장을 생성하는 데 특화된 모델</strong>이다.</li>
</ul>
</section>
<section id="bertbidirectional-encoder-representations-from-transformers.-2018" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="bertbidirectional-encoder-representations-from-transformers.-2018"><span class="header-section-number">3.4</span> BERT(Bidirectional Encoder Representations from Transformers. 2018)</h2>
<ul>
<li>Google이 OpenAI의 GPT 모델을 보고 반대로 문장을 이해하는 데 집중하는 모델을 만들었다.</li>
<li>Transformer의 인코더 구조를 사용하여 문장을 이해하는 모델을 만들었다.</li>
<li>NLU가 특화된 부분이기 때문에 Text 분류에서 GPT보다 더 나은 성능을 보인다.</li>
<li>BERT는 문장을 <strong>양방향으로 이해하는</strong> 언어 모델이다.</li>
<li>기존 모델들이 <strong>왼쪽에서 오른쪽</strong> 혹은 <strong>오른쪽에서 왼쪽</strong>으로만 문장을 해석했다면,</li>
<li>BERT는 문장을 <strong>양쪽 방향에서 동시에</strong> 해석한다.</li>
<li>그래서 더 깊은 문맥 이해가 가능하다.</li>
<li>동작 방식
<ul>
<li>BERT는 <strong>Transformer의 인코더 구조만</strong> 사용한다.</li>
<li>즉, 문장을 이해하고 벡터로 바꾸는 데 특화되어 있으며,</li>
<li>문장을 새로 생성하는 디코더 구조는 없다.</li>
<li>핵심 동작 방식은 두 가지 학습 방식으로 이루어진다:
<ul>
<li><strong>Masked Language Modeling (MLM)</strong>
<ul>
<li>입력 문장 중 일부 단어를 가려놓고, 그 단어가 무엇인지 맞히도록 학습한다.</li>
<li>예: “The cat sat on the [MASK].” → 모델은 ’mat’이라고 예측해야 한다.</li>
<li>이를 통해 문장의 앞뒤 <strong>모든 문맥</strong>을 참고해서 단어를 이해하는 법을 배운다.</li>
</ul></li>
<li><strong>Next Sentence Prediction (NSP)</strong>
<ul>
<li>두 문장을 입력한 뒤, 두 번째 문장이 첫 번째 문장의 <strong>진짜 다음 문장인지</strong> 판단하게 학습한다.</li>
<li>예:
<ul>
<li>문장1: “She opened the door.”</li>
<li>문장2: “She picked up the package.” → 연결된 문장 (True)</li>
<li>문장2: “The sun is a star.” → 무관한 문장 (False)</li>
</ul></li>
<li>문장 간의 관계 이해 능력을 키우기 위한 학습이다.</li>
</ul></li>
</ul></li>
</ul></li>
<li>문맥 기반 단어 임베딩 제공
<ul>
<li>같은 단어라도 문맥에 따라 다른 벡터로 표현됨</li>
</ul></li>
<li>사전학습 + 미세조정 구조 (Pretraining + Fine-tuning)
<ul>
<li>대규모 텍스트로 미리 학습해두고,</li>
<li>이후 실제 태스크(NER, 분류, QA 등)에 맞게 추가 학습만 하면 됨.</li>
</ul></li>
<li>BERT는 다양한 NLP 태스크에서 <strong>기록적인 성능 향상</strong>을 이끌었다.</li>
<li>이후 등장한 RoBERTa, ALBERT, DistilBERT, DeBERTa 등은 BERT의 변형이다.</li>
<li>현재 GPT 계열이 생성에 특화되어 있다면,
<ul>
<li><strong>BERT는 이해(이해 기반 태스크)에 특화된 모델</strong>이라고 보면 된다.</li>
</ul></li>
<li>BERT는 <strong>Transformer 인코더 기반의 양방향 문맥 이해 모델</strong>이다.</li>
<li><strong>단어를 문맥 안에서 정확하게 해석</strong>하기 위해 만들어졌다.</li>
<li><strong>문장 분류, 질의응답, 개체명 인식 등 NLP의 다양한 작업에 폭넓게 활용</strong>된다.</li>
</ul>
</section>
<section id="bartbidirectional-and-auto-regressive-transformers.-2019" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="bartbidirectional-and-auto-regressive-transformers.-2019"><span class="header-section-number">3.5</span> BART(Bidirectional and Auto-Regressive Transformers. 2019)</h2>
<ul>
<li>Encoder-Decoder 가 결합된 구조를 사용하여 문장을 이해하고 생성하는 모델을 만들었다.</li>
<li>BART는 <strong>BERT + GPT의 장점</strong>을 결합한 모델로, <strong>이해와 생성 모두에 강한 모델</strong>이다.</li>
<li>BART는 <strong>문장을 이해하고 → 그것을 기반으로 문장을 생성하는 모델</strong>이다.</li>
<li>즉, <strong>BERT처럼 입력을 양방향으로 이해</strong>하고, <strong>GPT처럼 자연스럽게 문장을 생성</strong>한다.</li>
<li>구조적으로는 <strong>Transformer 인코더 + 디코더</strong>를 모두 사용한다.</li>
<li>쉽게 말해 <strong>BERT + GPT를 합친 하이브리드 모델</strong>이다.</li>
<li>동작 방식
<ul>
<li><strong>Denoising Autoencoder</strong>: BART의 학습은 <strong>“노이즈 추가 → 원문 복원”</strong> 방식으로 이루어진다.</li>
<li>입력 문장에 노이즈를 준다</li>
<li>예:
<ul>
<li>원래 문장: <code>The cat sat on the mat.</code></li>
<li>망가뜨린 문장: <code>The [MASK] on the mat.</code> 또는 <code>sat the mat on the cat.</code> (순서 뒤섞기)</li>
</ul></li>
<li>모델은 이 망가진 문장을 보고 <strong>원래 문장을 복원</strong>한다. 즉, 문장을 이해하고, 적절한 형태로 <strong>다시 생성</strong>할 수 있어야 한다.</li>
<li>이 과정을 통해 BART는 <strong>이해 능력</strong>과 <strong>생성 능력</strong>을 동시에 학습하게 된다.</li>
</ul></li>
<li>구성
<ul>
<li><strong>인코더</strong>는 BERT처럼 <strong>양방향 문맥 이해</strong></li>
<li><strong>디코더</strong>는 GPT처럼 <strong>왼쪽→오른쪽 순서대로 문장 생성</strong></li>
</ul></li>
<li>이 구조 덕분에 <strong>복잡한 입력을 해석하고</strong>, 그에 맞는 <strong>정확하고 자연스러운 출력</strong>을 만들어낼 수 있다.</li>
<li>활용 분야
<ul>
<li>BART는 다음과 같은 <strong>생성 기반 작업</strong>에 특히 강하다:
<ul>
<li>텍스트 요약 (Summarization)</li>
<li>문장 생성 (Text Generation)</li>
<li>기계 번역 (Machine Translation)</li>
<li>문법 오류 수정 (Grammatical Error Correction)</li>
<li>질문 생성 (Question Generation)</li>
</ul></li>
</ul></li>
<li>특히 <strong>요약 모델로서 매우 뛰어난 성능</strong>을 보여주었고, Facebook AI에서 개발한 이후 HuggingFace에서도 적극적으로 채택되었다.</li>
</ul>
</section>
<section id="t5-text-to-text-transfer-transformer.-2020" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="t5-text-to-text-transfer-transformer.-2020"><span class="header-section-number">3.6</span> T5 (Text-to-Text Transfer Transformer. 2020)</h2>
<ul>
<li>T5는 모든 NLP 문제를 텍스트 → 텍스트 문제로 바꾸자는 발상에서 출발했다.</li>
<li>즉, 입력도 텍스트, 출력도 텍스트로 통일된 프레임워크를 사용한다.</li>
<li>T5는 구글이 제안한 범용 NLP 모델이다.</li>
<li>자연어처리에서 벌어지는 거의 모든 작업을 <strong>텍스트 입력 → 텍스트 출력</strong>으로 통합하는 것이 핵심이다.</li>
<li>요약, 번역, 문장 분류, 질문 생성, 질의 응답 등 모두 동일한 구조에서 처리 가능하다.</li>
<li>동작 방식
<ul>
<li>T5는 BART처럼 <strong>Transformer 인코더 + 디코더 구조</strong>를 사용한다.</li>
<li>하지만 BART와 달리, <strong>모든 태스크를 통일된 방식으로 표현</strong>하는 철학이 핵심이다.</li>
</ul></li>
<li>예시:
<ul>
<li>문장 분류
<ul>
<li>입력: <code>"sst2 sentence: I love this movie."</code></li>
<li>출력: <code>"positive"</code></li>
</ul></li>
<li>문장 요약
<ul>
<li>입력: <code>"summarize: The cat sat on the mat. It was sleepy."</code></li>
<li>출력: <code>"The cat was sleepy."</code></li>
</ul></li>
<li>질의 응답
<ul>
<li>입력: <code>"question: Where is the Eiffel Tower? context: The Eiffel Tower is in Paris."</code></li>
<li>출력: <code>"Paris"</code></li>
</ul></li>
<li>이처럼 <strong>작업을 구분하는 태그 + 텍스트 입력</strong>을 넣으면 <strong>디코더가 원하는 정답 텍스트를 생성</strong>한다.</li>
</ul></li>
<li>사전학습 방식
<ul>
<li>T5도 BART처럼 <strong>Denoising Autoencoder</strong> 방식으로 학습된다.</li>
<li>하지만 T5는 자체적으로 만든 <strong>Span Corruption</strong>이라는 방식을 쓴다:</li>
<li>문장에서 일부 구간(span)을 가리고, 그 구간을 <code>&lt;extra_id_0&gt;</code>, <code>&lt;extra_id_1&gt;</code> 같은 토큰으로 대체</li>
<li>모델이 이 빈칸들을 복원하게 함</li>
<li>이 과정을 통해 <strong>문장 이해 + 생성 능력</strong>을 동시에 기른다.</li>
</ul></li>
<li>특징
<ul>
<li><strong>모든 NLP 태스크를 텍스트 → 텍스트 문제로 통일</strong></li>
<li>다양한 태스크를 하나의 모델로 처리 가능</li>
<li>프롬프트 기반으로 유연하게 태스크 전환</li>
<li>학습 구조는 BART와 유사하지만, <strong>설계 철학은 더 범용적</strong>임</li>
</ul></li>
<li><strong>T5는 BART와 구조는 유사하나, 태스크 프레임워크가 다르다.</strong></li>
<li><strong>모든 입력과 출력을 텍스트로 다루며, 태스크 이름을 붙여 명시함</strong></li>
<li>따라서 여러 NLP 작업을 하나의 파이프라인에서 처리할 수 있다.</li>
<li>대표적인 범용 자연어 처리 모델 중 하나로, 후속 버전으로 T5.1.1, UL2, FLAN-T5 등이 있다.</li>
</ul>
</section>
<section id="llamalarge-language-model-meta-ai.-2023" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="llamalarge-language-model-meta-ai.-2023"><span class="header-section-number">3.7</span> LLaMA(Large Language Model Meta AI. 2023)</h2>
<ul>
<li>LLaMA는 Meta(구 Facebook)에서 제안한 <strong>대규모 언어 모델 시리즈</strong>이다.</li>
<li>이름은 <strong>Large Language Model Meta AI</strong>의 약자이다.</li>
<li>LLaMA는 범용 텍스트 생성 능력을 목표로 하는 <strong>GPT 계열 디코더 기반 모델</strong>이다.</li>
<li>고성능 언어 모델을 <strong>비교적 작은 파라미터 수로도 구현 가능</strong>하다는 점을 증명하고자 설계되었다.</li>
<li>논문 및 모델은 공개되어 <strong>학계, 오픈소스 커뮤니티에서 널리 활용되고 있음</strong>.</li>
<li>LLaMA는 1~2단계 모델 학습을 통해 **사전학습된 기반 모델 (Base LM)**만 제공하며, <strong>대화, 요약, 추론 등에 맞게 파인튜닝은 사용자가 직접 수행</strong>하도록 설계되어 있다.</li>
<li>동작 방식
<ul>
<li>LLaMA는 GPT처럼 <strong>Transformer 디코더 구조</strong>만 사용한다.</li>
<li>입력을 <strong>왼쪽에서 오른쪽</strong>으로 읽으며 <strong>다음 토큰을 예측</strong>하는 방식으로 작동한다.</li>
<li>학습 시점에 <strong>자기회귀 언어모델 (Autoregressive Language Modeling)</strong> 방식 사용.</li>
</ul></li>
<li>특징
<ul>
<li>GPT처럼 텍스트 생성 중심의 모델이지만, <strong>효율성과 학습 품질 향상에 집중된 다양한 설계 전략</strong>을 포함한다.</li>
<li>예:
<ul>
<li><strong>Norm 위치 변경 (Pre-normalization)</strong></li>
<li><strong>GEGLU 활성화 함수</strong></li>
<li><strong>더 긴 시퀀스 학습 (최대 2,048 토큰)</strong></li>
<li><strong>높은 품질의 텍스트 코퍼스만 선별하여 학습</strong></li>
</ul></li>
<li>성능 대비 <strong>모델 크기 효율이 매우 우수</strong>하여, 작은 파라미터 수로도 <strong>GPT-3 수준의 성능</strong>을 낼 수 있음.</li>
</ul></li>
<li>버전별 주요 모델
<ul>
<li><strong>LLaMA 1 (2023 초)</strong>
<ul>
<li>파라미터 크기: 7B, 13B, 33B, 65B</li>
<li>공개 후 오픈소스 생태계에서 광범위한 활용이 시작됨</li>
</ul></li>
<li><strong>LLaMA 2 (2023 중반)</strong>
<ul>
<li>성능 개선 및 다양한 크기: 7B, 13B, 70B</li>
<li><strong>LLaMA 2-Chat</strong>: 대화용으로 미세조정된 모델</li>
</ul></li>
<li><strong>LLaMA 3 (2024 출시)</strong>
<ul>
<li>Meta가 직접 <strong>SOTA급 성능</strong>을 표방하며 출시</li>
<li>8B, 70B 모델 제공, 대화형 fine-tuning 포함</li>
<li>상용 사용 가능, HuggingFace 등에서 공개됨</li>
</ul></li>
</ul></li>
<li>활용 방식
<ul>
<li>LLaMA는 <strong>기반 모델만 제공</strong>하기 때문에, 대화형 모델로 쓰려면 <strong>Alpaca, Vicuna, OpenChat, Zephyr</strong> 등의 <strong>LoRA 파인튜닝</strong> 모델을 함께 사용하는 경우가 많다.</li>
<li>특히 LLaMA는 <strong>프롬프트 기반 제어</strong>, <strong>추론</strong>, <strong>코드 생성</strong> 등 다양한 태스크에서 활용 가능하며, <strong>고품질 오픈소스 AI 개발의 중심</strong>으로 자리 잡았다.</li>
</ul></li>
<li>LLaMA는 GPT 계열의 디코더 언어 모델이다.</li>
<li><strong>작은 모델 크기로도 높은 성능</strong>을 발휘할 수 있도록 최적화됨.</li>
<li>다양한 오픈소스 프로젝트에서 핵심 기반 모델로 활용됨.</li>
<li>후속 시리즈인 <strong>LLaMA 2, 3</strong>는 대화형 파인튜닝 모델과 함께 상용 및 학술용으로 널리 쓰이고 있음.</li>
</ul>
<p>좋다. 이번에는 <strong>UL2</strong>와 <strong>FLAN</strong>에 대해 각각 T5 형식에 맞춰 설명하겠다. 둘 다 <strong>구글이 T5 이후에 개발한 모델 또는 학습 기법</strong>이며, <strong>텍스트 생성과 이해를 모두 강화</strong>하기 위한 방향성을 가진다.</p>
</section>
<section id="flan-fine-tuned-language-net-2022" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="flan-fine-tuned-language-net-2022"><span class="header-section-number">3.8</span> FLAN (Fine-tuned LAnguage Net, 2022)</h2>
<ul>
<li><strong>FLAN은 “Instruction Tuning”의 대표적 구현</strong>으로, <strong>UL2와 같은 사전학습된 언어 모델에 다양한 명령어(Task Prompt)를 학습시키는 과정</strong>이다.</li>
<li>FLAN은 T5 또는 UL2-T5에 적용되어 등장했으며, FLAN-T5, FLAN-UL2 같은 이름으로 모델이 배포된다.</li>
<li>목표는 <strong>명령어(prompt)를 이해하고 정확히 수행하는 능력 강화</strong>이다.</li>
<li>동작 방식
<ul>
<li>먼저 T5 또는 UL2-T5 모델을 준비한다.</li>
<li>그런 다음 <strong>Instruction Tuning</strong>을 수행한다. → 다양한 NLP 작업(요약, 번역, 추론, QA 등)을 명시적인 지시문 형식으로 학습</li>
</ul></li>
<li>예시:
<ul>
<li>입력: <code>"Translate English to French: I am happy."</code></li>
<li>출력: <code>"Je suis heureux."</code></li>
<li>입력: <code>"Summarize: The sun is hot. It rises in the east."</code></li>
<li>출력: <code>"The sun is hot and rises in the east."</code></li>
</ul></li>
<li>특징
<ul>
<li>다양한 명령어와 태스크를 학습시켜, <strong>프롬프트 이해 능력을 대폭 향상</strong>시킴</li>
<li><strong>Zero-shot / Few-shot</strong> 능력이 크게 향상됨</li>
<li>단순한 텍스트 생성 모델이 아닌 <strong>명령어 기반의 범용 도우미로 진화</strong></li>
</ul></li>
<li>요약
<ul>
<li>FLAN은 모델이 아니라 <strong>Instruction tuning 과정 또는 결과 모델 이름</strong>이다.</li>
<li>일반 언어모델에 <strong>명령어 기반 태스크 학습을 추가한 것</strong></li>
<li>대표적인 모델: <strong>FLAN-T5</strong>, <strong>FLAN-UL2</strong></li>
<li>현재 Gemini, PaLM, ChatGPT 등의 <strong>Instruction Following 능력의 기초가 된 전략</strong></li>
</ul></li>
</ul>
</section>
<section id="ul2unifying-language-learning.-2023" class="level2" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="ul2unifying-language-learning.-2023"><span class="header-section-number">3.9</span> UL2(Unifying Language Learning. 2023)</h2>
<ul>
<li><strong>UL2는 “Unifying Language Learning”의 약자</strong>로, 구글이 제안한 새로운 <strong>사전학습 방식</strong>이다.</li>
<li>목적은 기존 T5, BERT, GPT 계열 모델들의 <strong>단점을 보완하고 장점을 융합</strong>하는 것에 있다.</li>
<li><strong>이해 중심 태스크와 생성 중심 태스크 모두에 잘 작동</strong>하는 범용 사전학습 전략이다.</li>
<li>UL2는 기존 T5 구조를 사용하지만, <strong>학습 방식(프리트레이닝)이 완전히 다르다.</strong></li>
<li>동작 방식
<ul>
<li>UL2는 한 가지 방식이 아닌 <strong>세 가지 프리트레이닝 모드</strong>를 혼합하여 학습한다:
<ol type="1">
<li><strong>R-denoising (Random span masking)</strong>: T5처럼 일부 span을 가리고 복원</li>
<li><strong>X-denoising (Extreme masking)</strong>: 전체 문장을 거의 다 가리고 생성</li>
<li><strong>Causal LM</strong>: GPT처럼 왼쪽에서 오른쪽으로 생성 (Autoregressive) → 이 세 가지 모드를 비율에 따라 섞어 학습시킴 (Multi-task 사전학습)</li>
</ol></li>
</ul></li>
<li>예시:
<ul>
<li>입력: <code>fill in the blanks: The &lt;extra_id_0&gt; sat on the &lt;extra_id_1&gt;.</code></li>
<li>출력: <code>cat</code>, <code>mat</code></li>
<li>또는 GPT처럼 입력: <code>"The cat sat on"</code> → 출력: <code>" the mat."</code></li>
</ul></li>
<li>특징
<ul>
<li><strong>세 가지 방식의 장점을 융합</strong>하여 → 문장 이해 + 생성 모두에 강함</li>
<li>기존 T5는 디코더에서도 마스킹된 부분을 전부 본다 (비자연스러움) → UL2는 자연스러운 생성을 위해 <strong>Causal 방식도 병행</strong></li>
<li>다양한 태스크에 잘 작동하도록 설계됨</li>
</ul></li>
<li>요약
<ul>
<li>UL2는 모델이 아니라 <strong>사전학습 전략</strong>이다.</li>
<li>기존 Transformer 구조에 적용할 수 있음 (예: T5에 적용하면 UL2-T5)</li>
<li><strong>다양한 프리트레이닝 모드를 섞어 범용성과 자연스러움 극대화</strong></li>
<li>이후 FLAN 및 다양한 구글 LLM 개발의 기반이 됨</li>
</ul></li>
</ul>
</section>
<section id="결론" class="level2" data-number="3.10">
<h2 data-number="3.10" class="anchored" data-anchor-id="결론"><span class="header-section-number">3.10</span> 결론</h2>
<p>사전 학습 모델의 발전은 자연어 처리 분야에서 가장 중요한 패러다임 변화 중 하나다. 2015년 Google의 LSTM 실험부터 시작된 이 여정은 현재 우리가 사용하는 ChatGPT, Claude, Gemini 등 모든 대규모 언어 모델의 토대가 되었다.</p>
<ul>
<li><strong>기술적 진화의 핵심</strong>:
<ul>
<li><strong>정적 → 동적</strong>: Word2Vec에서 ELMo로의 전환으로 문맥 기반 표현 실현</li>
<li><strong>순차 → 병렬</strong>: Transformer의 등장으로 Self-Attention 기반 병렬 처리 가능</li>
<li><strong>단일 → 통합</strong>: T5의 텍스트-투-텍스트 프레임워크로 모든 NLP 태스크 통합</li>
<li><strong>일반 → 특화</strong>: GPT(생성), BERT(이해), BART(양방향) 등 목적별 특화</li>
</ul></li>
<li><strong>패러다임의 변화</strong>:
<ul>
<li><strong>Pre-training + Fine-tuning</strong>: 대규모 데이터로 사전 학습 후 특정 태스크 미세조정</li>
<li><strong>Transfer Learning</strong>: 학습된 지식을 다양한 하위 태스크로 전이</li>
<li><strong>Few-shot Learning</strong>: GPT 계열에서 보여준 예시 기반 학습 능력</li>
<li><strong>Instruction Following</strong>: FLAN으로 대표되는 명령어 이해 및 수행 능력</li>
</ul></li>
<li><strong>각 모델의 독특한 기여</strong>:
<ul>
<li><strong>ELMo</strong>: 문맥 기반 임베딩의 가능성 입증</li>
<li><strong>Transformer</strong>: 현대 AI의 기초 아키텍처 제공</li>
<li><strong>BERT</strong>: 양방향 문맥 이해의 혁신적 접근</li>
<li><strong>GPT</strong>: 생성형 AI와 In-context Learning의 선구자</li>
<li><strong>T5</strong>: 통합 프레임워크를 통한 범용성 확보</li>
<li><strong>LLaMA</strong>: 효율성과 성능의 균형점 제시</li>
</ul></li>
<li><strong>현재와 미래의 의미</strong>:
<ul>
<li>이들 모델은 단순한 기술적 발전을 넘어 AI와 인간의 상호작용 방식을 근본적으로 변화시켰다</li>
<li>ChatGPT의 성공으로 이어진 생성형 AI 붐의 기술적 토대 제공</li>
<li>언어 이해와 생성 능력의 비약적 향상으로 다양한 실용적 응용 가능</li>
</ul></li>
<li><strong>지속되는 혁신</strong>:
<ul>
<li>모델 크기와 성능의 지속적 확장</li>
<li>효율성과 접근성 개선을 위한 경량화 연구</li>
<li>다중 모달(텍스트, 이미지, 음성) 통합 모델로의 발전</li>
<li>더 나은 Instruction Following과 안전성 확보</li>
</ul></li>
</ul>
<p>사전 학습 모델의 발전은 여전히 진행 중이며, 각 모델이 제시한 핵심 아이디어들은 미래 AI 시스템의 기초가 되고 있다. 이러한 기술적 토대 위에서 더욱 강력하고 유용한 AI 시스템들이 계속 등장할 것으로 예상된다.</p>


</section>
</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/21.ptm_overview.html</guid>
  <pubDate>Mon, 20 Jan 2025 15:00:00 GMT</pubDate>
</item>
<item>
  <title>텍스트 벡터화: 신경망 기반 방법론</title>
  <dc:creator>Kwangmin Kim</dc:creator>
  <link>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/20.transformer.html</link>
  <description><![CDATA[ 




<section id="요약" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> 요약</h1>
<p>이 문서는 단어의 의미가 문맥에 따라 변하는 현상을 효과적으로 다루기 위해 등장한 <strong>동적/문맥적 임베딩(Contextualized Embedding)</strong> 방법론을 탐구한다. 정적 임베딩의 한계를 지적하고, 이를 극복하기 위한 주요 모델들의 핵심 아이디어와 특징을 소개한다.</p>
<p>주요 내용은 다음과 같다.</p>
<ul>
<li><strong>정적 임베딩 vs.&nbsp;동적 임베딩</strong>:
<ul>
<li>정적 임베딩(예: Word2Vec, GloVe)은 단어마다 고정된 벡터를 할당하여 문맥에 따른 의미 변화(다의성)를 포착하지 못하는 한계가 있다.</li>
<li>동적 임베딩은 동일한 단어라도 문맥에 따라 다른 벡터 표현을 생성하여 이러한 문제를 해결한다.</li>
</ul></li>
<li><strong>주요 문맥 기반 임베딩 모델</strong>:
<ul>
<li><strong>ELMo (Embeddings from Language Models)</strong>: 양방향 LSTM(BiLSTM)의 각 계층에서 얻은 내부 상태들을 가중합하여 문맥 정보를 풍부하게 담은 임베딩을 생성한다. 문자 단위 표현부터 시작하여 다양한 수준의 정보를 결합한다.</li>
<li><strong>BERT (Bidirectional Encoder Representations from Transformers)</strong>: 트랜스포머(Transformer)의 인코더 구조를 활용하여 문장 내 모든 단어의 양방향 문맥을 동시에 고려한다. ’Masked Language Model(MLM)’과 ’Next Sentence Prediction(NSP)’이라는 두 가지 혁신적인 사전 학습(pre-training) 목표를 통해 깊은 언어 이해 능력을 학습한다. 문서 전체의 표현으로는 <code>[CLS]</code> 토큰의 출력을 사용하거나 토큰 출력들의 풀링(pooling) 결과를 활용한다.</li>
<li><strong>SBERT (Sentence-BERT)</strong>: BERT의 출력을 문장 수준의 의미론적 벡터로 효율적으로 변환하기 위해 Siamese 또는 Triplet 네트워크 구조를 사용한다. 이를 통해 문장 간 유사도 계산 및 대규모 검색 작업의 효율성을 크게 향상시킨다.</li>
<li><strong>GPT (Generative Pre-trained Transformer)</strong>: 트랜스포머의 디코더 구조를 기반으로 하는 단방향(autoregressive) 언어 모델이다. 이전 단어들을 바탕으로 다음 단어를 예측하도록 학습하며, 이 과정에서 문맥을 이해하고 생성하는 능력을 키운다. 특히, 가중치 업데이트 없이 프롬프트에 몇 가지 예시(few-shot)를 제공하는 것만으로 새로운 작업을 수행하는 ‘In-context Learning’ 능력으로 주목받았다. 문서 표현으로는 첫 번째 토큰([BOS])의 출력을 활용하기도 한다.</li>
</ul></li>
<li><strong>실용적 응용 및 평가</strong>:
<ul>
<li>이러한 모델들은 문서 분류, 정보 검색, 질의응답, 기계 번역 등 다양한 NLP 태스크에서 혁신적인 성능 향상을 가져왔다.</li>
<li>모델 평가는 단어 유사도나 관계 유추 같은 내재적 평가(intrinsic evaluation)와 실제 다운스트림 태스크에서의 성능을 측정하는 외재적 평가(extrinsic evaluation)로 이루어진다.</li>
</ul></li>
</ul>
<p>이 문서를 통해 독자는 문맥을 이해하는 동적 임베딩 기술의 발전 과정과 핵심 원리를 파악하고, 다양한 NLP 문제 해결에 이를 어떻게 활용할 수 있는지에 대한 통찰을 얻을 수 있다.</p>
</section>
<section id="텍스트-인코딩-및-벡터화" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> 텍스트 인코딩 및 벡터화</h1>
<pre><code>텍스트 벡터화
├── 1. 전통적 방법 (통계 기반)
│   ├── BoW
│   ├── DTM
│   └── TF-IDF
│
├── 2. 신경망 기반 (문맥 독립)
│   ├── 문맥 독립적 임베딩
│   │   └── Embedding Layer (딥러닝 모델 내 구성 요소)
│   ├── Word2Vec (CBOW, Skip-gram)
│   ├── FastText
│   ├── GloVe
│   └── 기타 모델: Swivel, LexVec 등
│
└── 3. 문맥 기반 임베딩 (Contextual Embedding)
    ├── RNN 계열
    │   ├── LSTM
    │   ├── GRU
    │   └── ELMo
    └── Attention 메커니즘
        ├── Basic Attention
        ├── Self-Attention
        └── Multi-Head Attention
 
Transformer 이후 생성형 모델 발전 계열
├── Transformer 구조 (Vaswani et al., 2017)
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa
|   └── ALBERT
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
├── 한국어 특화: KoBERT, KoGPT, KLU-BERT 등 (Kakao,2019~)
└── 기타 발전 모델
    ├── T5, XLNet, ELECTRA
    └── PaLM, LaMDA, Gemini, Claude 등</code></pre>
<section id="문맥을-고려한-벡터화-2018-현재-동적-임베딩" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="문맥을-고려한-벡터화-2018-현재-동적-임베딩"><span class="header-section-number">2.1</span> 문맥을 고려한 벡터화 (2018-현재): 동적 임베딩</h2>
<section id="elmo-embedding-from-language-models-2018" class="level4" data-number="2.1.0.1">
<h4 data-number="2.1.0.1" class="anchored" data-anchor-id="elmo-embedding-from-language-models-2018"><span class="header-section-number">2.1.0.1</span> ELMo (Embedding from Language Models, 2018)</h4>
<ul>
<li>ELMo 수식: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BELMo%7D_k%5E%7Btask%7D%20=%20%5Cgamma%5E%7Btask%7D%20%5Csum_%7Bj=0%7D%5EL%20s_j%5E%7Btask%7D%20%5Cmathbf%7Bh%7D_%7Bk,j%7D%5E%7BLM%7D">
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cmathbf%7Bh%7D_%7Bk,j%7D%5E%7BLM%7D">: 각 레이어의 hidden state</strong></li>
</ul>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예시: 3층 BiLSTM에서 "bank" 단어 (k번째 위치)</span></span>
<span id="cb2-2">h_{bank,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>} <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> character_embedding(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bank"</span>)     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 레이어 0 (입력)</span></span>
<span id="cb2-3">h_{bank,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>} <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> first_LSTM_layer_output        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 레이어 1  </span></span>
<span id="cb2-4">h_{bank,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>} <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> second_LSTM_layer_output       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 레이어 2</span></span>
<span id="cb2-5">h_{bank,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>} <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> third_LSTM_layer_output        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 레이어 3 (최상위)</span></span></code></pre></div>
<ul>
<li><strong><img src="https://latex.codecogs.com/png.latex?s_j%5E%7Btask%7D">: 학습 가능한 가중치</strong>
<ul>
<li>각 레이어의 중요도를 태스크별로 학습</li>
<li>문법적 태스크 → 낮은 레이어 중시</li>
<li>의미적 태스크 → 높은 레이어 중시</li>
</ul></li>
<li><strong><img src="https://latex.codecogs.com/png.latex?%5Cgamma%5E%7Btask%7D">: 전체 스케일 조정</strong>
<ul>
<li>ELMo 벡터의 전체적인 크기 조정</li>
</ul></li>
</ul></li>
<li>계산 예시</li>
</ul>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># "bank" 단어의 ELMo 벡터 (감정 분석 태스크)</span></span>
<span id="cb3-2">h_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 문자 레벨</span></span>
<span id="cb3-3">h_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 낮은 레벨 (문법적)  </span></span>
<span id="cb3-4">h_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 높은 레벨 (의미적)</span></span>
<span id="cb3-5"></span>
<span id="cb3-6">s_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 문자 레벨 가중치 (낮음)</span></span>
<span id="cb3-7">s_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 문법 레벨 가중치  </span></span>
<span id="cb3-8">s_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 의미 레벨 가중치 (높음)</span></span>
<span id="cb3-9"></span>
<span id="cb3-10">ELMo_bank <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> γ × (s_0×h_0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> s_1×h_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> s_2×h_2)</span>
<span id="cb3-11">          <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span> × (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>×[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>×[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>×[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>])</span>
<span id="cb3-12">          <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.0</span> × [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.55</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.65</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>]</span>
<span id="cb3-13">          <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>]</span></code></pre></div>
<ul>
<li>양방향 정보의 중요성
<ul>
<li><strong>Forward만 사용할 경우:</strong></li>
</ul>
<pre><code>"The bank was closed because of ___"
→ "bank"를 이해할 때 "The"만 참고</code></pre>
<ul>
<li><strong>Backward까지 사용할 경우:</strong></li>
</ul>
<pre><code>"The bank was closed because of ___"
→ "bank"를 이해할 때 "was closed" 정보도 참고
→ 금융 기관으로 해석 가능성 증가</code></pre></li>
</ul>
</section>
<section id="bert-bidirectional-encoder-representations-from-transformers-2018" class="level4" data-number="2.1.0.2">
<h4 data-number="2.1.0.2" class="anchored" data-anchor-id="bert-bidirectional-encoder-representations-from-transformers-2018"><span class="header-section-number">2.1.0.2</span> BERT (Bidirectional Encoder Representations from Transformers, 2018)</h4>
<ul>
<li>양방향 문맥 동시 고려
<ul>
<li>15% 단어를 마스킹하여 예측</li>
<li>문장 간 관계 학습</li>
</ul></li>
<li><strong>핵심 혁신:</strong>
<ul>
<li><strong>Transformer 기반</strong>: 양방향 문맥 동시 고려
<ul>
<li><p><strong>기존 RNN의 한계:</strong></p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># RNN은 순차적 처리 (병렬화 어려움)</span></span>
<span id="cb6-2">h_1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RNN(x_1)</span>
<span id="cb6-3">h_2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RNN(x_2, h_1)      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># h_1이 완료되어야 시작 가능</span></span>
<span id="cb6-4">h_3 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RNN(x_3, h_2)      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># h_2가 완료되어야 시작 가능</span></span></code></pre></div></li>
<li><p><strong>Transformer의 장점:</strong></p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모든 위치를 동시에 처리 (병렬화 가능)</span></span>
<span id="cb7-2">attention_weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> compute_attention(all_words)</span>
<span id="cb7-3">all_representations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> apply_attention(all_words, attention_weights)</span></code></pre></div></li>
</ul></li>
<li><strong>Masked Language Model</strong>: 15% 단어를 마스킹하여 예측
<ul>
<li>BERT의 핵심 학습 방법
<ul>
<li><strong>기본 아이디어</strong>: 일부 단어를 숨기고 맞추게 하기</li>
</ul>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 원본 문장</span></span>
<span id="cb8-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"나는 [MASK]를 좋아한다"</span></span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모델이 학습하는 것</span></span>
<span id="cb8-5">P(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"사과"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 [MASK]를 좋아한다"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span></span>
<span id="cb8-6">P(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"바나나"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 [MASK]를 좋아한다"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>  </span>
<span id="cb8-7">P(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"컴퓨터"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 [MASK]를 좋아한다"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span></span></code></pre></div>
<ul>
<li><strong>15% 마스킹 전략:</strong></li>
</ul>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">입력 문장의 <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> 단어에 대해:</span>
<span id="cb9-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>: [MASK] 토큰으로 교체</span>
<span id="cb9-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>: 랜덤한 다른 단어로 교체  </span>
<span id="cb9-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>: 원래 단어 그대로 유지</span></code></pre></div>
<ul>
<li><p><strong>왜 이렇게 하는가?</strong> ```python # 80% [MASK]: 메인 학습 목적 “나는 [MASK]를 좋아한다”</p>
<p># 10% 랜덤 교체: 노이즈에 강한 표현 학습 “나는 컴퓨터를 좋아한다” # 원래는 “사과”</p>
<p># 10% 원본 유지: 실제 사용 시와 동일한 조건 “나는 사과를 좋아한다” ```</p></li>
</ul></li>
</ul></li>
<li><strong>Next Sentence Prediction</strong>: 문장 간 관계 학습</li>
</ul>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 실제 연속된 문장 (Positive)</span></span>
<span id="cb10-2">문장A: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 아침에 일어났다"</span></span>
<span id="cb10-3">문장B: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"그리고 아침 식사를 했다"</span></span>
<span id="cb10-4">Label: IsNext <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 랜덤하게 조합된 문장 (Negative)  </span></span>
<span id="cb10-7">문장A: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 아침에 일어났다"</span></span>
<span id="cb10-8">문장B: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"축구는 재미있는 스포츠다"</span></span>
<span id="cb10-9">Label: IsNext <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span></code></pre></div></li>
<li><strong>BERT의 문서 벡터화 방법:</strong>
<ul>
<li><strong>[CLS] 토큰</strong>: 문장/문서 전체 표현</li>
</ul>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">입력: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[CLS] 문장 내용 [SEP]"</span></span>
<span id="cb11-2">출력: [CLS]_벡터가 전체 문장의 의미를 담음</span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예시</span></span>
<span id="cb11-5">input_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[CLS]"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"사과를"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"좋아한다"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[SEP]"</span>]</span>
<span id="cb11-6">bert_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> bert_model(input_tokens)</span>
<span id="cb11-7">sentence_vector <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> bert_output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [CLS] 위치의 벡터</span></span></code></pre></div>
<ul>
<li><strong>Pooling 전략</strong>:
<ul>
<li>Mean pooling: <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20%5Cmathbf%7Bh%7D_i"></li>
<li>Max pooling: <img src="https://latex.codecogs.com/png.latex?%5Cmax(%5Cmathbf%7Bh%7D_1,%20...,%20%5Cmathbf%7Bh%7D_n)"></li>
</ul>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 모든 토큰의 BERT 출력</span></span>
<span id="cb12-2">token_representations <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb12-3">   [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [CLS]</span></span>
<span id="cb12-4">   [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># "나는"  </span></span>
<span id="cb12-5">   [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># "사과를"</span></span>
<span id="cb12-6">   [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># "좋아한다"</span></span>
<span id="cb12-7">   [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>],  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [SEP]</span></span>
<span id="cb12-8">]</span>
<span id="cb12-9"></span>
<span id="cb12-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Mean Pooling</span></span>
<span id="cb12-11">mean_vector <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mean(token_representations[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [CLS], [SEP] 제외</span></span>
<span id="cb12-12"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb12-13"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.43</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.53</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.63</span>]</span>
<span id="cb12-14"></span>
<span id="cb12-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Max Pooling  </span></span>
<span id="cb12-16">max_vector <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(token_representations[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 차원별 최댓값</span></span>
<span id="cb12-17"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>]</span></code></pre></div></li>
</ul></li>
<li><strong>특징</strong>:
<ul>
<li>단어의 의미적, 문법적 정보를 벡터 공간에 학습.</li>
<li>벡터 간 연산을 통해 단어 간 유사도, 유추 등 관계 표현 가능 (예: “king” - “man” + “woman” ≈ “queen”).</li>
</ul></li>
<li><strong>중요성</strong>: 현대 NLP 딥러닝 모델의 핵심 구성 요소로, 성능 향상에 크게 기여.</li>
</ul>
</section>
<section id="sbert-sentence-bert" class="level4" data-number="2.1.0.3">
<h4 data-number="2.1.0.3" class="anchored" data-anchor-id="sbert-sentence-bert"><span class="header-section-number">2.1.0.3</span> SBERT (Sentence-BERT)</h4>
<ul>
<li><p>최근 가장 보편적인 문장 또는 문서 임베딩 방법으로 SBERT가 이용된다.</p></li>
<li><p>문서의 유사도를 구할 때는 SBERT 사용을 권장</p></li>
<li><p>문장 벡터화 전략</p>
<ul>
<li>문장 간 유사도 계산</li>
<li>문장 간 유사도 계산 시 문장 임베딩 사용</li>
</ul></li>
<li><p>기존 BERT의 한계: 문장 유사도 계산의 비효율성</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1000개 문장의 유사도를 모두 구하려면</span></span>
<span id="cb13-2">sentences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"문장1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"문장2"</span>, ..., <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"문장1000"</span>]</span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 기존 BERT 방식 (비효율적)</span></span>
<span id="cb13-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>):</span>
<span id="cb13-6">   <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>):</span>
<span id="cb13-7">      combined <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[CLS] </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sentences[i]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> [SEP] </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sentences[j]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> [SEP]"</span></span>
<span id="cb13-8">      similarity <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> bert_classifier(combined)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 매번 BERT 실행</span></span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 총 계산 횟수: 1000 × 999 / 2 = 499,500번!</span></span></code></pre></div>
<ul>
<li>BERT로 문장 유사도를 계산하려면:
<ul>
<li>두 문장을 [SEP]로 연결</li>
<li>BERT에 입력하여 분류</li>
<li><img src="https://latex.codecogs.com/png.latex?O(n%5E2)"> 시간 복잡도 (n개 문장 비교 시)</li>
</ul></li>
</ul></li>
<li><p>SBERT의 해결책: Siamese Network 구조</p></li>
</ul>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># SBERT 방식 (효율적)</span></span>
<span id="cb14-2"></span>
<span id="cb14-3">문장 A → BERT → Pooling → Vector A</span>
<span id="cb14-4">문장 B → BERT → Pooling → Vector B</span>
<span id="cb14-5">유사도 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cosine_similarity(Vector A, Vector B)</span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1단계: 모든 문장을 미리 벡터화</span></span>
<span id="cb14-8">sentence_vectors <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb14-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> sentence <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> sentences:</span>
<span id="cb14-10">    vector <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sbert_model(sentence)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 각 문장마다 1번씩만 실행</span></span>
<span id="cb14-11">    sentence_vectors.append(vector)</span>
<span id="cb14-12"></span>
<span id="cb14-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2단계: 벡터 간 코사인 유사도로 빠른 계산</span></span>
<span id="cb14-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>):</span>
<span id="cb14-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>):</span>
<span id="cb14-16">        similarity <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cosine_similarity(sentence_vectors[i], sentence_vectors[j])</span>
<span id="cb14-17">        </span>
<span id="cb14-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 총 SBERT 실행 횟수: 1000번 (대폭 감소!)</span></span></code></pre></div>
<ul>
<li><strong>학습 목적 함수:</strong>
<ul>
<li><strong>Classification</strong>: <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%20=%20-%5Csum_%7Bi%7D%20y_i%20%5Clog(%5Ctext%7Bsoftmax%7D(W%5B%5Cmathbf%7Bu%7D;%20%5Cmathbf%7Bv%7D;%20%7C%5Cmathbf%7Bu%7D-%5Cmathbf%7Bv%7D%7C%5D))"></li>
</ul>
<div class="sourceCode" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 두 문장의 SBERT 벡터</span></span>
<span id="cb15-2">u <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sbert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 사과를 좋아한다"</span>)      <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [0.2, 0.4, 0.1, ...]</span></span>
<span id="cb15-3">v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> sbert(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 바나나를 좋아한다"</span>)    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [0.3, 0.5, 0.2, ...]</span></span>
<span id="cb15-4"></span>
<span id="cb15-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 특성 벡터 구성</span></span>
<span id="cb15-6">concat <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [u<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> v]                    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 연결: [0.2, 0.4, 0.1, 0.3, 0.5, 0.2, ...]</span></span>
<span id="cb15-7">abs_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span>u <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> v<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span>                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 절댓값 차이: [0.1, 0.1, 0.1, ...]</span></span>
<span id="cb15-8">features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [u<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> v<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> abs_diff]        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 최종 특성 벡터</span></span>
<span id="cb15-9"></span>
<span id="cb15-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 분류 (유사/비유사)</span></span>
<span id="cb15-11">logits <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> W <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> b</span>
<span id="cb15-12">probability <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> softmax(logits)</span>
<span id="cb15-13">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cross_entropy(probability, true_label)</span></code></pre></div>
<ul>
<li><strong>Regression</strong>: <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D%20=%20%5Ctext%7BMSE%7D(%5Ctext%7Bcosine%5C_sim%7D(%5Cmathbf%7Bu%7D,%20%5Cmathbf%7Bv%7D),%20%5Ctext%7Blabel%7D)"></li>
</ul>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 예측 유사도</span></span>
<span id="cb16-2">predicted_sim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cosine_similarity(u, v) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span></span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 실제 라벨 (0~1 점수)</span></span>
<span id="cb16-5">true_sim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 사람이 평가한 유사도</span></span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 손실 계산</span></span>
<span id="cb16-8">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (predicted_sim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> true_sim)² <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.85</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>)² <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0025</span></span></code></pre></div></li>
<li><strong>성능 개선:</strong>
<ul>
<li>시간 복잡도: <img src="https://latex.codecogs.com/png.latex?O(n%5E2)%20%5Crightarrow%20O(n)"></li>
</ul>
<div class="sourceCode" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 시간 복잡도 비교</span></span>
<span id="cb17-2">기존_BERT_시간 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> O(n²) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">²</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000</span></span>
<span id="cb17-3">SBERT_시간 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> O(n) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb17-4"></span>
<span id="cb17-5">속도_향상 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">000</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span><span class="er" style="color: #AD0000;
background-color: null;
font-style: inherit;">배</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span></span></code></pre></div>
<ul>
<li>의미적 유사도 정확도 대폭 향상</li>
<li>대규모 문서 검색 시스템</li>
<li>실시간 문장 유사도 계산</li>
<li>추천 시스템에서의 텍스트 매칭</li>
</ul></li>
</ul>
</section>
<section id="gptgenerative-pre-trained-transformer" class="level4" data-number="2.1.0.4">
<h4 data-number="2.1.0.4" class="anchored" data-anchor-id="gptgenerative-pre-trained-transformer"><span class="header-section-number">2.1.0.4</span> GPT(Generative Pre-trained Transformer)</h4>
<ul>
<li><p>단방향 언어 모델의 핵심 개념</p></li>
<li><p>BERT vs GPT의 근본적 차이</p></li>
<li><p><strong>BERT (양방향)</strong>:</p>
<pre><code>입력: "나는 [MASK]를 좋아한다"
모델이 보는 정보: "나는" + "를 좋아한다" (양쪽 모두)
예측: [MASK] = "사과"</code></pre></li>
<li><p><strong>GPT (단방향)</strong>:</p>
<pre><code>입력: "나는 사과를"
모델이 보는 정보: "나는 사과를" (왼쪽만)
예측: 다음 단어 = "좋아한다"</code></pre></li>
<li><p>왜 단방향일까?</p>
<ul>
<li><p><strong>생성 태스크의 특성</strong>:</p>
<div class="sourceCode" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 실제 텍스트 생성 시</span></span>
<span id="cb20-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"안녕하세요, 오늘 날씨가"</span></span>
<span id="cb20-3">→ 모델: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"좋네요"</span> (미래 정보는 알 수 없음)</span>
<span id="cb20-4"></span>
<span id="cb20-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 만약 양방향이라면?</span></span>
<span id="cb20-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"안녕하세요, 오늘 날씨가 [미래정보] 입니다"</span></span>
<span id="cb20-7">→ 실제 생성 시에는 미래 정보가 없으므로 불일치</span></code></pre></div></li>
</ul></li>
<li><p><strong>GPT의 학습 방식: Autoregressive Language Modeling</strong></p>
<ul>
<li><p>이전 토큰들로 다음 토큰 예측</p></li>
<li><p>수학적 목적 함수: <img src="https://latex.codecogs.com/png.latex?P(%5Ctext%7B%EB%AC%B8%EC%9E%A5%7D)%20=%20%5Cprod_%7Bt=1%7D%5ET%20P(w_t%20%7C%20w_1,%20w_2,%20...,%20w_%7Bt-1%7D)"></p>
<ul>
<li>문장의 확률 = 각 단어가 이전 단어들 조건 하에 나타날 확률의 곱</li>
</ul></li>
<li><p>구체적 학습 예시</p>
<ul>
<li><strong>훈련 문장</strong>: “나는 사과를 좋아한다”</li>
</ul>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 학습 데이터 구성</span></span>
<span id="cb21-2">입력 → 정답</span>
<span id="cb21-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"나는"</span> → <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"사과를"</span></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"나는 사과를"</span> → <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"좋아한다"</span>  </span>
<span id="cb21-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"나는 사과를 좋아한다"</span> → <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"&lt;끝&gt;"</span></span>
<span id="cb21-6"></span>
<span id="cb21-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 손실 함수</span></span>
<span id="cb21-8">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>log P(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"사과를"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는"</span>) </span>
<span id="cb21-9">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>log P(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"좋아한다"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 사과를"</span>)</span>
<span id="cb21-10">      <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>log P(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"&lt;끝&gt;"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"나는 사과를 좋아한다"</span>)</span></code></pre></div></li>
<li><p>Causal Masking (인과 마스킹)</p>
<ul>
<li>Attention에서 미래 정보 차단</li>
</ul>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Attention Matrix (4개 단어 예시)</span></span>
<span id="cb22-2">        나는  사과를  좋아한다  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>끝<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span></span>
<span id="cb22-3">나는     ✓     ✗      ✗      ✗</span>
<span id="cb22-4">사과를    ✓     ✓      ✗      ✗  </span>
<span id="cb22-5">좋아한다  ✓     ✓      ✓      ✗</span>
<span id="cb22-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span>끝<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>     ✓     ✓      ✓      ✓</span>
<span id="cb22-7"></span>
<span id="cb22-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ✓: 참고 가능, ✗: 마스킹 (참고 불가)</span></span></code></pre></div></li>
<li><p><strong>코드 구현</strong>:</p>
<div class="sourceCode" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 마스킹 행렬</span></span>
<span id="cb23-2">mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tril(torch.ones(seq_len, seq_len))</span>
<span id="cb23-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 상삼각 부분을 -무한대로 설정</span></span>
<span id="cb23-4">attention_scores.masked_fill_(mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e9</span>)</span>
<span id="cb23-5">attention_weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> softmax(attention_scores)</span></code></pre></div></li>
</ul></li>
<li><p><strong>첫 번째 토큰을 문서 표현으로 활용</strong></p>
<ul>
<li>정보 흐름의 특성
<ul>
<li>입력: “[BOS] 문장 내용들…”</li>
<li>각 토큰이 보는 정보량</li>
<li>토큰1 ([BOS]): 자기 자신만</li>
<li>토큰2: [BOS] + 토큰2<br>
</li>
<li>토큰3: [BOS] + 토큰2 + 토큰3</li>
</ul></li>
</ul></li>
<li><p><strong>왜 첫 번째 토큰인가?</strong></p>
<ul>
<li>정보 흐름의 특성
<ul>
<li>입력: “[BOS] 문장 내용들…”</li>
<li>각 토큰이 보는 정보량</li>
<li>토큰1 ([BOS]): 자기 자신만</li>
<li>토큰2: [BOS] + 토큰2<br>
</li>
<li>토큰3: [BOS] + 토큰2 + 토큰3</li>
<li>마지막토큰: [BOS] + 전체 문장</li>
<li>역설적으로, [BOS]는 전체 문장을 “예측”해야 하므로</li>
<li>전체 문장 정보를 압축한 표현을 학습하게 됨</li>
</ul></li>
<li>구체적 메커니즘
<ul>
<li>학습 과정에서의 압축</li>
</ul>
<div class="sourceCode" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPT가 학습하는 것</span></span>
<span id="cb24-2">P(전체_문장 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> [BOS]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> P(w1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span>[BOS]) × P(w2<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span>[BOS],w1) × ... × P(wn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span>[BOS],w1,...,wn<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb24-3"></span>
<span id="cb24-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [BOS] 토큰은 "이 문장이 어떤 내용일까?"를 예측해야 함</span></span>
<span id="cb24-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># → 문장의 주제, 감정, 스타일 등을 함축하는 표현을 학습</span></span></code></pre></div></li>
</ul></li>
<li><p><strong>실제 활용 예시</strong>:</p>
<div class="sourceCode" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 문서 분류</span></span>
<span id="cb25-2">document <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[BOS] 이 영화는 정말 재미있었다. 스토리도 좋고..."</span></span>
<span id="cb25-3">gpt_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpt_model(document)</span>
<span id="cb25-4">document_vector <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpt_output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [BOS] 위치의 벡터</span></span>
<span id="cb25-5">classification <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> classifier(document_vector)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 긍정/부정 분류</span></span></code></pre></div></li>
<li><p><strong>In-context Learning 심화 분석</strong></p>
<ul>
<li>기존 학습 방식과의 차이
<ul>
<li><p><strong>전통적 학습 (Fine-tuning)</strong>:</p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 1단계: 새로운 태스크 데이터로 모델 가중치 업데이트</span></span>
<span id="cb26-2">model.train()</span>
<span id="cb26-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">for</span> batch <span class="kw" style="color: #003B4F;
background-color: null;
font-style: inherit;">in</span> task_data:</span>
<span id="cb26-4">   loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> compute_loss(model(batch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>), batch.target)</span>
<span id="cb26-5">   loss.backward()</span>
<span id="cb26-6">   optimizer.step()</span>
<span id="cb26-7"></span>
<span id="cb26-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 2단계: 추론</span></span>
<span id="cb26-9">prediction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model(new_input)</span></code></pre></div></li>
<li><p><strong>In-context Learning</strong>:</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 가중치 업데이트 없이, 입력에 예시를 포함</span></span>
<span id="cb27-2">context <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb27-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">번역 예시:</span></span>
<span id="cb27-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">영어: Hello → 한국어: 안녕하세요</span></span>
<span id="cb27-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">영어: Thank you → 한국어: 감사합니다  </span></span>
<span id="cb27-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">영어: Good morning → 한국어: 좋은 아침</span></span>
<span id="cb27-7"></span>
<span id="cb27-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">영어: How are you? → 한국어:</span></span>
<span id="cb27-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb27-10"></span>
<span id="cb27-11">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpt_model(context)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># "어떻게 지내세요?" 출력</span></span></code></pre></div></li>
</ul></li>
</ul></li>
<li><p><strong>왜 In-context Learning이 가능한가?</strong></p>
<ul>
<li><p>패턴 인식 능력</p>
<ul>
<li>GPT가 학습 중 본 패턴들</li>
<li>“A는 B이다. C는 D이다. E는” → F 예측</li>
<li>“1+1=2, 2+2=4, 3+3=” → 6 예측</li>
<li>“cat→고양이, dog→개, bird→” → 새 예측</li>
</ul></li>
<li><p>메타 학습 (Learning to Learn)</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 다양한 패턴을 학습하면서 "학습하는 방법"을 학습</span></span>
<span id="cb28-2">패턴<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>: 번역 (A→B 형태)</span>
<span id="cb28-3">패턴<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>: 수학 (계산 규칙)  </span>
<span id="cb28-4">패턴<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>: 분류 (라벨링 규칙)</span>
<span id="cb28-5"></span>
<span id="cb28-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 새로운 패턴이 주어져도 빠르게 적응</span></span></code></pre></div></li>
</ul></li>
<li><p><strong>실제 In-context Learning 예시</strong></p>
<ul>
<li><p><strong>감정 분석 태스크</strong>:</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb29-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">다음은 리뷰와 감정을 분류한 예시입니다:</span></span>
<span id="cb29-3"></span>
<span id="cb29-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">리뷰: "이 영화 정말 재미있어요!" 감정: 긍정</span></span>
<span id="cb29-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">리뷰: "시간 낭비였습니다." 감정: 부정</span></span>
<span id="cb29-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">리뷰: "그냥 그래요." 감정: 중립</span></span>
<span id="cb29-7"></span>
<span id="cb29-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">리뷰: "배우들 연기가 훌륭했습니다!" 감정:</span></span>
<span id="cb29-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb29-10"></span>
<span id="cb29-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPT 출력: "긍정"</span></span></code></pre></div></li>
<li><p><strong>번역 태스크</strong>:</p>
<div class="sourceCode" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">English to Korean translation:</span></span>
<span id="cb30-3"></span>
<span id="cb30-4"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">English: I love programming</span></span>
<span id="cb30-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Korean: 나는 프로그래밍을 좋아합니다</span></span>
<span id="cb30-6"></span>
<span id="cb30-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">English: The weather is nice today  </span></span>
<span id="cb30-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Korean: 오늘 날씨가 좋네요</span></span>
<span id="cb30-9"></span>
<span id="cb30-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">English: What time is it now?</span></span>
<span id="cb30-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Korean:</span></span>
<span id="cb30-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb30-13"></span>
<span id="cb30-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPT 출력: "지금 몇 시인가요?"</span></span></code></pre></div></li>
</ul></li>
<li><p><strong>GPT 발전사와 특징</strong></p>
<ul>
<li><strong>GPT-1 (2018)</strong>
<ul>
<li>크기: 117M 파라미터</li>
<li>특징: Transformer 디코더만 사용</li>
<li>성능: 간단한 텍스트 생성</li>
</ul></li>
<li><strong>GPT-2 (2019)</strong>
<ul>
<li>크기: 1.5B 파라미터</li>
<li>특징: 스케일 확장의 효과 입증</li>
<li>성능: 일관성 있는 긴 텍스트 생성</li>
</ul></li>
<li><strong>GPT-3 (2020)</strong>
<ul>
<li>크기: 175B 파라미터<br>
</li>
<li>특징: In-context Learning의 강력한 능력</li>
<li>성능: Few-shot Learning으로 다양한 태스크 수행</li>
</ul></li>
<li><strong>GPT-4 (2023)</strong>
<ul>
<li>크기: 공개되지 않음 (추정 수조 개)</li>
<li>특징: 멀티모달 (텍스트 + 이미지)</li>
<li>성능: 인간 수준에 근접한 성능</li>
</ul></li>
</ul></li>
<li><p><strong>GPT vs BERT 비교 정리</strong></p></li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>측면</th>
<th>GPT</th>
<th>BERT</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>방향성</strong></td>
<td>단방향 (왼쪽→오른쪽)</td>
<td>양방향</td>
</tr>
<tr class="even">
<td><strong>학습 목표</strong></td>
<td>다음 토큰 예측</td>
<td>마스킹된 토큰 예측</td>
</tr>
<tr class="odd">
<td><strong>주요 용도</strong></td>
<td>생성 태스크</td>
<td>이해 태스크</td>
</tr>
<tr class="even">
<td><strong>문서 벡터</strong></td>
<td>첫 번째 토큰</td>
<td>[CLS] 토큰</td>
</tr>
<tr class="odd">
<td><strong>특별 능력</strong></td>
<td>In-context Learning</td>
<td>Fine-tuning 효율성</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>결론</strong>: GPT는 “다음에 올 단어를 예측”하는 단순한 목표로 학습하지만, 이 과정에서 언어의 패턴, 의미, 추론 능력까지 학습하게 되어 강력한 생성 및 추론 모델이 되었다.</li>
</ul>
</section>
<section id="실용적-응용-및-평가" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="실용적-응용-및-평가"><span class="header-section-number">2.1.1</span> 실용적 응용 및 평가</h3>
<section id="평가-지표" class="level4" data-number="2.1.1.1">
<h4 data-number="2.1.1.1" class="anchored" data-anchor-id="평가-지표"><span class="header-section-number">2.1.1.1</span> 평가 지표</h4>
<p><strong>Intrinsic Evaluation (내재적 평가):</strong> - <strong>단어 유사도</strong>: WordSim-353, SimLex-999 - 사람이 평가한 단어 유사도와 모델 예측의 상관관계 측정 - <strong>단어 관계</strong>: “king - man + woman = queen” - 벡터 연산으로 의미 관계 포착 정도 평가</p>
<p><strong>Extrinsic Evaluation (외재적 평가):</strong> - <strong>문서 분류 정확도</strong>: 실제 분류 태스크에서의 성능 - <strong>정보 검색 성능</strong>: NDCG, MAP - 검색 결과의 관련성 및 순위 정확도 - <strong>의미적 텍스트 유사도</strong>: STS benchmark - 문장 간 의미적 유사성 예측 성능</p>
</section>
<section id="모델-선택-가이드" class="level4" data-number="2.1.1.2">
<h4 data-number="2.1.1.2" class="anchored" data-anchor-id="모델-선택-가이드"><span class="header-section-number">2.1.1.2</span> 모델 선택 가이드</h4>
<ul>
<li><strong>소규모 데이터</strong>: FastText (OOV 처리)</li>
<li><strong>대규모 문서 분류</strong>: BERT fine-tuning</li>
<li><strong>실시간 유사도 계산</strong>: SBERT</li>
<li><strong>창작/생성 태스크</strong>: GPT 계열</li>
</ul>
</section>
<section id="통계적-해석" class="level4" data-number="2.1.1.3">
<h4 data-number="2.1.1.3" class="anchored" data-anchor-id="통계적-해석"><span class="header-section-number">2.1.1.3</span> 통계적 해석</h4>
<p>임베딩 공간에서의 기하학적 관계: <img src="https://latex.codecogs.com/png.latex?%5Ccos(%5Cmathbf%7Bv%7D_%7B%5Ctext%7Bsimilar%20words%7D%7D)%20%3E%20%5Ccos(%5Cmathbf%7Bv%7D_%7B%5Ctext%7Bdissimilar%20words%7D%7D)"></p>
<p><strong>시각화 도구</strong>: t-SNE/UMAP을 통한 의미적 클러스터링 확인</p>
</section>
</section>
</section>
<section id="결론" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="결론"><span class="header-section-number">2.2</span> 결론</h2>
<p>본 문서에서는 단어의 고정된 의미 표현을 넘어, 문맥에 따라 유연하게 변화하는 의미를 포착하는 동적 임베딩 방법론들을 심층적으로 살펴보았다. ELMo에서 시작하여 BERT, GPT, SBERT에 이르기까지, 이러한 문맥 기반 임베딩 모델들은 자연어 처리(NLP) 분야에 혁명적인 발전을 가져왔다.</p>
<p>주요 내용을 다시 한번 정리하면 다음과 같다.</p>
<ul>
<li><p><strong>정적 임베딩의 한계 극복</strong>: 초기의 워드 임베딩(Word2Vec, GloVe 등)은 단어의 의미를 단일 벡터로 표현하여 문맥에 따른 다의성을 반영하지 못했다. 동적 임베딩은 이 한계를 극복하고, 동일한 단어라도 문맥에 따라 다른 벡터 표현을 생성함으로써 보다 정교한 의미 이해를 가능하게 했다.</p></li>
<li><p><strong>주요 모델들의 혁신과 기여</strong>:</p>
<ul>
<li><strong>ELMo</strong>: 양방향 LSTM을 통해 문맥 정보를 통합하고, 여러 계층의 표현을 활용하여 풍부한 임베딩을 제공했다.</li>
<li><strong>BERT</strong>: 트랜스포머 아키텍처와 Masked Language Model, Next Sentence Prediction과 같은 혁신적인 사전 학습 방식을 도입하여 양방향 문맥 이해의 새로운 지평을 열었다. 이는 다양한 NLP 다운스트림 태스크에서 SOTA(State-of-the-Art) 성능을 달성하는 데 크게 기여했다.</li>
<li><strong>GPT</strong>: 단방향 트랜스포머 디코더를 기반으로 강력한 텍스트 생성 능력을 보여주었으며, 특히 GPT-3 이후 모델들은 In-context Learning이라는 새로운 패러다임을 제시하며 모델 활용의 유연성을 크게 확장했다.</li>
<li><strong>SBERT</strong>: 기존 BERT 모델을 문장 임베딩 생성에 효율적으로 사용할 수 있도록 Siamese 및 Triplet 네트워크 구조를 활용하여, 의미적으로 유사한 문장 벡터를 효과적으로 생성하고 문장 간 유사도 비교 작업의 속도와 정확도를 크게 향상시켰다.</li>
</ul></li>
<li><p><strong>패러다임의 전환과 LLM의 토대</strong>: 이러한 문맥 기반 임베딩 모델들의 발전은 단순한 특징 추출기를 넘어, 언어 자체를 깊이 이해하고 생성할 수 있는 대규모 언어 모델(Large Language Models, LLMs) 시대로 나아가는 핵심적인 발판이 되었다. 사전 학습과 미세 조정(fine-tuning) 패러다임, 그리고 최근의 프롬프트 기반 학습은 모델의 활용 범위를 크게 넓혔다.</p></li>
<li><p><strong>적절한 전략 선택의 지속적 중요성</strong>: 해결하고자 하는 특정 문제의 요구사항, 가용 데이터의 특성, 계산 자원 등을 고려하여 가장 적합한 임베딩 전략과 모델을 선택하는 것은 여전히 중요하다. 실용적인 응용을 위해서는 모델의 성능뿐만 아니라 효율성, 해석 가능성 등도 함께 고려해야 한다.</p></li>
</ul>
<p>문맥을 이해하는 텍스트 벡터화 기술은 앞으로도 계속 발전하여, 기계가 인간의 언어를 더욱 정교하게 이해하고 상호작용하는 미래를 앞당길 것이다. 이러한 기술의 발전은 정보 검색, 질의응답, 창작, 교육 등 사회 여러 분야에 걸쳐 혁신적인 변화를 주도할 잠재력을 지니고 있다.</p>


</section>
</section>

 ]]></description>
  <category>NLP</category>
  <category>Deep Learning</category>
  <guid>kk3225.netlify.app/docs/blog/posts/Deep_Learning/NLP/20.transformer.html</guid>
  <pubDate>Sun, 19 Jan 2025 15:00:00 GMT</pubDate>
</item>
</channel>
</rss>
