{"title":"Matrix Transformation (3) - Linear Form","markdown":{"yaml":{"title":"Matrix Transformation (3) - Linear Form","subtitle":"Linear Regression, Fully Connected layers, Neural Networks, Linear Classifiers","description":"template\n","categories":["Mathematics"],"author":"Kwangmin Kim","date":"04/02/2023","format":{"html":{"page-layout":"full","code-fold":true,"toc":true,"number-sections":true}},"draft":false},"headingText":"Linear Form","containsRefs":false,"markdown":"\n\n\nA linear form is a linear function that maps a vector space to its underlying field. Let $V$ be a vector space over a field $\\mathbb{F}$, and let $\\mathcal{L}(V,\\mathbb{F})$ denote the set of all linear functions from $V$ to $\\mathbb{F}$. A linear form on $V$ is an element of $\\mathcal{L}(V,\\mathbb{F})$.\n\nA linear form $\\varphi$ can be represented by a row vector of dimension $1\\times n$, where $n$ is the dimension of $V$. Let ${\\mathbf{e}_1, \\mathbf{e}_2, \\dots, \\mathbf{e}_n}$ be a basis for $V$, and let ${\\alpha_1, \\alpha_2, \\dots, \\alpha_n}$ be the corresponding dual basis for $\\mathcal{L}(V,\\mathbb{F})$, such that $\\alpha_i(\\mathbf{e}j) = \\delta{ij}$ (the Kronecker delta). Then, any linear form $\\varphi\\in\\mathcal{L}(V,\\mathbb{F})$ can be written as:\n$$\n\\varphi(x)=\\sum_{i=1}^{n}a_ix_i=\\mathbf a \\mathbf x^T=\\mathbf x \\mathbf a\n$$\n\nwhere $\\mathbf{x}\\in V$ is a column vector of dimension $n\\times 1$, $[\\mathbf{a}]$ is the row vector representing $\\varphi$, and $[\\mathbf{x}]$ is the column vector representing $\\mathbf{x}$.\n\nFor example, let $V = \\mathbb{R}^2$ be the vector space of 2-dimensional column vectors, and let $\\varphi\\in\\mathcal{L}(V,\\mathbb{R})$ be the linear form defined by $\\varphi(\\begin{bmatrix}x\\y\\end{bmatrix}) = 3x - 2y$. Then, we can represent $\\varphi$ as:\n\n$$\n[\\mathbf a]=\\begin{bmatrix} 3 & -2\\end{bmatrix} [\\mathbf x]=\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\varphi(x)=\\sum_{i=1}^{n}\\mathbf a\\mathbf x^T=3x_1-2x_2\n$$\n\nwhich shows that $\\varphi$ is a linear form on $V$.\n\nconsider a linear regression model that predicts the price of a house based on its size and location. The model can be represented by the linear form:\n\n$$\n\\varphi(x)=\\mathbf w\\mathbf x^T=\\sum_{i=1}^{n}w_ix_i=w_0+w_1x_1+w_2x_2\n$$\n\nwhere $\\varphi(\\mathbf{x})$ is the predicted price, $x_1$ is the size of the house, $x_2$ is a measure of the location (such as the distance from the city center), and $w_0$, $w_1$, and $w_2$ are the model parameters that control the intercept and the weights of the features. This linear form can be written in matrix form as:\n\n$$\n\\varphi(x)=\\mathbf x\\mathbf w=\\mathbf w \\mathbf x^T\n$$\n\nwhere $[\\mathbf{w}]$ is a row vector of the model parameters and $[\\mathbf{x}]$ is a row vector of the features.\n\nLinear forms can also be used in deep learning and machine learning models that involve linear transformations, such as fully connected layers in neural networks or linear classifiers. For example, consider a simple linear classifier that classifies images of digits into one of 10 classes. The classifier can be represented by the linear form:\n\n$$\n\\varphi(x)=\\mathbf x\\mathbf w + b =\\mathbf w \\mathbf x^T +b\n$$\n\nwhere $\\varphi(\\mathbf{x})$ is the predicted class score, $[\\mathbf{x}]$ is a row vector of the pixel values of the image, $[\\mathbf{w}]$ is a row vector of the weights of the classifier, and $b$ is the bias term. This linear form can be used to classify the image by selecting the class with the highest score.\n\nIn both of these examples, linear forms are used to represent linear relationships between variables or features, and the model parameters are learned through training on a set of labeled examples.","srcMarkdownNoYaml":"\n\n## Linear Form\n\nA linear form is a linear function that maps a vector space to its underlying field. Let $V$ be a vector space over a field $\\mathbb{F}$, and let $\\mathcal{L}(V,\\mathbb{F})$ denote the set of all linear functions from $V$ to $\\mathbb{F}$. A linear form on $V$ is an element of $\\mathcal{L}(V,\\mathbb{F})$.\n\nA linear form $\\varphi$ can be represented by a row vector of dimension $1\\times n$, where $n$ is the dimension of $V$. Let ${\\mathbf{e}_1, \\mathbf{e}_2, \\dots, \\mathbf{e}_n}$ be a basis for $V$, and let ${\\alpha_1, \\alpha_2, \\dots, \\alpha_n}$ be the corresponding dual basis for $\\mathcal{L}(V,\\mathbb{F})$, such that $\\alpha_i(\\mathbf{e}j) = \\delta{ij}$ (the Kronecker delta). Then, any linear form $\\varphi\\in\\mathcal{L}(V,\\mathbb{F})$ can be written as:\n$$\n\\varphi(x)=\\sum_{i=1}^{n}a_ix_i=\\mathbf a \\mathbf x^T=\\mathbf x \\mathbf a\n$$\n\nwhere $\\mathbf{x}\\in V$ is a column vector of dimension $n\\times 1$, $[\\mathbf{a}]$ is the row vector representing $\\varphi$, and $[\\mathbf{x}]$ is the column vector representing $\\mathbf{x}$.\n\nFor example, let $V = \\mathbb{R}^2$ be the vector space of 2-dimensional column vectors, and let $\\varphi\\in\\mathcal{L}(V,\\mathbb{R})$ be the linear form defined by $\\varphi(\\begin{bmatrix}x\\y\\end{bmatrix}) = 3x - 2y$. Then, we can represent $\\varphi$ as:\n\n$$\n[\\mathbf a]=\\begin{bmatrix} 3 & -2\\end{bmatrix} [\\mathbf x]=\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\varphi(x)=\\sum_{i=1}^{n}\\mathbf a\\mathbf x^T=3x_1-2x_2\n$$\n\nwhich shows that $\\varphi$ is a linear form on $V$.\n\nconsider a linear regression model that predicts the price of a house based on its size and location. The model can be represented by the linear form:\n\n$$\n\\varphi(x)=\\mathbf w\\mathbf x^T=\\sum_{i=1}^{n}w_ix_i=w_0+w_1x_1+w_2x_2\n$$\n\nwhere $\\varphi(\\mathbf{x})$ is the predicted price, $x_1$ is the size of the house, $x_2$ is a measure of the location (such as the distance from the city center), and $w_0$, $w_1$, and $w_2$ are the model parameters that control the intercept and the weights of the features. This linear form can be written in matrix form as:\n\n$$\n\\varphi(x)=\\mathbf x\\mathbf w=\\mathbf w \\mathbf x^T\n$$\n\nwhere $[\\mathbf{w}]$ is a row vector of the model parameters and $[\\mathbf{x}]$ is a row vector of the features.\n\nLinear forms can also be used in deep learning and machine learning models that involve linear transformations, such as fully connected layers in neural networks or linear classifiers. For example, consider a simple linear classifier that classifies images of digits into one of 10 classes. The classifier can be represented by the linear form:\n\n$$\n\\varphi(x)=\\mathbf x\\mathbf w + b =\\mathbf w \\mathbf x^T +b\n$$\n\nwhere $\\varphi(\\mathbf{x})$ is the predicted class score, $[\\mathbf{x}]$ is a row vector of the pixel values of the image, $[\\mathbf{w}]$ is a row vector of the weights of the classifier, and $b$ is the bias term. This linear form can be used to classify the image by selecting the class with the highest score.\n\nIn both of these examples, linear forms are used to represent linear relationships between variables or features, and the model parameters are learned through training on a set of labeled examples."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":true,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../../../../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"include-in-header":[{"text":"<style>\n.custom-footer { \n  text-align: center; \n  font-size: 0.8em; \n  color: #666; \n  margin-top: 2rem; \n}\n</style>\n"}],"include-after-body":["../../../../../js.html","../../../signup.html"],"output-file":"11.linear_form.html"},"language":{"toc-title-document":"목차","toc-title-website":"목차","related-formats-title":"기타 형식","related-notebooks-title":"Notebooks","source-notebooks-prefix":"원천","other-links-title":"기타 링크","code-links-title":"코드 링크","launch-dev-container-title":"Dev 컨테이너 실행","launch-binder-title":"랜치 Binder","article-notebook-label":"기사 노트북","notebook-preview-download":"노트북 다운로드","notebook-preview-download-src":"소스 다운로드","notebook-preview-back":"기사로 돌아가기","manuscript-meca-bundle":"MECA 아카이브","section-title-abstract":"초록","section-title-appendices":"부록","section-title-footnotes":"각주","section-title-references":"참고문헌","section-title-reuse":"라이센스","section-title-copyright":"저작권","section-title-citation":"인용","appendix-attribution-cite-as":"인용방법","appendix-attribution-bibtex":"BibTeX 인용:","appendix-view-license":"라이센스 보기","title-block-author-single":"저자","title-block-author-plural":"저자","title-block-affiliation-single":"소속","title-block-affiliation-plural":"소속","title-block-published":"공개","title-block-modified":"Modified","title-block-keywords":"키워드","callout-tip-title":"힌트","callout-note-title":"노트","callout-warning-title":"경고","callout-important-title":"중요","callout-caution-title":"주의","code-summary":"코드","code-tools-menu-caption":"코드","code-tools-show-all-code":"전체 코드 표시","code-tools-hide-all-code":"전체 코드 숨기기","code-tools-view-source":"소스 코드 표시","code-tools-source-code":"소스 코드","tools-share":"Share","tools-download":"Download","code-line":"선","code-lines":"윤곽","copy-button-tooltip":"클립보드 복사","copy-button-tooltip-success":"복사완료!","repo-action-links-edit":"편집","repo-action-links-source":"소스코드 보기","repo-action-links-issue":"이슈 보고","back-to-top":"맨 위로","search-no-results-text":"일치 없음","search-matching-documents-text":"일치된 문서","search-copy-link-title":"검색 링크 복사","search-hide-matches-text":"추가 검색 결과 숨기기","search-more-match-text":"추가 검색결과","search-more-matches-text":"추가 검색결과","search-clear-button-title":"제거","search-text-placeholder":"","search-detached-cancel-button-title":"취소","search-submit-button-title":"검색","search-label":"검색","toggle-section":"토글 섹션","toggle-sidebar":"사이드바 전환","toggle-dark-mode":"다크 모드 전환","toggle-reader-mode":"리더 모드 전환","toggle-navigation":"탐색 전환","crossref-fig-title":"그림","crossref-tbl-title":"표","crossref-lst-title":"목록","crossref-thm-title":"정리","crossref-lem-title":"보조정리","crossref-cor-title":"따름정리","crossref-prp-title":"명제","crossref-cnj-title":"추측","crossref-def-title":"정의","crossref-exm-title":"보기","crossref-exr-title":"예제","crossref-ch-prefix":"장","crossref-apx-prefix":"부록","crossref-sec-prefix":"섹션","crossref-eq-prefix":"방정식","crossref-lof-title":"그림 목록","crossref-lot-title":"표 목록","crossref-lol-title":"코드 목록","environment-proof-title":"증명","environment-remark-title":"주석","environment-solution-title":"해답","listing-page-order-by":"정렬","listing-page-order-by-default":"디폴트","listing-page-order-by-date-asc":"날짜(오름차순)","listing-page-order-by-date-desc":"날짜(내림차순)","listing-page-order-by-number-desc":"페이지 번호(내림차순)","listing-page-order-by-number-asc":"페이지 번호(오름차순)","listing-page-field-date":"날짜","listing-page-field-title":"제목","listing-page-field-description":"설명","listing-page-field-author":"저자","listing-page-field-filename":"파일명","listing-page-field-filemodified":"갱신일","listing-page-field-subtitle":"부제목","listing-page-field-readingtime":"읽기 시간","listing-page-field-wordcount":"단어 수","listing-page-field-categories":"분류","listing-page-minutes-compact":"{0} 분","listing-page-category-all":"전체","listing-page-no-matches":"일치 없음","listing-page-words":"{0} 단어","listing-page-filter":"필터","draft":"초안"},"metadata":{"lang":"ko","fig-responsive":true,"quarto-version":"1.5.56","theme":{"light":["cosmo","../../../../../theme.scss"],"dark":["cosmo","../../../../../theme-dark.scss"]},"code-copy":true,"grid":{"sidebar-width":"200px","body-width":"1200px","margin-width":"200px"},"comments":{"giscus":{"repo":"kmink3225/blog","category":"Blog"}},"title-block-banner":"#EDF3F9","title-block-banner-color":"black","toc-location":"right","open-graph":true,"twitter-card":true,"search":true,"date-format":"YYYY년 MM월 DD일","title":"Matrix Transformation (3) - Linear Form","subtitle":"Linear Regression, Fully Connected layers, Neural Networks, Linear Classifiers","description":"template\n","categories":["Mathematics"],"author":"Kwangmin Kim","date":"04/02/2023","draft":false,"page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"draft":false,"projectFormats":["html"]}