{"title":"Differentiation - Univariabe Function","markdown":{"yaml":{"title":"Differentiation - Univariabe Function","subtitle":"Univariable Differentiation","description":"To solve optimization problems, it is required to know about derivatives because derivatives are mostly used 최적화 문제를 풀기위해 미분이 항상 사용되기 떄문에 미분에 대해서 알 필요가 있다.\n","categories":["Mathematics"],"author":"Kwangmin Kim","date":"02/04/2023","format":{"html":{"page-layout":"full","code-fold":true}},"draft":false},"headingText":"Overview","containsRefs":false,"markdown":"\n\n<ul class=\"nav nav-pills\" id=\"language-tab\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link active\" id=\"Korean-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#Korean\" type=\"button\" role=\"tab\" aria-controls=\"Korean\" aria-selected=\"true\">Korean</button>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link\" id=\"English-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#English\" type=\"button\" role=\"tab\" aria-controls=\"knitr\" aria-selected=\"false\">English</button>\n  </li>\n\n<div class=\"tab-content\" id=\"language-tabcontent\">\n\n<div class=\"tab-pane fade  show active\" id=\"Korean\" role=\"tabpanel\" aria-labelledby=\"Korean-tab\">\n\n::: {#Korean .tab-pane .fade .show .active role=\"tabpanel\" aria-labelledby=\"Korean-tab\"}\n\n\n\n미분은 최적화 문제를 푼다는 의미는 목적함수를 최적화한다는 말이고 그 과정에서 대부분의 경우 미분을 사용하여 상황에 맞게 목적함수의 극소값이나 극대값을 구하게 된다. 예를 들어, 목적 함수 $f(x;w)$ 가 매개변수 또는 가중치 $w$ 에 의해 그 모양이 결정되므로 $f(x;w)$ 를 최소화하는 최적화 문제를 풀고 싶을 때 $f(x;w)$ 를 cost function (=$f(x;w)$ 의 함수) 또는 loss function (=$f(x;w)$ 의 함수) 으로 잘 정의를 한 후 cost function 또는 loss function을 최소화하는 매개변수 $w$ 를 구해야한다.\n대부분의 경우, Machine Learning (Deep Learning 포함) 에서 미분은 error를 줄이기 위해 사용한다.\n\n목적 함수 $f(x;w)$ 가 정의 됐을 때 목적 함수의 극 값을 구하기 위해서 변화량을 관찰해야 한다. 비단 목적함수를 포함한 어떤 현상을 함수로 표현할 때에도 문제를 해결하기 위해 변화량을 관찰하는 경우가 빈번하다.\n\n예를 들어, 선풍기 바람의 세기를 조절할 때 입력값은 바람 세기 버튼 출력값은 바람의 세기로 가정한다면 선풍기 바람 세기 입력에 따라 적절한 출력값을 갖도록 조정하고 싶을 것이다. 이때 변화량 관찰이 요구된다. 변화량을 잘 대변하는 것이 함수의 기울기이다. 함수의 기울기는 민감도 (sensitivity)로 표현되기도 한다(wiki). 기울기는 아래와 같이 정의된다.\n\n## 미분의 종류\n\n* 직접 미분\n  * 이번 블로그에서 정리한 내용\n  * 수동 미분: 식을 알고 손으로 미분하여 도함수를 얻음\n  * symbolic 연산: 기호를 이용하여 미분 연산 $\\rightarrow$ sympy package 이용\n  * 함수 복잡하면 풀기 매우 어려움\n* 간접 미분 \n  * 수치 미분 (numerical differentiation): 도함수를 몰라도 미분계수를 구하는데 사용\n  * 함수 복잡하면 시간 오래 걸림\n* 자동 미분 (automatic differentiation)\n  * 복잡한 함수를 간단한 함수로 쪼개어 직접 미분 - Pytorch\n  * 실무에서, 정합성 검사를 위해 자동 미분의 결과를 간접 미분의 결과와 맞추기도 한다.\n  * 간접 미분이 정답이 된다.\n\n## 일 변수 함수의 미분\n\n::: {#def-Slope}\n\nThe slope of line connected with the two points $P_1(x_1,y_1)$ and $P_2(x_2,y_2)$ is\n$$\nm=\\frac{y_2-y_1}{x_2-x_1}\n$$\n\n:::\n\n::: {#thm-PointSlope}\n\nThe point slope equation of line through $P_1(x_1,y_1)$ with slope $m$ is\n$$\ny-y_1=m(x-x_1)\n$$\n\n:::\n\n::: {#thm-SlopeIntercept}\n\nThe slope intercept euation of line with slope m and y-intercept b is\n$$\ny=mx+b\n$$\n\n:::\n\n$$\n\\begin{aligned}\n\\text{기울기}(slope)&=\\frac{\\text{출력의 변화량}}{\\text{입력의 변화량}}\\\\ \n&= \\text{입력 변화량에 대한 출력 변화량} \\\\\n&=\\frac{\\Delta output}{\\Delta input}\\\\\n&= \\text{단위 입력당 출력의 변화량}\\\\ \n&= \\text{민감도, 평균 변화율 (Rates Of Change), or etc}.\\\\\n\\end{aligned}\n$$\n\n\n::: {#def-평균변화율}\n\n\n$$\n\\begin{aligned}\n\\text{평균 변화율}&=\\Delta x\\text{에 대한} \\Delta y\\text{의 비율}\\\\\n&=\\frac{\\Delta y}{\\Delta x}=\\frac{f(b)-f(a)}{b-a}\\\\\n&=\\frac{f(a+\\Delta x)-f(a)}{\\Delta x}\n\\end{aligned}\n$$\n\n\n:::\n\n* 입력에 대한 변화율을 조절하고 싶을 때 필요한 개념 \n  * ex) 시약 농도 대비 신호 증폭의 변화율을 관찰\n* 하지만 관심의 대상의 관계 그래프가 직선이 아닌 **곡선의 형태**의 경우 평균 변화율이 대략적인 추세 정보만 제공해줄뿐 변화량의 자세한 정보를 제공해주지 못함\n  * sigmoid 형태의 경우 첫 포인트와 마지막 포인트의 평균 변화율을 보는 것 보다 구간을 짧게하여 여러 군데서 관찰하는 것이 graph의 shape를 더 잘 설명하는 것\n* 이 때, 입력값의 구간을 **충분히** 짧게 만들어 출력값의 변화량을 관찰하는 것이 미분이다. (limit의 개념, $\\epsilon-\\delta$ method)\n\n::: {#def-TangentLine}\n\nThe tangent line to the curve $y=f(x)$ at the point $P(a,f(a))$ is the line through P with slope\n\n$$\nm = \\lim_{x\\to a} f(x)\n$$\n\nprovided that this limit exists.\n:::\n\n\n\n::: {#def-Derivative}\n\nWhen $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is continuous and differentiable, the derivative of a function $f$ at a number $a \\in \\mathbb R$, denoted by $f'(a)$, is\n\n$$\n\\begin{aligned}\nf'(a) &= \\lim_{h\\to 0} \\frac{f(a+h)-f(a)}{h}\\\\\n      &= \\lim_{x\\to a} \\frac{f(x)-f(a)}{x-a}\n\\end{aligned}\n$$\n\nprovided that this limit exists. 이때 위의 함수의 극한값, $f'(a)$ 라고도 표시하며 점 $a$ 에서의 $f(x)$ 의 도함수 (derivative) 라고 한다. \n:::\n\n![James Stewart - Calculus Early Transcedentals, 7th Eidition, P.143](derivative.PNG)\n\n::: {#def-Differentiable}\nA function $f$ is differentiable at $a$ if $f'(a)$ exists. It is differentiable on an open interval (a,b) [or (a,$\\infty$), (-$\\infty$,a) or (-$\\infty$,$\\infty$)] if it is differentiable at every number in the interval.\n:::\n\n::: {#thm-Continuous}\nIf $f$ is differentiable at $a$, then $f$ is continuous at $a$.\n:::\n\n* 순간 변화율 = 미분 계수 = 접선의 기울기\n* 미분 (differentiation) : 순간 변화율 구하는 행위\n* 도함수 (derivative) : 도함수 자체는 equation 으로, 특정 포인트에서의 순간 변화율 (값)을 출력하는 함수\n* 문제를 풀때 도함수를 구하는 것인지, 미분계수를 계산하는 것인지를 구별해야함\n* 전체 도함수를 구하는것은 보통 굉장히 어려움. 하지만 한점에서의 순간변화율 즉, 미분계수를 구하는 것은 가능\n* 에러를 줄이는 데에는 값으로 나오는 순간 변화율을 구하는 것이 일반적으로 실현성이 있는 문제\n\n::: {#def-NaturalNumber}\nThe natural number, $e$ is the number such that $\\lim_{h\\to 0} \\frac{e^h-1}{h}=1$.\n:::\n\n모든 지수 함수 $f(x)=a^x$ 중에서 $f(x)=e^x$ 가 점 (0.1) 에서의 접선의 기울기가 $f'(0)=1$ 이 되는 수를 $e=2.71828...$ 라고 정의한다.\n\n### Notation\n\n$f'(x)$ 는 다음과 같은 기호들로도 흔히 표현된다.\n\n* Lagrange’s notation\n  * $y', f'(x)$\n  * 어떤 변수로 미분하는지에 대해서 명시적으로 표현되지 않았음. 고등학교때까진 univariable function을 미분 했기떄문에 이 표기법이 많이 사용되었음.\n* Leibniz’s notation\n  * $\\frac{dy}{dx}=\\frac{df}{dx}=\\frac{d}{dx}f(x)$\n  * 입력 변수와 출력 변수까지 모두 명시되어있음\n* Newton’s notation: \n  * $\\dot{y}, \\ddot{y}$\n  * 최적화 논문과 financial engineering 에서 본적 있음\n* Euler’s notation\n  * $D_xy, D_xf(x)$\n  * 시계열 논문과 미분방정식 논문에서 본적 있음\n\n### Example\n\n다음의 함수를 미분의 정의를 이용하여 도함수를 계산하시오\n\n1. $f(x)=c$ where c is a constant\n1. $f(x)=\\log x$\n1. $f(x)=e^x$\n1. $f(x)=\\sin x$\n\n[Derivative Formula](https://byjus.com/calculus-formulas/)는 모두 미분의 정의를 이용해서 구할 수 있음\n\n::: {#thm-Differentiation_Rules}\n1. **The Power Rule**, if $n$ is any real number, then the power function, $x^n$ is differentiated like the following:\n$$\n\\frac{d}{dx}(x^n)=nx^{n-1}\n$$\n\n1. **The Constant Multiple Rule**, if $c$ is a constand and $f$ is a differentiable function, then\n$$\n\\frac{d}{dx}(cf'(x))=c\\frac{d}{dx}f(x)=cf'(x)\n$$\n\n1. **The Sum Rule**, if $f$ and $g$ are both differentiable, then\n$$\n\\frac{d}{dx}[f(x)+g(x)]=\\frac{d}{dx}[f(x)]+\\frac{d}{dx}[g(x)]=f'(x) +g'(x)\n$$\n\n1. **The Difference Rule**, if $f$ and $g$ are both differentiable, then\n$$\n\\frac{d}{dx}[f(x)-g(x)]=\\frac{d}{dx}[f(x)]-\\frac{d}{dx}[g(x)]=f'(x) -g'(x)\n$$\n\n1. **The Product Rule**, if $f$ and $g$ are both differentiable, then\n$$\ny=f(x)g(x), y'=f'(x)g(x)+f(x)g'(x)\n$$\n\n1. **The quotient rule**, if $f$ and $g$ are both differentiable, then\n$$\ny=\\frac{f(x)}{g(x)}, y'=\\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}\n$$\n:::\n\n증명은 James Stewart의 Calculus Series 중 1개를 골라 참고하시기 바랍니다.\n\n### Example\n\n1. $S(x)=\\frac{1}{1+e^{-ax}}$ 를 $x$ 에 대해 미분해보시오.\n1. $f(x)=\\alpha_1 + \\frac{\\alpha_2-\\alpha_1}{1+e^{-\\alpha_4(x-\\alpha_3)}}$ 를 어떻게 미분할 것인지 생각해 보시오.\n1. $y=f(x)=(4x+3)^2$ 를  $x$ 에 대해 미분해보시오\n1. $y=f(x)=(4x+3)^{20}$ 를 $x$ 에 대해 어떻게 미분할 것인지 생각해보시오. (hint: composite function - Leibniz)\n\n\n### Example Answer\n\n#### sympy package example\n\n앞서와 언급한대로 파이썬 sympy package를 사용할 것인데 간단한 예를 본다. 먼저 기호의 정의를 해주고 수학 연산을 진행하면 된다.\n\n```{python}\n# import packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sympy as S\nimport matplotlib as mpl\nfrom mpl_toolkits import mplot3d\nimport matplotlib.font_manager as mfm\n\n```\n\n```{python}\n# 심볼 정의\nx=S.Symbol('x')\nh=S.Symbol('h')\nn=S.Symbol('n')\na=S.Symbol('a')\na1=S.Symbol('a1')\na2=S.Symbol('a2')\na3=S.Symbol('a3')\na4=S.Symbol('a4')\n\n## 인수분해\nS.factor(x**2+4*x+4)\n```\n\n* 인수분해와 값 넣기\n```{python}\nf=S.factor(x**2-5*x+6)\nprint(f.subs({x:3}))\nprint(f.subs({x:5}))\nf\n```\n\n* $2^x$ 미분과 값 넣기\n```{python}\ndf=S.limit((2**(x+h)-2**x)/h,h,0)\nprint(df.subs({x:3}))\nprint(df.subs({x:5}))\n\nprint(df.subs({x:3}).evalf()) # 정확한 값을 원할 경우\ndf\n```\n\n* $x^n$ 미분\n```{python}\ndf=S.limit(((x+h)**n-x**n)/h,h,0)\nprint(df.subs({x:3}))\nprint(df.subs({x:5}))\ndf\n```\n\n#### Example Answers \n\n* $f(x)=c$ 의 도함수 where c is a constant. c=2로 고정\n```{python}\nf=2\ndf=S.limit(((2)-2)/h,h,0)\ndf\n```\n\n* $f(x)=\\log x$ 의 도함수\n```{python}\nf=S.log(x)\ndf=S.limit((S.log(x+h)-S.log(x))/h,h,0)\ndf\n```\n\n* $f(x)=e^x$ 의 도함수\n```{python}\nf=S.exp(x)\ndf=S.limit((S.exp(x+h)-S.exp(x))/h,h,0)\ndf\n```\n\n* $f(x)=\\sin x$ 의 도함수\n```{python}\nf=S.sin(x)\ndf=S.limit((S.sin(x+h)-S.sin(x))/h,h,0)\ndf\n```\n* $S(x)=\\frac{1}{1+e^{-ax}}$ 를 $x$ 에 대해 미분해보시오.\n\n```{python}\nf=1/(1+S.exp(-a*x))\ndf=S.limit((1/(1+S.exp(-a*(x+h)))-1/(1+S.exp(-a*x)))/h,h,0)\ndf\n```\n\n이번 문제에서 $\\frac{ae^x}{(e^{-ax}+1)^2}$ 라는 sigmoid function의 도함수를 얻었다. 이 도함수를 간단한 수학적 조작으로 다른 표현으로 유도해보면 다음과 같다.\n$$\n\\begin{aligned}\n\\frac{d}{dx}S(x)&=\\frac{ae^{-ax}}{(e^{ax}+1)^2}\\\\\n                &=a\\frac{1}{(e^{ax}+1)}\\frac{e^{-ax}}{(e^{ax}+1)}\\\\\n                &=a\\frac{1}{(e^{ax}+1)}\\frac{1+e^{-ax}-1}{(e^{ax}+1)}\\\\\n                &=a\\frac{1}{(e^{ax}+1)}(1-\\frac{1}{(e^{ax}+1)})\\\\\n                &=aS(x)(1-S(x))\\\\\n\\end{aligned}\n$$\n\n위와 같이 $S(x)$ 의 도함수는 $aS(x)(1-S(x))$ 로 표현될 수 있다. sigmoid function은 neural network에서 activation function으로 사용되는데 forward propagation에서 이미 한 번 계산이 된다. backward propagation에서 activation function인 $S(x)$ 의 도함수를 다시 연산을 해야하는데 도함수가 $aS(x)(1-S(x))$ 것을 알면 복잡한 고차원 행렬곱 연산을 다시 수행하지 않아도 된다. 그래서 $S(x)$ 의 도함수를 $\\frac{ae^x}{(e^{-ax}+1)^2}$ 라고 코딩하는 것 보다는 $S(x)$ 의 행렬을 재활용하여 $aS(x)(1-S(x))$ 로 코딩해놓으면 연산 과정에서의 시간 복잡도를 줄일 수 있다. 이처럼 machine learning에서 수학적 통계적 지식을 잘 활용하면 좀 더 효율적인 모델링을 구현 할 수 있다.\n\n```{python}\n\nx1 = np.linspace(-6, 6, 100)\nsx = 1/(1+np.exp(-x1))\nd_sx = sx*(1-sx)\n\nplt.plot(x1,sx,color='black',label='S(x)')\nplt.plot(x1,d_sx,color='red',label='dS(x)')\n\nplt.xlabel('X')\nplt.xlabel('S(x)')\nplt.title('Simgoid Curve with its Derivative')\nplt.legend()\nplt.show()\n\n```\n\n\n* $f(x;\\mathbf\\alpha)=\\alpha_1 + \\frac{\\alpha_2-\\alpha_1}{1+e^{-\\alpha_4(x-\\alpha_3)}}$ 를 어떻게 미분할 것인지 생각해 보시오.\n\n위의 식은 logistic fucntion의 genral formular 형태인데 sigmoid function이 특수한 예이다. 함수의 shpae는 parameter에 의해 결정되는데 위의 경우 $\\alpha_1$ 은 함수의 최솟값 , $\\alpha_2$ 은 함수의 최댓값, $\\alpha_3$ 은 함수의 변곡점 및 $\\alpha_4$ logistic curve가 변곡점을 지나면서 증가하는 변화율을 묘사한다. sigmoid 형태의 data를 fitting하기 위해 위의 함수를 이용한다면 error를 최소화하는 parameter를 구해야하는데 이 또한 최적화 문제로 4개의 변수에 대한 미분이 필요하다. 2개 이상의 변수에 대해서 미분은 partial derivative (편미분)라고 하는데 다음 블로그에서 다룰 것이다.\n\n\n* $y=f(x)=(4x+3)^2$ 를  $x$ 에 대해 미분해보시오.\n\n```{python}\n\nS.limit(((4*(x+h)+3)**2-(4*x+3)**2)/h,h,0)\n```\n\n위의 도함수는 미분 공식 중 곱의 법칙을 사용하면 구할 수 있다.\n\n* $y=f(x)=(4x+3)^{20}$ 를 $x$ 에 대해 어떻게 미분할 것인지 생각해보시오. (hint: composite function - Leibniz)\n\n위의 문제처럼 곱의 법칙을 사용하면 20개의 인수에 대해서 차례대로 미분을 해야하므로 계산량이 엄청나게 많아진다. 이때 composite function (합성 함수)의 derivative를 구하는 chain rule을 이용하면 간단한 연산으로 도함수를 구할 수 있게 된다. deep learning 모델의 기초인 neural network는 layer nodes이 복잡하게 합성이 되는 합성 함수를 만들면서 forward propagation을 진행하고 backward propabation에서 이 복잡한 합성 함수의 미분을 수행하게 된다. 그러므로 합성 함수의 미분이 어떻게 수행되는지 아는 것은 deep learning을 수리적으로 이해하고 싶은 사람에게 있어서 중요할 수 있다. 합성 함수의 미분은 다른 블로그에서 다루도록 하겠다.\n:::\n</div>\n\n<div class=\"tab-pane fade\" id=\"English\" role=\"tabpanel\" aria-labelledby=\"English-tab\">\n\n\n\n</div>\n\n## Blog Guide Map Link\n\n* [Statistics Blog](../../statistics/guide_map/index.qmd)\n* [Engineering Blog](../../Engineering/guide_map/index.qmd)\n* [Deep Learning Blog](../../DL/guide_map/index.qmd)\n* [Machine Learning Blog](../../ML/guide_map/index.qmd)\n* [Mathematics Blog](../Mathmatics/guide_map/index.qmd)\n* [Patent Blog](../../Patent/guide_map/index.qmd)\n* [Validation Blog](../../Validation/guide_map/index.qmd)","srcMarkdownNoYaml":"\n\n<ul class=\"nav nav-pills\" id=\"language-tab\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link active\" id=\"Korean-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#Korean\" type=\"button\" role=\"tab\" aria-controls=\"Korean\" aria-selected=\"true\">Korean</button>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link\" id=\"English-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#English\" type=\"button\" role=\"tab\" aria-controls=\"knitr\" aria-selected=\"false\">English</button>\n  </li>\n\n<div class=\"tab-content\" id=\"language-tabcontent\">\n\n<div class=\"tab-pane fade  show active\" id=\"Korean\" role=\"tabpanel\" aria-labelledby=\"Korean-tab\">\n\n::: {#Korean .tab-pane .fade .show .active role=\"tabpanel\" aria-labelledby=\"Korean-tab\"}\n\n\n## Overview\n\n미분은 최적화 문제를 푼다는 의미는 목적함수를 최적화한다는 말이고 그 과정에서 대부분의 경우 미분을 사용하여 상황에 맞게 목적함수의 극소값이나 극대값을 구하게 된다. 예를 들어, 목적 함수 $f(x;w)$ 가 매개변수 또는 가중치 $w$ 에 의해 그 모양이 결정되므로 $f(x;w)$ 를 최소화하는 최적화 문제를 풀고 싶을 때 $f(x;w)$ 를 cost function (=$f(x;w)$ 의 함수) 또는 loss function (=$f(x;w)$ 의 함수) 으로 잘 정의를 한 후 cost function 또는 loss function을 최소화하는 매개변수 $w$ 를 구해야한다.\n대부분의 경우, Machine Learning (Deep Learning 포함) 에서 미분은 error를 줄이기 위해 사용한다.\n\n목적 함수 $f(x;w)$ 가 정의 됐을 때 목적 함수의 극 값을 구하기 위해서 변화량을 관찰해야 한다. 비단 목적함수를 포함한 어떤 현상을 함수로 표현할 때에도 문제를 해결하기 위해 변화량을 관찰하는 경우가 빈번하다.\n\n예를 들어, 선풍기 바람의 세기를 조절할 때 입력값은 바람 세기 버튼 출력값은 바람의 세기로 가정한다면 선풍기 바람 세기 입력에 따라 적절한 출력값을 갖도록 조정하고 싶을 것이다. 이때 변화량 관찰이 요구된다. 변화량을 잘 대변하는 것이 함수의 기울기이다. 함수의 기울기는 민감도 (sensitivity)로 표현되기도 한다(wiki). 기울기는 아래와 같이 정의된다.\n\n## 미분의 종류\n\n* 직접 미분\n  * 이번 블로그에서 정리한 내용\n  * 수동 미분: 식을 알고 손으로 미분하여 도함수를 얻음\n  * symbolic 연산: 기호를 이용하여 미분 연산 $\\rightarrow$ sympy package 이용\n  * 함수 복잡하면 풀기 매우 어려움\n* 간접 미분 \n  * 수치 미분 (numerical differentiation): 도함수를 몰라도 미분계수를 구하는데 사용\n  * 함수 복잡하면 시간 오래 걸림\n* 자동 미분 (automatic differentiation)\n  * 복잡한 함수를 간단한 함수로 쪼개어 직접 미분 - Pytorch\n  * 실무에서, 정합성 검사를 위해 자동 미분의 결과를 간접 미분의 결과와 맞추기도 한다.\n  * 간접 미분이 정답이 된다.\n\n## 일 변수 함수의 미분\n\n::: {#def-Slope}\n\nThe slope of line connected with the two points $P_1(x_1,y_1)$ and $P_2(x_2,y_2)$ is\n$$\nm=\\frac{y_2-y_1}{x_2-x_1}\n$$\n\n:::\n\n::: {#thm-PointSlope}\n\nThe point slope equation of line through $P_1(x_1,y_1)$ with slope $m$ is\n$$\ny-y_1=m(x-x_1)\n$$\n\n:::\n\n::: {#thm-SlopeIntercept}\n\nThe slope intercept euation of line with slope m and y-intercept b is\n$$\ny=mx+b\n$$\n\n:::\n\n$$\n\\begin{aligned}\n\\text{기울기}(slope)&=\\frac{\\text{출력의 변화량}}{\\text{입력의 변화량}}\\\\ \n&= \\text{입력 변화량에 대한 출력 변화량} \\\\\n&=\\frac{\\Delta output}{\\Delta input}\\\\\n&= \\text{단위 입력당 출력의 변화량}\\\\ \n&= \\text{민감도, 평균 변화율 (Rates Of Change), or etc}.\\\\\n\\end{aligned}\n$$\n\n\n::: {#def-평균변화율}\n\n\n$$\n\\begin{aligned}\n\\text{평균 변화율}&=\\Delta x\\text{에 대한} \\Delta y\\text{의 비율}\\\\\n&=\\frac{\\Delta y}{\\Delta x}=\\frac{f(b)-f(a)}{b-a}\\\\\n&=\\frac{f(a+\\Delta x)-f(a)}{\\Delta x}\n\\end{aligned}\n$$\n\n\n:::\n\n* 입력에 대한 변화율을 조절하고 싶을 때 필요한 개념 \n  * ex) 시약 농도 대비 신호 증폭의 변화율을 관찰\n* 하지만 관심의 대상의 관계 그래프가 직선이 아닌 **곡선의 형태**의 경우 평균 변화율이 대략적인 추세 정보만 제공해줄뿐 변화량의 자세한 정보를 제공해주지 못함\n  * sigmoid 형태의 경우 첫 포인트와 마지막 포인트의 평균 변화율을 보는 것 보다 구간을 짧게하여 여러 군데서 관찰하는 것이 graph의 shape를 더 잘 설명하는 것\n* 이 때, 입력값의 구간을 **충분히** 짧게 만들어 출력값의 변화량을 관찰하는 것이 미분이다. (limit의 개념, $\\epsilon-\\delta$ method)\n\n::: {#def-TangentLine}\n\nThe tangent line to the curve $y=f(x)$ at the point $P(a,f(a))$ is the line through P with slope\n\n$$\nm = \\lim_{x\\to a} f(x)\n$$\n\nprovided that this limit exists.\n:::\n\n\n\n::: {#def-Derivative}\n\nWhen $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ is continuous and differentiable, the derivative of a function $f$ at a number $a \\in \\mathbb R$, denoted by $f'(a)$, is\n\n$$\n\\begin{aligned}\nf'(a) &= \\lim_{h\\to 0} \\frac{f(a+h)-f(a)}{h}\\\\\n      &= \\lim_{x\\to a} \\frac{f(x)-f(a)}{x-a}\n\\end{aligned}\n$$\n\nprovided that this limit exists. 이때 위의 함수의 극한값, $f'(a)$ 라고도 표시하며 점 $a$ 에서의 $f(x)$ 의 도함수 (derivative) 라고 한다. \n:::\n\n![James Stewart - Calculus Early Transcedentals, 7th Eidition, P.143](derivative.PNG)\n\n::: {#def-Differentiable}\nA function $f$ is differentiable at $a$ if $f'(a)$ exists. It is differentiable on an open interval (a,b) [or (a,$\\infty$), (-$\\infty$,a) or (-$\\infty$,$\\infty$)] if it is differentiable at every number in the interval.\n:::\n\n::: {#thm-Continuous}\nIf $f$ is differentiable at $a$, then $f$ is continuous at $a$.\n:::\n\n* 순간 변화율 = 미분 계수 = 접선의 기울기\n* 미분 (differentiation) : 순간 변화율 구하는 행위\n* 도함수 (derivative) : 도함수 자체는 equation 으로, 특정 포인트에서의 순간 변화율 (값)을 출력하는 함수\n* 문제를 풀때 도함수를 구하는 것인지, 미분계수를 계산하는 것인지를 구별해야함\n* 전체 도함수를 구하는것은 보통 굉장히 어려움. 하지만 한점에서의 순간변화율 즉, 미분계수를 구하는 것은 가능\n* 에러를 줄이는 데에는 값으로 나오는 순간 변화율을 구하는 것이 일반적으로 실현성이 있는 문제\n\n::: {#def-NaturalNumber}\nThe natural number, $e$ is the number such that $\\lim_{h\\to 0} \\frac{e^h-1}{h}=1$.\n:::\n\n모든 지수 함수 $f(x)=a^x$ 중에서 $f(x)=e^x$ 가 점 (0.1) 에서의 접선의 기울기가 $f'(0)=1$ 이 되는 수를 $e=2.71828...$ 라고 정의한다.\n\n### Notation\n\n$f'(x)$ 는 다음과 같은 기호들로도 흔히 표현된다.\n\n* Lagrange’s notation\n  * $y', f'(x)$\n  * 어떤 변수로 미분하는지에 대해서 명시적으로 표현되지 않았음. 고등학교때까진 univariable function을 미분 했기떄문에 이 표기법이 많이 사용되었음.\n* Leibniz’s notation\n  * $\\frac{dy}{dx}=\\frac{df}{dx}=\\frac{d}{dx}f(x)$\n  * 입력 변수와 출력 변수까지 모두 명시되어있음\n* Newton’s notation: \n  * $\\dot{y}, \\ddot{y}$\n  * 최적화 논문과 financial engineering 에서 본적 있음\n* Euler’s notation\n  * $D_xy, D_xf(x)$\n  * 시계열 논문과 미분방정식 논문에서 본적 있음\n\n### Example\n\n다음의 함수를 미분의 정의를 이용하여 도함수를 계산하시오\n\n1. $f(x)=c$ where c is a constant\n1. $f(x)=\\log x$\n1. $f(x)=e^x$\n1. $f(x)=\\sin x$\n\n[Derivative Formula](https://byjus.com/calculus-formulas/)는 모두 미분의 정의를 이용해서 구할 수 있음\n\n::: {#thm-Differentiation_Rules}\n1. **The Power Rule**, if $n$ is any real number, then the power function, $x^n$ is differentiated like the following:\n$$\n\\frac{d}{dx}(x^n)=nx^{n-1}\n$$\n\n1. **The Constant Multiple Rule**, if $c$ is a constand and $f$ is a differentiable function, then\n$$\n\\frac{d}{dx}(cf'(x))=c\\frac{d}{dx}f(x)=cf'(x)\n$$\n\n1. **The Sum Rule**, if $f$ and $g$ are both differentiable, then\n$$\n\\frac{d}{dx}[f(x)+g(x)]=\\frac{d}{dx}[f(x)]+\\frac{d}{dx}[g(x)]=f'(x) +g'(x)\n$$\n\n1. **The Difference Rule**, if $f$ and $g$ are both differentiable, then\n$$\n\\frac{d}{dx}[f(x)-g(x)]=\\frac{d}{dx}[f(x)]-\\frac{d}{dx}[g(x)]=f'(x) -g'(x)\n$$\n\n1. **The Product Rule**, if $f$ and $g$ are both differentiable, then\n$$\ny=f(x)g(x), y'=f'(x)g(x)+f(x)g'(x)\n$$\n\n1. **The quotient rule**, if $f$ and $g$ are both differentiable, then\n$$\ny=\\frac{f(x)}{g(x)}, y'=\\frac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}\n$$\n:::\n\n증명은 James Stewart의 Calculus Series 중 1개를 골라 참고하시기 바랍니다.\n\n### Example\n\n1. $S(x)=\\frac{1}{1+e^{-ax}}$ 를 $x$ 에 대해 미분해보시오.\n1. $f(x)=\\alpha_1 + \\frac{\\alpha_2-\\alpha_1}{1+e^{-\\alpha_4(x-\\alpha_3)}}$ 를 어떻게 미분할 것인지 생각해 보시오.\n1. $y=f(x)=(4x+3)^2$ 를  $x$ 에 대해 미분해보시오\n1. $y=f(x)=(4x+3)^{20}$ 를 $x$ 에 대해 어떻게 미분할 것인지 생각해보시오. (hint: composite function - Leibniz)\n\n\n### Example Answer\n\n#### sympy package example\n\n앞서와 언급한대로 파이썬 sympy package를 사용할 것인데 간단한 예를 본다. 먼저 기호의 정의를 해주고 수학 연산을 진행하면 된다.\n\n```{python}\n# import packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sympy as S\nimport matplotlib as mpl\nfrom mpl_toolkits import mplot3d\nimport matplotlib.font_manager as mfm\n\n```\n\n```{python}\n# 심볼 정의\nx=S.Symbol('x')\nh=S.Symbol('h')\nn=S.Symbol('n')\na=S.Symbol('a')\na1=S.Symbol('a1')\na2=S.Symbol('a2')\na3=S.Symbol('a3')\na4=S.Symbol('a4')\n\n## 인수분해\nS.factor(x**2+4*x+4)\n```\n\n* 인수분해와 값 넣기\n```{python}\nf=S.factor(x**2-5*x+6)\nprint(f.subs({x:3}))\nprint(f.subs({x:5}))\nf\n```\n\n* $2^x$ 미분과 값 넣기\n```{python}\ndf=S.limit((2**(x+h)-2**x)/h,h,0)\nprint(df.subs({x:3}))\nprint(df.subs({x:5}))\n\nprint(df.subs({x:3}).evalf()) # 정확한 값을 원할 경우\ndf\n```\n\n* $x^n$ 미분\n```{python}\ndf=S.limit(((x+h)**n-x**n)/h,h,0)\nprint(df.subs({x:3}))\nprint(df.subs({x:5}))\ndf\n```\n\n#### Example Answers \n\n* $f(x)=c$ 의 도함수 where c is a constant. c=2로 고정\n```{python}\nf=2\ndf=S.limit(((2)-2)/h,h,0)\ndf\n```\n\n* $f(x)=\\log x$ 의 도함수\n```{python}\nf=S.log(x)\ndf=S.limit((S.log(x+h)-S.log(x))/h,h,0)\ndf\n```\n\n* $f(x)=e^x$ 의 도함수\n```{python}\nf=S.exp(x)\ndf=S.limit((S.exp(x+h)-S.exp(x))/h,h,0)\ndf\n```\n\n* $f(x)=\\sin x$ 의 도함수\n```{python}\nf=S.sin(x)\ndf=S.limit((S.sin(x+h)-S.sin(x))/h,h,0)\ndf\n```\n* $S(x)=\\frac{1}{1+e^{-ax}}$ 를 $x$ 에 대해 미분해보시오.\n\n```{python}\nf=1/(1+S.exp(-a*x))\ndf=S.limit((1/(1+S.exp(-a*(x+h)))-1/(1+S.exp(-a*x)))/h,h,0)\ndf\n```\n\n이번 문제에서 $\\frac{ae^x}{(e^{-ax}+1)^2}$ 라는 sigmoid function의 도함수를 얻었다. 이 도함수를 간단한 수학적 조작으로 다른 표현으로 유도해보면 다음과 같다.\n$$\n\\begin{aligned}\n\\frac{d}{dx}S(x)&=\\frac{ae^{-ax}}{(e^{ax}+1)^2}\\\\\n                &=a\\frac{1}{(e^{ax}+1)}\\frac{e^{-ax}}{(e^{ax}+1)}\\\\\n                &=a\\frac{1}{(e^{ax}+1)}\\frac{1+e^{-ax}-1}{(e^{ax}+1)}\\\\\n                &=a\\frac{1}{(e^{ax}+1)}(1-\\frac{1}{(e^{ax}+1)})\\\\\n                &=aS(x)(1-S(x))\\\\\n\\end{aligned}\n$$\n\n위와 같이 $S(x)$ 의 도함수는 $aS(x)(1-S(x))$ 로 표현될 수 있다. sigmoid function은 neural network에서 activation function으로 사용되는데 forward propagation에서 이미 한 번 계산이 된다. backward propagation에서 activation function인 $S(x)$ 의 도함수를 다시 연산을 해야하는데 도함수가 $aS(x)(1-S(x))$ 것을 알면 복잡한 고차원 행렬곱 연산을 다시 수행하지 않아도 된다. 그래서 $S(x)$ 의 도함수를 $\\frac{ae^x}{(e^{-ax}+1)^2}$ 라고 코딩하는 것 보다는 $S(x)$ 의 행렬을 재활용하여 $aS(x)(1-S(x))$ 로 코딩해놓으면 연산 과정에서의 시간 복잡도를 줄일 수 있다. 이처럼 machine learning에서 수학적 통계적 지식을 잘 활용하면 좀 더 효율적인 모델링을 구현 할 수 있다.\n\n```{python}\n\nx1 = np.linspace(-6, 6, 100)\nsx = 1/(1+np.exp(-x1))\nd_sx = sx*(1-sx)\n\nplt.plot(x1,sx,color='black',label='S(x)')\nplt.plot(x1,d_sx,color='red',label='dS(x)')\n\nplt.xlabel('X')\nplt.xlabel('S(x)')\nplt.title('Simgoid Curve with its Derivative')\nplt.legend()\nplt.show()\n\n```\n\n\n* $f(x;\\mathbf\\alpha)=\\alpha_1 + \\frac{\\alpha_2-\\alpha_1}{1+e^{-\\alpha_4(x-\\alpha_3)}}$ 를 어떻게 미분할 것인지 생각해 보시오.\n\n위의 식은 logistic fucntion의 genral formular 형태인데 sigmoid function이 특수한 예이다. 함수의 shpae는 parameter에 의해 결정되는데 위의 경우 $\\alpha_1$ 은 함수의 최솟값 , $\\alpha_2$ 은 함수의 최댓값, $\\alpha_3$ 은 함수의 변곡점 및 $\\alpha_4$ logistic curve가 변곡점을 지나면서 증가하는 변화율을 묘사한다. sigmoid 형태의 data를 fitting하기 위해 위의 함수를 이용한다면 error를 최소화하는 parameter를 구해야하는데 이 또한 최적화 문제로 4개의 변수에 대한 미분이 필요하다. 2개 이상의 변수에 대해서 미분은 partial derivative (편미분)라고 하는데 다음 블로그에서 다룰 것이다.\n\n\n* $y=f(x)=(4x+3)^2$ 를  $x$ 에 대해 미분해보시오.\n\n```{python}\n\nS.limit(((4*(x+h)+3)**2-(4*x+3)**2)/h,h,0)\n```\n\n위의 도함수는 미분 공식 중 곱의 법칙을 사용하면 구할 수 있다.\n\n* $y=f(x)=(4x+3)^{20}$ 를 $x$ 에 대해 어떻게 미분할 것인지 생각해보시오. (hint: composite function - Leibniz)\n\n위의 문제처럼 곱의 법칙을 사용하면 20개의 인수에 대해서 차례대로 미분을 해야하므로 계산량이 엄청나게 많아진다. 이때 composite function (합성 함수)의 derivative를 구하는 chain rule을 이용하면 간단한 연산으로 도함수를 구할 수 있게 된다. deep learning 모델의 기초인 neural network는 layer nodes이 복잡하게 합성이 되는 합성 함수를 만들면서 forward propagation을 진행하고 backward propabation에서 이 복잡한 합성 함수의 미분을 수행하게 된다. 그러므로 합성 함수의 미분이 어떻게 수행되는지 아는 것은 deep learning을 수리적으로 이해하고 싶은 사람에게 있어서 중요할 수 있다. 합성 함수의 미분은 다른 블로그에서 다루도록 하겠다.\n:::\n</div>\n\n<div class=\"tab-pane fade\" id=\"English\" role=\"tabpanel\" aria-labelledby=\"English-tab\">\n\n\n\n</div>\n\n## Blog Guide Map Link\n\n* [Statistics Blog](../../statistics/guide_map/index.qmd)\n* [Engineering Blog](../../Engineering/guide_map/index.qmd)\n* [Deep Learning Blog](../../DL/guide_map/index.qmd)\n* [Machine Learning Blog](../../ML/guide_map/index.qmd)\n* [Mathematics Blog](../Mathmatics/guide_map/index.qmd)\n* [Patent Blog](../../Patent/guide_map/index.qmd)\n* [Validation Blog](../../Validation/guide_map/index.qmd)"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":true,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../../../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"include-in-header":[{"text":"<style>\n.custom-footer { \n  text-align: center; \n  font-size: 0.8em; \n  color: #666; \n  margin-top: 2rem; \n}\n</style>\n"}],"include-after-body":["../../../../js.html","../../signup.html"],"output-file":"2023-02-04_uni_derivative.html"},"language":{"toc-title-document":"목차","toc-title-website":"목차","related-formats-title":"기타 형식","related-notebooks-title":"Notebooks","source-notebooks-prefix":"원천","other-links-title":"기타 링크","code-links-title":"코드 링크","launch-dev-container-title":"Dev 컨테이너 실행","launch-binder-title":"랜치 Binder","article-notebook-label":"기사 노트북","notebook-preview-download":"노트북 다운로드","notebook-preview-download-src":"소스 다운로드","notebook-preview-back":"기사로 돌아가기","manuscript-meca-bundle":"MECA 아카이브","section-title-abstract":"초록","section-title-appendices":"부록","section-title-footnotes":"각주","section-title-references":"참고문헌","section-title-reuse":"라이센스","section-title-copyright":"저작권","section-title-citation":"인용","appendix-attribution-cite-as":"인용방법","appendix-attribution-bibtex":"BibTeX 인용:","title-block-author-single":"저자","title-block-author-plural":"저자","title-block-affiliation-single":"소속","title-block-affiliation-plural":"소속","title-block-published":"공개","title-block-modified":"Modified","title-block-keywords":"키워드","callout-tip-title":"힌트","callout-note-title":"노트","callout-warning-title":"경고","callout-important-title":"중요","callout-caution-title":"주의","code-summary":"코드","code-tools-menu-caption":"코드","code-tools-show-all-code":"전체 코드 표시","code-tools-hide-all-code":"전체 코드 숨기기","code-tools-view-source":"소스 코드 표시","code-tools-source-code":"소스 코드","tools-share":"Share","tools-download":"Download","code-line":"선","code-lines":"윤곽","copy-button-tooltip":"클립보드 복사","copy-button-tooltip-success":"복사완료!","repo-action-links-edit":"편집","repo-action-links-source":"소스코드 보기","repo-action-links-issue":"이슈 보고","back-to-top":"맨 위로","search-no-results-text":"일치 없음","search-matching-documents-text":"일치된 문서","search-copy-link-title":"검색 링크 복사","search-hide-matches-text":"추가 검색 결과 숨기기","search-more-match-text":"추가 검색결과","search-more-matches-text":"추가 검색결과","search-clear-button-title":"제거","search-text-placeholder":"","search-detached-cancel-button-title":"취소","search-submit-button-title":"검색","search-label":"검색","toggle-section":"토글 섹션","toggle-sidebar":"사이드바 전환","toggle-dark-mode":"다크 모드 전환","toggle-reader-mode":"리더 모드 전환","toggle-navigation":"탐색 전환","crossref-fig-title":"그림","crossref-tbl-title":"표","crossref-lst-title":"목록","crossref-thm-title":"정리","crossref-lem-title":"보조정리","crossref-cor-title":"따름정리","crossref-prp-title":"명제","crossref-cnj-title":"추측","crossref-def-title":"정의","crossref-exm-title":"보기","crossref-exr-title":"예제","crossref-ch-prefix":"장","crossref-apx-prefix":"부록","crossref-sec-prefix":"섹션","crossref-eq-prefix":"방정식","crossref-lof-title":"그림 목록","crossref-lot-title":"표 목록","crossref-lol-title":"코드 목록","environment-proof-title":"증명","environment-remark-title":"주석","environment-solution-title":"해답","listing-page-order-by":"정렬","listing-page-order-by-default":"디폴트","listing-page-order-by-date-asc":"날짜(오름차순)","listing-page-order-by-date-desc":"날짜(내림차순)","listing-page-order-by-number-desc":"페이지 번호(내림차순)","listing-page-order-by-number-asc":"페이지 번호(오름차순)","listing-page-field-date":"날짜","listing-page-field-title":"제목","listing-page-field-description":"설명","listing-page-field-author":"저자","listing-page-field-filename":"파일명","listing-page-field-filemodified":"갱신일","listing-page-field-subtitle":"부제목","listing-page-field-readingtime":"읽기 시간","listing-page-field-wordcount":"단어 수","listing-page-field-categories":"분류","listing-page-minutes-compact":"{0} 분","listing-page-category-all":"전체","listing-page-no-matches":"일치 없음","listing-page-words":"{0} 단어"},"metadata":{"lang":"ko","fig-responsive":true,"quarto-version":"1.4.543","theme":{"light":["cosmo","../../../../theme.scss"],"dark":["cosmo","../../../../theme-dark.scss"]},"code-copy":true,"grid":{"sidebar-width":"200px","body-width":"1200px","margin-width":"200px"},"comments":{"giscus":{"repo":"kmink3225/blog","category":"Blog"}},"title-block-banner":"#EDF3F9","title-block-banner-color":"black","toc-location":"right","open-graph":true,"twitter-card":true,"search":true,"date-format":"YYYY년 MM월 DD일","title":"Differentiation - Univariabe Function","subtitle":"Univariable Differentiation","description":"To solve optimization problems, it is required to know about derivatives because derivatives are mostly used 최적화 문제를 풀기위해 미분이 항상 사용되기 떄문에 미분에 대해서 알 필요가 있다.\n","categories":["Mathematics"],"author":"Kwangmin Kim","date":"02/04/2023","draft":false,"page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}