{"title":"RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval","markdown":{"yaml":{"title":"RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"},"headingText":"환경 설정","containsRefs":false,"markdown":"\n\n\n\n\n[RAPTOR](https://arxiv.org/pdf/2401.18059.pdf) 논문은 문서의 색인 생성 및 검색에 대한 흥미로운 접근 방식을 제시합니다.\n\n[테디노트 논문 요약글(노션)](https://teddylee777.notion.site/RAPTOR-e835d306fc664dc2ad76191dee1cd859?pvs=4)\n\n- `leafs` 는 가장 low-level 의 시작 문서 집합입니다. 이 문서들은 임베딩되어 클러스터링됩니다.\n- 그런 다음 클러스터는 유사한 문서들 간의 정보를 더 높은 수준(더 추상적인)으로 요약합니다.\n\n이 과정은 재귀적으로 수행되어, 원본 문서(`leafs`)에서 더 추상적인 요약으로 이어지는 \"트리\"를 형성합니다.\n\n`leafs`는 다음과 같은 문서들로 구성될 수 있습니다.\n\n- 단일 문서에서의 텍스트 청크(논문에서 보여준 것처럼)\n- 전체 문서(아래에서 보여주는 것처럼)\n\n이번 튜토리얼에서는 LangChain 의 LCEL 문서에 이를 적용해 보도록 하겠습니다. 소스코드 기반의 RAG 시스템을 구축할 때 RAPTOR 방법론을 적용하는 방법에 대해서 다룹니다.\n\n\n\n\n## 데이터 전처리\n\n`doc`은 LCEL 문서의 고유한 웹 페이지입니다. context 는 2,000 토큰 미만에서 10,000 토큰 이상까지 다양합니다.\n\n웹 문서에서 텍스트 데이터를 추출하고, 텍스트의 토큰 수를 계산하여 히스토그램으로 시각화합니다.\n\n문서 텍스트를 정렬합니다. 이때 메타데이터의 `source` 를 기준으로 정렬한 뒤, 모든 문서를 연결합니다.\n\n`RecursiveCharacterTextSplitter`를 사용하여 텍스트를 분할합니다.\n\n다음으로는 분할된 chunk 들을 임베딩하여 vector store 에 저장합니다.\n\n## 모델 설정\n\n## 트리 구축\n\n트리 구축에서의 클러스터링 접근 방식에 대한 주요 개요입니다.\n\n**GMM (가우시안 혼합 모델)**\n\n- 다양한 클러스터에 걸쳐 데이터 포인트의 분포를 모델링합니다.\n- 모델의 베이지안 정보 기준(BIC)을 평가하여 최적의 클러스터 수를 결정합니다.\n\n**UMAP (Uniform Manifold Approximation and Projection)**\n\n- 클러스터링을 지원합니다.\n- 고차원 데이터의 차원을 축소합니다.\n- UMAP은 데이터 포인트의 유사성에 기반하여 자연스러운 그룹화를 강조하는 데 도움을 줍니다.\n\n**지역 및 전역 클러스터링**\n\n- 데이터를 저차원으로 차원 축소하여 클러스터링을 수행합니다.\n\n**임계값 설정**\n\n- GMM의 맥락에서 클러스터 멤버십을 결정하기 위해 적용됩니다.\n- 확률 분포를 기반으로 합니다(데이터 포인트를 ≥ 1 클러스터에 할당).\n\n---\n\nGMM 및 임계값 설정에 대한 코드는 아래 두 출처에서 언급된 Sarthi et al의 것입니다. \n\n**참조**\n\n- [원본 저장소](https://github.com/parthsarthi03/raptor/blob/master/raptor/cluster_tree_builder.py)\n- [소소한 조정](https://github.com/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/clustering.py)\n\n### 차원 축소\n\n`global_cluster_embeddings`\n\n- 입력된 임베딩 벡터를 전역적으로 차원 축소하기 위해 UMAP을 적용합니다. 전역적으로 차원을 축소한 결과물을 얻어 추후 클러스터링에 활용합니다.\n\n**과정**\n\n- n_neighbors: UMAP에 사용될 이웃(neighbor) 수를 정합니다. 데이터 포인트 하나를 이해할 때 주변 데이터 포인트 개수를 나타냅니다. 입력이 없으면 데이터 개수에 따라 자동으로 계산합니다.\n- umap.UMAP(...)를 사용하여, 고차원 임베딩을 dim 차원으로 축소합니다.\n- 축소된 벡터들은 전역적(global)인 구조 파악에 도움이 되는 저차원 표현입니다.\n\n---\n\n`local_cluster_embeddings`\n\n- 선택한 데이터 부분집합에 대해 로컬(국소적) 차원 축소를 수행합니다.\n\n**과정**\n\n- 글로벌 차원 축소와 유사하지만, 로컬 차원 축소는 이미 한 번 전역 클러스터링을 통해 추출한 특정 그룹(글로벌 클러스터) 내 데이터에 대해 다시 UMAP을 적용합니다.\n- 이 과정은 전역적으로 파악된 큰 구조 안에서 더 세밀한 클러스터 구조를 파악하는 데 도움이 됩니다.\n\n### 최적의 클러스터 수 계산\n\n`get_optimal_clusters` \n\n- 주어진 임베딩 데이터에 대해 가장 적절한 클러스터 수를 BIC 점수를 기반으로 결정합니다.\n- GMM과 BIC를 활용해 클러스터 개수를 자동으로 결정하므로, 사전에 클러스터 수를 지정할 필요가 없습니다.\n\n**과정**\n\n- 가능한 클러스터 수(1 ~ max_clusters 사이)를 순회하며 각 클러스터 개수로 GMM을 학습합니다.\n- 각 GMM에 대해 BIC 점수를 계산한 뒤 리스트에 저장합니다.\n- BIC 점수가 가장 낮은(가장 좋은 성능을 보이는) 클러스터 개수를 선택하여 반환합니다.\n\n### 클러스터링 수행\n\n`GMM_cluster` \n\n- GMM을 이용해 주어진 임베딩에 대해 클러스터를 할당합니다.\n\n**과정**\n\n- `get_optimal_clusters` 를 통해 최적의 클러스터 수를 찾습니다.\n- `GaussianMixture` 모델을 해당 클러스터 수로 학습합니다.\n- 각 데이터 포인트가 각 클러스터에 속할 확률(predict_proba)을 구합니다.\n- 주어진 threshold를 바탕으로, 확률이 임계값을 초과하는 클러스터만 레이블로 할당합니다.\n\n`perform_clustering` \n\n- 전역 차원 축소, 전역 클러스터링, 이후 로컬 차원 축소 및 로컬 클러스터링까지 전체 클러스터링 파이프라인을 수행하는 핵심 함수입니다.\n- 이전의 과정을 하나의 파이프라인으로 만들어 종합하는 역할을 수행합니다.\n\n**과정**\n\n- 입력된 embeddings가 충분한지 확인(적은 경우 단순 할당).\n- 전역 차원 축소: `global_cluster_embeddings` 로 전체 임베딩에 대해 UMAP 적용.\n- 전역 클러스터링: 전역 차원 축소 결과에 대해 `GMM_cluster` 를 사용하여 전역 클러스터 형성.\n- 각 전역 클러스터에 속하는 데이터만 추출 -> 해당 집합에 대해 로컬 차원 축소(`local_cluster_embeddings`) 수행.\n- 로컬 차원 축소 결과에 대해 다시 `GMM_cluster` 로 로컬 클러스터링 수행.\n- 최종적으로, 각 데이터 포인트에 대해서 전역 및 로컬 클러스터 레이블을 함께 반환합니다.\n\n주어진 텍스트 리스트를 임베딩 모델을 이용해 벡터로 변환합니다.\n\n`embed_cluster_texts` \n\n- 텍스트 리스트를 임베딩하고, 위에서 정의한 클러스터링 절차를 수행한 뒤 결과를 데이터프레임 형태로 반환합니다\n\n**과정**\n\n- embed 함수를 통해 텍스트를 임베딩합니다.\n- perform_clustering를 호출하여 클러스터 라벨을 얻습니다.\n- 원본 텍스트, 임베딩, 클러스터 정보를 하나의 DataFrame에 통합하여 반환합니다.\n\n`fmt_txt` 함수는 `pandas`의 `DataFrame`에서 텍스트 문서를 단일 문자열로 포맷팅합니다.\n\n`embed_cluster_summarize_texts` \n\n- 텍스트 리스트에 대해 임베딩 → 클러스터링 → 요약 까지 전체 프로세스를 수행합니다.\n\n**과정**\n\n- 임베딩 & 클러스터링: `embed_cluster_texts` 함수를 이용해 입력된 텍스트를 임베딩하고 클러스터링한 결과를 `df_clusters` 로 얻습니다. 이 `df_clusters` 는 각 문서와 그 문서를 할당받은 (하나 이상일 수 있는) 클러스터를 가지고 있습니다.\n  \n- 클러스터 할당 확장: 어떤 문서가 여러 클러스터에 속할 수 있으므로, 이를 행 단위로 '문서-클러스터' 페어로 확장한 `expanded_df` 를 만듭니다. 이렇게 하면 이후 처리(특히 요약 단계)에서 각 클러스터별로 문서를 쉽게 그룹화할 수 있습니다.\n\n- LLM(대형 언어 모델)을 이용한 요약: 각 클러스터에 속한 문서들의 텍스트를 하나의 문자열로 합친 뒤(`fmt_txt` 사용), 프롬프트 템플릿을 통해 LLM에 전달합니다. LLM은 해당 클러스터에 대한 요약 문장을 생성합니다.\n\n- 요약 결과 정리: 클러스터별 요약 결과를 `df_summary` DataFrame에 저장합니다. 여기에는 summaries(요약문), level(입력 파라미터로 받은 처리 수준), cluster(클러스터 식별자)가 포함됩니다.\n\n`recursive_embed_cluster_summarize`\n\n- 텍스트 데이터에 대해 여러 \"단계(Level)\"에 걸쳐 클러스터링과 요약을 반복적으로 수행합니다.\n- 처음에는 원본 텍스트에 대해 클러스터링 및 요약을 수행한 뒤, 각 클러스터 요약을 다음 단계의 입력 텍스트로 삼아 다시 임베딩 → 클러스터링 → 요약을 반복합니다.\n\n전체 문서의 개수를 확인합니다.\n\n이제 `recursive_embed_cluster_summarize` 함수를 호출하여 트리 구축을 시작합니다.\n\n- `level=1` 은 첫 번째 단계의 클러스터링 및 요약부터 시작한다는 의미입니다.\n- `n_levels=3` 은 최대 세 단계까지(조건이 맞는 한) 클러스터링과 요약을 재귀적으로 반복할 수 있다는 뜻입니다.\n- \n결과적으로, 원본 텍스트(leaf_texts)는 먼저 level=1에서 요약되고 클러스터링됩니다. 그 결과로 나온 각 클러스터의 요약이 다음 단계의 입력(level=2)이 되고, 이를 다시 요약하여 클러스터링 한 결과가 level=3 단계의 입력이 될 수 있습니다. \n\n이 과정을 통해 점차 더 추상적이고 집약된 요약 정보를 얻을 수 있게 됩니다.\n\n다음으로는 vectorstore를 생성하고 로컬에 저장합니다.\n\nDB 를 로컬에 저장합니다.\n\n\n`vectorstore` 로부터 `retriever`를 생성합니다.\n\n## RAG 체인 정의\n\n이제 생성된 vectorstore를 이용해 RAG 체인을 정의하고 실행하여 결과를 확인합니다.\n\n[LangSmith 링크](https://smith.langchain.com/public/3e459bd4-4265-4c1d-b43d-279a1204d983/r)\n\n[LangSmith 링크](https://smith.langchain.com/public/c29887c7-f005-450a-a747-7d932c753721/r)\n","srcMarkdownNoYaml":"\n\n\n\n\n[RAPTOR](https://arxiv.org/pdf/2401.18059.pdf) 논문은 문서의 색인 생성 및 검색에 대한 흥미로운 접근 방식을 제시합니다.\n\n[테디노트 논문 요약글(노션)](https://teddylee777.notion.site/RAPTOR-e835d306fc664dc2ad76191dee1cd859?pvs=4)\n\n- `leafs` 는 가장 low-level 의 시작 문서 집합입니다. 이 문서들은 임베딩되어 클러스터링됩니다.\n- 그런 다음 클러스터는 유사한 문서들 간의 정보를 더 높은 수준(더 추상적인)으로 요약합니다.\n\n이 과정은 재귀적으로 수행되어, 원본 문서(`leafs`)에서 더 추상적인 요약으로 이어지는 \"트리\"를 형성합니다.\n\n`leafs`는 다음과 같은 문서들로 구성될 수 있습니다.\n\n- 단일 문서에서의 텍스트 청크(논문에서 보여준 것처럼)\n- 전체 문서(아래에서 보여주는 것처럼)\n\n이번 튜토리얼에서는 LangChain 의 LCEL 문서에 이를 적용해 보도록 하겠습니다. 소스코드 기반의 RAG 시스템을 구축할 때 RAPTOR 방법론을 적용하는 방법에 대해서 다룹니다.\n\n\n\n## 환경 설정\n\n## 데이터 전처리\n\n`doc`은 LCEL 문서의 고유한 웹 페이지입니다. context 는 2,000 토큰 미만에서 10,000 토큰 이상까지 다양합니다.\n\n웹 문서에서 텍스트 데이터를 추출하고, 텍스트의 토큰 수를 계산하여 히스토그램으로 시각화합니다.\n\n문서 텍스트를 정렬합니다. 이때 메타데이터의 `source` 를 기준으로 정렬한 뒤, 모든 문서를 연결합니다.\n\n`RecursiveCharacterTextSplitter`를 사용하여 텍스트를 분할합니다.\n\n다음으로는 분할된 chunk 들을 임베딩하여 vector store 에 저장합니다.\n\n## 모델 설정\n\n## 트리 구축\n\n트리 구축에서의 클러스터링 접근 방식에 대한 주요 개요입니다.\n\n**GMM (가우시안 혼합 모델)**\n\n- 다양한 클러스터에 걸쳐 데이터 포인트의 분포를 모델링합니다.\n- 모델의 베이지안 정보 기준(BIC)을 평가하여 최적의 클러스터 수를 결정합니다.\n\n**UMAP (Uniform Manifold Approximation and Projection)**\n\n- 클러스터링을 지원합니다.\n- 고차원 데이터의 차원을 축소합니다.\n- UMAP은 데이터 포인트의 유사성에 기반하여 자연스러운 그룹화를 강조하는 데 도움을 줍니다.\n\n**지역 및 전역 클러스터링**\n\n- 데이터를 저차원으로 차원 축소하여 클러스터링을 수행합니다.\n\n**임계값 설정**\n\n- GMM의 맥락에서 클러스터 멤버십을 결정하기 위해 적용됩니다.\n- 확률 분포를 기반으로 합니다(데이터 포인트를 ≥ 1 클러스터에 할당).\n\n---\n\nGMM 및 임계값 설정에 대한 코드는 아래 두 출처에서 언급된 Sarthi et al의 것입니다. \n\n**참조**\n\n- [원본 저장소](https://github.com/parthsarthi03/raptor/blob/master/raptor/cluster_tree_builder.py)\n- [소소한 조정](https://github.com/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-raptor/llama_index/packs/raptor/clustering.py)\n\n### 차원 축소\n\n`global_cluster_embeddings`\n\n- 입력된 임베딩 벡터를 전역적으로 차원 축소하기 위해 UMAP을 적용합니다. 전역적으로 차원을 축소한 결과물을 얻어 추후 클러스터링에 활용합니다.\n\n**과정**\n\n- n_neighbors: UMAP에 사용될 이웃(neighbor) 수를 정합니다. 데이터 포인트 하나를 이해할 때 주변 데이터 포인트 개수를 나타냅니다. 입력이 없으면 데이터 개수에 따라 자동으로 계산합니다.\n- umap.UMAP(...)를 사용하여, 고차원 임베딩을 dim 차원으로 축소합니다.\n- 축소된 벡터들은 전역적(global)인 구조 파악에 도움이 되는 저차원 표현입니다.\n\n---\n\n`local_cluster_embeddings`\n\n- 선택한 데이터 부분집합에 대해 로컬(국소적) 차원 축소를 수행합니다.\n\n**과정**\n\n- 글로벌 차원 축소와 유사하지만, 로컬 차원 축소는 이미 한 번 전역 클러스터링을 통해 추출한 특정 그룹(글로벌 클러스터) 내 데이터에 대해 다시 UMAP을 적용합니다.\n- 이 과정은 전역적으로 파악된 큰 구조 안에서 더 세밀한 클러스터 구조를 파악하는 데 도움이 됩니다.\n\n### 최적의 클러스터 수 계산\n\n`get_optimal_clusters` \n\n- 주어진 임베딩 데이터에 대해 가장 적절한 클러스터 수를 BIC 점수를 기반으로 결정합니다.\n- GMM과 BIC를 활용해 클러스터 개수를 자동으로 결정하므로, 사전에 클러스터 수를 지정할 필요가 없습니다.\n\n**과정**\n\n- 가능한 클러스터 수(1 ~ max_clusters 사이)를 순회하며 각 클러스터 개수로 GMM을 학습합니다.\n- 각 GMM에 대해 BIC 점수를 계산한 뒤 리스트에 저장합니다.\n- BIC 점수가 가장 낮은(가장 좋은 성능을 보이는) 클러스터 개수를 선택하여 반환합니다.\n\n### 클러스터링 수행\n\n`GMM_cluster` \n\n- GMM을 이용해 주어진 임베딩에 대해 클러스터를 할당합니다.\n\n**과정**\n\n- `get_optimal_clusters` 를 통해 최적의 클러스터 수를 찾습니다.\n- `GaussianMixture` 모델을 해당 클러스터 수로 학습합니다.\n- 각 데이터 포인트가 각 클러스터에 속할 확률(predict_proba)을 구합니다.\n- 주어진 threshold를 바탕으로, 확률이 임계값을 초과하는 클러스터만 레이블로 할당합니다.\n\n`perform_clustering` \n\n- 전역 차원 축소, 전역 클러스터링, 이후 로컬 차원 축소 및 로컬 클러스터링까지 전체 클러스터링 파이프라인을 수행하는 핵심 함수입니다.\n- 이전의 과정을 하나의 파이프라인으로 만들어 종합하는 역할을 수행합니다.\n\n**과정**\n\n- 입력된 embeddings가 충분한지 확인(적은 경우 단순 할당).\n- 전역 차원 축소: `global_cluster_embeddings` 로 전체 임베딩에 대해 UMAP 적용.\n- 전역 클러스터링: 전역 차원 축소 결과에 대해 `GMM_cluster` 를 사용하여 전역 클러스터 형성.\n- 각 전역 클러스터에 속하는 데이터만 추출 -> 해당 집합에 대해 로컬 차원 축소(`local_cluster_embeddings`) 수행.\n- 로컬 차원 축소 결과에 대해 다시 `GMM_cluster` 로 로컬 클러스터링 수행.\n- 최종적으로, 각 데이터 포인트에 대해서 전역 및 로컬 클러스터 레이블을 함께 반환합니다.\n\n주어진 텍스트 리스트를 임베딩 모델을 이용해 벡터로 변환합니다.\n\n`embed_cluster_texts` \n\n- 텍스트 리스트를 임베딩하고, 위에서 정의한 클러스터링 절차를 수행한 뒤 결과를 데이터프레임 형태로 반환합니다\n\n**과정**\n\n- embed 함수를 통해 텍스트를 임베딩합니다.\n- perform_clustering를 호출하여 클러스터 라벨을 얻습니다.\n- 원본 텍스트, 임베딩, 클러스터 정보를 하나의 DataFrame에 통합하여 반환합니다.\n\n`fmt_txt` 함수는 `pandas`의 `DataFrame`에서 텍스트 문서를 단일 문자열로 포맷팅합니다.\n\n`embed_cluster_summarize_texts` \n\n- 텍스트 리스트에 대해 임베딩 → 클러스터링 → 요약 까지 전체 프로세스를 수행합니다.\n\n**과정**\n\n- 임베딩 & 클러스터링: `embed_cluster_texts` 함수를 이용해 입력된 텍스트를 임베딩하고 클러스터링한 결과를 `df_clusters` 로 얻습니다. 이 `df_clusters` 는 각 문서와 그 문서를 할당받은 (하나 이상일 수 있는) 클러스터를 가지고 있습니다.\n  \n- 클러스터 할당 확장: 어떤 문서가 여러 클러스터에 속할 수 있으므로, 이를 행 단위로 '문서-클러스터' 페어로 확장한 `expanded_df` 를 만듭니다. 이렇게 하면 이후 처리(특히 요약 단계)에서 각 클러스터별로 문서를 쉽게 그룹화할 수 있습니다.\n\n- LLM(대형 언어 모델)을 이용한 요약: 각 클러스터에 속한 문서들의 텍스트를 하나의 문자열로 합친 뒤(`fmt_txt` 사용), 프롬프트 템플릿을 통해 LLM에 전달합니다. LLM은 해당 클러스터에 대한 요약 문장을 생성합니다.\n\n- 요약 결과 정리: 클러스터별 요약 결과를 `df_summary` DataFrame에 저장합니다. 여기에는 summaries(요약문), level(입력 파라미터로 받은 처리 수준), cluster(클러스터 식별자)가 포함됩니다.\n\n`recursive_embed_cluster_summarize`\n\n- 텍스트 데이터에 대해 여러 \"단계(Level)\"에 걸쳐 클러스터링과 요약을 반복적으로 수행합니다.\n- 처음에는 원본 텍스트에 대해 클러스터링 및 요약을 수행한 뒤, 각 클러스터 요약을 다음 단계의 입력 텍스트로 삼아 다시 임베딩 → 클러스터링 → 요약을 반복합니다.\n\n전체 문서의 개수를 확인합니다.\n\n이제 `recursive_embed_cluster_summarize` 함수를 호출하여 트리 구축을 시작합니다.\n\n- `level=1` 은 첫 번째 단계의 클러스터링 및 요약부터 시작한다는 의미입니다.\n- `n_levels=3` 은 최대 세 단계까지(조건이 맞는 한) 클러스터링과 요약을 재귀적으로 반복할 수 있다는 뜻입니다.\n- \n결과적으로, 원본 텍스트(leaf_texts)는 먼저 level=1에서 요약되고 클러스터링됩니다. 그 결과로 나온 각 클러스터의 요약이 다음 단계의 입력(level=2)이 되고, 이를 다시 요약하여 클러스터링 한 결과가 level=3 단계의 입력이 될 수 있습니다. \n\n이 과정을 통해 점차 더 추상적이고 집약된 요약 정보를 얻을 수 있게 됩니다.\n\n다음으로는 vectorstore를 생성하고 로컬에 저장합니다.\n\nDB 를 로컬에 저장합니다.\n\n\n`vectorstore` 로부터 `retriever`를 생성합니다.\n\n## RAG 체인 정의\n\n이제 생성된 vectorstore를 이용해 RAG 체인을 정의하고 실행하여 결과를 확인합니다.\n\n[LangSmith 링크](https://smith.langchain.com/public/3e459bd4-4265-4c1d-b43d-279a1204d983/r)\n\n[LangSmith 링크](https://smith.langchain.com/public/c29887c7-f005-450a-a747-7d932c753721/r)\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":true,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../../../../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"include-in-header":[{"text":"<style>\n.custom-footer { \n  text-align: center; \n  font-size: 0.8em; \n  color: #666; \n  margin-top: 2rem; \n}\n</style>\n"}],"include-after-body":["../../../../../js.html","../../../signup.html"],"output-file":"04-RAPTOR-Long-Context-RAG-CODE.html"},"language":{"toc-title-document":"목차","toc-title-website":"목차","related-formats-title":"기타 형식","related-notebooks-title":"Notebooks","source-notebooks-prefix":"원천","other-links-title":"기타 링크","code-links-title":"코드 링크","launch-dev-container-title":"Dev 컨테이너 실행","launch-binder-title":"랜치 Binder","article-notebook-label":"기사 노트북","notebook-preview-download":"노트북 다운로드","notebook-preview-download-src":"소스 다운로드","notebook-preview-back":"기사로 돌아가기","manuscript-meca-bundle":"MECA 아카이브","section-title-abstract":"초록","section-title-appendices":"부록","section-title-footnotes":"각주","section-title-references":"참고문헌","section-title-reuse":"라이센스","section-title-copyright":"저작권","section-title-citation":"인용","appendix-attribution-cite-as":"인용방법","appendix-attribution-bibtex":"BibTeX 인용:","title-block-author-single":"저자","title-block-author-plural":"저자","title-block-affiliation-single":"소속","title-block-affiliation-plural":"소속","title-block-published":"공개","title-block-modified":"Modified","title-block-keywords":"키워드","callout-tip-title":"힌트","callout-note-title":"노트","callout-warning-title":"경고","callout-important-title":"중요","callout-caution-title":"주의","code-summary":"코드","code-tools-menu-caption":"코드","code-tools-show-all-code":"전체 코드 표시","code-tools-hide-all-code":"전체 코드 숨기기","code-tools-view-source":"소스 코드 표시","code-tools-source-code":"소스 코드","tools-share":"Share","tools-download":"Download","code-line":"선","code-lines":"윤곽","copy-button-tooltip":"클립보드 복사","copy-button-tooltip-success":"복사완료!","repo-action-links-edit":"편집","repo-action-links-source":"소스코드 보기","repo-action-links-issue":"이슈 보고","back-to-top":"맨 위로","search-no-results-text":"일치 없음","search-matching-documents-text":"일치된 문서","search-copy-link-title":"검색 링크 복사","search-hide-matches-text":"추가 검색 결과 숨기기","search-more-match-text":"추가 검색결과","search-more-matches-text":"추가 검색결과","search-clear-button-title":"제거","search-text-placeholder":"","search-detached-cancel-button-title":"취소","search-submit-button-title":"검색","search-label":"검색","toggle-section":"토글 섹션","toggle-sidebar":"사이드바 전환","toggle-dark-mode":"다크 모드 전환","toggle-reader-mode":"리더 모드 전환","toggle-navigation":"탐색 전환","crossref-fig-title":"그림","crossref-tbl-title":"표","crossref-lst-title":"목록","crossref-thm-title":"정리","crossref-lem-title":"보조정리","crossref-cor-title":"따름정리","crossref-prp-title":"명제","crossref-cnj-title":"추측","crossref-def-title":"정의","crossref-exm-title":"보기","crossref-exr-title":"예제","crossref-ch-prefix":"장","crossref-apx-prefix":"부록","crossref-sec-prefix":"섹션","crossref-eq-prefix":"방정식","crossref-lof-title":"그림 목록","crossref-lot-title":"표 목록","crossref-lol-title":"코드 목록","environment-proof-title":"증명","environment-remark-title":"주석","environment-solution-title":"해답","listing-page-order-by":"정렬","listing-page-order-by-default":"디폴트","listing-page-order-by-date-asc":"날짜(오름차순)","listing-page-order-by-date-desc":"날짜(내림차순)","listing-page-order-by-number-desc":"페이지 번호(내림차순)","listing-page-order-by-number-asc":"페이지 번호(오름차순)","listing-page-field-date":"날짜","listing-page-field-title":"제목","listing-page-field-description":"설명","listing-page-field-author":"저자","listing-page-field-filename":"파일명","listing-page-field-filemodified":"갱신일","listing-page-field-subtitle":"부제목","listing-page-field-readingtime":"읽기 시간","listing-page-field-wordcount":"단어 수","listing-page-field-categories":"분류","listing-page-minutes-compact":"{0} 분","listing-page-category-all":"전체","listing-page-no-matches":"일치 없음","listing-page-words":"{0} 단어"},"metadata":{"lang":"ko","fig-responsive":true,"quarto-version":"1.4.543","theme":{"light":["cosmo","../../../../../theme.scss"],"dark":["cosmo","../../../../../theme-dark.scss"]},"code-copy":true,"grid":{"sidebar-width":"200px","body-width":"1200px","margin-width":"200px"},"comments":{"giscus":{"repo":"kmink3225/blog","category":"Blog"}},"title-block-banner":"#EDF3F9","title-block-banner-color":"black","toc-location":"right","open-graph":true,"twitter-card":true,"search":true,"date-format":"YYYY년 MM월 DD일","title":"RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}