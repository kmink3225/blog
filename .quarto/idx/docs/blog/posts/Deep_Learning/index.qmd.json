{"title":"Deep Learning","markdown":{"yaml":{"title":"Deep Learning","subtitle":"Deep Learning Content List","description":"","categories":["Deep Learning","AI"],"author":"Kwangmin Kim","date":"05/01/2023","format":{"html":{"page-layout":"full","code-fold":true,"toc":true,"number-sections":true}},"draft":false},"headingText":"딥러닝 기초 커리큘럼","containsRefs":false,"markdown":"\n\n\n## 함수\n\n1.  스칼라 함수\n2.  선형회귀 시뮬레이션\n3.  다변수 스칼라 함수\n4.  이진분류\n5.  벡터함수와 합성함수\n6.  벡터함수와 인공신경망\n7.  합성함수를 이용한 이진분류\n\n## 선형대수 및 신경망 기초\n\n1.  행렬과 행렬곱\n2.  특별한 행렬들의 성질\n3.  행렬곱으로 인공신경망 표현하기\n4.  행렬을 활용한 신경망 이진분류 및 다중분류\n5.  손실함수의 이해\n6.  인공신경망 회귀\n\n## 역전파를 위한 미분 개념\n\n1.  미분\n2.  합성함수 미분 (Chain Rule)\n3.  편미분\n4.  경사도 벡터\n5.  다변수 함수 체인룰\n6.  자코비안 행렬\n7.  수치미분\n\n## 최적화 알고리즘\n\n1.  최적화 이론 기초\n2.  제약 최적화 이론 기초\n\n### 전통적 최적화 방법론\n\n1.  1차원 최적화 방법\n2.  경사도벡터\n3.  경사하강법 (Gradient Descent)\n4.  최속강하법 (Steepest Descent)\n5.  최소자승법 & 가중최소자승법\n6.  켤레경사법 (Conjugate Gradient)\n7.  뉴턴법 (Newton-Raphson)\n8.  가우스-뉴턴법 (Gauss-Newton)\n9.  BFGS (Broyden–Fletcher–Goldfarb–Shanno)\n10. Levenberg-Marquardt 방법\n\n### 현대적 최적화 방법론\n\n1.  모멘텀 (Momentum)\n2.  Nesterov 가속 경사 (Nesterov Accelerated Gradient, NAG)\n3.  AdaGrad (Adaptive Gradient)\n4.  RMSProp (Root Mean Square Propagation)\n5.  Adam (Adaptive Moment Estimation)\n6.  AdamW (Adaptive Moment Estimation with Weight Decay)\n7.  Nadam (Nesterov-accelerated Adaptive Moment Estimation)\n8.  SAG/SAGA (Stochastic Average Gradient)\n9.  SWA (Stochastic Weight Averaging)\n10. FTRL (Follow The Regularized Leader)\n11. 유사 뉴턴 방법 (Quasi-Newton Methods): L-BFGS (Limited-memory BFGS)\n12. 유전 알고리즘 (Genetic Algorithms)\n13. 입자 군집 최적화 (Particle Swarm Optimization, PSO)\n14. 베이지안 최적화 (Bayesian Optimization)\n15. 최적화 알고리즘 비교\n\n## 선형 모델\n\n1.  사이킷런 선형 모델\n2.  다항특성 실험\n3.  선형 회귀의 데이터 행렬\n4.  선형회귀 데이터 행렬과 선형 모델\n5.  선형회귀 기저함수 모델 (특성 방정식)\n6.  선형회귀 목적함수\n7.  선형회귀 목적함수 미분\n8.  선형회귀 그레디언트\n9.  선형회귀 학습하기\n10. 오버피팅\n11. 정규화\n12. 제약 최적화\n\n## 로지스틱 회귀분석\n\n1.  개념\n2.  로지스틱 회귀 목적함수\n3.  로지스틱 목적함수 수치 미분\n4.  로지스틱 회귀 그레디언트\n5.  로지스틱 회귀 숫자 이미지 학습\n6.  로지스틱 회귀에 다항 특성 부여\n\n## 자동미분\n\n1.  Chain Rule\n2.  자동미분\n3.  파이토치 자동미분 기능\n4.  파이토치 다변수 함수 자동미분\n5.  자동 미분의 원리\n6.  자동 미분 구현\n7.  자동 미분 예제 코딩 실습\n8.  자동 미분을 이용한 로지스틱 회귀 1\n9.  자동 미분을 이용한 로지스틱 회귀 2\n10. 자동 미분을 이용한 로지스틱 회귀 3\n\n## 다층 신경망\n\n1.  선형 분류기의 합성\n2.  다층 신경망\n3.  수치미분을 이용한 신경망 학습\n4.  역전파 알고리즘: 포워드 패스와 z2까지 미분하기\n5.  역전파 알고리즘: W2와 b2에 대해 미분하기\n6.  역전파 알고리즘: b1에 대해 미분하기\n7.  역전파 알고리즘: W1에 대해 미분하기\n8.  역전파 알고리즘의 일반규칙: 자코비안 전치와 연쇄법칙\n9.  데이터가 여러개일 때 역전파 이해하기\n10. 역전파를 이용한 신경망 학습 구현\n11. fashion-mnist 실습\n\n## 심화 신경망 아키텍처\n\n1.  더 깊은 다층 신경망 설계하기\n2.  그래디언트 소실/폭발 문제와 해결책\n3.  활성화 함수의 종류와 특성 (ReLU, Leaky ReLU, GELU 등)\n4.  가중치 초기화 방법론 (Xavier, He 초기화 등)\n5.  배치 정규화의 원리와 구현\n6.  드롭아웃 기법의 이해와 적용\n7.  잔차 연결(Residual Connection)과 ResNet 구조\n8.  하이퍼파라미터 튜닝 전략\n9.  조기 종료(Early Stopping)와 학습률 스케줄링\n10. 앙상블 기법과 모델 평균화\n11. 심화 신경망 아키텍처 실습 (CIFAR-10 분류)\n\n## 컨볼루션 신경망(CNN)\n\n1.  CNN의 기본 구조와 원리\n2.  컨볼루션 연산과 필터의 이해\n3.  풀링 레이어와 특성 맵\n4.  대표적인 CNN 아키텍처 (LeNet, AlexNet, VGG)\n5.  깊은 CNN 구조 (ResNet, Inception, DenseNet)\n6.  전이학습과 파인튜닝 기법\n7.  객체 탐지 알고리즘 (R-CNN, YOLO, SSD)\n8.  세그멘테이션 기법 (FCN, U-Net, Mask R-CNN)\n9.  CNN 시각화 및 해석 방법\n10. CNN 프로젝트 (이미지 분류 및 객체 탐지) \\## 자연어 처리(NLP)\n\n### NLP 기초\n\n1.  자연어 처리의 개념\n2.  [자연어 처리 개요](./NLP/nlp_overview.qmd)\\\n3.  [정규표현식](./NLP/nlp_regular_expression.qmd)\n4.  텍스트 전처리 기법 (토큰화, 정규화, 불용어 제거)\\\n5.  토큰화\n6.  정규표현식을 활용한 텍스트 정제\n7.  정수 인코딩\\\n8.  패딩\n9.  텍스트 표현 방법\n10. 텍스트의 벡터화\n11. 카운트 기반의 벡터화\\\n12. 신경망 기반의 벡터화 - Multi Layer Perceptron\n13. One-hot 인코딩 개념\n\n### NLP 중급\n\n1.  워드 임베딩\n2.  워드 임베딩 모델\n    1.  Word2Vec\n    2.  GloVe\n    3.  FastText\n3.  RNN\n4.  RNN 기본 개념\n5.  LSTM\n6.  GRU\n7.  언어 모델링의 기초 개념\n8.  N-gram 모델과 통계적 언어 모델\n9.  NLP 응용 태스크\n    1.  감성 분석과 텍스트 분류 기법\n    2.  개체명 인식과 품사 태깅\n    3.  문서 유사도 계산과 정보 검색\n10. 실전 NLP 기초 프로젝트 (텍스트 분류, 감성 분석)\n11. 자연어 처리 분야의 주요 연구 분야\n12. 텍스트 정제의 이해\n13. 자연어 처리 단계\n14. 자연어 전처리에 사용하는 파이썬\n15. 카운트 기반 핵심어 분석\n16. 의미 연결망 분석 방법\n17. 자연어를 이해하기 위한 주요 신경망\n18. Seq2Seq\n19. Attention\n20. Transformer와 그 이후\n\n## 순환 신경망(RNN)과 시퀀스 모델링\n\n1.  시퀀스 데이터의 특성과 처리 방법\n2.  기본 RNN 구조와 작동 원리\n3.  그래디언트 소실 문제와 장기 의존성\n4.  LSTM 네트워크의 구조와 게이트 메커니즘\n5.  GRU(Gated Recurrent Unit)의 이해\n6.  양방향 RNN과 다층 RNN 구조\n7.  시퀀스-투-시퀀스 모델과 인코더-디코더 구조\n8.  자연어 처리를 위한 RNN 응용\n9.  시계열 예측 모델링\n10. 실전 RNN 프로젝트 (텍스트 생성, 기계 번역)\n\n## 어텐션 메커니즘\n\n1.  어텐션 메커니즘의 기본 개념\n2.  셀프 어텐션과 멀티헤드 어텐션\n3.  어텐션 스코어 계산 방법\n4.  쿼리, 키, 밸류의 개념\n5.  어텐션 마스킹 기법\n\n## 트랜스포머 아키텍처\n\n1.  트랜스포머 아키텍처의 구조와 원리\n2.  인코더-디코더 트랜스포머 모델\n3.  위치 인코딩 방법\n4.  BERT 모델의 구조와 사전학습 방법\n5.  GPT 계열 모델의 이해와 응용\n6.  트랜스포머 기반 언어 모델의 파인튜닝\n7.  비전 트랜스포머(ViT)와 이미지 처리\n8.  실전 트랜스포머 프로젝트 (질의응답, 요약 생성)\n\n## 자연어 처리 중급\n\n1.  자연어 처리 기초 - 텍스트 표현과 임베딩\n    1.  텍스트 표현의 기초\n        1.  텍스트를 숫자로 표현하기 위한 방법\n        2.  단어 빈도를 활용한 벡터 표현 방법 (BoW, TF-IDF)\n    2.  단어 임베딩 기법\n        1.  Word2Vec (CBOW, Skip-gram)\n        2.  GloVe, FastText\n        3.  Embedding Layer와 신경망 연동\n2.  자연어 처리 중급 - 기본 아키텍처와 태스크\n    1.  NLP 태스크 이해\n        1.  NLP 태스크의 유형과 특성\n        2.  텍스트 분류 문제 (감성 분석, 주제 분류 등)\n        3.  시퀀스 레이블링 문제 (개체명 인식, 품사 태깅 등)\n        4.  생성 태스크 (요약, 번역, 대화 등)\n    2.  순환 신경망 기반 모델\n        1.  RNN (Recurrent Neural Network) 기본 구조\n        2.  LSTM (Long Short-Term Memory)\n        3.  GRU (Gated Recurrent Unit)\n        4.  RNN 언어 모델\n    3.  시퀀스-투-시퀀스 모델\n        1.  Seq2Seq 아키텍처 개념\n        2.  Encoder-Decoder 구조\n        3.  Beam Search 디코딩 전략\n        4.  subword tokenization (BPE, WordPiece 등)\n3.  자연어 처리 고급 - 어텐션과 트랜스포머\n    1.  어텐션 메커니즘\n        1.  Attention Mechanism의 기본 개념\n        2.  다양한 어텐션 유형 (Bahdanau, Luong 등)\n    2.  트랜스포머 아키텍처\n        1.  Transformer Encoder - Positional Encoding\n        2.  Transformer Encoder - Multihead Self-Attention\n        3.  Transformer Encoder - FFNN (Feed-Forward Neural Network)\n        4.  Transformer Decoder\n        5.  트랜스포머 전체 아키텍처 이해\n4.  최신 NLP - 사전학습 언어 모델(PLM)\n    1.  언어 모델링의 발전\n        1.  사전학습 언어 모델 개념과 중요성\n        2.  RNN 언어 모델에서 트랜스포머 기반 모델로의 전환\n    2.  주요 사전학습 언어 모델\n        1.  BERT (Bidirectional Encoder Representations from Transformers)\n        2.  GPT (Generative Pre-trained Transformer) 계열\n        3.  BART (Bidirectional and Auto-Regressive Transformers)\n        4.  T5 (Text-to-Text Transfer Transformer)\n5.  실전 NLP - 허깅페이스 활용\n    1.  허깅페이스 생태계 이해\n        1.  현업에서의 방향성과 허깅페이스의 중요성\n        2.  허깅페이스 소개 및 주요 라이브러리\n        3.  허깅페이스 토크나이저 활용법\n    2.  모델 학습과 활용\n        1.  PLM 기반 모델 학습 방법론\n        2.  모델 파이프라인 구성\n6.  실제 프로젝트 적용\n    1.  텍스트 분류 프로젝트\n        1.  한국어 금융 뉴스 이진 분류\n            1.  데이터 전처리\n            2.  모델링과 예측\n    2.  다중 클래스 분류 프로젝트\n        1.  KorNLI 다중 클래스 분류\n            1.  데이터 전처리\n            2.  모델링과 예측\n    3.  다중 레이블 분류 프로젝트\n        1.  혐오 발언 다중 레이블 분류\n            1.  데이터 전처리\n            2.  모델링 및 예측\n7.  자연어 처리 최신 트렌드\n    1.  최신 동향과 미래 방향\n        1.  대형 모델(LLM)의 강세\n        2.  In-context Learning\n        3.  멀티링구얼, 멀티모달, 멀티태스크 접근\n\n## 고급 자연어 처리(NLP)\n\n1.  대규모 언어 모델(LLM)의 구조와 원리\n2.  사전학습과 파인튜닝 패러다임\n3.  프롬프트 엔지니어링과 인컨텍스트 학습\n4.  지시학습(Instruction Tuning)과 RLHF\n5.  다국어 모델과 크로스 링구얼 전이\n6.  문서 요약과 질의응답 시스템\n7.  대화 시스템과 챗봇 개발\n8.  텍스트 생성 제어와 디코딩 전략\n9.  언어 모델 평가 방법론\n10. 실전 고급 NLP 프로젝트 (챗봇, 요약 시스템)\n\n## 생성 모델\n\n1.  생성 모델의 개념과 종류\n2.  오토인코더의 구조와 원리\n3.  변분 오토인코더(VAE)의 수학적 기초\n4.  생성적 적대 신경망(GAN)의 기본 구조\n5.  다양한 GAN 아키텍처 (DCGAN, WGAN, StyleGAN)\n6.  조건부 생성 모델과 제어 가능한 생성\n7.  디퓨전 모델의 원리와 구조\n8.  텍스트-이미지 생성 모델 (DALL-E, Stable Diffusion)\n9.  생성 모델의 평가 방법\n10. 실전 생성 모델 프로젝트 (이미지 생성, 스타일 변환)\n\n## 강화학습과 딥 강화학습\n\n1.  강화학습의 기본 개념과 용어\n2.  확률과정(Random Process)\n3.  마르코프 결정 과정(MDP)\n4.  가치 기반 학습과 Q-러닝\n5.  정책 기반 학습과 정책 그래디언트\n6.  딥 Q-네트워크(DQN)의 구조와 알고리즘\n7.  Actor-Critic 방법론과 A3C, PPO 알고리즘\n8.  모델 기반 강화학습과 시뮬레이션\n9.  멀티에이전트 강화학습 시스템\n10. 강화학습의 탐색-활용 딜레마\n11. 실전 강화학습 프로젝트 (게임 에이전트 개발)\n\n## Introduction to RL (1) 강화학습 입문하기\n\n1.  지도학습과 강화학습\n2.  순차적 의사결정 문제\n3.  리워드\n4.  에이전트와 환경\n5.  Exploitation vs Exploration\n\n## Introduction to RL (2) Markov Decision Process\n\n1.  Markov Process\n2.  Markov Reward Process\n3.  Markov Decision Process\n\n## Introduction to RL (3) 벨만 방정식\n\n1.  벨만 기대 방정식 0단계\n2.  벨만 기대 방정식 1, 2단계\n3.  벨만 최적 방정식 0단계\n4.  벨만 최적 방정식 1, 2단계\n\n## RL in toy problems (1) MDP를 알 때의 플래닝\n\n1.  밸류 평가하기\n2.  Policy Iteration\n3.  Value Iteration\n\n## RL in toy problems (2) MDP를 모를 때의 밸류 평가\n\n1.  Monte Carlo Learning\n2.  TD Learning\n3.  MC와 TD 실습\n4.  MC vs TD\n\n## RL into the wild (1) Deep RL 첫걸음\n\n1.  함수를 활용한 근사\n2.  인공신경망의 도입\n3.  파이토치를 활용한 간단 실습\n\n## RL into the wild (2) Value 기반 에이전트\n\n1.  밸류 네트워크의 학습\n2.  딥 q 러닝 이론\n3.  딥 q 러닝 구현 및 실습\n\n## RL into the wild (3) Policy 기반 에이전트\n\n1.  Policy Gradient Theorem\n2.  REINFORCE 알고리즘\n3.  REINFORCE 알고리즘 실습\n4.  액터-크리틱 1부\n5.  액터-크리틱 2부\n\n## RL into the wild (4) Policy Gradient 심화\n\n1.  A3C\n2.  A3C 구현\n3.  PPO 이론\n4.  PPO 구현\n5.  알파고\n6.  알파고 제로\n\n## 딥러닝 최적화 및 확장\n\n1.  고급 최적화 알고리즘 (Adam, AdamW, LAMB)\n2.  학습률 스케줄링 전략과 구현\n3.  분산 학습 및 데이터 병렬화\n4.  모델 병렬화 및 파이프라인 병렬화\n5.  혼합 정밀도 훈련과 양자화 기법\n6.  모델 가지치기와 지식 증류\n7.  신경망 아키텍처 검색(NAS)\n8.  메타 러닝과 few-shot 학습\n9.  연합 학습과 프라이버시 보존 기법\n10. 그린 AI와 효율적인 딥러닝\n\n## MLOps와 딥러닝 시스템\n\n1.  MLOps의 개념과 생명주기\n2.  실험 추적 및 버전 관리\n3.  모델 패키징 및 서빙 아키텍처\n4.  배치 추론과 실시간 추론 시스템\n5.  모델 모니터링 및 성능 평가\n6.  A/B 테스트와 점진적 배포\n7.  모델 재학습 파이프라인 구축\n8.  클라우드 기반 딥러닝 인프라\n9.  엣지 디바이스를 위한 모델 최적화\n10. 실전 MLOps 프로젝트 (엔드투엔드 시스템 구축)\n\n## 최신 연구 동향 및 응용\n\n1.  자기지도학습과 표현 학습\n2.  멀티모달 학습 (텍스트-이미지, 오디오-비디오)\n3.  신경망 해석 가능성과 설명 가능한 AI\n4.  공정성, 편향성, 윤리적 AI\n5.  연속학습과 과거지식 망각 방지\n6.  그래프 신경망과 관계형 데이터 처리\n7.  신경망 기반 추천 시스템\n8.  의료 영상 및 헬스케어 응용\n9.  자율주행 및 로보틱스 응용\n10. 최신 논문 리뷰 및 구현 실습\n\n## AutoEncoder\n\n1.  오토인코더의 개념 및 주요 구성\n2.  VAE\n3.  오토인코더의 활용\n\n## Generative Adversarial Networks\n\n1.  GAN의 개념 및 주요 구성\n2.  DCGAN\n3.  GAN의 활용\n\n## 알고 있으면 쓸모있는 AI 관련 지식\n\n1.  Transfer Learning, Meta Learning, Few-shot Learning (1)\n2.  Transfer Learning, Meta Learning, Few-shot Learning (2)\n3.  XAI\n4.  신경망의 성능 개선 방법 (신경망 설계 관점)\n5.  신경망의 성능 개선 방법 (데이터 관점)\n6.  시스템 관점의 인공지능의 이해\n\n## 실습 환경 이해하기\n\n1.  실습 환경 이해하기\n\n## 화학물질 제조 데이터의 분류기 실습\n\n1.  문제 정의 및 데이터의 이해\n2.  주요 코드 미리보기\n3.  실습\n\n## 자전거 대여량 예측 모델 실습\n\n1.  문제 정의 및 데이터의 이해\n2.  구현을 위한 코드의 이해\n\n## 군집 모델 실습\n\n1.  문제 정의 및 데이터의 이해\n2.  구현을 위한 코드의 이해\n\n## 인공신경망을 사용한 분류기 실습\n\n1.  인공신경망 코드를 위한 주요 코드의 이해 (1)\n2.  인공신경망 코드를 위한 주요 코드의 이해 (2)\n3.  인공신경망을 사용한 분류기 생성\n\n## 인공신경망을 사용한 분류기 실습 (2)\n\n1.  인공신경망 코드를 위한 주요 코드의 이해\n2.  인공신경망 설계하기\n3.  인공신경망 학습하기\n\n## AlexNet을 사용한 이미지 분류기 실습\n\n1.  구현을 위한 코드의 이해\n2.  실습\n\n## VGGNet을 사용한 이미지 분류기 실습\n\n1.  구현을 위한 코드의 이해\n2.  실습\n\n## 이미지를 생성하는 오토인코더 실습\n\n1.  주요 코드 미리보기\n2.  VAE 실습\n\n## 감정분석 모델 구현을 통한 자연어 처리 실습\n\n1.  주요 코드 미리보기 (2)\n2.  주요 코드 미리보기 (1)\n3.  감정분석 모델 실습\n\n## 이미지를 생성하는 GAN 실습\n\n1.  GAN 실습\n\n## ResNet을 사용한 이미지 분류기 실습\n\n1.  ResNet을 사용한 이미지 분류기 실습_모듈 이해하기\n2.  RNet을 사용한 이미지 분류기 실습_ArgParse 이해하기\n\n## Computer Vision\n\n## Introduction\n\n1.  강사 소개\n2.  컴퓨터 비전 소개\n3.  개발 환경 소개\n\n## 데이터 구축\n\n1.  데이터셋 중요도\n2.  어노테이션\n3.  데이터셋 포맷\n4.  CVAT\n5.  빅데이터\n6.  데이터 구축 정리\n\n## Classification\n\n1.  Classification이란\n2.  CNN 복습\n3.  Classification 평가 지표\n4.  Classification 모델 설명\n5.  Classification 데이터셋\n6.  Classification 실습\n7.  Classification 정리\n\n## Object Detection\n\n1.  Object detection 설명\n2.  전통적인 object detection 방법\n3.  Two-stage 기법 설명\n4.  One-stage 기법 설명\n5.  최신 모델 설명 1부\n6.  최신 모델 설명 2부\n7.  Object detection 데이터셋\n8.  Object detection 실습\n9.  Object detection 정리\n\n## Segmentation\n\n1.  Segmentation 설명\n2.  Semantic Segmentation 모델 설명\n3.  Instance Segmentation\n4.  Panoptic Segmentation 모델 설명\n5.  Segmentation 데이터셋 설명 및 제작\n6.  Segmentation 실습\n7.  Segmentation 정리\n\n## Metric learning\n\n1.  Metric learning 설명\n2.  Metric learning 목적 함수\n3.  Metric learning 학습 방법\n4.  Metric learning 알고리즘\n5.  Metric learning 데이터셋 설명, 모델 학습 및 평가\n6.  Metric learning 정리\n\n## Computer Vision 기술 트랜드\n\n1.  Computer Vision Tasks 비교 요약\n2.  Computer Vision Application 1부\n3.  Computer Vision Application 2부\n4.  다양한 Computer Vision 분야 소개 1부\n5.  다양한 Computer Vision 분야 소개 2부\n6.  다양한 Computer Vision 분야 소개 3부\n7.  다양한 Computer Vision 분야 소개 4부\n8.  다양한 Computer Vision 분야 소개 5부\n9.  전체 강의 마무리 인사\n\n## Classification\n\n1.  실습 데이터 1 분석\n2.  Classfication 패키지 소개\n3.  Classfication 모델 설명\n4.  Classfication 모델 학습\n5.  Classfication 모델 평가 및 분석\n6.  실습 데이터 2 분석\n7.  classification 모델 설명\n8.  classification 모델 학습\n9.  classification 모델 평가 및 분석\n\n## Object Detection\n\n1.  Object Detection 패키지 소개\n2.  Object Detection 학습\n3.  Object Detection 평가 및 분석\n4.  Object Detection 모델 설명\n\n## Instance Segmentation\n\n1.  Instance Segmentation 패키지 소개\n2.  Instance Segmentation 데이터 구축 및 학습\n3.  Instance Segmentation 모델 소개\n\n## Image Retrieval\n\n1.  실습 데이터 분석\n2.  Image Retrieval 모델 설명 및 학습\n3.  Image Retrieval 활용\n\n## MLP 활용 회귀 - 데이터 직군 연봉 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  MLP 활용 연봉 예측 (1)\n7.  MLP 활용 연봉 예측 (2)\n\n## MLP 활용 분류 - 정상, 피싱 사이트 분류\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  MLP 활용 피싱 사이트 예측 (1)\n7.  MLP 활용 피싱 사이트 예측 (2)\n\n## TabNet 활용 회귀 - 부동산 가격 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  TabNet 활용 소득 예측 (1)\n7.  TabNet 활용 소득 예측 (2)\n\n## TabNet 활용 분류 - 데이터 직군 이직 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  TabNet 활용 이직 예측 (1)\n7.  TabNet 활용 이직 예측 (2)\n\n## AutoEncoder 활용 이상 탐지 - 심장 질병 이상 환자 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  데이터 범주화 및 탐색 (1)\n5.  데이터 범주화 및 탐색 (2)\n6.  AutoEncoder 활용 이상 진단 (1)\n7.  AutoEncoder 활용 이상 진단 (2)","srcMarkdownNoYaml":"\n\n# 딥러닝 기초 커리큘럼\n\n## 함수\n\n1.  스칼라 함수\n2.  선형회귀 시뮬레이션\n3.  다변수 스칼라 함수\n4.  이진분류\n5.  벡터함수와 합성함수\n6.  벡터함수와 인공신경망\n7.  합성함수를 이용한 이진분류\n\n## 선형대수 및 신경망 기초\n\n1.  행렬과 행렬곱\n2.  특별한 행렬들의 성질\n3.  행렬곱으로 인공신경망 표현하기\n4.  행렬을 활용한 신경망 이진분류 및 다중분류\n5.  손실함수의 이해\n6.  인공신경망 회귀\n\n## 역전파를 위한 미분 개념\n\n1.  미분\n2.  합성함수 미분 (Chain Rule)\n3.  편미분\n4.  경사도 벡터\n5.  다변수 함수 체인룰\n6.  자코비안 행렬\n7.  수치미분\n\n## 최적화 알고리즘\n\n1.  최적화 이론 기초\n2.  제약 최적화 이론 기초\n\n### 전통적 최적화 방법론\n\n1.  1차원 최적화 방법\n2.  경사도벡터\n3.  경사하강법 (Gradient Descent)\n4.  최속강하법 (Steepest Descent)\n5.  최소자승법 & 가중최소자승법\n6.  켤레경사법 (Conjugate Gradient)\n7.  뉴턴법 (Newton-Raphson)\n8.  가우스-뉴턴법 (Gauss-Newton)\n9.  BFGS (Broyden–Fletcher–Goldfarb–Shanno)\n10. Levenberg-Marquardt 방법\n\n### 현대적 최적화 방법론\n\n1.  모멘텀 (Momentum)\n2.  Nesterov 가속 경사 (Nesterov Accelerated Gradient, NAG)\n3.  AdaGrad (Adaptive Gradient)\n4.  RMSProp (Root Mean Square Propagation)\n5.  Adam (Adaptive Moment Estimation)\n6.  AdamW (Adaptive Moment Estimation with Weight Decay)\n7.  Nadam (Nesterov-accelerated Adaptive Moment Estimation)\n8.  SAG/SAGA (Stochastic Average Gradient)\n9.  SWA (Stochastic Weight Averaging)\n10. FTRL (Follow The Regularized Leader)\n11. 유사 뉴턴 방법 (Quasi-Newton Methods): L-BFGS (Limited-memory BFGS)\n12. 유전 알고리즘 (Genetic Algorithms)\n13. 입자 군집 최적화 (Particle Swarm Optimization, PSO)\n14. 베이지안 최적화 (Bayesian Optimization)\n15. 최적화 알고리즘 비교\n\n## 선형 모델\n\n1.  사이킷런 선형 모델\n2.  다항특성 실험\n3.  선형 회귀의 데이터 행렬\n4.  선형회귀 데이터 행렬과 선형 모델\n5.  선형회귀 기저함수 모델 (특성 방정식)\n6.  선형회귀 목적함수\n7.  선형회귀 목적함수 미분\n8.  선형회귀 그레디언트\n9.  선형회귀 학습하기\n10. 오버피팅\n11. 정규화\n12. 제약 최적화\n\n## 로지스틱 회귀분석\n\n1.  개념\n2.  로지스틱 회귀 목적함수\n3.  로지스틱 목적함수 수치 미분\n4.  로지스틱 회귀 그레디언트\n5.  로지스틱 회귀 숫자 이미지 학습\n6.  로지스틱 회귀에 다항 특성 부여\n\n## 자동미분\n\n1.  Chain Rule\n2.  자동미분\n3.  파이토치 자동미분 기능\n4.  파이토치 다변수 함수 자동미분\n5.  자동 미분의 원리\n6.  자동 미분 구현\n7.  자동 미분 예제 코딩 실습\n8.  자동 미분을 이용한 로지스틱 회귀 1\n9.  자동 미분을 이용한 로지스틱 회귀 2\n10. 자동 미분을 이용한 로지스틱 회귀 3\n\n## 다층 신경망\n\n1.  선형 분류기의 합성\n2.  다층 신경망\n3.  수치미분을 이용한 신경망 학습\n4.  역전파 알고리즘: 포워드 패스와 z2까지 미분하기\n5.  역전파 알고리즘: W2와 b2에 대해 미분하기\n6.  역전파 알고리즘: b1에 대해 미분하기\n7.  역전파 알고리즘: W1에 대해 미분하기\n8.  역전파 알고리즘의 일반규칙: 자코비안 전치와 연쇄법칙\n9.  데이터가 여러개일 때 역전파 이해하기\n10. 역전파를 이용한 신경망 학습 구현\n11. fashion-mnist 실습\n\n## 심화 신경망 아키텍처\n\n1.  더 깊은 다층 신경망 설계하기\n2.  그래디언트 소실/폭발 문제와 해결책\n3.  활성화 함수의 종류와 특성 (ReLU, Leaky ReLU, GELU 등)\n4.  가중치 초기화 방법론 (Xavier, He 초기화 등)\n5.  배치 정규화의 원리와 구현\n6.  드롭아웃 기법의 이해와 적용\n7.  잔차 연결(Residual Connection)과 ResNet 구조\n8.  하이퍼파라미터 튜닝 전략\n9.  조기 종료(Early Stopping)와 학습률 스케줄링\n10. 앙상블 기법과 모델 평균화\n11. 심화 신경망 아키텍처 실습 (CIFAR-10 분류)\n\n## 컨볼루션 신경망(CNN)\n\n1.  CNN의 기본 구조와 원리\n2.  컨볼루션 연산과 필터의 이해\n3.  풀링 레이어와 특성 맵\n4.  대표적인 CNN 아키텍처 (LeNet, AlexNet, VGG)\n5.  깊은 CNN 구조 (ResNet, Inception, DenseNet)\n6.  전이학습과 파인튜닝 기법\n7.  객체 탐지 알고리즘 (R-CNN, YOLO, SSD)\n8.  세그멘테이션 기법 (FCN, U-Net, Mask R-CNN)\n9.  CNN 시각화 및 해석 방법\n10. CNN 프로젝트 (이미지 분류 및 객체 탐지) \\## 자연어 처리(NLP)\n\n### NLP 기초\n\n1.  자연어 처리의 개념\n2.  [자연어 처리 개요](./NLP/nlp_overview.qmd)\\\n3.  [정규표현식](./NLP/nlp_regular_expression.qmd)\n4.  텍스트 전처리 기법 (토큰화, 정규화, 불용어 제거)\\\n5.  토큰화\n6.  정규표현식을 활용한 텍스트 정제\n7.  정수 인코딩\\\n8.  패딩\n9.  텍스트 표현 방법\n10. 텍스트의 벡터화\n11. 카운트 기반의 벡터화\\\n12. 신경망 기반의 벡터화 - Multi Layer Perceptron\n13. One-hot 인코딩 개념\n\n### NLP 중급\n\n1.  워드 임베딩\n2.  워드 임베딩 모델\n    1.  Word2Vec\n    2.  GloVe\n    3.  FastText\n3.  RNN\n4.  RNN 기본 개념\n5.  LSTM\n6.  GRU\n7.  언어 모델링의 기초 개념\n8.  N-gram 모델과 통계적 언어 모델\n9.  NLP 응용 태스크\n    1.  감성 분석과 텍스트 분류 기법\n    2.  개체명 인식과 품사 태깅\n    3.  문서 유사도 계산과 정보 검색\n10. 실전 NLP 기초 프로젝트 (텍스트 분류, 감성 분석)\n11. 자연어 처리 분야의 주요 연구 분야\n12. 텍스트 정제의 이해\n13. 자연어 처리 단계\n14. 자연어 전처리에 사용하는 파이썬\n15. 카운트 기반 핵심어 분석\n16. 의미 연결망 분석 방법\n17. 자연어를 이해하기 위한 주요 신경망\n18. Seq2Seq\n19. Attention\n20. Transformer와 그 이후\n\n## 순환 신경망(RNN)과 시퀀스 모델링\n\n1.  시퀀스 데이터의 특성과 처리 방법\n2.  기본 RNN 구조와 작동 원리\n3.  그래디언트 소실 문제와 장기 의존성\n4.  LSTM 네트워크의 구조와 게이트 메커니즘\n5.  GRU(Gated Recurrent Unit)의 이해\n6.  양방향 RNN과 다층 RNN 구조\n7.  시퀀스-투-시퀀스 모델과 인코더-디코더 구조\n8.  자연어 처리를 위한 RNN 응용\n9.  시계열 예측 모델링\n10. 실전 RNN 프로젝트 (텍스트 생성, 기계 번역)\n\n## 어텐션 메커니즘\n\n1.  어텐션 메커니즘의 기본 개념\n2.  셀프 어텐션과 멀티헤드 어텐션\n3.  어텐션 스코어 계산 방법\n4.  쿼리, 키, 밸류의 개념\n5.  어텐션 마스킹 기법\n\n## 트랜스포머 아키텍처\n\n1.  트랜스포머 아키텍처의 구조와 원리\n2.  인코더-디코더 트랜스포머 모델\n3.  위치 인코딩 방법\n4.  BERT 모델의 구조와 사전학습 방법\n5.  GPT 계열 모델의 이해와 응용\n6.  트랜스포머 기반 언어 모델의 파인튜닝\n7.  비전 트랜스포머(ViT)와 이미지 처리\n8.  실전 트랜스포머 프로젝트 (질의응답, 요약 생성)\n\n## 자연어 처리 중급\n\n1.  자연어 처리 기초 - 텍스트 표현과 임베딩\n    1.  텍스트 표현의 기초\n        1.  텍스트를 숫자로 표현하기 위한 방법\n        2.  단어 빈도를 활용한 벡터 표현 방법 (BoW, TF-IDF)\n    2.  단어 임베딩 기법\n        1.  Word2Vec (CBOW, Skip-gram)\n        2.  GloVe, FastText\n        3.  Embedding Layer와 신경망 연동\n2.  자연어 처리 중급 - 기본 아키텍처와 태스크\n    1.  NLP 태스크 이해\n        1.  NLP 태스크의 유형과 특성\n        2.  텍스트 분류 문제 (감성 분석, 주제 분류 등)\n        3.  시퀀스 레이블링 문제 (개체명 인식, 품사 태깅 등)\n        4.  생성 태스크 (요약, 번역, 대화 등)\n    2.  순환 신경망 기반 모델\n        1.  RNN (Recurrent Neural Network) 기본 구조\n        2.  LSTM (Long Short-Term Memory)\n        3.  GRU (Gated Recurrent Unit)\n        4.  RNN 언어 모델\n    3.  시퀀스-투-시퀀스 모델\n        1.  Seq2Seq 아키텍처 개념\n        2.  Encoder-Decoder 구조\n        3.  Beam Search 디코딩 전략\n        4.  subword tokenization (BPE, WordPiece 등)\n3.  자연어 처리 고급 - 어텐션과 트랜스포머\n    1.  어텐션 메커니즘\n        1.  Attention Mechanism의 기본 개념\n        2.  다양한 어텐션 유형 (Bahdanau, Luong 등)\n    2.  트랜스포머 아키텍처\n        1.  Transformer Encoder - Positional Encoding\n        2.  Transformer Encoder - Multihead Self-Attention\n        3.  Transformer Encoder - FFNN (Feed-Forward Neural Network)\n        4.  Transformer Decoder\n        5.  트랜스포머 전체 아키텍처 이해\n4.  최신 NLP - 사전학습 언어 모델(PLM)\n    1.  언어 모델링의 발전\n        1.  사전학습 언어 모델 개념과 중요성\n        2.  RNN 언어 모델에서 트랜스포머 기반 모델로의 전환\n    2.  주요 사전학습 언어 모델\n        1.  BERT (Bidirectional Encoder Representations from Transformers)\n        2.  GPT (Generative Pre-trained Transformer) 계열\n        3.  BART (Bidirectional and Auto-Regressive Transformers)\n        4.  T5 (Text-to-Text Transfer Transformer)\n5.  실전 NLP - 허깅페이스 활용\n    1.  허깅페이스 생태계 이해\n        1.  현업에서의 방향성과 허깅페이스의 중요성\n        2.  허깅페이스 소개 및 주요 라이브러리\n        3.  허깅페이스 토크나이저 활용법\n    2.  모델 학습과 활용\n        1.  PLM 기반 모델 학습 방법론\n        2.  모델 파이프라인 구성\n6.  실제 프로젝트 적용\n    1.  텍스트 분류 프로젝트\n        1.  한국어 금융 뉴스 이진 분류\n            1.  데이터 전처리\n            2.  모델링과 예측\n    2.  다중 클래스 분류 프로젝트\n        1.  KorNLI 다중 클래스 분류\n            1.  데이터 전처리\n            2.  모델링과 예측\n    3.  다중 레이블 분류 프로젝트\n        1.  혐오 발언 다중 레이블 분류\n            1.  데이터 전처리\n            2.  모델링 및 예측\n7.  자연어 처리 최신 트렌드\n    1.  최신 동향과 미래 방향\n        1.  대형 모델(LLM)의 강세\n        2.  In-context Learning\n        3.  멀티링구얼, 멀티모달, 멀티태스크 접근\n\n## 고급 자연어 처리(NLP)\n\n1.  대규모 언어 모델(LLM)의 구조와 원리\n2.  사전학습과 파인튜닝 패러다임\n3.  프롬프트 엔지니어링과 인컨텍스트 학습\n4.  지시학습(Instruction Tuning)과 RLHF\n5.  다국어 모델과 크로스 링구얼 전이\n6.  문서 요약과 질의응답 시스템\n7.  대화 시스템과 챗봇 개발\n8.  텍스트 생성 제어와 디코딩 전략\n9.  언어 모델 평가 방법론\n10. 실전 고급 NLP 프로젝트 (챗봇, 요약 시스템)\n\n## 생성 모델\n\n1.  생성 모델의 개념과 종류\n2.  오토인코더의 구조와 원리\n3.  변분 오토인코더(VAE)의 수학적 기초\n4.  생성적 적대 신경망(GAN)의 기본 구조\n5.  다양한 GAN 아키텍처 (DCGAN, WGAN, StyleGAN)\n6.  조건부 생성 모델과 제어 가능한 생성\n7.  디퓨전 모델의 원리와 구조\n8.  텍스트-이미지 생성 모델 (DALL-E, Stable Diffusion)\n9.  생성 모델의 평가 방법\n10. 실전 생성 모델 프로젝트 (이미지 생성, 스타일 변환)\n\n## 강화학습과 딥 강화학습\n\n1.  강화학습의 기본 개념과 용어\n2.  확률과정(Random Process)\n3.  마르코프 결정 과정(MDP)\n4.  가치 기반 학습과 Q-러닝\n5.  정책 기반 학습과 정책 그래디언트\n6.  딥 Q-네트워크(DQN)의 구조와 알고리즘\n7.  Actor-Critic 방법론과 A3C, PPO 알고리즘\n8.  모델 기반 강화학습과 시뮬레이션\n9.  멀티에이전트 강화학습 시스템\n10. 강화학습의 탐색-활용 딜레마\n11. 실전 강화학습 프로젝트 (게임 에이전트 개발)\n\n## Introduction to RL (1) 강화학습 입문하기\n\n1.  지도학습과 강화학습\n2.  순차적 의사결정 문제\n3.  리워드\n4.  에이전트와 환경\n5.  Exploitation vs Exploration\n\n## Introduction to RL (2) Markov Decision Process\n\n1.  Markov Process\n2.  Markov Reward Process\n3.  Markov Decision Process\n\n## Introduction to RL (3) 벨만 방정식\n\n1.  벨만 기대 방정식 0단계\n2.  벨만 기대 방정식 1, 2단계\n3.  벨만 최적 방정식 0단계\n4.  벨만 최적 방정식 1, 2단계\n\n## RL in toy problems (1) MDP를 알 때의 플래닝\n\n1.  밸류 평가하기\n2.  Policy Iteration\n3.  Value Iteration\n\n## RL in toy problems (2) MDP를 모를 때의 밸류 평가\n\n1.  Monte Carlo Learning\n2.  TD Learning\n3.  MC와 TD 실습\n4.  MC vs TD\n\n## RL into the wild (1) Deep RL 첫걸음\n\n1.  함수를 활용한 근사\n2.  인공신경망의 도입\n3.  파이토치를 활용한 간단 실습\n\n## RL into the wild (2) Value 기반 에이전트\n\n1.  밸류 네트워크의 학습\n2.  딥 q 러닝 이론\n3.  딥 q 러닝 구현 및 실습\n\n## RL into the wild (3) Policy 기반 에이전트\n\n1.  Policy Gradient Theorem\n2.  REINFORCE 알고리즘\n3.  REINFORCE 알고리즘 실습\n4.  액터-크리틱 1부\n5.  액터-크리틱 2부\n\n## RL into the wild (4) Policy Gradient 심화\n\n1.  A3C\n2.  A3C 구현\n3.  PPO 이론\n4.  PPO 구현\n5.  알파고\n6.  알파고 제로\n\n## 딥러닝 최적화 및 확장\n\n1.  고급 최적화 알고리즘 (Adam, AdamW, LAMB)\n2.  학습률 스케줄링 전략과 구현\n3.  분산 학습 및 데이터 병렬화\n4.  모델 병렬화 및 파이프라인 병렬화\n5.  혼합 정밀도 훈련과 양자화 기법\n6.  모델 가지치기와 지식 증류\n7.  신경망 아키텍처 검색(NAS)\n8.  메타 러닝과 few-shot 학습\n9.  연합 학습과 프라이버시 보존 기법\n10. 그린 AI와 효율적인 딥러닝\n\n## MLOps와 딥러닝 시스템\n\n1.  MLOps의 개념과 생명주기\n2.  실험 추적 및 버전 관리\n3.  모델 패키징 및 서빙 아키텍처\n4.  배치 추론과 실시간 추론 시스템\n5.  모델 모니터링 및 성능 평가\n6.  A/B 테스트와 점진적 배포\n7.  모델 재학습 파이프라인 구축\n8.  클라우드 기반 딥러닝 인프라\n9.  엣지 디바이스를 위한 모델 최적화\n10. 실전 MLOps 프로젝트 (엔드투엔드 시스템 구축)\n\n## 최신 연구 동향 및 응용\n\n1.  자기지도학습과 표현 학습\n2.  멀티모달 학습 (텍스트-이미지, 오디오-비디오)\n3.  신경망 해석 가능성과 설명 가능한 AI\n4.  공정성, 편향성, 윤리적 AI\n5.  연속학습과 과거지식 망각 방지\n6.  그래프 신경망과 관계형 데이터 처리\n7.  신경망 기반 추천 시스템\n8.  의료 영상 및 헬스케어 응용\n9.  자율주행 및 로보틱스 응용\n10. 최신 논문 리뷰 및 구현 실습\n\n## AutoEncoder\n\n1.  오토인코더의 개념 및 주요 구성\n2.  VAE\n3.  오토인코더의 활용\n\n## Generative Adversarial Networks\n\n1.  GAN의 개념 및 주요 구성\n2.  DCGAN\n3.  GAN의 활용\n\n## 알고 있으면 쓸모있는 AI 관련 지식\n\n1.  Transfer Learning, Meta Learning, Few-shot Learning (1)\n2.  Transfer Learning, Meta Learning, Few-shot Learning (2)\n3.  XAI\n4.  신경망의 성능 개선 방법 (신경망 설계 관점)\n5.  신경망의 성능 개선 방법 (데이터 관점)\n6.  시스템 관점의 인공지능의 이해\n\n## 실습 환경 이해하기\n\n1.  실습 환경 이해하기\n\n## 화학물질 제조 데이터의 분류기 실습\n\n1.  문제 정의 및 데이터의 이해\n2.  주요 코드 미리보기\n3.  실습\n\n## 자전거 대여량 예측 모델 실습\n\n1.  문제 정의 및 데이터의 이해\n2.  구현을 위한 코드의 이해\n\n## 군집 모델 실습\n\n1.  문제 정의 및 데이터의 이해\n2.  구현을 위한 코드의 이해\n\n## 인공신경망을 사용한 분류기 실습\n\n1.  인공신경망 코드를 위한 주요 코드의 이해 (1)\n2.  인공신경망 코드를 위한 주요 코드의 이해 (2)\n3.  인공신경망을 사용한 분류기 생성\n\n## 인공신경망을 사용한 분류기 실습 (2)\n\n1.  인공신경망 코드를 위한 주요 코드의 이해\n2.  인공신경망 설계하기\n3.  인공신경망 학습하기\n\n## AlexNet을 사용한 이미지 분류기 실습\n\n1.  구현을 위한 코드의 이해\n2.  실습\n\n## VGGNet을 사용한 이미지 분류기 실습\n\n1.  구현을 위한 코드의 이해\n2.  실습\n\n## 이미지를 생성하는 오토인코더 실습\n\n1.  주요 코드 미리보기\n2.  VAE 실습\n\n## 감정분석 모델 구현을 통한 자연어 처리 실습\n\n1.  주요 코드 미리보기 (2)\n2.  주요 코드 미리보기 (1)\n3.  감정분석 모델 실습\n\n## 이미지를 생성하는 GAN 실습\n\n1.  GAN 실습\n\n## ResNet을 사용한 이미지 분류기 실습\n\n1.  ResNet을 사용한 이미지 분류기 실습_모듈 이해하기\n2.  RNet을 사용한 이미지 분류기 실습_ArgParse 이해하기\n\n## Computer Vision\n\n## Introduction\n\n1.  강사 소개\n2.  컴퓨터 비전 소개\n3.  개발 환경 소개\n\n## 데이터 구축\n\n1.  데이터셋 중요도\n2.  어노테이션\n3.  데이터셋 포맷\n4.  CVAT\n5.  빅데이터\n6.  데이터 구축 정리\n\n## Classification\n\n1.  Classification이란\n2.  CNN 복습\n3.  Classification 평가 지표\n4.  Classification 모델 설명\n5.  Classification 데이터셋\n6.  Classification 실습\n7.  Classification 정리\n\n## Object Detection\n\n1.  Object detection 설명\n2.  전통적인 object detection 방법\n3.  Two-stage 기법 설명\n4.  One-stage 기법 설명\n5.  최신 모델 설명 1부\n6.  최신 모델 설명 2부\n7.  Object detection 데이터셋\n8.  Object detection 실습\n9.  Object detection 정리\n\n## Segmentation\n\n1.  Segmentation 설명\n2.  Semantic Segmentation 모델 설명\n3.  Instance Segmentation\n4.  Panoptic Segmentation 모델 설명\n5.  Segmentation 데이터셋 설명 및 제작\n6.  Segmentation 실습\n7.  Segmentation 정리\n\n## Metric learning\n\n1.  Metric learning 설명\n2.  Metric learning 목적 함수\n3.  Metric learning 학습 방법\n4.  Metric learning 알고리즘\n5.  Metric learning 데이터셋 설명, 모델 학습 및 평가\n6.  Metric learning 정리\n\n## Computer Vision 기술 트랜드\n\n1.  Computer Vision Tasks 비교 요약\n2.  Computer Vision Application 1부\n3.  Computer Vision Application 2부\n4.  다양한 Computer Vision 분야 소개 1부\n5.  다양한 Computer Vision 분야 소개 2부\n6.  다양한 Computer Vision 분야 소개 3부\n7.  다양한 Computer Vision 분야 소개 4부\n8.  다양한 Computer Vision 분야 소개 5부\n9.  전체 강의 마무리 인사\n\n## Classification\n\n1.  실습 데이터 1 분석\n2.  Classfication 패키지 소개\n3.  Classfication 모델 설명\n4.  Classfication 모델 학습\n5.  Classfication 모델 평가 및 분석\n6.  실습 데이터 2 분석\n7.  classification 모델 설명\n8.  classification 모델 학습\n9.  classification 모델 평가 및 분석\n\n## Object Detection\n\n1.  Object Detection 패키지 소개\n2.  Object Detection 학습\n3.  Object Detection 평가 및 분석\n4.  Object Detection 모델 설명\n\n## Instance Segmentation\n\n1.  Instance Segmentation 패키지 소개\n2.  Instance Segmentation 데이터 구축 및 학습\n3.  Instance Segmentation 모델 소개\n\n## Image Retrieval\n\n1.  실습 데이터 분석\n2.  Image Retrieval 모델 설명 및 학습\n3.  Image Retrieval 활용\n\n## MLP 활용 회귀 - 데이터 직군 연봉 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  MLP 활용 연봉 예측 (1)\n7.  MLP 활용 연봉 예측 (2)\n\n## MLP 활용 분류 - 정상, 피싱 사이트 분류\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  MLP 활용 피싱 사이트 예측 (1)\n7.  MLP 활용 피싱 사이트 예측 (2)\n\n## TabNet 활용 회귀 - 부동산 가격 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  TabNet 활용 소득 예측 (1)\n7.  TabNet 활용 소득 예측 (2)\n\n## TabNet 활용 분류 - 데이터 직군 이직 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  가설 수립 및 검증 (1)\n5.  가설 수립 및 검증 (2)\n6.  TabNet 활용 이직 예측 (1)\n7.  TabNet 활용 이직 예측 (2)\n\n## AutoEncoder 활용 이상 탐지 - 심장 질병 이상 환자 예측\n\n1.  문제 상황 및 데이터 살펴보기\n2.  문제 해결 프로세스 정의\n3.  Data 전처리 및 EDA\n4.  데이터 범주화 및 탐색 (1)\n5.  데이터 범주화 및 탐색 (2)\n6.  AutoEncoder 활용 이상 진단 (1)\n7.  AutoEncoder 활용 이상 진단 (2)"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":true,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../../../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"include-in-header":[{"text":"<style>\n.custom-footer { \n  text-align: center; \n  font-size: 0.8em; \n  color: #666; \n  margin-top: 2rem; \n}\n</style>\n"}],"include-after-body":["../../../../js.html","../../signup.html"],"output-file":"index.html"},"language":{"toc-title-document":"목차","toc-title-website":"목차","related-formats-title":"기타 형식","related-notebooks-title":"Notebooks","source-notebooks-prefix":"원천","other-links-title":"기타 링크","code-links-title":"코드 링크","launch-dev-container-title":"Dev 컨테이너 실행","launch-binder-title":"랜치 Binder","article-notebook-label":"기사 노트북","notebook-preview-download":"노트북 다운로드","notebook-preview-download-src":"소스 다운로드","notebook-preview-back":"기사로 돌아가기","manuscript-meca-bundle":"MECA 아카이브","section-title-abstract":"초록","section-title-appendices":"부록","section-title-footnotes":"각주","section-title-references":"참고문헌","section-title-reuse":"라이센스","section-title-copyright":"저작권","section-title-citation":"인용","appendix-attribution-cite-as":"인용방법","appendix-attribution-bibtex":"BibTeX 인용:","title-block-author-single":"저자","title-block-author-plural":"저자","title-block-affiliation-single":"소속","title-block-affiliation-plural":"소속","title-block-published":"공개","title-block-modified":"Modified","title-block-keywords":"키워드","callout-tip-title":"힌트","callout-note-title":"노트","callout-warning-title":"경고","callout-important-title":"중요","callout-caution-title":"주의","code-summary":"코드","code-tools-menu-caption":"코드","code-tools-show-all-code":"전체 코드 표시","code-tools-hide-all-code":"전체 코드 숨기기","code-tools-view-source":"소스 코드 표시","code-tools-source-code":"소스 코드","tools-share":"Share","tools-download":"Download","code-line":"선","code-lines":"윤곽","copy-button-tooltip":"클립보드 복사","copy-button-tooltip-success":"복사완료!","repo-action-links-edit":"편집","repo-action-links-source":"소스코드 보기","repo-action-links-issue":"이슈 보고","back-to-top":"맨 위로","search-no-results-text":"일치 없음","search-matching-documents-text":"일치된 문서","search-copy-link-title":"검색 링크 복사","search-hide-matches-text":"추가 검색 결과 숨기기","search-more-match-text":"추가 검색결과","search-more-matches-text":"추가 검색결과","search-clear-button-title":"제거","search-text-placeholder":"","search-detached-cancel-button-title":"취소","search-submit-button-title":"검색","search-label":"검색","toggle-section":"토글 섹션","toggle-sidebar":"사이드바 전환","toggle-dark-mode":"다크 모드 전환","toggle-reader-mode":"리더 모드 전환","toggle-navigation":"탐색 전환","crossref-fig-title":"그림","crossref-tbl-title":"표","crossref-lst-title":"목록","crossref-thm-title":"정리","crossref-lem-title":"보조정리","crossref-cor-title":"따름정리","crossref-prp-title":"명제","crossref-cnj-title":"추측","crossref-def-title":"정의","crossref-exm-title":"보기","crossref-exr-title":"예제","crossref-ch-prefix":"장","crossref-apx-prefix":"부록","crossref-sec-prefix":"섹션","crossref-eq-prefix":"방정식","crossref-lof-title":"그림 목록","crossref-lot-title":"표 목록","crossref-lol-title":"코드 목록","environment-proof-title":"증명","environment-remark-title":"주석","environment-solution-title":"해답","listing-page-order-by":"정렬","listing-page-order-by-default":"디폴트","listing-page-order-by-date-asc":"날짜(오름차순)","listing-page-order-by-date-desc":"날짜(내림차순)","listing-page-order-by-number-desc":"페이지 번호(내림차순)","listing-page-order-by-number-asc":"페이지 번호(오름차순)","listing-page-field-date":"날짜","listing-page-field-title":"제목","listing-page-field-description":"설명","listing-page-field-author":"저자","listing-page-field-filename":"파일명","listing-page-field-filemodified":"갱신일","listing-page-field-subtitle":"부제목","listing-page-field-readingtime":"읽기 시간","listing-page-field-wordcount":"단어 수","listing-page-field-categories":"분류","listing-page-minutes-compact":"{0} 분","listing-page-category-all":"전체","listing-page-no-matches":"일치 없음","listing-page-words":"{0} 단어"},"metadata":{"lang":"ko","fig-responsive":true,"quarto-version":"1.4.543","theme":{"light":["cosmo","../../../../theme.scss"],"dark":["cosmo","../../../../theme-dark.scss"]},"code-copy":true,"grid":{"sidebar-width":"200px","body-width":"1200px","margin-width":"200px"},"comments":{"giscus":{"repo":"kmink3225/blog","category":"Blog"}},"title-block-banner":"#EDF3F9","title-block-banner-color":"black","toc-location":"right","open-graph":true,"twitter-card":true,"search":true,"date-format":"YYYY년 MM월 DD일","title":"Deep Learning","subtitle":"Deep Learning Content List","description":"","categories":["Deep Learning","AI"],"author":"Kwangmin Kim","date":"05/01/2023","draft":false,"page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}