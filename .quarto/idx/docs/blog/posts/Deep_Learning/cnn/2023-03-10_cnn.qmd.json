{"title":"CNN","markdown":{"yaml":{"title":"CNN","author":"Kwangmin Kim","date":"2023.03.10","categories":["Deep Learning"],"format":{"html":{"page-layout":"full","toc":true,"code-fold":true,"number-sections":true}}},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n## Fully Connected Layer (MLP)의 문제점\n\nAffine Layer는 인접하는 Layers의 nodes가 모두 연결되고 출력의 수가 임의로 정해지는 특징을 갖는데 이 때 data shape가 무시가 되는 단점이 있다. 이미지 데이터는 보통 (weight, height, color channel) 형태의 shape를 갖지만 MLP에서 이 3차원 구조가 1차원으로 flatten된다. 다시 말해서, 3차원의 이미지 pixels이라는 여러 독립 변수의 위치적 상관성이 1차원화 되면서 무시가 된다.\n\n많은 일반 머신러닝 모델이나 통계 분석 모델은 독립 변수가 독립이라는 가정이 고려되어야 하지만 이미지의 독립 변수들이 서로 독립이 아니다. 픽셀값은 그 위치에 따라서 서로 상관성이 존재한다. 초기엔 독립 변수인 픽셀을 일렬로 늘어뜨려 input으로 사용했지만 위치 기반 픽셀의 상관성 정도를 자세히 반영하진 못했다. 이를 보완하기 위해 CNN에서는 **region feature**가 고안됐다. 이처럼, CNN은 이미지 인식 분야에서 독보적인 영역을 갖고 있다.\n\n## Region Feature\n\nRegion Feature 또는 Graphic Feature라고도 한다. 픽셀의 지역 정보를 학습할 수 있는 신경망 구조가 CNN이다. \n\n# CNN\n\n![CNN Structure Example](../../../../../images/cnn/figure1.png){#fig-CNN_structure}\n\n**Convolutional Neural Network** (CNN)은 합성곱(convolution)으로 이루어진 인공신경망으로 Region Feature를 학습하기 위한 모형이다. CNN은 \n\n* region feature를 추출하기 위한 convolution layer, \n* activation function,\n* feature dimension을 위한 pooling layer \n* fully connected layer (Multi Layer Perceptron (MLP) or Affine Transformation)\n* Softmax function\n\n로 구성되어 있다 (See @fig-CNN_structure).\n\n\n## Convolution Layer (Conv)\n\nkernel 또는 filter라고 불리는 특징 추출기(Feature detector)를 사용하여 데이터의 특징을 추출하는 CNN 모델의 핵심 부분이다. kernel 를 정의해 입력 층의 이미지의 feature를 추출한다. kernel는 region feature의 크기와 weight을 정의하게 된다. 예를 들어, kernel을 (3x3)으로 정하면 9칸에 가중치를 설정하여 이미지 픽셀값 (a part of input feature map)과 kernel의 weight의 선형결합으로 conv layer를 구성하는 하나의 값을 얻어낸다 (See @fig-CNN_structure 의 노란색 사각형). \n\nconvolution layer의 input/output은 보통 feature map이라고 부르며 input data를 input feature map, output data를 output feature map로 부르기도 한다. 즉, feature map 과 input/output data는 같은 의미로 사용되고 feature map = input data + kernel (= receptive field = filter)로 구성된다.\n\n\n### Convolution Operation \n\nConvolution Operation (합성곱 연산)은 filter operation (filter 연산)이라고도 불린다. @fig-conv_operation 을 보면 입력 데이터 (이미지의 pixels)와 filter의 가중치가 element-wise 별로 곱해져 더해진다. 이 연산을 fused-multiply-add (FMA) or multiply-accumulate operation 라고도 부른다. 예를 들어, input data의 `r matrix(c(4,9,2,5,6,2,2,4,5),nrow=3,byrow = T)`와 filter1 의 `r  matrix(c(1,0,-1,1,0,-1,1,0,-1),nrow=3,byrow = T)` 가 곱해지고 더해져 `r matrix(c(4,9,2,5,6,2,2,4,5),nrow=3,byrow = T)*matrix(c(1,0,-1,1,0,-1,1,0,-1),nrow=3,byrow = T)`의 결과가 Conv Layer의 output data의 한 칸을 구성하게 된다. \n\n![Convolution Operation Example](../../../../../images/cnn/figure2.png){#fig-conv_operation}\n\n이렇게, 2차원 입력에 대한 convolution (conv) operation은 @fig-conv-operation-process 과 같이 동작한다. Sharpen filter라고 쓰여진 3x3 행렬은 kernel로서 입력 데이터의 특징을 추출하는데, 입력 데이터의 전체를 보는 것이 \n아닌 kernel size 만큼의 일부분만을 보며 특징을 추출한다. feature map은 kernel의 개수만큼 생성되는데 일반적으로 다양한 특징을 추출하기 위해 하나의 conv layer에서 여러개의 kernel을 사용한다. kernel size에 정해진 규칙은 없으나 주로 3*3 많이 사용하며 대게 conv layer마다 다른 kernel size를 적용한다. Fully connected layer에서의 weight는 CNN에서 filter의 weight과 대응되고 CNN에서의 bias는 항상 scalar로 주어진다.\n\n![Convolution Operation Process Example](../../../../../images/cnn/figure3.gif){#fig-conv-operation-process}\n\n### 합성곱 연산을 위한 설정 사항\n\n- padding : 입력 데이터의 테두리를 0으로 채워 데이터의 크기를 늘려준다\n    - **왜 padding을 사용하는가?** padding이 없을 경우 합성곱은 입력 데이터의 1행 1열부터 시작된다. 그런데 합성곱은 입력 데이터에서 kernel size만큼의 영역을 하나로 축소하여 특징을 추출하기 때문에 이 경우 입력 데이터의 가장자리, edge 부분의 특징을 추출하기 어렵다. edge의 특징까지 추출하고자 하면 적어도 0행 0열부터 kernel을 적용해야 하는데 허공에서 element-wise 계산을 할 수 없으니 0을 추가해준다. 다시 말해서, padding은 output data size를 조정할 목적으로 사용된다.\n    ![Output Feature Map](../2023-03-10_cnn/output_featuremap.png){#fig-output_featuremap}\n- stride : kernel이 얼만큼씩 이동하면서 합성곱 계산을 할 것인지를 의미한다.\n    - stride를 키우게 되면 output data size가 작아지기 때문에 일반적으로 한 칸씩 이동한다.\n    ![Stride Example](../../../../../images/cnn/stride.PNG){#fig-stride}\n- weight sharing:    \n- kernel size : kernel의 행과 열 개수\n    - 사이즈가 작을수록 국소 단위의 특징을 추출한다.\n- kernel 개수 또는 channel 개수 : 몇 개의 feature map을 추출하고 싶은지에 따라 kernel 개수를 정한다.\n    ![Channel Number](../../../../../images/cnn/channel%20number.PNG){#fig-channel_number}\n* 이미지 데이터에서의 channel 예시\n  * 고양이 이미지와 같이 컬러 이미지 데이터는 하나의 이미지에 대해 Red, Green, Blue (RGB) 3개의 색상으로 이루어져 있다 \n    ![RGB 이미지를 red, green, blue channel 별 분리하여 표시](../../../../../images/cnn/image_featuremap.png){#fig-img_featuremap}\n    ![이미지 데이터의 RGB channel에 대한 convolution 계산 예시](../../../../../images/cnn/image_featuremap_convolution.png){#fig-img_featuremap_conv}\n\n### feature map의 shape 계산 방법\n\nfeature map은 다음 레이어의 입력 데이터가 되기 때문에 feature map의 shape을 계산할 수 있어야한다.\n\n#### 2 Dimension Input Data Size\n\n다음과 같이 output data size계산을 위한 notation을 정의할 때,\n\n* input data size : $(H,W)$\n* filter size : $(FH, FW)$\n* output data size : $(OH, OW)$\n* padding : $P$ (width number)\n* stride : $S$\n* a function to make the calculation result an integer\n  * floor function : $\\lfloor \\text{ } \\rfloor$\n  * ceiling : $\\lceil \\text{ } \\rceil$\n  * rounding to the nearest integer: $\\lfloor \\text{ } \\rceil$\n\n$$\n\\begin{aligned}\n  OH=&\\lfloor\\frac{H+2P-FH}{S}+1\\rfloor\\\\\n  OW=&\\lfloor\\frac{W+2P-FW}{S}+1\\rfloor\n\\end{aligned}\n$$\n\n의 관계식을 따르게 된다.\n\n* 예시1- input size: (4x4), P:1, S:1, filter size : (3x3)일 때, $(OH,OW)=(4,4)$\n* 예시2- input size: (7x7), P:0, S:2, filter size : (3x3)일 때, $(OH,OW)=(3,3)$\n* 예시3- input size: (28x31), P:2, S:3, filter size : (5x5)일 때, $(OH,OW)=(10,11)$\n\n\n\n#### 3 Dimension Input Data Size\n\n길이 또는 채널 방향으로 feature map이 늘어나기 때문에 그 결과는 @fig-conv_operation 과 같이 나온다. 반드시 input data의 channel 수와 output data channel수가 같아야한다. 채널이 3개면 filter 당 3장의 feature map이 나오게 된다. filter의 종류의 수 weight의 종류의 수로 output data의 길이를 늘리려면 (즉, 다수의 채널로 만드려면) filter의 수 (=weight의 종류)를 늘리면 된다. FN: Flter Number일 때  filter의 가중치 데이터 크기는 (output data channel, input data channel, height, width)로 표현한다. Bias는 $(FN,1,1)$ 로 표현하여 채널 하나에 값 하나씩 할당되게 디자인한다. Output data size는 $(FN,OH,OW)$ 로 표현된다. \n\n참고) \n$$\n(FN,1,1) + (FN,OH,OW) \\overset{\\text{broadcasting}} \\rightarrow (FN,OH,OW) \n$$\n\n* 예시- 채널=3, (FH,FW)=(4,4), $FN=20$ 이면 $(20,3,4,4)$ 로 표현\n\n## Batch Processing\n\n데이터를 (데이터수, 채널 수, 높이, 너비) $= (N,C,H,W)$ 순으로 저장하여 처리하여 NN에 4차원 데이터가 하나가 흐를 때마다 데이터 N개의 합성곱 연산이 발생한다. N번의 처리를 한번에 수행한다.\n\n## Pooling Layer\n\n## Fully Connected Layer\n","srcMarkdownNoYaml":"\n\n# Introduction\n\n## Fully Connected Layer (MLP)의 문제점\n\nAffine Layer는 인접하는 Layers의 nodes가 모두 연결되고 출력의 수가 임의로 정해지는 특징을 갖는데 이 때 data shape가 무시가 되는 단점이 있다. 이미지 데이터는 보통 (weight, height, color channel) 형태의 shape를 갖지만 MLP에서 이 3차원 구조가 1차원으로 flatten된다. 다시 말해서, 3차원의 이미지 pixels이라는 여러 독립 변수의 위치적 상관성이 1차원화 되면서 무시가 된다.\n\n많은 일반 머신러닝 모델이나 통계 분석 모델은 독립 변수가 독립이라는 가정이 고려되어야 하지만 이미지의 독립 변수들이 서로 독립이 아니다. 픽셀값은 그 위치에 따라서 서로 상관성이 존재한다. 초기엔 독립 변수인 픽셀을 일렬로 늘어뜨려 input으로 사용했지만 위치 기반 픽셀의 상관성 정도를 자세히 반영하진 못했다. 이를 보완하기 위해 CNN에서는 **region feature**가 고안됐다. 이처럼, CNN은 이미지 인식 분야에서 독보적인 영역을 갖고 있다.\n\n## Region Feature\n\nRegion Feature 또는 Graphic Feature라고도 한다. 픽셀의 지역 정보를 학습할 수 있는 신경망 구조가 CNN이다. \n\n# CNN\n\n![CNN Structure Example](../../../../../images/cnn/figure1.png){#fig-CNN_structure}\n\n**Convolutional Neural Network** (CNN)은 합성곱(convolution)으로 이루어진 인공신경망으로 Region Feature를 학습하기 위한 모형이다. CNN은 \n\n* region feature를 추출하기 위한 convolution layer, \n* activation function,\n* feature dimension을 위한 pooling layer \n* fully connected layer (Multi Layer Perceptron (MLP) or Affine Transformation)\n* Softmax function\n\n로 구성되어 있다 (See @fig-CNN_structure).\n\n\n## Convolution Layer (Conv)\n\nkernel 또는 filter라고 불리는 특징 추출기(Feature detector)를 사용하여 데이터의 특징을 추출하는 CNN 모델의 핵심 부분이다. kernel 를 정의해 입력 층의 이미지의 feature를 추출한다. kernel는 region feature의 크기와 weight을 정의하게 된다. 예를 들어, kernel을 (3x3)으로 정하면 9칸에 가중치를 설정하여 이미지 픽셀값 (a part of input feature map)과 kernel의 weight의 선형결합으로 conv layer를 구성하는 하나의 값을 얻어낸다 (See @fig-CNN_structure 의 노란색 사각형). \n\nconvolution layer의 input/output은 보통 feature map이라고 부르며 input data를 input feature map, output data를 output feature map로 부르기도 한다. 즉, feature map 과 input/output data는 같은 의미로 사용되고 feature map = input data + kernel (= receptive field = filter)로 구성된다.\n\n\n### Convolution Operation \n\nConvolution Operation (합성곱 연산)은 filter operation (filter 연산)이라고도 불린다. @fig-conv_operation 을 보면 입력 데이터 (이미지의 pixels)와 filter의 가중치가 element-wise 별로 곱해져 더해진다. 이 연산을 fused-multiply-add (FMA) or multiply-accumulate operation 라고도 부른다. 예를 들어, input data의 `r matrix(c(4,9,2,5,6,2,2,4,5),nrow=3,byrow = T)`와 filter1 의 `r  matrix(c(1,0,-1,1,0,-1,1,0,-1),nrow=3,byrow = T)` 가 곱해지고 더해져 `r matrix(c(4,9,2,5,6,2,2,4,5),nrow=3,byrow = T)*matrix(c(1,0,-1,1,0,-1,1,0,-1),nrow=3,byrow = T)`의 결과가 Conv Layer의 output data의 한 칸을 구성하게 된다. \n\n![Convolution Operation Example](../../../../../images/cnn/figure2.png){#fig-conv_operation}\n\n이렇게, 2차원 입력에 대한 convolution (conv) operation은 @fig-conv-operation-process 과 같이 동작한다. Sharpen filter라고 쓰여진 3x3 행렬은 kernel로서 입력 데이터의 특징을 추출하는데, 입력 데이터의 전체를 보는 것이 \n아닌 kernel size 만큼의 일부분만을 보며 특징을 추출한다. feature map은 kernel의 개수만큼 생성되는데 일반적으로 다양한 특징을 추출하기 위해 하나의 conv layer에서 여러개의 kernel을 사용한다. kernel size에 정해진 규칙은 없으나 주로 3*3 많이 사용하며 대게 conv layer마다 다른 kernel size를 적용한다. Fully connected layer에서의 weight는 CNN에서 filter의 weight과 대응되고 CNN에서의 bias는 항상 scalar로 주어진다.\n\n![Convolution Operation Process Example](../../../../../images/cnn/figure3.gif){#fig-conv-operation-process}\n\n### 합성곱 연산을 위한 설정 사항\n\n- padding : 입력 데이터의 테두리를 0으로 채워 데이터의 크기를 늘려준다\n    - **왜 padding을 사용하는가?** padding이 없을 경우 합성곱은 입력 데이터의 1행 1열부터 시작된다. 그런데 합성곱은 입력 데이터에서 kernel size만큼의 영역을 하나로 축소하여 특징을 추출하기 때문에 이 경우 입력 데이터의 가장자리, edge 부분의 특징을 추출하기 어렵다. edge의 특징까지 추출하고자 하면 적어도 0행 0열부터 kernel을 적용해야 하는데 허공에서 element-wise 계산을 할 수 없으니 0을 추가해준다. 다시 말해서, padding은 output data size를 조정할 목적으로 사용된다.\n    ![Output Feature Map](../2023-03-10_cnn/output_featuremap.png){#fig-output_featuremap}\n- stride : kernel이 얼만큼씩 이동하면서 합성곱 계산을 할 것인지를 의미한다.\n    - stride를 키우게 되면 output data size가 작아지기 때문에 일반적으로 한 칸씩 이동한다.\n    ![Stride Example](../../../../../images/cnn/stride.PNG){#fig-stride}\n- weight sharing:    \n- kernel size : kernel의 행과 열 개수\n    - 사이즈가 작을수록 국소 단위의 특징을 추출한다.\n- kernel 개수 또는 channel 개수 : 몇 개의 feature map을 추출하고 싶은지에 따라 kernel 개수를 정한다.\n    ![Channel Number](../../../../../images/cnn/channel%20number.PNG){#fig-channel_number}\n* 이미지 데이터에서의 channel 예시\n  * 고양이 이미지와 같이 컬러 이미지 데이터는 하나의 이미지에 대해 Red, Green, Blue (RGB) 3개의 색상으로 이루어져 있다 \n    ![RGB 이미지를 red, green, blue channel 별 분리하여 표시](../../../../../images/cnn/image_featuremap.png){#fig-img_featuremap}\n    ![이미지 데이터의 RGB channel에 대한 convolution 계산 예시](../../../../../images/cnn/image_featuremap_convolution.png){#fig-img_featuremap_conv}\n\n### feature map의 shape 계산 방법\n\nfeature map은 다음 레이어의 입력 데이터가 되기 때문에 feature map의 shape을 계산할 수 있어야한다.\n\n#### 2 Dimension Input Data Size\n\n다음과 같이 output data size계산을 위한 notation을 정의할 때,\n\n* input data size : $(H,W)$\n* filter size : $(FH, FW)$\n* output data size : $(OH, OW)$\n* padding : $P$ (width number)\n* stride : $S$\n* a function to make the calculation result an integer\n  * floor function : $\\lfloor \\text{ } \\rfloor$\n  * ceiling : $\\lceil \\text{ } \\rceil$\n  * rounding to the nearest integer: $\\lfloor \\text{ } \\rceil$\n\n$$\n\\begin{aligned}\n  OH=&\\lfloor\\frac{H+2P-FH}{S}+1\\rfloor\\\\\n  OW=&\\lfloor\\frac{W+2P-FW}{S}+1\\rfloor\n\\end{aligned}\n$$\n\n의 관계식을 따르게 된다.\n\n* 예시1- input size: (4x4), P:1, S:1, filter size : (3x3)일 때, $(OH,OW)=(4,4)$\n* 예시2- input size: (7x7), P:0, S:2, filter size : (3x3)일 때, $(OH,OW)=(3,3)$\n* 예시3- input size: (28x31), P:2, S:3, filter size : (5x5)일 때, $(OH,OW)=(10,11)$\n\n\n\n#### 3 Dimension Input Data Size\n\n길이 또는 채널 방향으로 feature map이 늘어나기 때문에 그 결과는 @fig-conv_operation 과 같이 나온다. 반드시 input data의 channel 수와 output data channel수가 같아야한다. 채널이 3개면 filter 당 3장의 feature map이 나오게 된다. filter의 종류의 수 weight의 종류의 수로 output data의 길이를 늘리려면 (즉, 다수의 채널로 만드려면) filter의 수 (=weight의 종류)를 늘리면 된다. FN: Flter Number일 때  filter의 가중치 데이터 크기는 (output data channel, input data channel, height, width)로 표현한다. Bias는 $(FN,1,1)$ 로 표현하여 채널 하나에 값 하나씩 할당되게 디자인한다. Output data size는 $(FN,OH,OW)$ 로 표현된다. \n\n참고) \n$$\n(FN,1,1) + (FN,OH,OW) \\overset{\\text{broadcasting}} \\rightarrow (FN,OH,OW) \n$$\n\n* 예시- 채널=3, (FH,FW)=(4,4), $FN=20$ 이면 $(20,3,4,4)$ 로 표현\n\n## Batch Processing\n\n데이터를 (데이터수, 채널 수, 높이, 너비) $= (N,C,H,W)$ 순으로 저장하여 처리하여 NN에 4차원 데이터가 하나가 흐를 때마다 데이터 N개의 합성곱 연산이 발생한다. N번의 처리를 한번에 수행한다.\n\n## Pooling Layer\n\n## Fully Connected Layer\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":true,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../../../../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"include-in-header":[{"text":"<style>\n.custom-footer { \n  text-align: center; \n  font-size: 0.8em; \n  color: #666; \n  margin-top: 2rem; \n}\n</style>\n"}],"include-after-body":["../../../../../js.html","../../../signup.html"],"output-file":"2023-03-10_cnn.html"},"language":{"toc-title-document":"목차","toc-title-website":"목차","related-formats-title":"기타 형식","related-notebooks-title":"Notebooks","source-notebooks-prefix":"원천","other-links-title":"기타 링크","code-links-title":"코드 링크","launch-dev-container-title":"Dev 컨테이너 실행","launch-binder-title":"랜치 Binder","article-notebook-label":"기사 노트북","notebook-preview-download":"노트북 다운로드","notebook-preview-download-src":"소스 다운로드","notebook-preview-back":"기사로 돌아가기","manuscript-meca-bundle":"MECA 아카이브","section-title-abstract":"초록","section-title-appendices":"부록","section-title-footnotes":"각주","section-title-references":"참고문헌","section-title-reuse":"라이센스","section-title-copyright":"저작권","section-title-citation":"인용","appendix-attribution-cite-as":"인용방법","appendix-attribution-bibtex":"BibTeX 인용:","appendix-view-license":"라이센스 보기","title-block-author-single":"저자","title-block-author-plural":"저자","title-block-affiliation-single":"소속","title-block-affiliation-plural":"소속","title-block-published":"공개","title-block-modified":"Modified","title-block-keywords":"키워드","callout-tip-title":"힌트","callout-note-title":"노트","callout-warning-title":"경고","callout-important-title":"중요","callout-caution-title":"주의","code-summary":"코드","code-tools-menu-caption":"코드","code-tools-show-all-code":"전체 코드 표시","code-tools-hide-all-code":"전체 코드 숨기기","code-tools-view-source":"소스 코드 표시","code-tools-source-code":"소스 코드","tools-share":"Share","tools-download":"Download","code-line":"선","code-lines":"윤곽","copy-button-tooltip":"클립보드 복사","copy-button-tooltip-success":"복사완료!","repo-action-links-edit":"편집","repo-action-links-source":"소스코드 보기","repo-action-links-issue":"이슈 보고","back-to-top":"맨 위로","search-no-results-text":"일치 없음","search-matching-documents-text":"일치된 문서","search-copy-link-title":"검색 링크 복사","search-hide-matches-text":"추가 검색 결과 숨기기","search-more-match-text":"추가 검색결과","search-more-matches-text":"추가 검색결과","search-clear-button-title":"제거","search-text-placeholder":"","search-detached-cancel-button-title":"취소","search-submit-button-title":"검색","search-label":"검색","toggle-section":"토글 섹션","toggle-sidebar":"사이드바 전환","toggle-dark-mode":"다크 모드 전환","toggle-reader-mode":"리더 모드 전환","toggle-navigation":"탐색 전환","crossref-fig-title":"그림","crossref-tbl-title":"표","crossref-lst-title":"목록","crossref-thm-title":"정리","crossref-lem-title":"보조정리","crossref-cor-title":"따름정리","crossref-prp-title":"명제","crossref-cnj-title":"추측","crossref-def-title":"정의","crossref-exm-title":"보기","crossref-exr-title":"예제","crossref-ch-prefix":"장","crossref-apx-prefix":"부록","crossref-sec-prefix":"섹션","crossref-eq-prefix":"방정식","crossref-lof-title":"그림 목록","crossref-lot-title":"표 목록","crossref-lol-title":"코드 목록","environment-proof-title":"증명","environment-remark-title":"주석","environment-solution-title":"해답","listing-page-order-by":"정렬","listing-page-order-by-default":"디폴트","listing-page-order-by-date-asc":"날짜(오름차순)","listing-page-order-by-date-desc":"날짜(내림차순)","listing-page-order-by-number-desc":"페이지 번호(내림차순)","listing-page-order-by-number-asc":"페이지 번호(오름차순)","listing-page-field-date":"날짜","listing-page-field-title":"제목","listing-page-field-description":"설명","listing-page-field-author":"저자","listing-page-field-filename":"파일명","listing-page-field-filemodified":"갱신일","listing-page-field-subtitle":"부제목","listing-page-field-readingtime":"읽기 시간","listing-page-field-wordcount":"단어 수","listing-page-field-categories":"분류","listing-page-minutes-compact":"{0} 분","listing-page-category-all":"전체","listing-page-no-matches":"일치 없음","listing-page-words":"{0} 단어","listing-page-filter":"필터","draft":"초안"},"metadata":{"lang":"ko","fig-responsive":true,"quarto-version":"1.5.56","theme":{"light":["cosmo","../../../../../theme.scss"],"dark":["cosmo","../../../../../theme-dark.scss"]},"code-copy":true,"grid":{"sidebar-width":"200px","body-width":"1200px","margin-width":"200px"},"comments":{"giscus":{"repo":"kmink3225/blog","category":"Blog"}},"title-block-banner":"#EDF3F9","title-block-banner-color":"black","toc-location":"right","open-graph":true,"twitter-card":true,"search":true,"date-format":"YYYY년 MM월 DD일","title":"CNN","author":"Kwangmin Kim","date":"2023.03.10","categories":["Deep Learning"],"page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}