{"title":"GPU와 CUDA를 활용한 딥러닝 환경 구축","markdown":{"yaml":{"title":"GPU와 CUDA를 활용한 딥러닝 환경 구축","subtitle":"GPU 기초부터 CUDA 설치까지 완벽 가이드","description":"딥러닝을 위한 GPU와 CUDA의 개념을 이해하고, 실제 환경 구축 방법을 알아본다.\nNVIDIA GPU를 활용한 딥러닝 가속화 환경을 단계별로 설정하는 방법을 다룬다.\n","categories":["Engineering","Infrastructure"],"author":"Kwangmin Kim","date":"05/01/2023","format":{"html":{"page-layout":"full","code-fold":true,"toc":true,"number-sections":true}},"comments":{"utterances":{"repo":"./docs/comments"}},"draft":false,"execute":{"eval":false}},"headingText":"GPU란 무엇인가?","containsRefs":false,"markdown":"\n\n\n## CPU의 정의\n\n* **CPU(Central Processing Unit)**는 컴퓨터의 중앙 처리 장치\n* 모든 연산과 제어를 담당하는 핵심 부품이다. \n* 복잡한 명령어를 순차적으로 처리하는 데 최적화되어 있으며, 일반적으로 4-32개의 고성능 코어를 가지고 있다.\n* 그냥 컴퓨터의 두뇌라고 생각하면 된다. \n* 컴퓨터의 일반적이고 기본적인 모든 연산은 CPU가 처리한다.\n\n### CPU (Central Processing Unit)\n\n* **설계 철학**: 복잡한 명령어를 빠르게 순차 처리\n* **코어 구조**: 적은 수의 강력한 코어 (4-32개)\n* **캐시 메모리**: 대용량 캐시로 지연 시간 최소화\n* **분기 예측**: 복잡한 제어 흐름 처리에 최적화\n\n## GPU의 정의\n\n* **GPU(Graphics Processing Unit)**는 원래 그래픽 처리를 위해 설계된 전용 프로세서이다. \n* 하지만 현재는 딥러닝과 같은 병렬 연산이 필요한 작업에서 CPU보다 훨씬 뛰어난 성능을 보여준다.\n\n### GPU (Graphics Processing Unit)\n\n* **설계 철학**: 단순한 연산을 대량으로 병렬 처리\n* **코어 구조**: 많은 수의 단순한 코어 (수백-수천개)\n* **메모리**: 높은 대역폭의 전용 메모리(VRAM)\n* **SIMD 구조**: 같은 명령을 여러 데이터에 동시 적용\n\n\n## 딥러닝에서 GPU를 사용하는 이유\n\n### 행렬 연산의 병렬성\n\n딥러닝의 핵심인 행렬 곱셈은 본질적으로 병렬 처리가 가능:\n\n$$\nC_{ij} = \\sum_{k=1}^{n} A_{ik} \\times B_{kj}\n$$\n\n각 $C_{ij}$ 원소는 독립적으로 계산 가능하므로 GPU의 수천 개 코어가 동시에 처리할 수 있다.\n\n### 대용량 데이터 처리\n\n* **배치 처리**: GPU의 수천 개 코어가 동시에 연산 수행, 특히 합성곱(Convolution) 연산에서 큰 성능 향상\n  * 합성곱: 이미지나 신호 처리에서 사용되는 수학적 연산으로, 필터(커널)를 입력 데이터 위에서 슬라이딩하며 각 위치에서 요소별 곱셈과 합을 수행하는 연산. CNN에서 특징 추출의 핵심 연산이며, 각 필터 연산이 독립적이어서 GPU의 병렬 처리에 매우 적합함\n* **높은 메모리 대역폭**: CPU 대비 10-20배 빠른 메모리 접근\n* **병렬 데이터 로딩**: 여러 데이터를 동시에 GPU 메모리로 전송\n* **전용 메모리(VRAM)**: GPU 전용 메모리로 빠른 데이터 접근, CPU-GPU 간 데이터 전송 최소화\n\n### 성능 비교\n\n| 특성 | CPU | GPU |\n|------|-----|-----|\n| 코어 수 | 적음 (4-32개) | 많음 (수백-수천개) |\n| 연산 방식 | 순차 처리 | 병렬 처리 |\n| 메모리 대역폭 | 낮음 | 높음 |\n| 딥러닝 성능 | 느림 | 빠름 |\n| 전력 효율성 | 높음 | 낮음 |\n\n\n# CUDA란 무엇인가?\n\n## CUDA의 정의\n\n* **CUDA(Compute Unified Device Architecture)**는 NVIDIA에서 개발한 병렬 컴퓨팅 플랫폼 및 프로그래밍 모델\n* 딥러닝 모델을 가속화하기 위해 사용되는 프로그래밍 모델\n\n## CUDA의 핵심 개념\n\n### 병렬 프로그래밍 모델\n\n```python\n# CPU 코드 (순차 처리)\nfor i in range(1000000):\n    result[i] = a[i] + b[i]\n\n# GPU 코드 개념 (병렬 처리)\n# 1000000개의 스레드가 동시에 실행\n```\n\n### 메모리 계층 구조\n\n- **스레드(Thread)**: GPU에서 실제 연산을 수행하는 최소 실행 단위\n  - CPU의 스레드와 달리 GPU 스레드는 매우 가벼움 (컨텍스트 스위칭 비용이 거의 없음)\n  - 수천 개의 스레드가 동시에 실행되어 병렬 처리 수행\n  - 각 스레드는 고유한 ID를 가지며, 이를 통해 처리할 데이터를 구분\n- **글로벌 메모리**: 모든 스레드가 접근 가능, 느림\n- **공유 메모리**: 블록 내 스레드 공유, 빠름  \n- **레지스터**: 개별 스레드 전용, 가장 빠름\n\n### 스레드 계층 구조\n\n```\nGrid (전체 작업)\n├── Block 1\n│   ├── Thread 1\n│   ├── Thread 2\n│   └── ...\n├── Block 2\n└── ...\n```\n\n# GPU와 CUDA의 관계\n\n## GPU (하드웨어)\n\n- **물리적 장치**: 실제 그래픽 카드에 탑재된 프로세서\n- **병렬 처리 능력**: 수천 개의 코어로 동시 연산 수행\n- **하드웨어 자원**: 메모리, 연산 유닛 등 물리적 자원 제공\n\n## CUDA (소프트웨어 플랫폼)\n\n- **프로그래밍 도구**: GPU의 병렬 처리 능력을 활용할 수 있게 해주는 소프트웨어\n- **개발 환경**: GPU 프로그래밍을 위한 컴파일러, 라이브러리, API 제공\n- **NVIDIA 전용**: NVIDIA GPU에서만 동작\n\n## 딥러닝에서의 역할\n\n1. **GPU**: 실제 행렬 연산을 병렬로 처리\n2. **CUDA**: PyTorch, TensorFlow 등이 GPU를 쉽게 사용할 수 있도록 지원\n\n* **GPU는 하드웨어이고 CUDA는 그 하드웨어를 활용하기 위한 소프트웨어 플랫폼**\n* CUDA가 있어야 딥러닝 프레임워크들이 GPU의 성능을 제대로 활용할 수 있다.\n\n\n# 딥러닝에서 GPU 활용\n\n## 주요 딥러닝 프레임워크의 GPU 지원\n\n### PyTorch\n\n```python\nimport torch\n\n# GPU 사용 가능 여부 확인\nprint(torch.cuda.is_available())\n\n# 텐서를 GPU로 이동\ntensor = torch.randn(1000, 1000)\ntensor_gpu = tensor.cuda()\n\n# 모델을 GPU로 이동\nmodel = MyModel()\nmodel = model.cuda()\n```\n\n### TensorFlow\n\n```python\nimport tensorflow as tf\n\n# GPU 사용 가능 여부 확인\nprint(tf.config.list_physical_devices('GPU'))\n\n# GPU 메모리 증가 설정\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    tf.config.experimental.set_memory_growth(gpus[0], True)\n```\n\n# GPU 환경 구축 가이드\n\n## 하드웨어 요구사항 확인\n\n### GPU 확인 방법\n\n```bash\n# Windows\nnvidia-smi\n\n# Linux\nlspci | grep -i nvidia\n```\n\n* 이 명령어가 실행되면 GPU 정보와 CUDA 버전이 표시된다.\n* 만약 \"nvidia-smi is not recognized\" 오류가 나면 NVIDIA 드라이버를 설치해야 한다.\n\n```bash\n# 나의 예시\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 561.19                 Driver Version: 561.19         CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce RTX 2070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n| N/A   53C    P8             10W /   89W |     727MiB /   8192MiB |      5%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A      2340    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n|    0   N/A  N/A     14556    C+G   C:\\Windows\\explorer.exe                     N/A      |\n|    0   N/A  N/A     15068    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n|    0   N/A  N/A     19280    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n|    0   N/A  N/A     20256    C+G   ..._v10z8vjag6ke6\\OMENAudioControl.exe      N/A      |\n|    0   N/A  N/A     20340    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n|    0   N/A  N/A     21916    C+G   ...ta\\Local\\Programs\\cursor\\Cursor.exe      N/A      |\n|    0   N/A  N/A     23780    C+G   ...on\\137.0.3296.83\\msedgewebview2.exe      N/A      |\n|    0   N/A  N/A     25400    C+G   ...812_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n|    0   N/A  N/A     26072    C+G   ...\\HncUtils\\Service\\HncUpdateTray.exe      N/A      |\n|    0   N/A  N/A     26104    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n|    0   N/A  N/A     26248    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n|    0   N/A  N/A     29228    C+G   ...on\\137.0.3296.83\\msedgewebview2.exe      N/A      |\n|    0   N/A  N/A     31772    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n|    0   N/A  N/A     32572    C+G   ...812_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n|    0   N/A  N/A     35516    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n|    0   N/A  N/A     35628    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n|    0   N/A  N/A     38204    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n|    0   N/A  N/A     40680    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n+-----------------------------------------------------------------------------------------+\n```\n\n* 모델: RTX 2070 (아마도 RTX 2070 Super로 보임)\n* VRAM: 8GB (8192MiB)\n* 현재 메모리 사용량: 727MB / 8192MB (약 9% 사용 중)\n* GPU 사용률: 5% (거의 유휴 상태)\n* 전력 소모: 10W / 89W (매우 낮음, 절전 모드)\n\n### 권장 GPU 사양\n\n- **입문용**: GTX 1660 Super (6GB VRAM)\n  * 할 수 있는 것들:\n    * 간단한 CNN 모델 (MNIST, CIFAR-10)\n    * 작은 데이터셋으로 실습\n    * 기본적인 PyTorch/TensorFlow 튜토리얼\n    * 배치 크기 16-32 정도\n  * 제한사항:\n    * 큰 모델(ResNet-50, Transformer) 훈련 어려움\n    * ImageNet 같은 대용량 데이터셋 처리 힘듦\n    * 배치 크기를 작게 해야 함 (메모리 부족)\n- **중급용**: RTX 3070 (8GB VRAM)\n  * 할 수 있는 것들:\n    * 중간 크기 모델 훈련 (ResNet-34, EfficientNet-B0)\n    * 전이학습(Transfer Learning) 실험\n    * 개인 프로젝트, 캐글 대회 참여\n    * 배치 크기 32-64\n  * 제한사항:\n    * 매우 큰 모델(GPT, BERT Large) 훈련 어려움\n    * 긴 시퀀스 처리 제한적\n    * 상용 서비스 수준의 모델 훈련은 힘듦  \n- **고급용**: RTX 4090 (24GB VRAM)\n  * 할 수 있는 것들:\n    * 대형 모델 훈련 (BERT, GPT-2 Small)\n    * 고해상도 이미지 처리\n    * 복잡한 연구 실험\n    * 배치 크기 128-256\n    * 상용 서비스 프로토타입\n    * 가능한 실험:\n      * 대용량 데이터셋 처리\n      * 복잡한 모델 훈련\n      * 최신 모델 실험\n      * 빠른 추론 최적화\n\n| GPU | 가격대 | 전력 소모 | 성능/가격 비율 |\n|-----|--------|-----------|----------------|\n| GTX 1660 Super | 30-40만원 | 125W | 높음 |\n| RTX 3070 | 60-80만원 | 220W | 중간 |\n| RTX 4090 | 200-250만원 | 450W | 낮음 |\n\n## NVIDIA 드라이버 설치\n\n### Windows\n1. [NVIDIA 공식 사이트](https://www.nvidia.com/drivers)에서 드라이버 다운로드\n2. 설치 파일 실행 후 지시에 따라 설치\n3. 재부팅 후 `nvidia-smi` 명령어로 확인\n\n### Linux (Ubuntu)\n```bash\n# 자동 설치 (권장)\nsudo ubuntu-drivers autoinstall\n\n# 수동 설치\nsudo apt update\nsudo apt install nvidia-driver-525\nsudo reboot\n\n# 설치 확인\nnvidia-smi\n```\n\n# Python 딥러닝 환경 구축\n\n\n##  Conda 환경 생성\n```bash\n# 새 환경 생성\nconda create -n nblog python=3.11\nconda activate nblog\n```\n\n## CUDA Toolkit 설치\n\n### 버전 호환성 확인\n\n| PyTorch 버전 | CUDA 버전 | Python 버전 |\n|-------------|-----------|-------------|\n| 2.1.x | 11.8, 12.1 | 3.8-3.11 |\n| 2.0.x | 11.7, 11.8 | 3.8-3.11 |\n| 1.13.x | 11.6, 11.7 | 3.7-3.10 |\n\n\n### CUDA와 Pytorch 설치 \n\n\n```{python}\n#\n## 1. PyTorch 설치 (CUDA 12.1 권장)\n#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n#\n## 2. transformers 및 관련 패키지\n#pip install transformers\n#pip install accelerate\n#pip install datasets  # 데이터셋 사용시\n\nimport torch\n\nprint(f\"PyTorch 버전: {torch.__version__}\")\nprint(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\nprint(f\"CUDA 버전 (PyTorch): {torch.version.cuda}\")\nprint(f\"GPU 이름: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n```\n\n### TensorFlow 설치\n```{python}\npip install tensorflow[and-cuda]\n\n# pytorch 설치 후 텐서플로우 설치 시 제거\n#pip uninstall tensorflow tensorflow-gpu tensorflow-cpu\n#pip uninstall tensorboard tensorboard-plugin-wit\n## 캐시 정리\n#pip cache purge\n```\n\n### 설치 확인\n\n\n```{python}\nimport torch\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    \n    # 간단한 텐서 연산\n    a = torch.randn(1000, 1000).to(device)\n    b = torch.randn(1000, 1000).to(device)\n    \n    # GPU에서 행렬 곱셈\n    c = torch.matmul(a, b)\n    \n    print(\"✅ GPU 텐서 연산 성공!\")\n    print(f\"결과 shape: {c.shape}\")\n    print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n    \n    # 메모리 정리\n    torch.cuda.empty_cache()\n\n```\n\n\n```{python}\n# 더 가벼운 모델로 테스트\nmodel_name = \"prajjwal1/bert-tiny\"  # 매우 작은 모델\n\ntry:\n    from transformers import AutoTokenizer, AutoModel\n    \n    print(\"모델 다운로드 중...\")\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModel.from_pretrained(model_name).to(device)\n    \n    print(\"GPU에서 추론 실행 중...\")\n    text = \"GPU 테스트입니다\"\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    print(\"✅ 작은 모델로 GPU 테스트 성공!\")\n    print(f\"출력 shape: {outputs.last_hidden_state.shape}\")\n    print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n    \nexcept Exception as e:\n    print(f\"여전히 오류: {e}\")\n```\n\n```{python}\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\nprint(\"=== PyTorch GPU 테스트 ===\")\nprint(f\"PyTorch 버전: {torch.__version__}\")\nprint(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"CUDA 버전: {torch.version.cuda}\")\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    \n    # transformers 테스트\n    device = torch.device(\"cuda\")\n    model_name = \"distilbert-base-uncased\"\n    \n    try:\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        model = AutoModel.from_pretrained(model_name).to(device)\n        \n        text = \"GPU test with transformers\"\n        inputs = tokenizer(text, return_tensors=\"pt\")\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n        \n        print(\"✅ transformers GPU 테스트 성공!\")\n        print(f\"출력 shape: {outputs.last_hidden_state.shape}\")\n        print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n        \n    except Exception as e:\n        print(f\"❌ 오류: {e}\")\nelse:\n    print(\"❌ CUDA를 사용할 수 없습니다.\")\n```\n\n# 성능 최적화 팁\n\n\n```{python}\n# 배치 크기 조정\n\n# VRAM에 따른 권장 배치 크기\n# 6GB VRAM: batch_size = 16-32\n# 8GB VRAM: batch_size = 32-64  \n# 12GB VRAM: batch_size = 64-128\n\nbatch_size = 32  # VRAM 용량에 맞게 조정\n\n# 혼합 정밀도 훈련\n# PyTorch AMP 사용\nfrom torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()\n\nfor data, target in dataloader:\n    optimizer.zero_grad()\n    \n    with autocast():\n        output = model(data)\n        loss = criterion(output, target)\n    \n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n```\n\n## GPU 메모리 관리\n```{python}\n# PyTorch 메모리 정리\ntorch.cuda.empty_cache()\n\n# 메모리 사용량 확인\nprint(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\nprint(f\"Reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n```\n\n# 실제 성능 벤치마크\n\n## 간단한 벤치마크 코드\n```{python}\nimport torch\nimport time\n\ndef benchmark_gpu():\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # 큰 행렬 생성\n    a = torch.randn(5000, 5000).to(device)\n    b = torch.randn(5000, 5000).to(device)\n    \n    # 성능 측정\n    start_time = time.time()\n    for _ in range(100):\n        c = torch.mm(a, b)\n    end_time = time.time()\n    \n    print(f\"Device: {device}\")\n    print(f\"Time: {end_time - start_time:.2f} seconds\")\n    print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n\nbenchmark_gpu()\n```\n\n## 실제 딥러닝 모델 성능 비교\n```{python}\nimport torch\nimport torch.nn as nn\nimport time\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(1000, 2000),\n            nn.ReLU(),\n            nn.Linear(2000, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, 10)\n        )\n    \n    def forward(self, x):\n        return self.layers(x)\n\ndef train_benchmark(device):\n    model = SimpleModel().to(device)\n    optimizer = torch.optim.Adam(model.parameters())\n    criterion = nn.CrossEntropyLoss()\n    \n    # 더미 데이터\n    data = torch.randn(1000, 1000).to(device)\n    targets = torch.randint(0, 10, (1000,)).to(device)\n    \n    start_time = time.time()\n    \n    for epoch in range(100):\n        optimizer.zero_grad()\n        outputs = model(data)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n    \n    end_time = time.time()\n    print(f\"{device} training time: {end_time - start_time:.2f} seconds\")\n\n# CPU vs GPU 비교\ntrain_benchmark('cpu')\ntrain_benchmark('cuda')\n```\n\n# 결론\n\nGPU와 CUDA를 활용한 딥러닝 환경 구축은 다음과 같은 이점을 제공합니다:\n\n1. **훈련 시간 단축**: 10-100배 빠른 모델 훈련\n2. **더 큰 모델 실험**: 메모리 효율성으로 복잡한 모델 실험 가능\n3. **실시간 추론**: 빠른 GPU 연산으로 실시간 서비스 구현\n\n딥러닝을 시작하는 분들에게는 적절한 GPU 환경 구축이 필수적입니다. 하드웨어 선택부터 소프트웨어 설치까지 체계적으로 접근하면 효율적인 딥러닝 개발 환경을 구축할 수 있습니다.\n","srcMarkdownNoYaml":"\n\n# GPU란 무엇인가?\n\n## CPU의 정의\n\n* **CPU(Central Processing Unit)**는 컴퓨터의 중앙 처리 장치\n* 모든 연산과 제어를 담당하는 핵심 부품이다. \n* 복잡한 명령어를 순차적으로 처리하는 데 최적화되어 있으며, 일반적으로 4-32개의 고성능 코어를 가지고 있다.\n* 그냥 컴퓨터의 두뇌라고 생각하면 된다. \n* 컴퓨터의 일반적이고 기본적인 모든 연산은 CPU가 처리한다.\n\n### CPU (Central Processing Unit)\n\n* **설계 철학**: 복잡한 명령어를 빠르게 순차 처리\n* **코어 구조**: 적은 수의 강력한 코어 (4-32개)\n* **캐시 메모리**: 대용량 캐시로 지연 시간 최소화\n* **분기 예측**: 복잡한 제어 흐름 처리에 최적화\n\n## GPU의 정의\n\n* **GPU(Graphics Processing Unit)**는 원래 그래픽 처리를 위해 설계된 전용 프로세서이다. \n* 하지만 현재는 딥러닝과 같은 병렬 연산이 필요한 작업에서 CPU보다 훨씬 뛰어난 성능을 보여준다.\n\n### GPU (Graphics Processing Unit)\n\n* **설계 철학**: 단순한 연산을 대량으로 병렬 처리\n* **코어 구조**: 많은 수의 단순한 코어 (수백-수천개)\n* **메모리**: 높은 대역폭의 전용 메모리(VRAM)\n* **SIMD 구조**: 같은 명령을 여러 데이터에 동시 적용\n\n\n## 딥러닝에서 GPU를 사용하는 이유\n\n### 행렬 연산의 병렬성\n\n딥러닝의 핵심인 행렬 곱셈은 본질적으로 병렬 처리가 가능:\n\n$$\nC_{ij} = \\sum_{k=1}^{n} A_{ik} \\times B_{kj}\n$$\n\n각 $C_{ij}$ 원소는 독립적으로 계산 가능하므로 GPU의 수천 개 코어가 동시에 처리할 수 있다.\n\n### 대용량 데이터 처리\n\n* **배치 처리**: GPU의 수천 개 코어가 동시에 연산 수행, 특히 합성곱(Convolution) 연산에서 큰 성능 향상\n  * 합성곱: 이미지나 신호 처리에서 사용되는 수학적 연산으로, 필터(커널)를 입력 데이터 위에서 슬라이딩하며 각 위치에서 요소별 곱셈과 합을 수행하는 연산. CNN에서 특징 추출의 핵심 연산이며, 각 필터 연산이 독립적이어서 GPU의 병렬 처리에 매우 적합함\n* **높은 메모리 대역폭**: CPU 대비 10-20배 빠른 메모리 접근\n* **병렬 데이터 로딩**: 여러 데이터를 동시에 GPU 메모리로 전송\n* **전용 메모리(VRAM)**: GPU 전용 메모리로 빠른 데이터 접근, CPU-GPU 간 데이터 전송 최소화\n\n### 성능 비교\n\n| 특성 | CPU | GPU |\n|------|-----|-----|\n| 코어 수 | 적음 (4-32개) | 많음 (수백-수천개) |\n| 연산 방식 | 순차 처리 | 병렬 처리 |\n| 메모리 대역폭 | 낮음 | 높음 |\n| 딥러닝 성능 | 느림 | 빠름 |\n| 전력 효율성 | 높음 | 낮음 |\n\n\n# CUDA란 무엇인가?\n\n## CUDA의 정의\n\n* **CUDA(Compute Unified Device Architecture)**는 NVIDIA에서 개발한 병렬 컴퓨팅 플랫폼 및 프로그래밍 모델\n* 딥러닝 모델을 가속화하기 위해 사용되는 프로그래밍 모델\n\n## CUDA의 핵심 개념\n\n### 병렬 프로그래밍 모델\n\n```python\n# CPU 코드 (순차 처리)\nfor i in range(1000000):\n    result[i] = a[i] + b[i]\n\n# GPU 코드 개념 (병렬 처리)\n# 1000000개의 스레드가 동시에 실행\n```\n\n### 메모리 계층 구조\n\n- **스레드(Thread)**: GPU에서 실제 연산을 수행하는 최소 실행 단위\n  - CPU의 스레드와 달리 GPU 스레드는 매우 가벼움 (컨텍스트 스위칭 비용이 거의 없음)\n  - 수천 개의 스레드가 동시에 실행되어 병렬 처리 수행\n  - 각 스레드는 고유한 ID를 가지며, 이를 통해 처리할 데이터를 구분\n- **글로벌 메모리**: 모든 스레드가 접근 가능, 느림\n- **공유 메모리**: 블록 내 스레드 공유, 빠름  \n- **레지스터**: 개별 스레드 전용, 가장 빠름\n\n### 스레드 계층 구조\n\n```\nGrid (전체 작업)\n├── Block 1\n│   ├── Thread 1\n│   ├── Thread 2\n│   └── ...\n├── Block 2\n└── ...\n```\n\n# GPU와 CUDA의 관계\n\n## GPU (하드웨어)\n\n- **물리적 장치**: 실제 그래픽 카드에 탑재된 프로세서\n- **병렬 처리 능력**: 수천 개의 코어로 동시 연산 수행\n- **하드웨어 자원**: 메모리, 연산 유닛 등 물리적 자원 제공\n\n## CUDA (소프트웨어 플랫폼)\n\n- **프로그래밍 도구**: GPU의 병렬 처리 능력을 활용할 수 있게 해주는 소프트웨어\n- **개발 환경**: GPU 프로그래밍을 위한 컴파일러, 라이브러리, API 제공\n- **NVIDIA 전용**: NVIDIA GPU에서만 동작\n\n## 딥러닝에서의 역할\n\n1. **GPU**: 실제 행렬 연산을 병렬로 처리\n2. **CUDA**: PyTorch, TensorFlow 등이 GPU를 쉽게 사용할 수 있도록 지원\n\n* **GPU는 하드웨어이고 CUDA는 그 하드웨어를 활용하기 위한 소프트웨어 플랫폼**\n* CUDA가 있어야 딥러닝 프레임워크들이 GPU의 성능을 제대로 활용할 수 있다.\n\n\n# 딥러닝에서 GPU 활용\n\n## 주요 딥러닝 프레임워크의 GPU 지원\n\n### PyTorch\n\n```python\nimport torch\n\n# GPU 사용 가능 여부 확인\nprint(torch.cuda.is_available())\n\n# 텐서를 GPU로 이동\ntensor = torch.randn(1000, 1000)\ntensor_gpu = tensor.cuda()\n\n# 모델을 GPU로 이동\nmodel = MyModel()\nmodel = model.cuda()\n```\n\n### TensorFlow\n\n```python\nimport tensorflow as tf\n\n# GPU 사용 가능 여부 확인\nprint(tf.config.list_physical_devices('GPU'))\n\n# GPU 메모리 증가 설정\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    tf.config.experimental.set_memory_growth(gpus[0], True)\n```\n\n# GPU 환경 구축 가이드\n\n## 하드웨어 요구사항 확인\n\n### GPU 확인 방법\n\n```bash\n# Windows\nnvidia-smi\n\n# Linux\nlspci | grep -i nvidia\n```\n\n* 이 명령어가 실행되면 GPU 정보와 CUDA 버전이 표시된다.\n* 만약 \"nvidia-smi is not recognized\" 오류가 나면 NVIDIA 드라이버를 설치해야 한다.\n\n```bash\n# 나의 예시\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 561.19                 Driver Version: 561.19         CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce RTX 2070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n| N/A   53C    P8             10W /   89W |     727MiB /   8192MiB |      5%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A      2340    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n|    0   N/A  N/A     14556    C+G   C:\\Windows\\explorer.exe                     N/A      |\n|    0   N/A  N/A     15068    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n|    0   N/A  N/A     19280    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n|    0   N/A  N/A     20256    C+G   ..._v10z8vjag6ke6\\OMENAudioControl.exe      N/A      |\n|    0   N/A  N/A     20340    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n|    0   N/A  N/A     21916    C+G   ...ta\\Local\\Programs\\cursor\\Cursor.exe      N/A      |\n|    0   N/A  N/A     23780    C+G   ...on\\137.0.3296.83\\msedgewebview2.exe      N/A      |\n|    0   N/A  N/A     25400    C+G   ...812_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n|    0   N/A  N/A     26072    C+G   ...\\HncUtils\\Service\\HncUpdateTray.exe      N/A      |\n|    0   N/A  N/A     26104    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n|    0   N/A  N/A     26248    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n|    0   N/A  N/A     29228    C+G   ...on\\137.0.3296.83\\msedgewebview2.exe      N/A      |\n|    0   N/A  N/A     31772    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n|    0   N/A  N/A     32572    C+G   ...812_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n|    0   N/A  N/A     35516    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n|    0   N/A  N/A     35628    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n|    0   N/A  N/A     38204    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n|    0   N/A  N/A     40680    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n+-----------------------------------------------------------------------------------------+\n```\n\n* 모델: RTX 2070 (아마도 RTX 2070 Super로 보임)\n* VRAM: 8GB (8192MiB)\n* 현재 메모리 사용량: 727MB / 8192MB (약 9% 사용 중)\n* GPU 사용률: 5% (거의 유휴 상태)\n* 전력 소모: 10W / 89W (매우 낮음, 절전 모드)\n\n### 권장 GPU 사양\n\n- **입문용**: GTX 1660 Super (6GB VRAM)\n  * 할 수 있는 것들:\n    * 간단한 CNN 모델 (MNIST, CIFAR-10)\n    * 작은 데이터셋으로 실습\n    * 기본적인 PyTorch/TensorFlow 튜토리얼\n    * 배치 크기 16-32 정도\n  * 제한사항:\n    * 큰 모델(ResNet-50, Transformer) 훈련 어려움\n    * ImageNet 같은 대용량 데이터셋 처리 힘듦\n    * 배치 크기를 작게 해야 함 (메모리 부족)\n- **중급용**: RTX 3070 (8GB VRAM)\n  * 할 수 있는 것들:\n    * 중간 크기 모델 훈련 (ResNet-34, EfficientNet-B0)\n    * 전이학습(Transfer Learning) 실험\n    * 개인 프로젝트, 캐글 대회 참여\n    * 배치 크기 32-64\n  * 제한사항:\n    * 매우 큰 모델(GPT, BERT Large) 훈련 어려움\n    * 긴 시퀀스 처리 제한적\n    * 상용 서비스 수준의 모델 훈련은 힘듦  \n- **고급용**: RTX 4090 (24GB VRAM)\n  * 할 수 있는 것들:\n    * 대형 모델 훈련 (BERT, GPT-2 Small)\n    * 고해상도 이미지 처리\n    * 복잡한 연구 실험\n    * 배치 크기 128-256\n    * 상용 서비스 프로토타입\n    * 가능한 실험:\n      * 대용량 데이터셋 처리\n      * 복잡한 모델 훈련\n      * 최신 모델 실험\n      * 빠른 추론 최적화\n\n| GPU | 가격대 | 전력 소모 | 성능/가격 비율 |\n|-----|--------|-----------|----------------|\n| GTX 1660 Super | 30-40만원 | 125W | 높음 |\n| RTX 3070 | 60-80만원 | 220W | 중간 |\n| RTX 4090 | 200-250만원 | 450W | 낮음 |\n\n## NVIDIA 드라이버 설치\n\n### Windows\n1. [NVIDIA 공식 사이트](https://www.nvidia.com/drivers)에서 드라이버 다운로드\n2. 설치 파일 실행 후 지시에 따라 설치\n3. 재부팅 후 `nvidia-smi` 명령어로 확인\n\n### Linux (Ubuntu)\n```bash\n# 자동 설치 (권장)\nsudo ubuntu-drivers autoinstall\n\n# 수동 설치\nsudo apt update\nsudo apt install nvidia-driver-525\nsudo reboot\n\n# 설치 확인\nnvidia-smi\n```\n\n# Python 딥러닝 환경 구축\n\n\n##  Conda 환경 생성\n```bash\n# 새 환경 생성\nconda create -n nblog python=3.11\nconda activate nblog\n```\n\n## CUDA Toolkit 설치\n\n### 버전 호환성 확인\n\n| PyTorch 버전 | CUDA 버전 | Python 버전 |\n|-------------|-----------|-------------|\n| 2.1.x | 11.8, 12.1 | 3.8-3.11 |\n| 2.0.x | 11.7, 11.8 | 3.8-3.11 |\n| 1.13.x | 11.6, 11.7 | 3.7-3.10 |\n\n\n### CUDA와 Pytorch 설치 \n\n\n```{python}\n#\n## 1. PyTorch 설치 (CUDA 12.1 권장)\n#pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n#\n## 2. transformers 및 관련 패키지\n#pip install transformers\n#pip install accelerate\n#pip install datasets  # 데이터셋 사용시\n\nimport torch\n\nprint(f\"PyTorch 버전: {torch.__version__}\")\nprint(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\nprint(f\"CUDA 버전 (PyTorch): {torch.version.cuda}\")\nprint(f\"GPU 이름: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n```\n\n### TensorFlow 설치\n```{python}\npip install tensorflow[and-cuda]\n\n# pytorch 설치 후 텐서플로우 설치 시 제거\n#pip uninstall tensorflow tensorflow-gpu tensorflow-cpu\n#pip uninstall tensorboard tensorboard-plugin-wit\n## 캐시 정리\n#pip cache purge\n```\n\n### 설치 확인\n\n\n```{python}\nimport torch\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    \n    # 간단한 텐서 연산\n    a = torch.randn(1000, 1000).to(device)\n    b = torch.randn(1000, 1000).to(device)\n    \n    # GPU에서 행렬 곱셈\n    c = torch.matmul(a, b)\n    \n    print(\"✅ GPU 텐서 연산 성공!\")\n    print(f\"결과 shape: {c.shape}\")\n    print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n    \n    # 메모리 정리\n    torch.cuda.empty_cache()\n\n```\n\n\n```{python}\n# 더 가벼운 모델로 테스트\nmodel_name = \"prajjwal1/bert-tiny\"  # 매우 작은 모델\n\ntry:\n    from transformers import AutoTokenizer, AutoModel\n    \n    print(\"모델 다운로드 중...\")\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModel.from_pretrained(model_name).to(device)\n    \n    print(\"GPU에서 추론 실행 중...\")\n    text = \"GPU 테스트입니다\"\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    print(\"✅ 작은 모델로 GPU 테스트 성공!\")\n    print(f\"출력 shape: {outputs.last_hidden_state.shape}\")\n    print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n    \nexcept Exception as e:\n    print(f\"여전히 오류: {e}\")\n```\n\n```{python}\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\nprint(\"=== PyTorch GPU 테스트 ===\")\nprint(f\"PyTorch 버전: {torch.__version__}\")\nprint(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"CUDA 버전: {torch.version.cuda}\")\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    \n    # transformers 테스트\n    device = torch.device(\"cuda\")\n    model_name = \"distilbert-base-uncased\"\n    \n    try:\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        model = AutoModel.from_pretrained(model_name).to(device)\n        \n        text = \"GPU test with transformers\"\n        inputs = tokenizer(text, return_tensors=\"pt\")\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n        with torch.no_grad():\n            outputs = model(**inputs)\n        \n        print(\"✅ transformers GPU 테스트 성공!\")\n        print(f\"출력 shape: {outputs.last_hidden_state.shape}\")\n        print(f\"GPU 메모리 사용량: {torch.cuda.memory_allocated()/1024**2:.1f} MB\")\n        \n    except Exception as e:\n        print(f\"❌ 오류: {e}\")\nelse:\n    print(\"❌ CUDA를 사용할 수 없습니다.\")\n```\n\n# 성능 최적화 팁\n\n\n```{python}\n# 배치 크기 조정\n\n# VRAM에 따른 권장 배치 크기\n# 6GB VRAM: batch_size = 16-32\n# 8GB VRAM: batch_size = 32-64  \n# 12GB VRAM: batch_size = 64-128\n\nbatch_size = 32  # VRAM 용량에 맞게 조정\n\n# 혼합 정밀도 훈련\n# PyTorch AMP 사용\nfrom torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()\n\nfor data, target in dataloader:\n    optimizer.zero_grad()\n    \n    with autocast():\n        output = model(data)\n        loss = criterion(output, target)\n    \n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n```\n\n## GPU 메모리 관리\n```{python}\n# PyTorch 메모리 정리\ntorch.cuda.empty_cache()\n\n# 메모리 사용량 확인\nprint(f\"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\nprint(f\"Reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n```\n\n# 실제 성능 벤치마크\n\n## 간단한 벤치마크 코드\n```{python}\nimport torch\nimport time\n\ndef benchmark_gpu():\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    # 큰 행렬 생성\n    a = torch.randn(5000, 5000).to(device)\n    b = torch.randn(5000, 5000).to(device)\n    \n    # 성능 측정\n    start_time = time.time()\n    for _ in range(100):\n        c = torch.mm(a, b)\n    end_time = time.time()\n    \n    print(f\"Device: {device}\")\n    print(f\"Time: {end_time - start_time:.2f} seconds\")\n    print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n\nbenchmark_gpu()\n```\n\n## 실제 딥러닝 모델 성능 비교\n```{python}\nimport torch\nimport torch.nn as nn\nimport time\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(1000, 2000),\n            nn.ReLU(),\n            nn.Linear(2000, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, 10)\n        )\n    \n    def forward(self, x):\n        return self.layers(x)\n\ndef train_benchmark(device):\n    model = SimpleModel().to(device)\n    optimizer = torch.optim.Adam(model.parameters())\n    criterion = nn.CrossEntropyLoss()\n    \n    # 더미 데이터\n    data = torch.randn(1000, 1000).to(device)\n    targets = torch.randint(0, 10, (1000,)).to(device)\n    \n    start_time = time.time()\n    \n    for epoch in range(100):\n        optimizer.zero_grad()\n        outputs = model(data)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n    \n    end_time = time.time()\n    print(f\"{device} training time: {end_time - start_time:.2f} seconds\")\n\n# CPU vs GPU 비교\ntrain_benchmark('cpu')\ntrain_benchmark('cuda')\n```\n\n# 결론\n\nGPU와 CUDA를 활용한 딥러닝 환경 구축은 다음과 같은 이점을 제공합니다:\n\n1. **훈련 시간 단축**: 10-100배 빠른 모델 훈련\n2. **더 큰 모델 실험**: 메모리 효율성으로 복잡한 모델 실험 가능\n3. **실시간 추론**: 빠른 GPU 연산으로 실시간 서비스 구현\n\n딥러닝을 시작하는 분들에게는 적절한 GPU 환경 구축이 필수적입니다. 하드웨어 선택부터 소프트웨어 설치까지 체계적으로 접근하면 효율적인 딥러닝 개발 환경을 구축할 수 있습니다.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":false,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../../../../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"include-in-header":[{"text":"<style>\n.custom-footer { \n  text-align: center; \n  font-size: 0.8em; \n  color: #666; \n  margin-top: 2rem; \n}\n</style>\n"}],"include-after-body":["../../../../../js.html","../../../signup.html"],"output-file":"2.gpu.html"},"language":{"toc-title-document":"목차","toc-title-website":"목차","related-formats-title":"기타 형식","related-notebooks-title":"Notebooks","source-notebooks-prefix":"원천","other-links-title":"기타 링크","code-links-title":"코드 링크","launch-dev-container-title":"Dev 컨테이너 실행","launch-binder-title":"랜치 Binder","article-notebook-label":"기사 노트북","notebook-preview-download":"노트북 다운로드","notebook-preview-download-src":"소스 다운로드","notebook-preview-back":"기사로 돌아가기","manuscript-meca-bundle":"MECA 아카이브","section-title-abstract":"초록","section-title-appendices":"부록","section-title-footnotes":"각주","section-title-references":"참고문헌","section-title-reuse":"라이센스","section-title-copyright":"저작권","section-title-citation":"인용","appendix-attribution-cite-as":"인용방법","appendix-attribution-bibtex":"BibTeX 인용:","title-block-author-single":"저자","title-block-author-plural":"저자","title-block-affiliation-single":"소속","title-block-affiliation-plural":"소속","title-block-published":"공개","title-block-modified":"Modified","title-block-keywords":"키워드","callout-tip-title":"힌트","callout-note-title":"노트","callout-warning-title":"경고","callout-important-title":"중요","callout-caution-title":"주의","code-summary":"코드","code-tools-menu-caption":"코드","code-tools-show-all-code":"전체 코드 표시","code-tools-hide-all-code":"전체 코드 숨기기","code-tools-view-source":"소스 코드 표시","code-tools-source-code":"소스 코드","tools-share":"Share","tools-download":"Download","code-line":"선","code-lines":"윤곽","copy-button-tooltip":"클립보드 복사","copy-button-tooltip-success":"복사완료!","repo-action-links-edit":"편집","repo-action-links-source":"소스코드 보기","repo-action-links-issue":"이슈 보고","back-to-top":"맨 위로","search-no-results-text":"일치 없음","search-matching-documents-text":"일치된 문서","search-copy-link-title":"검색 링크 복사","search-hide-matches-text":"추가 검색 결과 숨기기","search-more-match-text":"추가 검색결과","search-more-matches-text":"추가 검색결과","search-clear-button-title":"제거","search-text-placeholder":"","search-detached-cancel-button-title":"취소","search-submit-button-title":"검색","search-label":"검색","toggle-section":"토글 섹션","toggle-sidebar":"사이드바 전환","toggle-dark-mode":"다크 모드 전환","toggle-reader-mode":"리더 모드 전환","toggle-navigation":"탐색 전환","crossref-fig-title":"그림","crossref-tbl-title":"표","crossref-lst-title":"목록","crossref-thm-title":"정리","crossref-lem-title":"보조정리","crossref-cor-title":"따름정리","crossref-prp-title":"명제","crossref-cnj-title":"추측","crossref-def-title":"정의","crossref-exm-title":"보기","crossref-exr-title":"예제","crossref-ch-prefix":"장","crossref-apx-prefix":"부록","crossref-sec-prefix":"섹션","crossref-eq-prefix":"방정식","crossref-lof-title":"그림 목록","crossref-lot-title":"표 목록","crossref-lol-title":"코드 목록","environment-proof-title":"증명","environment-remark-title":"주석","environment-solution-title":"해답","listing-page-order-by":"정렬","listing-page-order-by-default":"디폴트","listing-page-order-by-date-asc":"날짜(오름차순)","listing-page-order-by-date-desc":"날짜(내림차순)","listing-page-order-by-number-desc":"페이지 번호(내림차순)","listing-page-order-by-number-asc":"페이지 번호(오름차순)","listing-page-field-date":"날짜","listing-page-field-title":"제목","listing-page-field-description":"설명","listing-page-field-author":"저자","listing-page-field-filename":"파일명","listing-page-field-filemodified":"갱신일","listing-page-field-subtitle":"부제목","listing-page-field-readingtime":"읽기 시간","listing-page-field-wordcount":"단어 수","listing-page-field-categories":"분류","listing-page-minutes-compact":"{0} 분","listing-page-category-all":"전체","listing-page-no-matches":"일치 없음","listing-page-words":"{0} 단어"},"metadata":{"lang":"ko","fig-responsive":true,"quarto-version":"1.4.543","theme":{"light":["cosmo","../../../../../theme.scss"],"dark":["cosmo","../../../../../theme-dark.scss"]},"code-copy":true,"grid":{"sidebar-width":"200px","body-width":"1200px","margin-width":"200px"},"comments":{"giscus":{"repo":"kmink3225/blog","category":"Blog"},"utterances":{"repo":"./docs/comments"}},"title-block-banner":"#EDF3F9","title-block-banner-color":"black","toc-location":"right","open-graph":true,"twitter-card":true,"search":true,"date-format":"YYYY년 MM월 DD일","title":"GPU와 CUDA를 활용한 딥러닝 환경 구축","subtitle":"GPU 기초부터 CUDA 설치까지 완벽 가이드","description":"딥러닝을 위한 GPU와 CUDA의 개념을 이해하고, 실제 환경 구축 방법을 알아본다.\nNVIDIA GPU를 활용한 딥러닝 가속화 환경을 단계별로 설정하는 방법을 다룬다.\n","categories":["Engineering","Infrastructure"],"author":"Kwangmin Kim","date":"05/01/2023","draft":false,"page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}