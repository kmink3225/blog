{"title":"Task Handling Techniques","markdown":{"yaml":{"title":"Task Handling Techniques","subtitle":"BranchPython Operator (Branch Processing), @task.brancch (Branch Processing), BaseBranchOperator (Branch Processing), Trigger Rule Setting, Task Groups, Edge Labels","description":"Advanced Techniques to handle tasks (Branch Processing)\n","categories":["Engineering"],"author":"Kwangmin Kim","date":"05/01/2023","format":{"html":{"page-layout":"full","code-fold":true,"toc":true,"number-sections":true}},"comments":{"utterances":{"repo":"./docs/comments"}},"draft":false},"headingText":"Task 분기 처리하기 With BranchPythonOperator","containsRefs":false,"markdown":"\n\n<ul class=\"nav nav-pills\" id=\"language-tab\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link active\" id=\"Korean-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#Korean\" type=\"button\" role=\"tab\" aria-controls=\"Korean\" aria-selected=\"true\">Korean</button>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link\" id=\"English-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#English\" type=\"button\" role=\"tab\" aria-controls=\"knitr\" aria-selected=\"false\">English</button>\n  </li>\n\n<div class=\"tab-content\" id=\"language-tabcontent\">\n\n<div class=\"tab-pane fade  show active\" id=\"Korean\" role=\"tabpanel\" aria-labelledby=\"Korean-tab\">\n\n::: {#Korean .tab-pane .fade .show .active role=\"tabpanel\" aria-labelledby=\"Korean-tab\"}\n\n\n## Task 분기 처리 유형\n\n* Task 분기처리가 필요한 이유\n\n```{dot}\n\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    task1 [shape=box];\n    task2_1 [shape=box];\n    task2_2 [shape=box];\n    task2_3 [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  task1 -> task2_1;\n  task1 -> task2_2;\n  task1 -> task2_3;\n  \n}\n```\n\n* 위와 같이 task1이 실행된 후 여러 후차적인 task를 병렬로 실행되어야 할 때  \n* task flow에서 task1의 결과에 따라 선택적으로 task2-x 중 하나만 수행되도록 구성해야 할 때가 있다.\n* eg) Task1 의 결과로 ‘Good’,’Bad’,’Pending’ 이라는 결과 3 개 중 하나가 나오고 그에 따라 ask2-1 ~ task2-3 중 하나가 실행되도록 해야 할 경우\n\n## Airflow에서 지원하는 Task 분기처리 방법\n\n* Task 분기처리 방법 3가지\n    * BranchPythonOperator\n    * task.branch decorator 이용\n    * BaseBranchOperator 클래스를 상속하여 직접 개발\n\n### BranchPythonOperator\n\n```markdown\n\ndef select_random():\n    import random\n\n    item_lst= ['A','B','C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A';\n        return 'task_a' # task_id를 string 값으로 return해야함\n    elif selected_item in ['B','C] \n        return ['task_b','task_c'] # 여러 task를 동시에 수행시킬 땐 string 리스트로 반환\n\n# 일반 operator의 parameter도 있음\npython_branch_task = BranchPythonOperator(\n    task_id ='python_branch_task',\n    python_callable=select_random #select_random function 호출\n)\n\npython_branch_task >> [task_a , task_b , task_c]\n\n```\n\n```{dot}\n\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    python_branch_task [shape=box];\n    task_a [shape=box];\n    task_b [shape=box];\n    task_c [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  python_branch_task -> task_a;\n  python_branch_task -> task_b;\n  python_branch_task -> task_c;\n  \n}\n```\n\n\n* Dags Full Example\n\n```markdown\nfrom airflow import DAG\nimport pendulum\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.python import BranchPythonOperator\n\nwith DAG(\n    dag_id='dags_branch_python_operator',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'), \n    schedule='0 1 * * *',\n    catchup=False\n) as dag:\n    def select_random():\n        import random\n\n        item_lst = ['A','B','C']\n        selected_item = random.choice(item_lst)\n        if selected_item == 'A':\n            return 'task_a' # task_id를 string 값으로 return해야함\n        elif selected_item in ['B','C']:\n            return ['task_b','task_c'] # 여러 task를 동시에 수행시킬 땐 리스트로 반환\n    \n    # 일반 operator의 parameter도 있음\n    python_branch_task = BranchPythonOperator(\n        task_id='python_branch_task',\n        python_callable=select_random\n    )\n    \n    # 후행 task 3개\n    def common_func(**kwargs):\n        print(kwargs['selected'])\n\n    task_a = PythonOperator(\n        task_id='task_a',\n        python_callable=common_func,\n        op_kwargs={'selected':'A'}\n    )\n\n    task_b = PythonOperator(\n        task_id='task_b',\n        python_callable=common_func,\n        op_kwargs={'selected':'B'}\n    )\n\n    task_c = PythonOperator(\n        task_id='task_c',\n        python_callable=common_func,\n        op_kwargs={'selected':'C'}\n    )\n\n    python_branch_task >> [task_a, task_b, task_c]\n\n```\n\n* 나의 경우 airflow web service상에서 1회 실행 시켰을 때 selected_item의 값이 task_b, task_b가 선택됐음\n    * graph 버튼을 눌러 보면 가장 최근에 돌았던 task들이 return 된다. \n    * task_a가 분홍색 박스로 skipped 상태인 것을 확인 할 수 있다.\n    * graph에서 python_branch_task를 누르고 xcom을 누르면 다음과 같은 table을 확인할 수 있다.\n\n    |Key\t                 |Value |\n    |:-----------------------|:-----|\n    |skipmixin_key |\t{'followed': ['task_c', 'task_b']} |\n    |return_value  |\t['task_b', 'task_c'] |\n\n    * 여기서 `skipmixin_key` 의 value값의 key 값이 'followed' 이고 ['task_c', 'task_b'] 인 것을 볼 수 있다. 필요시 어떤 task들이 선택되었는지 확인하려면 xcom을 통해 확인 가능하다.\n    * log 를 보면\n    ```markdown\n    [2023-06-23, 23:20:01 UTC] {python.py:183} INFO - Done. Returned value was: ['task_b', 'task_c']\n    [2023-06-23, 23:20:01 UTC] {python.py:216} INFO - Branch callable return ['task_b', 'task_c']\n    [2023-06-23, 23:20:01 UTC] {skipmixin.py:161} INFO - Following branch ['task_b', 'task_c']\n    [2023-06-23, 23:20:01 UTC] {skipmixin.py:221} INFO - Skipping tasks ['task_a']    \n    ```\n\n\n# Task 분기처리하기 with task.branch\n\n## Task.branch 이해: BranchPythonOperator vs task.branch Decorator\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n```markdown\nfrom airflow.operators.python import BranchPythonOperator\ndef select_random(): \n    import random\n    item_lst = ['A','B','C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A':\n        return 'task_a'\n    elif selected_item in ['B','C']\n        return ['task_b','task_c']\n\npython_branch_task = BranchPythonOperator(\n    task_id= 'branching',\n    python_callable = select_random\n)\npython_branch_task >> [task_a , task_b , task_c]\n```\n\n:::\n\n::: {.column width=\"50%\"}\n\n```markdown\nfrom airflow.operators.python import task\n\n@task.branch(task_id='python_branch_task')\ndef select_random(): \n    import random\n    item_lst = ['A','B','C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A':\n        return 'task_a'\n    elif selected_item in ['B','C']\n        return ['task_b','task_c']\n\nselect_random() >> [task_a , task_b , task_c]\n\n```\n\n:::\n\n::::\n\n* BranchPythonOperator와 비교하여 select_random()을 호출 또는 맵핑 하는 방식이 decorator에서는 `@task.branch(task_id='python_branch_task')`으로 표현 되었고 task flow를 표현하는 task connection 방식도 `select_random() >> [task_a , task_b , task_c]` 로 표현 됐다.\n*  BranchPythonOperator의 `python_branch_task` object와 task.branch (decorator)의 select_random()는 사실상 같은 객체이다.\n* 차이점은 `BranchPythonOperator(...)`를 실행시킨 것과 `select_random(...)` 함수를 실행한 것 외엔 그 역할과 기능은 같다 (같은 object 반환). \n* Dags Full Example\n\n```markdown\nfrom airflow import DAG\nfrom datetime import datetime\nfrom airflow.operators.python import PythonOperator\nfrom airflow.decorators import task\n\nwith DAG(\n    dag_id='dags_python_with_branch_decorator',\n    start_date=datetime(2023,4,1),\n    schedule=None,\n    catchup=False\n) as dag:\n    @task.branch(task_id='python_branch_task')\n    def select_random():\n        import random\n        item_lst = ['A', 'B', 'C']\n        selected_item = random.choice(item_lst)\n        if selected_item == 'A':\n            return 'task_a'\n        elif selected_item in ['B','C']:\n            return ['task_b','task_c']\n    \n    def common_func(**kwargs):\n        print(kwargs['selected'])\n\n    task_a = PythonOperator(\n        task_id='task_a',\n        python_callable=common_func,\n        op_kwargs={'selected':'A'}\n    )\n\n    task_b = PythonOperator(\n        task_id='task_b',\n        python_callable=common_func,\n        op_kwargs={'selected':'B'}\n    )\n\n    task_c = PythonOperator(\n        task_id='task_c',\n        python_callable=common_func,\n        op_kwargs={'selected':'C'}\n    )\n\n    select_random() >> [task_a, task_b, task_c]\n```\n\n* airflow web service의 결과물은 BranchPythonOperator나 decorator나 같았음\n\n# Task 분기처리하기 With BaseBranchOperator\n\nBaseBranchOperator 클래스 상속해서 직접 함수를 개발해서 사용해야함.\n\n## BaseBranchOperator 이해 요약\n\n```markdown\nfrom airflow.operators.branch import BaseBranchOperator\nwith DAG(...\n) as dag:\n    class CustomBranchOperator(BaseBranchOperator): #클래스 이름은 임의로 지정해 줌\n    #Python의 class 상속 syntax: class MyclassName(상속할className):\n    #Python은 다중 상속가능\n        def choose_branch(self,context): \n        # 함수 재정의 : Overriding, 함수 이름 바꾸면 안됨!\n        # parameter도 바꾸면 안됨\n            import random\n            print(context) # context에 어떤 내용이 있는지 출력\n\n            item_lst = ['A', 'B','C]\n            selected_item = random.choice(item_lst)\n            if selected_item == 'A':\n                return 'task_a'\n            elif selected_item in ['B','C']:\n                return ['task_b','task_c']\n\ncustom_branch_operator = CustomBranchOperator(task_id ='python_branch_task') # 클래스 실행하여 custom_branch_operator object 생성\ncustom_branch_operator >> [task_a , task_b , task_c]\n```\n\n* 클래스 상속하여 새로운 클래스 만들어야함: BaseBranchOperator 상속시 choose_branch 함수를 구현해 줘야 함\n* `CustomBranchOperator` 클래스 이름은 임의로 지정해준 이름\n* class 선언시 `class childClass(상속할parentClass):` 상속할 부모클래스를 2개이상 지정하는 다중 상속이 가능하긴 하지만 권고하지 않음.\n* `choose_branch()` 함수를 만든 이유를 알기 위해선 BaseBranchOperator class에 대해서 알아야함\n    * [airflow operators-airflow.operators.branch or google 'airflow operators'](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/operators/branch/index.html)\n    :::{.callout-note}\n    ## Description\n\n    Bases: airflow.models.baseoperator.BaseOperator, airflow.models.skipmixin.SkipMixin\n    A base class for creating operators with branching functionality, like to BranchPythonOperator.\n    **Users should create a subclass from this operator and implement the function choose_branch(self, context). This should run whatever business logic is needed to determine the branch, and return either the task_id for a single task (as a str) or a list of task_ids**.\n    The operator will continue with the returned task_id(s), and all other tasks directly downstream of this operator will be skipped.\n    :::\n    * 함수명과 인자(argument)명도 반드시 일치시켜야함\n    * `choose_branch(self,context)`의 context는 pythonOperator 쓸때 **kwargs의 parameters들을 사용할 수 있게 해주는 parameter\n        * context 인자엔 op_kargs와 같이 data_interval_start, data_interval_end 등과 같은 정보를 제공해주는 인자\n    * `print(context)` 결과\n    ```markdown\n    [2023-06-24, 00:29:33 UTC] {logging_mixin.py:149} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fc3d5dd2cd0>, 'dag': <DAG: dags_base_branch_operator>, 'dag_run': <DagRun dags_base_branch_operator @ 2023-06-24 00:29:31.444830+00:00: manual__2023-06-24T00:29:31.444830+00:00, state:running, queued_at: 2023-06-24 00:29:31.455604+00:00. externally triggered: True>, 'data_interval_end': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'ds': '2023-06-24', 'ds_nodash': '20230624', 'execution_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'expanded_ti_count': None, 'inlets': [], 'logical_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2023-06-24', 'next_ds_nodash': '20230624', 'next_execution_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2023-06-24', 'prev_ds_nodash': '20230624', 'prev_execution_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'manual__2023-06-24T00:29:31.444830+00:00', 'task': <Task(CustomBranchOperator): python_branch_task>, 'task_instance': <TaskInstance: dags_base_branch_operator.python_branch_task manual__2023-06-24T00:29:31.444830+00:00 [running]>, 'task_instance_key_str': 'dags_base_branch_operator__python_branch_task__20230624', 'test_mode': False, 'ti': <TaskInstance: dags_base_branch_operator.python_branch_task manual__2023-06-24T00:29:31.444830+00:00 [running]>, 'tomorrow_ds': '2023-06-25', 'tomorrow_ds_nodash': '20230625', 'triggering_dataset_events': <Proxy at 0x7fc3ab28c8c0 with factory <function TaskInstance.get_template_context.<locals>.get_triggering_events at 0x7fc3ab277c20>>, 'ts': '2023-06-24T00:29:31.444830+00:00', 'ts_nodash': '20230624T002931', 'ts_nodash_with_tz': '20230624T002931.444830+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2023-06-23', 'yesterday_ds_nodash': '20230623'}\n    ```\n    context결과물은 위와 같은 시간 정보를 담고 있기 때문에 꺼내쓸 수 있다. \n* 분기 처리 결과는 다른 2 방식의 결과와 같음\n\n* DAG Full Example \n\n```markdown\nfrom airflow import DAG\nimport pendulum\nfrom airflow.operators.branch import BaseBranchOperator\nfrom airflow.operators.python import PythonOperator\n\nwith DAG(\n    dag_id='dags_base_branch_operator',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'),\n    schedule=None,\n    catchup=False\n) as dag:\n    class CustomBranchOperator(BaseBranchOperator):\n        def choose_branch(self, context):\n            import random\n            print(context) # context에 어떤 내용이 있는지 출력\n            \n            item_lst = ['A', 'B', 'C']\n            selected_item = random.choice(item_lst)\n            if selected_item == 'A':\n                return 'task_a'\n            elif selected_item in ['B','C']:\n                return ['task_b','task_c']\n\n    \n    custom_branch_operator = CustomBranchOperator(task_id='python_branch_task')\n\n    \n    def common_func(**kwargs):\n        print(kwargs['selected'])\n\n    task_a = PythonOperator(\n        task_id='task_a',\n        python_callable=common_func,\n        op_kwargs={'selected':'A'}\n    )\n\n    task_b = PythonOperator(\n        task_id='task_b',\n        python_callable=common_func,\n        op_kwargs={'selected':'B'}\n    )\n\n    task_c = PythonOperator(\n        task_id='task_c',\n        python_callable=common_func,\n        op_kwargs={'selected':'C'}\n    )\n\n    custom_branch_operator >> [task_a, task_b, task_c]\n\n```\n## Summary\n\n* Task 분기처리 방법\n    1. BranchPythonOperator (자주 사용)\n    1. task.branch 데커레이터 이용 (자주 사용)\n    1. BaseBranchOperator 상속 , choose_branch 를 재정의해야 함 (덜 사용)\n* 공통적으로 리턴 값으로 후행 Task 의 id 를 str 또는 list 로 리턴해야 함\n* 3가지 분기처리 방법은 방법만 다를 뿐 결과는 동일함\n* 3 보다는 1 또는 2를 주로 사용함\n\n# Trigger Rule\n\n## Trigger Rule 종류\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    task1 [shape=box];\n    task2 [shape=box];\n    task3 [shape=box];\n    task4 [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  task1 -> task4;\n  task2 -> task4;\n  task3 -> task4; \n}\n```\n\n* branch와 반대되는 개념으로 여러 상위 tasks가 하나의 하위 task로 연결되는 flow로 만들때 사용 \n* 즉, 여러 상위 Task 들의 상태에 따라 후행 task의 수행여부 결정할 때 쓰인다 \n* 기본 값 : 여러 상위 Task들이 모두 성공시에만 수행\n* 상위 task의 수행 상태에 따라 조건적으로 후행 task의 수행 여부를 결정할 수 있다.\n* trigger option은 하위 task를 이용하여 줄 수 있다.\n* 모든 airflow operator는 trigger rule option을 줄 수 있다. \n* 11가지 trigger rules \n\n| Default                       | Left      |\n|:------------------------------|:----------|\n| all_success (default)         | 상위 tasks 가 모두 성공하면 실행  |\n| all_failed                    | 상위 tasks 가 모두 실패하면 실행  |\n| all_done                      | 상위 tasks 가 모두 수행되면 실행 (실패도 수행된것에 포함)  |\n| all_skipped                   | 상위 tasks 가 모두 Skipped 상태면 실행  |\n| one_failed                    | 상위 tasks 중 하나 이상 실패하면 실행 (모든 상위 Tasks의 완료를 기다리지 않음) |\n| one_success                   | 상위 tasks 중 하나 이상 성공하면 실행 (모든 상위 Tasks의 완료를 기다리지 않음) |\n| one_done                      | 상위 tasks 중 하나 이상 성공 또는 실패 하면 실행|\n| none_failed                   | 상위 task s중 실패가 없는 경우 실행 (성공 또는 Skipped 상태) |\n| none_failed_min_one_success   | 상위 tasks 중 실패가 없고 성공한 Task가 적어도 1개 이상이면 실행 |\n| none_skipped                  | Skip된 상위 Task가 없으면 실행 (상위 Task가 성공, 실패하여도 무방)   |\n| always                        | 언제나 실행 |\n\n* 위의 표에서 모든 상위 **task를 기다리지 않음**은 각 각의 상위 task들의 처리 시간이 다를 때 가장 빠르게 처리되는 상위 task에 따라서 후행 task가 수행된다는 것을 의미한다. 예를 들어, one_failed의 경우\n    * 상위 task1 (2분소요)\n    * 상위 task2 (10분소요)\n    * 상위 task3 (20분소요) 일때, \n    * 상위 task 3개 중 task1의 결과가 먼저 fail이 나올 경우 task2,3 을 기다리지 않고 바로 triger가 발동되어 하위 task4가 수행된다.\n\n\n## 2. Trigger Rule 실습) trigger_rule = all_done\n\n* 아래 예시에서 4개의 task가 정의됨\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n```markdown\n\n# 상위 task1\nbash_upstream_1 = BashOperator(\n    task_id = 'bash_upstream_1',\n    bash_command = 'echo upstream1'\n)\n\n@task(task_id =='python_upstream_1') # 상위 task2\ndef python_upstream_1():\n    AirflowException('downstream_1 Exception!') # AirflowException() fail을 반환하여 무조건 task 실패처리가되도록 설정\n\n@task(task_id =='python_upstream_2') # 상위 task3\ndef python_upstream_2():\n    print('정상 처리')\n\n@task(task_id ='python_downstream_1', trigger_rule ='all_done') #하위 task4\ndef python_downstream_1():\n    print('정상 처리')\n\n[bash_upstream_1 , python_upstream_1(), python_upstream_2()] >> python_downstream_1()\n\n```\n:::\n\n::: {.column width=\"50%\"}\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    bash_upstream_1 [shape=box];\n    python_upstream_1 [shape=box];\n    python_upstream_2 [shape=box];\n    python_downstream_1 [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  bash_upstream_1 -> python_downstream_1;\n  python_upstream_1 -> python_downstream_1;\n  python_upstream_2 -> python_downstream_1; \n}\n```\n\n:::\n\n::::\n\n* bash_upstream_1(성공), python_upstream_1(실패), python_upstream_2(성공). \n* triger rule이 all done이기 때문에 python_upstream_1(실패)여도 python_downstream_1은 수행되어야 한다.\n* 다른 Operator such as BashOperator, pythonOperator의 경우도 `trigger_rule =='all_done'` parameter 똑같이 넣어주면 됨\n\n\n## 2. Trigger Rule 실습) triger_rule = none_skipped\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```markdown\n@task.branch(task_id ='branching') #상위 task1\ndef random_branch():\n    import random\n    item_lst = [' A', ' B', 'C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A':\n        return 'task_a'\n    elif selected_item == 'B':\n        return 'task_b'\n    elif selected_item == 'C':\n        return 'task_c'\n\n#상위 task2\ntask_a = BashOperator(\n    task_id ='task_a',\n    bash_command = 'echo upstream1'\n    )\n\n#상위 task3\n@task(task_id ='task_b')\ndef task_b():\n    print('정상 처리')\n\n#상위 task4\n@task(task_id =='task_c')\ndef task_c():\n    print('정상 처리')\n\n#하위 task5\n@task(task_id =='task_d', trigger_rule ='none_skipped')\ndef task_d():\n    print('정상 처리')\n\nrandom_branch() >> [task_a , task_b(), task_c()] >> task_d()\n\n```\n\n:::\n\n::: {.column width=\"50%\"}\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    random_branch [shape=box];\n    task_a [shape=box];\n    task_b [shape=box];\n    task_c [shape=box];\n    task_d [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  random_branch -> task_a;\n  random_branch -> task_b;\n  random_branch -> task_c;\n  task_a -> task_d;\n  task_b -> task_d;\n  task_c -> task_d;\n}\n```\n\n:::\n\n::::\n\n* skip이 있기 때문에 실제로 task_d가 돌지 말아야한다.\n* Dags Full Example\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```markdown\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom airflow.exceptions import AirflowException\n\nimport pendulum\n\nwith DAG(\n    dag_id='dags_python_with_trigger_rule_eg1',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'),\n    schedule=None,\n    catchup=False\n) as dag:\n    bash_upstream_1 = BashOperator(\n        task_id='bash_upstream_1',\n        bash_command='echo upstream1'\n    )\n\n    @task(task_id='python_upstream_1')\n    def python_upstream_1():\n        raise AirflowException('downstream_1 Exception!')\n\n\n    @task(task_id='python_upstream_2')\n    def python_upstream_2():\n        print('정상 처리')\n\n    @task(task_id='python_downstream_1', trigger_rule='all_done')\n    def python_downstream_1():\n        print('정상 처리')\n\n    [bash_upstream_1, python_upstream_1(), python_upstream_2()] >> python_downstream_1()\n```\n:::\n\n::: {.column width=\"50%\"}\n```markdown\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom airflow.exceptions import AirflowException\n\nimport pendulum\n\nwith DAG(\n    dag_id='dags_python_with_trigger_rule_eg2',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'),\n    schedule=None,\n    catchup=False\n) as dag:\n    @task.branch(task_id='branching')\n    def random_branch():\n        import random\n        item_lst = ['A', 'B', 'C']\n        selected_item = random.choice(item_lst)\n        if selected_item == 'A':\n            return 'task_a'\n        elif selected_item == 'B':\n            return 'task_b'\n        elif selected_item == 'C':\n            return 'task_c'\n\n    task_a = BashOperator(\n        task_id='task_a',\n        bash_command='echo upstream1'\n    )\n\n    @task(task_id='task_b')\n    def task_b():\n        print('정상 처리')\n\n\n    @task(task_id='task_c')\n    def task_c():\n        print('정상 처리')\n\n    @task(task_id='task_d', trigger_rule='none_skipped')\n    def task_d():\n        print('정상 처리')\n\n    random_branch() >> [task_a, task_b(), task_c()] >> task_d()\n```\n:::\n\n::::\n\n\n# Task Group\n\n## Task Group 개념\n\n* tasks를 모아 관리\n* Task들의 모음: dags안에 task가 많을 경우 비슷한 기능의 tasks 그룹으로 모아서 관리\n    * 예를 들어, dag안에 50개의 tasks 있다고 할 때, 5개 tasks가 서로 연관성이 높은 connection을 이루고 이런 group이 10개가 있을 수 있다. \n* [link: UI Graph탭에서 Task 들을 Group 화하여 보여줌-TaskGroups or google 'airflow dags'](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#taskgroups)\n    * content >> Core Concepts >> DAGs >> DAG Visualization >> Task Groups\n* Task Group 안에 Task Group 을 중첩하여 계층적으로 구성 가능\n* 위의 링크에서 section1 과 section2 로 grouping되어 있고 section2에는 inner_section_2 라는 또 다른 task group이 있다.\n* 꼭 써야하는 이유는 성능적인 면에서 딱히 없지만 task flow의 가독성이 높아짐\n\n## Task Group 실습 \n\n1. task_group 데커레이터 이용\n\n```markdown\nfrom airflow.decorators import task_group\nwith DAG(...\n) as dag:\n    @task_group(group_id ='first_group')\n    def group_1():\n    ''' task_group 데커레이터를 이용한 첫 번째 그룹''' # docstring: 함수를 설명하는 기법\n    # airflow UI에서는 tooltip이라고 표시됨\n\n    @task(task_id ='inner_function1')\n    def inner_func1(**kwargs):\n        print('첫 번째 TaskGroup 내 첫 번째 task 입니다')\n\n    inner_function2 = PythonOperator(\n        task_id ='inner_function2',\n        python_callable = inner_func,\n        op_kwargs={'msg':'첫 번째 TaskGroup 내 두 번쨰 task 입니다.'}\n    )\n    inner_func1() >> inner_function2\n```\n\n2. task_group 데커레이터 이용하지 않음 (클래스 이용)\n\n```markdown\nfrom airflow.utils.task_group import TaskGroup\n    with TaskGroup(group_id ='second_group', tooltip='두 번째 그룹') as group_2: # with MyClassName(arg1,age2,...) \n    # tooltipe은 decorator를 이용한 task_group 생성때의 docstring과 같은 역할을 함\n        @task(task_id ='inner_function1')\n        def inner_func1 (**kwargs):\n            print('두 번째 TaskGroup 내 첫 번째 task 입니다.')\n\n        inner_function2 = PythonOperator(\n            task_id = 'inner_function2',\n            python_collable = inner_func,\n            op_kwargs = {'msg': '두 번째 TaskGroup 내 두 번째 task 입니다'}\n        )\ninner_func1() >> inner_function2\n```\n\n* Dags Full Example\n\n```markdown\nfrom airflow import DAG\nimport pendulum\nimport datetime\nfrom airflow.operators.python import PythonOperator\nfrom airflow.decorators import task\nfrom airflow.decorators import task_group\nfrom airflow.utils.task_group import TaskGroup\n\nwith DAG(\n    dag_id=\"dags_python_with_task_group\",\n    schedule=None,\n    start_date=pendulum.datetime(2023, 4, 1, tz=\"Asia/Seoul\"),\n    catchup=False\n) as dag:\n    def inner_func(**kwargs):\n        msg = kwargs.get('msg') or '' \n        print(msg)\n\n    @task_group(group_id='first_group')\n    def group_1():\n        ''' task_group 데커레이터를 이용한 첫 번째 그룹 '''\n\n        @task(task_id='inner_function1')\n        def inner_func1(**kwargs):\n            print('첫 번째 TaskGroup 내 첫 번째 task입니다.')\n\n        inner_function2 = PythonOperator(\n            task_id='inner_function2',\n            python_callable=inner_func,\n            op_kwargs={'msg':'첫 번째 TaskGroup내 두 번쨰 task입니다.'}\n        )\n\n        inner_func1() >> inner_function2\n\n    with TaskGroup(group_id='second_group', tooltip='두 번째 그룹') as group_2:\n        ''' 클래스 안에 적은 docstring은 표시되지 않음'''\n        @task(task_id='inner_function1')\n        def inner_func1(**kwargs):\n            print('두 번째 TaskGroup 내 첫 번째 task입니다.')\n\n        inner_function2 = PythonOperator(\n            task_id='inner_function2',\n            python_callable=inner_func,\n            op_kwargs={'msg': '두 번째 TaskGroup내 두 번째 task입니다.'}\n        )\n        inner_func1() >> inner_function2\n\n    group_1() >> group_2\n```\n\n* 위에서 task_id와 group_id가 같지만 에러가 안나는 이유가 task group이 다르기 때문.\n* 위에서 볼 수 있듯이 task group 또한 flow 설정할 수 있음 `group_1() >> group_2`\n\n\n## 요약\n\n* Task Group 작성 방법은 2 가지가 존재함 (데커레이터 & 클래스)\n* Task Group 안에 Task Group 중첩하여 정의 가능\n* Task Group 간에도 Flow 정의 가능\n* Group이 다르면 task_id 가 같아도 무방\n* Tooltip 파라미터를 이용해 UI 화면에서 Task group 에 대한 설명 제공 가능\n    (데커레이터 활용시 docstring 으로도 가능)\n\n# Edge label\n\n## Edge Label 개념\n\n* Task 연결에 대한 설명 (즉 edge에 대한 Comment)\n\n## Edge Label 만들기\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    ingest [shape=box];\n    analyze [shape=box];\n    check_integrity [shape=box];\n    describe_integrity [shape=box];\n    email_error [shape=box];\n    report [shape=box];\n    save [shape=box];\n    label= \"Task Flow\";\n  }\n\n  ingest -> analyze ;\n  analyze -> check_integrity ;\n  check_integrity -> describe_integrity[label=\"Errors Found\"];\n  describe_integrity -> email_error;\n  email_error -> report;\n  check_integrity -> save[label=\"No Errors\"];\n  save -> report;\n  \n  \n}\n```\n\n## Edge Label 실습 1\n\n```markdown\n\nfrom airflow.utils.edgemodifier import Label\nempty_1 = EmptyOperator(\n    task_id ='empty_1'\n)\n\nempty_2 = EmptyOperator(\n    task_id='empty_2'\n)\nempty_1 >> Label ('1 과 2 사이') >> empty_2\n```\n\n## Edge Label 실습 2\n\n```markdown\n\nfrom airflow.utils.edgemodifier import Label\nempty_2 = EmptyOperator(\n    task_id = 'empty_2'\n)\n\nempty_3 = EmptyOperator(\n    task_id ='empty_3'\n)\n\nempty_4 = EmptyOperator(\n    task_id ='empty_4'\n)\n\nempty_5 = EmptyOperator(\n    task_id ='empty_5'\n)\n\nempty_6 = EmptyOperator(\n    task_id ='empty_6'\n)\n\nempty_2 >> Label('Start Branch') >> [empty_3, empty_4, empty_5 ] >> Label('End Branch') >> empty_6\n```\n\n* 이렇게 분기가 펼쳐지고 모아지는 경우 모든 분기 edges에 label이 붙게 된다.\n* Full DAG Example\n\n```markdown\nfrom airflow import DAG\nimport pendulum\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\n\nwith DAG(\n    dag_id=\"dags_empty_with_edge_label\",\n    schedule=None,\n    start_date=pendulum.datetime(2023, 4, 1, tz=\"Asia/Seoul\"),\n    catchup=False\n) as dag:\n    \n    empty_1 = EmptyOperator(\n        task_id='empty_1'\n    )\n\n    empty_2 = EmptyOperator(\n        task_id='empty_2'\n    )\n\n    empty_1 >> Label('1과 2사이') >> empty_2\n\n    empty_3 = EmptyOperator(\n        task_id='empty_3'\n    )\n\n    empty_4 = EmptyOperator(\n        task_id='empty_4'\n    )\n\n    empty_5 = EmptyOperator(\n        task_id='empty_5'\n    )\n\n    empty_6 = EmptyOperator(\n        task_id='empty_6'\n    )\n\n    empty_2 >> Label('Start Branch') >> [empty_3,empty_4,empty_5] >> Label('End Branch') >> empty_6\n```\n* empty operator이기 때문에 실행은 airflow web servce에서 실행은 안해도 된다.\n\n:::\n\n</div>\n\n<div class=\"tab-pane fade\" id=\"English\" role=\"tabpanel\" aria-labelledby=\"English-tab\">\n\n::: {#English .tab-pane .fade role=\"tabpanel\" aria-labelledby=\"English-tab\"}\n\n:::\n\n\n</div>\n\n\n# Go to Blog Content List\n\n[Blog Content List](../../content_list.qmd)  \n[Engineering Content List](../../Engineering/guide_map/index.qmd)","srcMarkdownNoYaml":"\n\n<ul class=\"nav nav-pills\" id=\"language-tab\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link active\" id=\"Korean-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#Korean\" type=\"button\" role=\"tab\" aria-controls=\"Korean\" aria-selected=\"true\">Korean</button>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link\" id=\"English-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#English\" type=\"button\" role=\"tab\" aria-controls=\"knitr\" aria-selected=\"false\">English</button>\n  </li>\n\n<div class=\"tab-content\" id=\"language-tabcontent\">\n\n<div class=\"tab-pane fade  show active\" id=\"Korean\" role=\"tabpanel\" aria-labelledby=\"Korean-tab\">\n\n::: {#Korean .tab-pane .fade .show .active role=\"tabpanel\" aria-labelledby=\"Korean-tab\"}\n\n# Task 분기 처리하기 With BranchPythonOperator\n\n## Task 분기 처리 유형\n\n* Task 분기처리가 필요한 이유\n\n```{dot}\n\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    task1 [shape=box];\n    task2_1 [shape=box];\n    task2_2 [shape=box];\n    task2_3 [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  task1 -> task2_1;\n  task1 -> task2_2;\n  task1 -> task2_3;\n  \n}\n```\n\n* 위와 같이 task1이 실행된 후 여러 후차적인 task를 병렬로 실행되어야 할 때  \n* task flow에서 task1의 결과에 따라 선택적으로 task2-x 중 하나만 수행되도록 구성해야 할 때가 있다.\n* eg) Task1 의 결과로 ‘Good’,’Bad’,’Pending’ 이라는 결과 3 개 중 하나가 나오고 그에 따라 ask2-1 ~ task2-3 중 하나가 실행되도록 해야 할 경우\n\n## Airflow에서 지원하는 Task 분기처리 방법\n\n* Task 분기처리 방법 3가지\n    * BranchPythonOperator\n    * task.branch decorator 이용\n    * BaseBranchOperator 클래스를 상속하여 직접 개발\n\n### BranchPythonOperator\n\n```markdown\n\ndef select_random():\n    import random\n\n    item_lst= ['A','B','C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A';\n        return 'task_a' # task_id를 string 값으로 return해야함\n    elif selected_item in ['B','C] \n        return ['task_b','task_c'] # 여러 task를 동시에 수행시킬 땐 string 리스트로 반환\n\n# 일반 operator의 parameter도 있음\npython_branch_task = BranchPythonOperator(\n    task_id ='python_branch_task',\n    python_callable=select_random #select_random function 호출\n)\n\npython_branch_task >> [task_a , task_b , task_c]\n\n```\n\n```{dot}\n\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    python_branch_task [shape=box];\n    task_a [shape=box];\n    task_b [shape=box];\n    task_c [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  python_branch_task -> task_a;\n  python_branch_task -> task_b;\n  python_branch_task -> task_c;\n  \n}\n```\n\n\n* Dags Full Example\n\n```markdown\nfrom airflow import DAG\nimport pendulum\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.python import BranchPythonOperator\n\nwith DAG(\n    dag_id='dags_branch_python_operator',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'), \n    schedule='0 1 * * *',\n    catchup=False\n) as dag:\n    def select_random():\n        import random\n\n        item_lst = ['A','B','C']\n        selected_item = random.choice(item_lst)\n        if selected_item == 'A':\n            return 'task_a' # task_id를 string 값으로 return해야함\n        elif selected_item in ['B','C']:\n            return ['task_b','task_c'] # 여러 task를 동시에 수행시킬 땐 리스트로 반환\n    \n    # 일반 operator의 parameter도 있음\n    python_branch_task = BranchPythonOperator(\n        task_id='python_branch_task',\n        python_callable=select_random\n    )\n    \n    # 후행 task 3개\n    def common_func(**kwargs):\n        print(kwargs['selected'])\n\n    task_a = PythonOperator(\n        task_id='task_a',\n        python_callable=common_func,\n        op_kwargs={'selected':'A'}\n    )\n\n    task_b = PythonOperator(\n        task_id='task_b',\n        python_callable=common_func,\n        op_kwargs={'selected':'B'}\n    )\n\n    task_c = PythonOperator(\n        task_id='task_c',\n        python_callable=common_func,\n        op_kwargs={'selected':'C'}\n    )\n\n    python_branch_task >> [task_a, task_b, task_c]\n\n```\n\n* 나의 경우 airflow web service상에서 1회 실행 시켰을 때 selected_item의 값이 task_b, task_b가 선택됐음\n    * graph 버튼을 눌러 보면 가장 최근에 돌았던 task들이 return 된다. \n    * task_a가 분홍색 박스로 skipped 상태인 것을 확인 할 수 있다.\n    * graph에서 python_branch_task를 누르고 xcom을 누르면 다음과 같은 table을 확인할 수 있다.\n\n    |Key\t                 |Value |\n    |:-----------------------|:-----|\n    |skipmixin_key |\t{'followed': ['task_c', 'task_b']} |\n    |return_value  |\t['task_b', 'task_c'] |\n\n    * 여기서 `skipmixin_key` 의 value값의 key 값이 'followed' 이고 ['task_c', 'task_b'] 인 것을 볼 수 있다. 필요시 어떤 task들이 선택되었는지 확인하려면 xcom을 통해 확인 가능하다.\n    * log 를 보면\n    ```markdown\n    [2023-06-23, 23:20:01 UTC] {python.py:183} INFO - Done. Returned value was: ['task_b', 'task_c']\n    [2023-06-23, 23:20:01 UTC] {python.py:216} INFO - Branch callable return ['task_b', 'task_c']\n    [2023-06-23, 23:20:01 UTC] {skipmixin.py:161} INFO - Following branch ['task_b', 'task_c']\n    [2023-06-23, 23:20:01 UTC] {skipmixin.py:221} INFO - Skipping tasks ['task_a']    \n    ```\n\n\n# Task 분기처리하기 with task.branch\n\n## Task.branch 이해: BranchPythonOperator vs task.branch Decorator\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n```markdown\nfrom airflow.operators.python import BranchPythonOperator\ndef select_random(): \n    import random\n    item_lst = ['A','B','C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A':\n        return 'task_a'\n    elif selected_item in ['B','C']\n        return ['task_b','task_c']\n\npython_branch_task = BranchPythonOperator(\n    task_id= 'branching',\n    python_callable = select_random\n)\npython_branch_task >> [task_a , task_b , task_c]\n```\n\n:::\n\n::: {.column width=\"50%\"}\n\n```markdown\nfrom airflow.operators.python import task\n\n@task.branch(task_id='python_branch_task')\ndef select_random(): \n    import random\n    item_lst = ['A','B','C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A':\n        return 'task_a'\n    elif selected_item in ['B','C']\n        return ['task_b','task_c']\n\nselect_random() >> [task_a , task_b , task_c]\n\n```\n\n:::\n\n::::\n\n* BranchPythonOperator와 비교하여 select_random()을 호출 또는 맵핑 하는 방식이 decorator에서는 `@task.branch(task_id='python_branch_task')`으로 표현 되었고 task flow를 표현하는 task connection 방식도 `select_random() >> [task_a , task_b , task_c]` 로 표현 됐다.\n*  BranchPythonOperator의 `python_branch_task` object와 task.branch (decorator)의 select_random()는 사실상 같은 객체이다.\n* 차이점은 `BranchPythonOperator(...)`를 실행시킨 것과 `select_random(...)` 함수를 실행한 것 외엔 그 역할과 기능은 같다 (같은 object 반환). \n* Dags Full Example\n\n```markdown\nfrom airflow import DAG\nfrom datetime import datetime\nfrom airflow.operators.python import PythonOperator\nfrom airflow.decorators import task\n\nwith DAG(\n    dag_id='dags_python_with_branch_decorator',\n    start_date=datetime(2023,4,1),\n    schedule=None,\n    catchup=False\n) as dag:\n    @task.branch(task_id='python_branch_task')\n    def select_random():\n        import random\n        item_lst = ['A', 'B', 'C']\n        selected_item = random.choice(item_lst)\n        if selected_item == 'A':\n            return 'task_a'\n        elif selected_item in ['B','C']:\n            return ['task_b','task_c']\n    \n    def common_func(**kwargs):\n        print(kwargs['selected'])\n\n    task_a = PythonOperator(\n        task_id='task_a',\n        python_callable=common_func,\n        op_kwargs={'selected':'A'}\n    )\n\n    task_b = PythonOperator(\n        task_id='task_b',\n        python_callable=common_func,\n        op_kwargs={'selected':'B'}\n    )\n\n    task_c = PythonOperator(\n        task_id='task_c',\n        python_callable=common_func,\n        op_kwargs={'selected':'C'}\n    )\n\n    select_random() >> [task_a, task_b, task_c]\n```\n\n* airflow web service의 결과물은 BranchPythonOperator나 decorator나 같았음\n\n# Task 분기처리하기 With BaseBranchOperator\n\nBaseBranchOperator 클래스 상속해서 직접 함수를 개발해서 사용해야함.\n\n## BaseBranchOperator 이해 요약\n\n```markdown\nfrom airflow.operators.branch import BaseBranchOperator\nwith DAG(...\n) as dag:\n    class CustomBranchOperator(BaseBranchOperator): #클래스 이름은 임의로 지정해 줌\n    #Python의 class 상속 syntax: class MyclassName(상속할className):\n    #Python은 다중 상속가능\n        def choose_branch(self,context): \n        # 함수 재정의 : Overriding, 함수 이름 바꾸면 안됨!\n        # parameter도 바꾸면 안됨\n            import random\n            print(context) # context에 어떤 내용이 있는지 출력\n\n            item_lst = ['A', 'B','C]\n            selected_item = random.choice(item_lst)\n            if selected_item == 'A':\n                return 'task_a'\n            elif selected_item in ['B','C']:\n                return ['task_b','task_c']\n\ncustom_branch_operator = CustomBranchOperator(task_id ='python_branch_task') # 클래스 실행하여 custom_branch_operator object 생성\ncustom_branch_operator >> [task_a , task_b , task_c]\n```\n\n* 클래스 상속하여 새로운 클래스 만들어야함: BaseBranchOperator 상속시 choose_branch 함수를 구현해 줘야 함\n* `CustomBranchOperator` 클래스 이름은 임의로 지정해준 이름\n* class 선언시 `class childClass(상속할parentClass):` 상속할 부모클래스를 2개이상 지정하는 다중 상속이 가능하긴 하지만 권고하지 않음.\n* `choose_branch()` 함수를 만든 이유를 알기 위해선 BaseBranchOperator class에 대해서 알아야함\n    * [airflow operators-airflow.operators.branch or google 'airflow operators'](https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/operators/branch/index.html)\n    :::{.callout-note}\n    ## Description\n\n    Bases: airflow.models.baseoperator.BaseOperator, airflow.models.skipmixin.SkipMixin\n    A base class for creating operators with branching functionality, like to BranchPythonOperator.\n    **Users should create a subclass from this operator and implement the function choose_branch(self, context). This should run whatever business logic is needed to determine the branch, and return either the task_id for a single task (as a str) or a list of task_ids**.\n    The operator will continue with the returned task_id(s), and all other tasks directly downstream of this operator will be skipped.\n    :::\n    * 함수명과 인자(argument)명도 반드시 일치시켜야함\n    * `choose_branch(self,context)`의 context는 pythonOperator 쓸때 **kwargs의 parameters들을 사용할 수 있게 해주는 parameter\n        * context 인자엔 op_kargs와 같이 data_interval_start, data_interval_end 등과 같은 정보를 제공해주는 인자\n    * `print(context)` 결과\n    ```markdown\n    [2023-06-24, 00:29:33 UTC] {logging_mixin.py:149} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fc3d5dd2cd0>, 'dag': <DAG: dags_base_branch_operator>, 'dag_run': <DagRun dags_base_branch_operator @ 2023-06-24 00:29:31.444830+00:00: manual__2023-06-24T00:29:31.444830+00:00, state:running, queued_at: 2023-06-24 00:29:31.455604+00:00. externally triggered: True>, 'data_interval_end': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'ds': '2023-06-24', 'ds_nodash': '20230624', 'execution_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'expanded_ti_count': None, 'inlets': [], 'logical_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2023-06-24', 'next_ds_nodash': '20230624', 'next_execution_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2023-06-24', 'prev_ds_nodash': '20230624', 'prev_execution_date': DateTime(2023, 6, 24, 0, 29, 31, 444830, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'manual__2023-06-24T00:29:31.444830+00:00', 'task': <Task(CustomBranchOperator): python_branch_task>, 'task_instance': <TaskInstance: dags_base_branch_operator.python_branch_task manual__2023-06-24T00:29:31.444830+00:00 [running]>, 'task_instance_key_str': 'dags_base_branch_operator__python_branch_task__20230624', 'test_mode': False, 'ti': <TaskInstance: dags_base_branch_operator.python_branch_task manual__2023-06-24T00:29:31.444830+00:00 [running]>, 'tomorrow_ds': '2023-06-25', 'tomorrow_ds_nodash': '20230625', 'triggering_dataset_events': <Proxy at 0x7fc3ab28c8c0 with factory <function TaskInstance.get_template_context.<locals>.get_triggering_events at 0x7fc3ab277c20>>, 'ts': '2023-06-24T00:29:31.444830+00:00', 'ts_nodash': '20230624T002931', 'ts_nodash_with_tz': '20230624T002931.444830+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2023-06-23', 'yesterday_ds_nodash': '20230623'}\n    ```\n    context결과물은 위와 같은 시간 정보를 담고 있기 때문에 꺼내쓸 수 있다. \n* 분기 처리 결과는 다른 2 방식의 결과와 같음\n\n* DAG Full Example \n\n```markdown\nfrom airflow import DAG\nimport pendulum\nfrom airflow.operators.branch import BaseBranchOperator\nfrom airflow.operators.python import PythonOperator\n\nwith DAG(\n    dag_id='dags_base_branch_operator',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'),\n    schedule=None,\n    catchup=False\n) as dag:\n    class CustomBranchOperator(BaseBranchOperator):\n        def choose_branch(self, context):\n            import random\n            print(context) # context에 어떤 내용이 있는지 출력\n            \n            item_lst = ['A', 'B', 'C']\n            selected_item = random.choice(item_lst)\n            if selected_item == 'A':\n                return 'task_a'\n            elif selected_item in ['B','C']:\n                return ['task_b','task_c']\n\n    \n    custom_branch_operator = CustomBranchOperator(task_id='python_branch_task')\n\n    \n    def common_func(**kwargs):\n        print(kwargs['selected'])\n\n    task_a = PythonOperator(\n        task_id='task_a',\n        python_callable=common_func,\n        op_kwargs={'selected':'A'}\n    )\n\n    task_b = PythonOperator(\n        task_id='task_b',\n        python_callable=common_func,\n        op_kwargs={'selected':'B'}\n    )\n\n    task_c = PythonOperator(\n        task_id='task_c',\n        python_callable=common_func,\n        op_kwargs={'selected':'C'}\n    )\n\n    custom_branch_operator >> [task_a, task_b, task_c]\n\n```\n## Summary\n\n* Task 분기처리 방법\n    1. BranchPythonOperator (자주 사용)\n    1. task.branch 데커레이터 이용 (자주 사용)\n    1. BaseBranchOperator 상속 , choose_branch 를 재정의해야 함 (덜 사용)\n* 공통적으로 리턴 값으로 후행 Task 의 id 를 str 또는 list 로 리턴해야 함\n* 3가지 분기처리 방법은 방법만 다를 뿐 결과는 동일함\n* 3 보다는 1 또는 2를 주로 사용함\n\n# Trigger Rule\n\n## Trigger Rule 종류\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    task1 [shape=box];\n    task2 [shape=box];\n    task3 [shape=box];\n    task4 [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  task1 -> task4;\n  task2 -> task4;\n  task3 -> task4; \n}\n```\n\n* branch와 반대되는 개념으로 여러 상위 tasks가 하나의 하위 task로 연결되는 flow로 만들때 사용 \n* 즉, 여러 상위 Task 들의 상태에 따라 후행 task의 수행여부 결정할 때 쓰인다 \n* 기본 값 : 여러 상위 Task들이 모두 성공시에만 수행\n* 상위 task의 수행 상태에 따라 조건적으로 후행 task의 수행 여부를 결정할 수 있다.\n* trigger option은 하위 task를 이용하여 줄 수 있다.\n* 모든 airflow operator는 trigger rule option을 줄 수 있다. \n* 11가지 trigger rules \n\n| Default                       | Left      |\n|:------------------------------|:----------|\n| all_success (default)         | 상위 tasks 가 모두 성공하면 실행  |\n| all_failed                    | 상위 tasks 가 모두 실패하면 실행  |\n| all_done                      | 상위 tasks 가 모두 수행되면 실행 (실패도 수행된것에 포함)  |\n| all_skipped                   | 상위 tasks 가 모두 Skipped 상태면 실행  |\n| one_failed                    | 상위 tasks 중 하나 이상 실패하면 실행 (모든 상위 Tasks의 완료를 기다리지 않음) |\n| one_success                   | 상위 tasks 중 하나 이상 성공하면 실행 (모든 상위 Tasks의 완료를 기다리지 않음) |\n| one_done                      | 상위 tasks 중 하나 이상 성공 또는 실패 하면 실행|\n| none_failed                   | 상위 task s중 실패가 없는 경우 실행 (성공 또는 Skipped 상태) |\n| none_failed_min_one_success   | 상위 tasks 중 실패가 없고 성공한 Task가 적어도 1개 이상이면 실행 |\n| none_skipped                  | Skip된 상위 Task가 없으면 실행 (상위 Task가 성공, 실패하여도 무방)   |\n| always                        | 언제나 실행 |\n\n* 위의 표에서 모든 상위 **task를 기다리지 않음**은 각 각의 상위 task들의 처리 시간이 다를 때 가장 빠르게 처리되는 상위 task에 따라서 후행 task가 수행된다는 것을 의미한다. 예를 들어, one_failed의 경우\n    * 상위 task1 (2분소요)\n    * 상위 task2 (10분소요)\n    * 상위 task3 (20분소요) 일때, \n    * 상위 task 3개 중 task1의 결과가 먼저 fail이 나올 경우 task2,3 을 기다리지 않고 바로 triger가 발동되어 하위 task4가 수행된다.\n\n\n## 2. Trigger Rule 실습) trigger_rule = all_done\n\n* 아래 예시에서 4개의 task가 정의됨\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n```markdown\n\n# 상위 task1\nbash_upstream_1 = BashOperator(\n    task_id = 'bash_upstream_1',\n    bash_command = 'echo upstream1'\n)\n\n@task(task_id =='python_upstream_1') # 상위 task2\ndef python_upstream_1():\n    AirflowException('downstream_1 Exception!') # AirflowException() fail을 반환하여 무조건 task 실패처리가되도록 설정\n\n@task(task_id =='python_upstream_2') # 상위 task3\ndef python_upstream_2():\n    print('정상 처리')\n\n@task(task_id ='python_downstream_1', trigger_rule ='all_done') #하위 task4\ndef python_downstream_1():\n    print('정상 처리')\n\n[bash_upstream_1 , python_upstream_1(), python_upstream_2()] >> python_downstream_1()\n\n```\n:::\n\n::: {.column width=\"50%\"}\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    bash_upstream_1 [shape=box];\n    python_upstream_1 [shape=box];\n    python_upstream_2 [shape=box];\n    python_downstream_1 [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  bash_upstream_1 -> python_downstream_1;\n  python_upstream_1 -> python_downstream_1;\n  python_upstream_2 -> python_downstream_1; \n}\n```\n\n:::\n\n::::\n\n* bash_upstream_1(성공), python_upstream_1(실패), python_upstream_2(성공). \n* triger rule이 all done이기 때문에 python_upstream_1(실패)여도 python_downstream_1은 수행되어야 한다.\n* 다른 Operator such as BashOperator, pythonOperator의 경우도 `trigger_rule =='all_done'` parameter 똑같이 넣어주면 됨\n\n\n## 2. Trigger Rule 실습) triger_rule = none_skipped\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```markdown\n@task.branch(task_id ='branching') #상위 task1\ndef random_branch():\n    import random\n    item_lst = [' A', ' B', 'C']\n    selected_item = random.choice(item_lst)\n    if selected_item == 'A':\n        return 'task_a'\n    elif selected_item == 'B':\n        return 'task_b'\n    elif selected_item == 'C':\n        return 'task_c'\n\n#상위 task2\ntask_a = BashOperator(\n    task_id ='task_a',\n    bash_command = 'echo upstream1'\n    )\n\n#상위 task3\n@task(task_id ='task_b')\ndef task_b():\n    print('정상 처리')\n\n#상위 task4\n@task(task_id =='task_c')\ndef task_c():\n    print('정상 처리')\n\n#하위 task5\n@task(task_id =='task_d', trigger_rule ='none_skipped')\ndef task_d():\n    print('정상 처리')\n\nrandom_branch() >> [task_a , task_b(), task_c()] >> task_d()\n\n```\n\n:::\n\n::: {.column width=\"50%\"}\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    random_branch [shape=box];\n    task_a [shape=box];\n    task_b [shape=box];\n    task_c [shape=box];\n    task_d [shape=box];\n    \n    label= \"Task Flow\";\n  }\n\n  random_branch -> task_a;\n  random_branch -> task_b;\n  random_branch -> task_c;\n  task_a -> task_d;\n  task_b -> task_d;\n  task_c -> task_d;\n}\n```\n\n:::\n\n::::\n\n* skip이 있기 때문에 실제로 task_d가 돌지 말아야한다.\n* Dags Full Example\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n```markdown\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom airflow.exceptions import AirflowException\n\nimport pendulum\n\nwith DAG(\n    dag_id='dags_python_with_trigger_rule_eg1',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'),\n    schedule=None,\n    catchup=False\n) as dag:\n    bash_upstream_1 = BashOperator(\n        task_id='bash_upstream_1',\n        bash_command='echo upstream1'\n    )\n\n    @task(task_id='python_upstream_1')\n    def python_upstream_1():\n        raise AirflowException('downstream_1 Exception!')\n\n\n    @task(task_id='python_upstream_2')\n    def python_upstream_2():\n        print('정상 처리')\n\n    @task(task_id='python_downstream_1', trigger_rule='all_done')\n    def python_downstream_1():\n        print('정상 처리')\n\n    [bash_upstream_1, python_upstream_1(), python_upstream_2()] >> python_downstream_1()\n```\n:::\n\n::: {.column width=\"50%\"}\n```markdown\nfrom airflow import DAG\nfrom airflow.decorators import task\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom airflow.exceptions import AirflowException\n\nimport pendulum\n\nwith DAG(\n    dag_id='dags_python_with_trigger_rule_eg2',\n    start_date=pendulum.datetime(2023,4,1, tz='Asia/Seoul'),\n    schedule=None,\n    catchup=False\n) as dag:\n    @task.branch(task_id='branching')\n    def random_branch():\n        import random\n        item_lst = ['A', 'B', 'C']\n        selected_item = random.choice(item_lst)\n        if selected_item == 'A':\n            return 'task_a'\n        elif selected_item == 'B':\n            return 'task_b'\n        elif selected_item == 'C':\n            return 'task_c'\n\n    task_a = BashOperator(\n        task_id='task_a',\n        bash_command='echo upstream1'\n    )\n\n    @task(task_id='task_b')\n    def task_b():\n        print('정상 처리')\n\n\n    @task(task_id='task_c')\n    def task_c():\n        print('정상 처리')\n\n    @task(task_id='task_d', trigger_rule='none_skipped')\n    def task_d():\n        print('정상 처리')\n\n    random_branch() >> [task_a, task_b(), task_c()] >> task_d()\n```\n:::\n\n::::\n\n\n# Task Group\n\n## Task Group 개념\n\n* tasks를 모아 관리\n* Task들의 모음: dags안에 task가 많을 경우 비슷한 기능의 tasks 그룹으로 모아서 관리\n    * 예를 들어, dag안에 50개의 tasks 있다고 할 때, 5개 tasks가 서로 연관성이 높은 connection을 이루고 이런 group이 10개가 있을 수 있다. \n* [link: UI Graph탭에서 Task 들을 Group 화하여 보여줌-TaskGroups or google 'airflow dags'](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#taskgroups)\n    * content >> Core Concepts >> DAGs >> DAG Visualization >> Task Groups\n* Task Group 안에 Task Group 을 중첩하여 계층적으로 구성 가능\n* 위의 링크에서 section1 과 section2 로 grouping되어 있고 section2에는 inner_section_2 라는 또 다른 task group이 있다.\n* 꼭 써야하는 이유는 성능적인 면에서 딱히 없지만 task flow의 가독성이 높아짐\n\n## Task Group 실습 \n\n1. task_group 데커레이터 이용\n\n```markdown\nfrom airflow.decorators import task_group\nwith DAG(...\n) as dag:\n    @task_group(group_id ='first_group')\n    def group_1():\n    ''' task_group 데커레이터를 이용한 첫 번째 그룹''' # docstring: 함수를 설명하는 기법\n    # airflow UI에서는 tooltip이라고 표시됨\n\n    @task(task_id ='inner_function1')\n    def inner_func1(**kwargs):\n        print('첫 번째 TaskGroup 내 첫 번째 task 입니다')\n\n    inner_function2 = PythonOperator(\n        task_id ='inner_function2',\n        python_callable = inner_func,\n        op_kwargs={'msg':'첫 번째 TaskGroup 내 두 번쨰 task 입니다.'}\n    )\n    inner_func1() >> inner_function2\n```\n\n2. task_group 데커레이터 이용하지 않음 (클래스 이용)\n\n```markdown\nfrom airflow.utils.task_group import TaskGroup\n    with TaskGroup(group_id ='second_group', tooltip='두 번째 그룹') as group_2: # with MyClassName(arg1,age2,...) \n    # tooltipe은 decorator를 이용한 task_group 생성때의 docstring과 같은 역할을 함\n        @task(task_id ='inner_function1')\n        def inner_func1 (**kwargs):\n            print('두 번째 TaskGroup 내 첫 번째 task 입니다.')\n\n        inner_function2 = PythonOperator(\n            task_id = 'inner_function2',\n            python_collable = inner_func,\n            op_kwargs = {'msg': '두 번째 TaskGroup 내 두 번째 task 입니다'}\n        )\ninner_func1() >> inner_function2\n```\n\n* Dags Full Example\n\n```markdown\nfrom airflow import DAG\nimport pendulum\nimport datetime\nfrom airflow.operators.python import PythonOperator\nfrom airflow.decorators import task\nfrom airflow.decorators import task_group\nfrom airflow.utils.task_group import TaskGroup\n\nwith DAG(\n    dag_id=\"dags_python_with_task_group\",\n    schedule=None,\n    start_date=pendulum.datetime(2023, 4, 1, tz=\"Asia/Seoul\"),\n    catchup=False\n) as dag:\n    def inner_func(**kwargs):\n        msg = kwargs.get('msg') or '' \n        print(msg)\n\n    @task_group(group_id='first_group')\n    def group_1():\n        ''' task_group 데커레이터를 이용한 첫 번째 그룹 '''\n\n        @task(task_id='inner_function1')\n        def inner_func1(**kwargs):\n            print('첫 번째 TaskGroup 내 첫 번째 task입니다.')\n\n        inner_function2 = PythonOperator(\n            task_id='inner_function2',\n            python_callable=inner_func,\n            op_kwargs={'msg':'첫 번째 TaskGroup내 두 번쨰 task입니다.'}\n        )\n\n        inner_func1() >> inner_function2\n\n    with TaskGroup(group_id='second_group', tooltip='두 번째 그룹') as group_2:\n        ''' 클래스 안에 적은 docstring은 표시되지 않음'''\n        @task(task_id='inner_function1')\n        def inner_func1(**kwargs):\n            print('두 번째 TaskGroup 내 첫 번째 task입니다.')\n\n        inner_function2 = PythonOperator(\n            task_id='inner_function2',\n            python_callable=inner_func,\n            op_kwargs={'msg': '두 번째 TaskGroup내 두 번째 task입니다.'}\n        )\n        inner_func1() >> inner_function2\n\n    group_1() >> group_2\n```\n\n* 위에서 task_id와 group_id가 같지만 에러가 안나는 이유가 task group이 다르기 때문.\n* 위에서 볼 수 있듯이 task group 또한 flow 설정할 수 있음 `group_1() >> group_2`\n\n\n## 요약\n\n* Task Group 작성 방법은 2 가지가 존재함 (데커레이터 & 클래스)\n* Task Group 안에 Task Group 중첩하여 정의 가능\n* Task Group 간에도 Flow 정의 가능\n* Group이 다르면 task_id 가 같아도 무방\n* Tooltip 파라미터를 이용해 UI 화면에서 Task group 에 대한 설명 제공 가능\n    (데커레이터 활용시 docstring 으로도 가능)\n\n# Edge label\n\n## Edge Label 개념\n\n* Task 연결에 대한 설명 (즉 edge에 대한 Comment)\n\n## Edge Label 만들기\n\n```{dot}\ndigraph G {\n  compound=true;\n  rankdir=LR;\n  subgraph cluster0 {\n    rankdir=TB;\n    ingest [shape=box];\n    analyze [shape=box];\n    check_integrity [shape=box];\n    describe_integrity [shape=box];\n    email_error [shape=box];\n    report [shape=box];\n    save [shape=box];\n    label= \"Task Flow\";\n  }\n\n  ingest -> analyze ;\n  analyze -> check_integrity ;\n  check_integrity -> describe_integrity[label=\"Errors Found\"];\n  describe_integrity -> email_error;\n  email_error -> report;\n  check_integrity -> save[label=\"No Errors\"];\n  save -> report;\n  \n  \n}\n```\n\n## Edge Label 실습 1\n\n```markdown\n\nfrom airflow.utils.edgemodifier import Label\nempty_1 = EmptyOperator(\n    task_id ='empty_1'\n)\n\nempty_2 = EmptyOperator(\n    task_id='empty_2'\n)\nempty_1 >> Label ('1 과 2 사이') >> empty_2\n```\n\n## Edge Label 실습 2\n\n```markdown\n\nfrom airflow.utils.edgemodifier import Label\nempty_2 = EmptyOperator(\n    task_id = 'empty_2'\n)\n\nempty_3 = EmptyOperator(\n    task_id ='empty_3'\n)\n\nempty_4 = EmptyOperator(\n    task_id ='empty_4'\n)\n\nempty_5 = EmptyOperator(\n    task_id ='empty_5'\n)\n\nempty_6 = EmptyOperator(\n    task_id ='empty_6'\n)\n\nempty_2 >> Label('Start Branch') >> [empty_3, empty_4, empty_5 ] >> Label('End Branch') >> empty_6\n```\n\n* 이렇게 분기가 펼쳐지고 모아지는 경우 모든 분기 edges에 label이 붙게 된다.\n* Full DAG Example\n\n```markdown\nfrom airflow import DAG\nimport pendulum\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.utils.edgemodifier import Label\n\n\nwith DAG(\n    dag_id=\"dags_empty_with_edge_label\",\n    schedule=None,\n    start_date=pendulum.datetime(2023, 4, 1, tz=\"Asia/Seoul\"),\n    catchup=False\n) as dag:\n    \n    empty_1 = EmptyOperator(\n        task_id='empty_1'\n    )\n\n    empty_2 = EmptyOperator(\n        task_id='empty_2'\n    )\n\n    empty_1 >> Label('1과 2사이') >> empty_2\n\n    empty_3 = EmptyOperator(\n        task_id='empty_3'\n    )\n\n    empty_4 = EmptyOperator(\n        task_id='empty_4'\n    )\n\n    empty_5 = EmptyOperator(\n        task_id='empty_5'\n    )\n\n    empty_6 = EmptyOperator(\n        task_id='empty_6'\n    )\n\n    empty_2 >> Label('Start Branch') >> [empty_3,empty_4,empty_5] >> Label('End Branch') >> empty_6\n```\n* empty operator이기 때문에 실행은 airflow web servce에서 실행은 안해도 된다.\n\n:::\n\n</div>\n\n<div class=\"tab-pane fade\" id=\"English\" role=\"tabpanel\" aria-labelledby=\"English-tab\">\n\n::: {#English .tab-pane .fade role=\"tabpanel\" aria-labelledby=\"English-tab\"}\n\n:::\n\n\n</div>\n\n\n# Go to Blog Content List\n\n[Blog Content List](../../content_list.qmd)  \n[Engineering Content List](../../Engineering/guide_map/index.qmd)"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":true,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"github","css":["../../../../../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"include-in-header":[{"text":"<style>\n.custom-footer { \n  text-align: center; \n  font-size: 0.8em; \n  color: #666; \n  margin-top: 2rem; \n}\n</style>\n"}],"include-after-body":["../../../../../js.html","../../../signup.html"],"output-file":"07.task_handling.html"},"language":{"toc-title-document":"목차","toc-title-website":"목차","related-formats-title":"기타 형식","related-notebooks-title":"Notebooks","source-notebooks-prefix":"원천","other-links-title":"기타 링크","code-links-title":"코드 링크","launch-dev-container-title":"Dev 컨테이너 실행","launch-binder-title":"랜치 Binder","article-notebook-label":"기사 노트북","notebook-preview-download":"노트북 다운로드","notebook-preview-download-src":"소스 다운로드","notebook-preview-back":"기사로 돌아가기","manuscript-meca-bundle":"MECA 아카이브","section-title-abstract":"초록","section-title-appendices":"부록","section-title-footnotes":"각주","section-title-references":"참고문헌","section-title-reuse":"라이센스","section-title-copyright":"저작권","section-title-citation":"인용","appendix-attribution-cite-as":"인용방법","appendix-attribution-bibtex":"BibTeX 인용:","title-block-author-single":"저자","title-block-author-plural":"저자","title-block-affiliation-single":"소속","title-block-affiliation-plural":"소속","title-block-published":"공개","title-block-modified":"Modified","title-block-keywords":"키워드","callout-tip-title":"힌트","callout-note-title":"노트","callout-warning-title":"경고","callout-important-title":"중요","callout-caution-title":"주의","code-summary":"코드","code-tools-menu-caption":"코드","code-tools-show-all-code":"전체 코드 표시","code-tools-hide-all-code":"전체 코드 숨기기","code-tools-view-source":"소스 코드 표시","code-tools-source-code":"소스 코드","tools-share":"Share","tools-download":"Download","code-line":"선","code-lines":"윤곽","copy-button-tooltip":"클립보드 복사","copy-button-tooltip-success":"복사완료!","repo-action-links-edit":"편집","repo-action-links-source":"소스코드 보기","repo-action-links-issue":"이슈 보고","back-to-top":"맨 위로","search-no-results-text":"일치 없음","search-matching-documents-text":"일치된 문서","search-copy-link-title":"검색 링크 복사","search-hide-matches-text":"추가 검색 결과 숨기기","search-more-match-text":"추가 검색결과","search-more-matches-text":"추가 검색결과","search-clear-button-title":"제거","search-text-placeholder":"","search-detached-cancel-button-title":"취소","search-submit-button-title":"검색","search-label":"검색","toggle-section":"토글 섹션","toggle-sidebar":"사이드바 전환","toggle-dark-mode":"다크 모드 전환","toggle-reader-mode":"리더 모드 전환","toggle-navigation":"탐색 전환","crossref-fig-title":"그림","crossref-tbl-title":"표","crossref-lst-title":"목록","crossref-thm-title":"정리","crossref-lem-title":"보조정리","crossref-cor-title":"따름정리","crossref-prp-title":"명제","crossref-cnj-title":"추측","crossref-def-title":"정의","crossref-exm-title":"보기","crossref-exr-title":"예제","crossref-ch-prefix":"장","crossref-apx-prefix":"부록","crossref-sec-prefix":"섹션","crossref-eq-prefix":"방정식","crossref-lof-title":"그림 목록","crossref-lot-title":"표 목록","crossref-lol-title":"코드 목록","environment-proof-title":"증명","environment-remark-title":"주석","environment-solution-title":"해답","listing-page-order-by":"정렬","listing-page-order-by-default":"디폴트","listing-page-order-by-date-asc":"날짜(오름차순)","listing-page-order-by-date-desc":"날짜(내림차순)","listing-page-order-by-number-desc":"페이지 번호(내림차순)","listing-page-order-by-number-asc":"페이지 번호(오름차순)","listing-page-field-date":"날짜","listing-page-field-title":"제목","listing-page-field-description":"설명","listing-page-field-author":"저자","listing-page-field-filename":"파일명","listing-page-field-filemodified":"갱신일","listing-page-field-subtitle":"부제목","listing-page-field-readingtime":"읽기 시간","listing-page-field-wordcount":"단어 수","listing-page-field-categories":"분류","listing-page-minutes-compact":"{0} 분","listing-page-category-all":"전체","listing-page-no-matches":"일치 없음","listing-page-words":"{0} 단어"},"metadata":{"lang":"ko","fig-responsive":true,"quarto-version":"1.4.543","theme":{"light":["cosmo","../../../../../theme.scss"],"dark":["cosmo","../../../../../theme-dark.scss"]},"code-copy":true,"grid":{"sidebar-width":"200px","body-width":"1200px","margin-width":"200px"},"comments":{"giscus":{"repo":"kmink3225/blog","category":"Blog"},"utterances":{"repo":"./docs/comments"}},"title-block-banner":"#EDF3F9","title-block-banner-color":"black","toc-location":"right","open-graph":true,"twitter-card":true,"search":true,"date-format":"YYYY년 MM월 DD일","title":"Task Handling Techniques","subtitle":"BranchPython Operator (Branch Processing), @task.brancch (Branch Processing), BaseBranchOperator (Branch Processing), Trigger Rule Setting, Task Groups, Edge Labels","description":"Advanced Techniques to handle tasks (Branch Processing)\n","categories":["Engineering"],"author":"Kwangmin Kim","date":"05/01/2023","draft":false,"page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}