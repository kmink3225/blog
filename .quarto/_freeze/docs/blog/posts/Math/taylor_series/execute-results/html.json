{
  "hash": "cfb97fc1883c52e347ad6dc7bdd6924c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Taylor's Series\nsubtitle: Taylor's Series and Second Derivative Test\ndescription: |\n  \ncategories:\n  - Mathematics\nauthor: Kwangmin Kim\ndate: 03/16/2023\nformat: \n  html:\n    page-layout: full\n    code-fold: true\n    toc: true\n    number-sections: true\ndraft: False\n---\n\n<ul class=\"nav nav-pills\" id=\"language-tab\" role=\"tablist\">\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link active\" id=\"Korean-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#Korean\" type=\"button\" role=\"tab\" aria-controls=\"Korean\" aria-selected=\"true\">Korean</button>\n  </li>\n  <li class=\"nav-item\" role=\"presentation\">\n    <button class=\"nav-link\" id=\"English-tab\" data-bs-toggle=\"tab\" data-bs-target=\"#English\" type=\"button\" role=\"tab\" aria-controls=\"knitr\" aria-selected=\"false\">English</button>\n  </li>\n\n<div class=\"tab-content\" id=\"language-tabcontent\">\n\n<div class=\"tab-pane fade  show active\" id=\"Korean\" role=\"tabpanel\" aria-labelledby=\"Korean-tab\">\n\n::: {#Korean .tab-pane .fade .show .active role=\"tabpanel\" aria-labelledby=\"Korean-tab\"}\n\n## Definition\n\n::: {#def-sequence}\n\nA **sequence** is a list of numbers written in a definite order:\n$$\na_1, a_2, a_3, \\dots, a_n, a_{n+1} \\dots  \n$$\n\nthe number $a_1$, $a_2$, and $a_n$ are called the first term, the second term, the nth term.\nSince for every positive inter $n$ there is a corresponding number $a_n$, a sequence can be defined as a funtion with domain of the set of positive integers.\nThe notation of the sequence function is $a_n$ instead of $f(n)$ in convention:\n$$\n\\text{The sequence } \\{a_1,a_2,a_3,\\dots\\} \\text{ is also denoted by } \\{a_n\\} \\text{ or } \\{a_n\\}_{n=1}^{\\infty}\n$$\n.\n:::\n\n::: {#def-series}\n\nA **series or infinite series** is defined as a sum of  the terms of an infinite sequence $\\{a_n\\}_{n=1}^{\\infty}$:\n$$\na_1+ a_2+ a_3+ \\dots+ a_n+ a_{n+1} \\dots  \n$$\n\nThe notation of a series is: $\\sum_{n=1}^{\\infty} a_n$ or $\\sum a_n$.\n:::\n\n::: {#def-power_series}\n\nA **power series** is a series of the following form:\n$$\n\\sum_{n=0}^{\\infty} c_nx^n = c_0x^0+c_1x^1+c_2x^2+ \\dots+ c_nx^n+c_{n+1}x^{n+1}+\\dots  \n$$\n\nwhere $x$ is a variable and the $c_n$'s are constants called the coefficients of the series.\n:::\n\n::: {#def-power_series}\n\nA **power series centered at a** is a series of the following form:\n$$\n\\begin{aligned}\n    \\sum_{n=0}^{\\infty} c_n(x-a)^n &= c_0(x-a)^0+c_1(x-a)^1+c_2(x-a)^2+ \\dots+ c_n(x-a)^n+c_{n+1}(x-a)^{n+1}+\\dots  \\\\\n                                    &= c_0+c_1(x-a)^1+c_2(x-a)^2+ \\dots+ c_n(x-a)^n+c_{n+1}(x-a)^{n+1}+\\dots  \n\\end{aligned}\n$$\n\nwhere $x$ is a variable and the $c_n$'s are constants called the coefficients of the series.\n:::\n\n::: {#thm-power_series_expansion}\n\n $f$ is said to be a **expanded power series centered at a** :\n$$\n\\text{if }f(x)=\\sum_{n=0}^{\\infty} c_n(x-a)^n |x-a|<R, \\text{ then, its coefficients are given by the formula } c_n=\\frac{f^{(n)}(a)}{n!}\n$$\n\nwhere $x$ is a variable and the $c_n$'s are constants called the coefficients of the series.\n:::\n\nProof)\n\nLet $f$ is any function that can be represented by a powerseries.\n\n$$\n\\begin{aligned}\n    \n    f(x) &= c_0+c_1(x-a)^1+c_2(x-a)^2+ \\dots+ c_n(x-a)^n+c_{n+1}(x-a)^{n+1}+\\dots \\text{  }|x-a|<R\\\\\n    f(a) &= 0\\\\\n    f'(x) &= c_1+2c_2(x-a)+ 3c_3(x-a)^2+ \\dots \\text{  }|x-a|<R\\\\ \\\\\n    f'(a) &= c_1 \\\\\n    f''(x) &= 2c_2(x-a)+ 2\\times 3c_3(x-a)+ 3\\times 4c_4(x-a)^2+ \\dots \\text{  }|x-a|<R\\\\\n    f''(a) &= 2c_2 \\\\\n    f'''(x) &= 3!c_3 + 4! c_4(x-a)+3\\times 4 \\times 5 c_4(x-a)^2 \\dots \\text{  }|x-a|<R\\\\\n    f'''(a) &= 3!c_3 \\\\\n    \\vdots \\\\\n    f^{(n)}(a) &= n!c_n \\\\\n    c_n&=\\frac{f^{(n)}}{n!}\n\\end{aligned}\n$$\n\n::: {#def-taylor_series}\n\n $f$ is said to be a **Taylor's series** if f has a expanded power series at a with the following form:\n$$\n\\begin{aligned}\n    f(x)&=\\sum_{n=0}^{\\infty} \\frac{f^{(n)}(a)}{n!}(x-a)^n \\\\\n        &= \\frac{f^{(0)}(a)}{0!}(x-a)^0+\\frac{f^{(1)}(a)}{1!}(x-a)^1+\\frac{f^{(2)}(a)}{2!}(x-a)^2+\\frac{f^{(0)}(a)}{0!}(x-a)^3 + \\dots \\\\\n        &= f(a)+\\frac{f^{(1)}(a)}{1!}(x-a)^1+\\frac{f^{(2)}(a)}{2!}(x-a)^2+\\frac{f^{(3)}(a)}{3!}(x-a)^3 + \\dots \n\\end{aligned}\n$$\n:::\n\n::: {#def-maclaurin_series}\n\n $f$ is said to be a **Maclaurin series** if f has a Taylor's series with the special case $a=0$:\n$$\n\\begin{aligned}\n    f(x)&=\\sum_{n=0}^{\\infty} \\frac{f^{(n)}(0)}{n!}(x)^n \\\\\n        &= \\frac{f^{(0)}(0)}{0!}x^0+\\frac{f^{(1)}(0)}{1!}x^1+\\frac{f^{(2)}(0)}{2!}x^2+\\frac{f^{(3)}(0)}{3!}x^3 + \\dots \\\\\n        &= f(0)+\\frac{f^{(1)}(0)}{1!}x^1+\\frac{f^{(2)}(0)}{2!}x^2+\\frac{f^{(3)}(0)}{3!}x^3 + \\dots \n\\end{aligned}\n$$\n:::\n\n::: {#945223c0 .cell execution_count=1}\n``` {.python .cell-code}\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndegrees = (1, 3, 5, 7)\nls = ('-', '--', '-.', ':')\n\ndef  taylor_e(x, a, n) :\n    \"\"\"\n    x* = a 에서 전개\n    f(x) = f(a) + f'(a)*(x-a) + (1/2!)f''(a)(x-a)^2 + ... + (1/k!)f^(k)(a)(x-a)^k + R_k\n    \"\"\"\n    signs  = (1, -1, -1, 1)\n    derivs = (np.cos, np.sin, np.cos, np.sin)\n\n    fx =  np.sin(a) \n    \n    for i in range(1, n+1) : \n        fx += (signs[(i%4)-1]*derivs[(i%4)-1](a)) / math.factorial(i)*(x-a)**i\n    \n    return fx\n    \nx = np.linspace(-10, 10, 100)\ny = np.sin(x)\n\nfig = plt.figure(figsize=(12,5))\nax = fig.add_subplot(1, 1, 1)\n\nax.xaxis.set_tick_params(labelsize=12)\nax.yaxis.set_tick_params(labelsize=12)\nax.set_xlabel(r'$x$', fontsize=15)\nax.set_ylabel(r'$x$', fontsize=15)\nax.grid(False)\n\ntaylors = (taylor_e(x, 0, i) for i in degrees)\nax.plot(x, y , lw=3, color='gray', \n        label=r\"sin(x)\")\n\nfor i, taylor in enumerate(taylors) :\n    ax.plot(x, taylor, lw=2, ls=ls[i], color='k', \n            label=\"degree {}\".format(degrees[i]))\n\n\nax.legend(fontsize=11)\nax.set_ylim([-5, 5])\n\n# plt.suptitle(\"Taylor series, order=1,2,3\", fontsize=15)\n\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](taylor_series_files/figure-html/cell-2-output-1.png){}\n:::\n:::\n\n\n::: {#thm-taylor_series_remainder}\n\n If $f(x)$ is differentiable (and therefore continuous) $n$ times on $[a,b]$ , then there exists $c$ such that\n$$\n\\begin{aligned}\n    f(b)&=f(a)+f'(a)(b-a)+\\frac{f^{(2)}(a)^2}{2!}(b-a)^2+\\dots+\\\\\n    &\\frac{f^{(n-1)}(a)}{(n-1)!}(b-a)^{n-1} + \\frac{f^{(n)}(c)}{n!}(b-a)^{n}, a<c<b\n\\end{aligned}\n$$\n.\n:::\n\nProof) find $k$ such that $f(b)-(f(a)+f'(a)(b-a)+\\frac{f^{(2)}(a)^2}{2!}(b-a)^2+\\dots+\\frac{f^{(n-1)}(a)}{(n-1)!}(b-a)^{n-1} + k(b-a)^{n})=0$.\n\n$$\n\\begin{aligned}\n    \\text{Let }F(x)&=f(b)-(f(x)+f'(x)(b-x)+\\frac{f^{(2)}(a)^2}{2!}(b-x)^2+\\dots+\\\\\n    &\\frac{f^{(n-1)}(x)}{(n-1)!}(b-x)^{n-1} + k(b-x)^{n})\n\\end{aligned}\n$$\n\nThen, $F(x)$ is differentiable on $[a,b]$. In addition, since $F(a)=F(b)=0$, there exists $c$ such that $F'(c)=0$, $a<c<b$ by the Mean Value Theorem. Thus,\n\n$$\n\\begin{aligned}\n  F'(x)&=-\\frac{f^{(n)}(x)}{(n-1)!}(b-x)^{n-1}+kn(b-x)^{n-1}\\\\\n  F'(c)&=-\\frac{f^{(n)}(c)}{(n-1)!}(b-c)^{n-1}+kn(b-c)^{n-1}=0\\\\\n  kn&=\\frac{f^{(n)}(c)}{(n-1)!}\\\\\n  \\therefore k&=\\frac{f^{(n)}(c)}{n!}\n\\end{aligned}\n$$\n\n::: {#thm-taylor_series_remainder2}\n\n If $f$ is differentiable (and therefore continuous) $n$ times on $[a,b]$ , $x^*,x \\in [a,b]$, and $x\\ne x^*$, there exists $\\theta$ such that $0<\\theta<1$ and  \n$$\n\\begin{aligned}\n    f(x)&=f(x^*)+f'(x^*)(x-x^*)+\\frac{f^{(2)}(x^*)^2}{2!}(x-x^*)^2+\\dots+\\\\\n    &\\frac{f^{(n-1)}(x^*)}{(n-1)!}(x-x^*)^{n-1} + \\frac{f^{(n)}(x^*+\\theta(x-x^*))}{n!}(x-x^*)^{n}\n\\end{aligned}\n$$\n.\n:::\n\nIn the above expression (@thm-taylor_series_remainder2), $f(x)$ can be expressed with finite terms because it is differentiable $n$ times. The symbol $\\theta$ represents a value between 0 and 1, and it is used in the context of Taylor's theorem with remainder (see @def-taylor_series). The general form of Taylor's theorem with remainder is:\n\n$$\nf(x) = f(x^*) + \\frac{f'(x^*)}{1!}(x-x^*) + \\frac{f''(x^*)}{2!}(x-x^*)^2 + ... + \\frac{f^{(n)}(x^*)}{n!}(x-x^*)^n + R_n(x)\n$$\n\nwhere $R_n(x)$ is the remainder term that involves the $n+1$ th derivative of f evaluated at some point $c$ between $x$ and $x^*$:\n\n$$\n\\begin{aligned}\n  R_n(x)&=f(x)- (f(x^*) + \\frac{f'(x^*)}{1!}(x-x^*) + \\frac{f''(x^*)}{2!}(x-a)^2 + ... + \\frac{f^{(n)}(x^*)}{n!}(x-x^*)^n)\\\\\n  R_n(x)&= \\frac{f^{(n+1)}(c)}{(n+1)!}(x-x^*)^{n+1}\n\\end{aligned}\n$$\n\nIn the given expression, $x^*+\\theta(x-x^*)$ is the value of $c$ that lies between $x$ and $x^*$, where $\\theta$ is a scalar value between $0$ and $1$. In other words, $c$ is an internally dividing point, $i$  that divides the segment $\\overline{xx^*}$ in the ratio $\\overline{x^*i}:\\overline{ix}=\\theta:(1-\\theta)$ because $x^*+\\theta(x-x^*)=x^*(1-\\theta)+\\theta x$ .Therefore, $x^*+\\theta(x-x^*)$ of the remainder term in the expression is somewhere between $x and x^*$:\n\n$$\n\\frac{f^{(n)}(x^*+\\theta(x-x^*))}{(n)!}(x-x^*)^{n}\n$$\n\n\n### Example\n\n$f(x)=x^3-3x^2+4$\n\n::: {#dcfa6948 .cell execution_count=2}\n``` {.python .cell-code}\ndef f(x):\n    return x**3-3*x**2+4\ndef df(x):\n    return 3*x**2-6*x\ndef d2f(x):\n    return 6*x-6\ndef d3f(n):\n    return np.repeat(6,n)\n\n\n\n# Define the Taylor series expansion up to the 3rd order\ndef taylor(x):\n    return f(0) + df(0)*x + d2f(0)*(x**2)/2 + d3f(len(x))*(x**3)/6 \n\n# Create a range of x values\nx = np.linspace(-np.pi, np.pi, 100)\n\n# Calculate the function and its approximation using the Taylor series expansion\ny = f(x)\ny2 = df(x)\ny3 = d2f(x)\ny_approx = taylor(x)\n\n# Plot the function and its approximation\n\nplt.plot(x, y, '--',lw=5, label=r'$f(x)=x^3-3x^2+4$')\nplt.plot(x, df(x), label=r'$f(x)=3x^2-6x$')\nplt.plot(x, d2f(x), label=r'$f(x)=6x-6$')\nplt.plot(x, d3f(len(x)), label=r'$f(x)=6$')\nplt.plot(x, y_approx, label='Taylor Approximation')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](taylor_series_files/figure-html/cell-3-output-1.png){}\n:::\n:::\n\n\nIf $f(x)=x^3-3x^2+4$, then $\\frac{df(x)}{dx}=3x^2-6x$, $\\frac{d^2f(x)}{dx^2}=6x-6$, $\\frac{d^3f(x)}{dx^3}=6$, $\\frac{d^nf(x)}{dx^n}=0, n\\ge 4$. \n\nFor $x\\ne x^*$,\n\n$$\n\\begin{aligned}\n  f(x)&=f(x^*)+f'(x^*)(x-x^*)+\\frac{f^{(2)}(x^*)^2}{2!}(x-x^*)^2+\\frac{f^{(3)}(x^*+\\theta(x-x^*))^3}{3!}(x-x^*)^3\\\\\n  f(x)&=f(x^*)+(3x^2-6x)(x-x^*)+\\frac{(6x-6)}{2!}(x-x^*)^2+\\frac{6}{3!}(x-x^*)^3\\\\\n  f(x)&=f(0)+(3x^2-6x)(x)+\\frac{(6x-6)}{2!}(x)^2+\\frac{6}{3!}(x)^3 \\text{ } (x^*=0)\\\\\n  f(x)&=x^3-3x^2+4\n\\end{aligned}     \n$$\n\nIf f is differentated 3 times, f is expressed with $\\theta$. But, if differentiated more than 4 times, the $\\theta$ disappears.\n\n### Second Derivative Test\n\nThe second derivative test is a method used to determine whether a critical point of a function is a local maximum, local minimum, or a saddle point. The test uses the sign of the second derivative of the function at the critical point to determine its nature. In other words, the second derivative test uses the sign of the second derivative to determine the concavity of the function at a critical point, which in turn determines whether the critical point is a local maximum, local minimum, or a saddle point.\n\n::: {#def-2nd_derivative}\n\nLet $f$ be a function with a critical point at $x^*$. If $f$ is twice differentiable at $x^*$, then:\n\n* If $f''(x^*) > 0$, then $f$ has a local minimum at $x^*$.\n* If $f''(x^*) < 0$, then $f$ has a local maximum at $x^*$.\n* If $f''(x^*) = 0$ and there exist values of $x$ close to $x^*$ such that $f''(x) < 0$ and $f''(x) > 0$, then $f$ has a saddle point at $x^*$.\n* If $f''(x^*) = 0$ and there do not exist values of $x$ close to $x^*$ such that $f''(x) < 0$ and $f''(x) > 0$, then the test is inconclusive and we may need to use other methods to determine the nature of the critical point.\n\n:::\n\nThe second derivative test is a method used to determine the nature of a critical point of a function by examining the concavity of the function at that point.\n\nIf the second derivative of the function is positive at a critical point, then the function is concave up at that point, and the critical point is a local minimum. If the second derivative is negative, then the function is concave down, and the critical point is a local maximum. If the second derivative is zero, the test is inconclusive, and the other methods should be tried to determine the nature of the critical point. If there exist values of $x$ close to $x^*$ such that $f''(x) < 0$ and $f''(x) > 0$, then $f$ has a saddle point at $x^*$ (see @fig-saddle). \n\n\n::: {.callout-tip}\n\n## What Is a Saddle Point? \n\nA saddle point is a type of critical point of a function where the first-order partial derivatives of the function are zero, but the behavior of the function around the point is neither a local maximum nor a local minimum. Instead, the behavior is like a saddle shape, hence the name \"saddle point\" (see @fig-saddle).\n\nAt a saddle point, the function changes concavity in different directions, meaning that the function is concave up in some directions and concave down in other directions. In other words, the Hessian matrix of the function (the matrix of second-order partial derivatives) evaluated at the saddle point has both positive and negative eigenvalues, indicating that the curvature of the function changes in different directions.\n\nSaddle points are important in optimization and machine learning because they can cause difficulties in finding the global minimum of a function. At a saddle point, gradient-based optimization algorithms can get stuck because the gradient is zero but the curvature of the function prevents the algorithm from moving in a direction that decreases the function value. This can result in slow convergence or even convergence to a suboptimal solution.\n\n:::\n\n![Saddle Point Example](./saddle_point.PNG){width=100, #fig-saddle}\n\n[Sourced from Wiki By Nicoguaro - Own work, CC BY 3.0](https://commons.wikimedia.org/w/index.php?curid=20570051)\n\nThus, for the problem of finding the maximum and minimum, it is usually sufficient for $f$ to be differentiable twice in a taylor series. \n\n\n\n\n$$\n\\begin{aligned}\n    f(x)&=f(x^*)+f'(x^*)(x-x^*)+\\frac{f^{(2)}(x^*+\\theta(x-x^*))}{2!}(x-x^*)^{2} ,\\text{ } 0<\\theta<1\n\\end{aligned}\n$$ {#eq-second_derivative}\n\nIt is the case that $f'(x^*)=0$ to find $x^*$ that makes the extrema (minimum or maximum) of $f$. So, we can set $f'(x^*)$ in @eq-second_derivative as $0$. Then,\n\n$$\n\\begin{aligned}\n    f(x)&=f(x^*)+\\frac{f^{(2)}(x^*+\\theta(x-x^*))}{2!}(x-x^*)^{2} ,\\text{ } 0<\\theta<1\n\\end{aligned}\n$$ {#eq-second_derivative2}\n\nIn @eq-second_derivative2, we can make a certain conclusion on the second derivative test depending on the sign of the variable (not a constant because of $\\theta$), $f^{(2)}(x^*+\\theta(x-x^*))$ because $(x-x^*)^{2}>0$:\n\n* If $f'(x^*)=0$, $x \\in [a,b]$, and $f''(x)>0$, then $f(x)=f(x^*)+d, \\text{ } (d>0)$  \n$\\therefore f(x)>f(x^*)$, which means that $f(x)$ has a minimum at $x^*$.\n* If $f'(x^*)=0$, $x \\in [a,b]$, and $f''(x)<0$, then $f(x)=f(x^*)-d, \\text{ } (d>0)$   \n$\\therefore f(x)<f(x^*)$, which means that $f(x)$ has a maximum at $x^*$.\n\n\n#### Example\n\nIf $f(x)=e^{x^2}, f'(x)=2xe^{x^2}, \\text{ and } f^{''}(x)=(2+4x^2)e^{x^2}$, the case $f'(x^*)=0$ is when $x^*=0$. Since $f^{''}(x)>0$ for all $x \\in \\mathbb{R}$, $f(0)=1$ is a minimum at $x^*$.\n\n$f(x)=e^{x^2}$\n\n::: {#27f55a19 .cell execution_count=3}\n``` {.python .cell-code}\ndef f(x):\n    return np.exp(x**2)\ndef df(x):\n    return 2*x*np.exp(x**2)\ndef d2f(x):\n    return (2+4*x**2)*np.exp(x**2)\n\n# Create a range of x values\nx = np.linspace(-1, 1, 100)\n\n# Calculate the function and its approximation using the Taylor series expansion\ny = f(x)\ny2 = df(x)\ny3 = d2f(x)\ny_approx = taylor(x)\n\n# Plot the function and its approximation\n\nplt.plot(x, y, label=r\"$f(x)=e^{x^2}$\")\nplt.plot(x, df(x), label=r\"$f'(x)=2xe^{x^2}$\")\nplt.plot(x, d2f(x), label=r\"$f^{''}(x)=(2+4x^2)e^{x^2}$\")\nplt.axhline(y=0, color='gray')\nplt.axvline(x=0, color='gray')\n\nplt.plot(x, y_approx, label='Taylor Approximation')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](taylor_series_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\n:::\n</div>\n\n<div class=\"tab-pane fade\" id=\"English\" role=\"tabpanel\" aria-labelledby=\"English-tab\">\n\n::: {#English .tab-pane .fade role=\"tabpanel\" aria-labelledby=\"English-tab\"}\n\n:::\n\n\n</div>\n\n",
    "supporting": [
      "taylor_series_files"
    ],
    "filters": [],
    "includes": {}
  }
}