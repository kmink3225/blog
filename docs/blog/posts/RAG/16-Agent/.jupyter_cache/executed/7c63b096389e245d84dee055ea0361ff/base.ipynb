{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5512c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\RAG\\16-Agent':\n",
    "  os.chdir(r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\RAG\\16-Agent')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af09f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97312244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH15-Debate-Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa0c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "    ) -> None:\n",
    "        # 에이전트의 이름을 설정합니다.\n",
    "        self.name = name\n",
    "        # 시스템 메시지를 설정합니다.\n",
    "        self.system_message = system_message\n",
    "        # LLM 모델을 설정합니다.\n",
    "        self.model = model\n",
    "        # 에이전트 이름을 지정합니다.\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        # 에이전트를 초기화합니다.\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        대화 내역을 초기화합니다.\n",
    "        \"\"\"\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        메시지에 시스템 메시지 + 대화내용과 마지막으로 에이전트의 이름을 추가합니다.\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join([self.prefix] + self.message_history)),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "\n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        name 이 말한 message 를 메시지 내역에 추가합니다.\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "790c686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        # 에이전트 목록을 설정합니다.\n",
    "        self.agents = agents\n",
    "        # 시뮬레이션 단계를 초기화합니다.\n",
    "        self._step = 0\n",
    "        # 다음 발언자를 선택하는 함수를 설정합니다.\n",
    "        self.select_next_speaker = selection_function\n",
    "\n",
    "    def reset(self):\n",
    "        # 모든 에이전트를 초기화합니다.\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        name 의 message 로 대화를 시작합니다.\n",
    "        \"\"\"\n",
    "        # 모든 에이전트가 메시지를 받습니다.\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # 시뮬레이션 단계를 증가시킵니다.\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. 다음 발언자를 선택합니다.\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. 다음 발언자에게 메시지를 전송합니다.\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. 모든 에이전트가 메시지를 받습니다.\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. 시뮬레이션 단계를 증가시킵니다.\n",
    "        self._step += 1\n",
    "\n",
    "        # 발언자의 이름과 메시지를 반환합니다.\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d8e0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "\n",
    "class DialogueAgentWithTools(DialogueAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatOpenAI,\n",
    "        tools,\n",
    "    ) -> None:\n",
    "        # 부모 클래스의 생성자를 호출합니다.\n",
    "        super().__init__(name, system_message, model)\n",
    "        # 주어진 도구 이름과 인자를 사용하여 도구를 로드합니다.\n",
    "        self.tools = tools\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        메시지 기록에 챗 모델을 적용하고 메시지 문자열을 반환합니다.\n",
    "        \"\"\"\n",
    "        prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "        agent = create_openai_tools_agent(self.model, self.tools, prompt)\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=self.tools, verbose=False)\n",
    "        # AI 메시지를 생성합니다.\n",
    "        message = AIMessage(\n",
    "            content=agent_executor.invoke(\n",
    "                {\n",
    "                    \"input\": \"\\n\".join(\n",
    "                        [self.system_message.content]\n",
    "                        + [self.prefix]\n",
    "                        + self.message_history\n",
    "                    )\n",
    "                }\n",
    "            )[\"output\"]\n",
    "        )\n",
    "\n",
    "        # 생성된 메시지의 내용을 반환합니다.\n",
    "        return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6b0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader1 = TextLoader(\"data/의대증원반대.txt\")\n",
    "loader2 = TextLoader(\"data/의대증원찬성.txt\")\n",
    "\n",
    "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# 문서를 로드하고 분할합니다.\n",
    "docs1 = loader1.load_and_split(text_splitter)\n",
    "docs2 = loader2.load_and_split(text_splitter)\n",
    "\n",
    "# VectorStore를 생성합니다.\n",
    "vector1 = FAISS.from_documents(docs1, OpenAIEmbeddings())\n",
    "vector2 = FAISS.from_documents(docs2, OpenAIEmbeddings())\n",
    "\n",
    "# Retriever를 생성합니다.\n",
    "doctor_retriever = vector1.as_retriever(search_kwargs={\"k\": 5})\n",
    "gov_retriever = vector2.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "858d2e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성하는 함수를 가져옵니다.\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "doctor_retriever_tool = create_retriever_tool(\n",
    "    doctor_retriever,\n",
    "    name=\"document_search\",\n",
    "    description=\"This is a document about the Korean Medical Association's opposition to the expansion of university medical schools. \"\n",
    "    \"Refer to this document when you want to present a rebuttal to the proponents of medical school expansion.\",\n",
    ")\n",
    "\n",
    "gov_retriever_tool = create_retriever_tool(\n",
    "    gov_retriever,\n",
    "    name=\"document_search\",\n",
    "    description=\"This is a document about the Korean government's support for the expansion of university medical schools. \"\n",
    "    \"Refer to this document when you want to provide a rebuttal to the opposition to medical school expansion.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2623d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
    "# k=6은 검색 결과를 6개까지 가져오겠다는 의미입니다\n",
    "search = TavilySearchResults(k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e09804",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"Doctor Union(의사협회)\": [doctor_retriever_tool],  # 의사협회 에이전트 도구 목록\n",
    "    \"Government(대한민국 정부)\": [gov_retriever_tool],  # 정부 에이전트 도구 목록\n",
    "}\n",
    "\n",
    "# 토론 주제 선정\n",
    "topic = \"2024 현재, 대한민국 대학교 의대 정원 확대 충원은 필요한가?\"\n",
    "\n",
    "# 토론자를 설명하는 문구의 단어 제한\n",
    "word_limit = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe4ecc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_search = {\n",
    "    \"Doctor Union(의사협회)\": [search],  # 의사협회 에이전트 도구 목록\n",
    "    \"Government(대한민국 정부)\": [search],  # 정부 에이전트 도구 목록\n",
    "}\n",
    "# 토론 주제 선정\n",
    "topic = \"2024년 현재, 대한민국 대학교 의대 정원 확대 충원은 필요한가?\"\n",
    "word_limit = 50  # 작업 브레인스토밍을 위한 단어 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30740a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_description = f\"\"\"Here is the topic of conversation: {topic}\n",
    "The participants are: {', '.join(names.keys())}\"\"\"\n",
    "\n",
    "agent_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of the conversation participant.\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_agent_description(name):\n",
    "    agent_specifier_prompt = [\n",
    "        agent_descriptor_system_message,\n",
    "        HumanMessage(\n",
    "            content=f\"\"\"{conversation_description}\n",
    "            Please reply with a description of {name}, in {word_limit} words or less in expert tone. \n",
    "            Speak directly to {name}.\n",
    "            Give them a point of view.\n",
    "            Do not add anything else. Answer in KOREAN.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    "    # ChatOpenAI를 사용하여 에이전트 설명을 생성합니다.\n",
    "    agent_description = ChatOpenAI(temperature=0)(agent_specifier_prompt).content\n",
    "    return agent_description\n",
    "\n",
    "\n",
    "# 각 참가자의 이름에 대한 에이전트 설명을 생성합니다.\n",
    "agent_descriptions = {name: generate_agent_description(name) for name in names}\n",
    "\n",
    "# 생성한 에이전트 설명을 출력합니다.\n",
    "agent_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d191632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_descriptions = {\n",
    "    \"Doctor Union(의사협회)\": \"의사협회는 의료계의 권익을 보호하고 의사들의 이해관계를 대변하는 기관입니다. 의사들의 업무 환경과 안전을 중시하며, 환자 안전과 질 높은 의료 서비스를 제공하기 위해 노력합니다. \"\n",
    "    \"지금도 의사의 수는 충분하다는 입장이며, 의대 증원은 필수 의료나 지방 의료 활성화에 대한 실효성이 떨어집니다. 의대 증원을 감행할 경우, 의료 교육 현장의 인프라가 갑작스러운 증원을 감당하지 못할 것이란 우려를 표합니다.\",\n",
    "    \"Government(대한민국 정부)\": \"대한민국 정부는 국가의 행정을 책임지는 주체로서, 국민의 복지와 발전을 책임져야 합니다. \"\n",
    "    \"우리나라는 의사수가 절대 부족한 상황이며, 노인인구가 늘어나면서 의료 수요가 급증하고 있습니다. OECD 국가들도 최근 의사수를 늘렸습니다. 또한, 증원된 의사 인력이 필수의료와 지역 의료로 갈 수있도록 튼튼한 의료사고 안정망 구축 및 보상 체계의 공정성을 높이고자 합니다.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70cbeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_system_message(name, description, tools):\n",
    "    return f\"\"\"{conversation_description}\n",
    "    \n",
    "Your name is {name}.\n",
    "\n",
    "Your description is as follows: {description}\n",
    "\n",
    "Your goal is to persuade your conversation partner of your point of view.\n",
    "\n",
    "DO look up information with your tool to refute your partner's claims.\n",
    "DO cite your sources.\n",
    "\n",
    "DO NOT fabricate fake citations.\n",
    "DO NOT cite any source that you did not look up.\n",
    "\n",
    "DO NOT restate something that has already been said in the past.\n",
    "DO NOT add anything else.\n",
    "\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\n",
    "Answer in KOREAN.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "agent_system_messages = {\n",
    "    name: generate_system_message(name, description, tools)\n",
    "    for (name, tools), description in zip(names.items(), agent_descriptions.values())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac5945ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 시스템 메시지를 순회합니다.\n",
    "for name, system_message in agent_system_messages.items():\n",
    "    # 에이전트의 이름을 출력합니다.\n",
    "    print(name)\n",
    "    # 에이전트의 시스템 메시지를 출력합니다.\n",
    "    print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8772b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_specifier_prompt = [\n",
    "    # 주제를 더 구체적으로 만들 수 있습니다.\n",
    "    SystemMessage(content=\"You can make a topic more specific.\"),\n",
    "    HumanMessage(\n",
    "        content=f\"\"\"{topic}\n",
    "        \n",
    "        You are the moderator. \n",
    "        Please make the topic more specific.\n",
    "        Please reply with the specified quest in 100 words or less.\n",
    "        Speak directly to the participants: {*names,}.  \n",
    "        Do not add anything else.\n",
    "        Answer in Korean.\"\"\"  # 다른 것은 추가하지 마세요.\n",
    "    ),\n",
    "]\n",
    "# 구체화된 주제를 생성합니다.\n",
    "specified_topic = ChatOpenAI(temperature=1.0)(topic_specifier_prompt).content\n",
    "\n",
    "print(f\"Original topic:\\n{topic}\\n\")  # 원래 주제를 출력합니다.\n",
    "print(f\"Detailed topic:\\n{specified_topic}\\n\")  # 구체화된 주제를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd8fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 세부 주제 설정\n",
    "specified_topic = \"정부는 2025년 입시부터 의대 입학정원을 2000명 늘린다고 발표했습니다. 이에 의사단체는 전국에서 규탄집회를 열어 반발하고 있습니다. 의대 정원 확대를 둘러싼 논란 쟁점을 짚어보고, 필수 의료와 지역 의료 해법에 대해서 토론해주세요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d2adad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이는 결과가 컨텍스트 제한을 초과하는 것을 방지하기 위함입니다.\n",
    "agents = [\n",
    "    DialogueAgentWithTools(\n",
    "        name=name,\n",
    "        system_message=SystemMessage(content=system_message),\n",
    "        model=ChatOpenAI(model_name=\"gpt-4-turbo-preview\", temperature=0.2),\n",
    "        tools=tools,\n",
    "    )\n",
    "    for (name, tools), system_message in zip(\n",
    "        names.items(), agent_system_messages.values()\n",
    "    )\n",
    "]\n",
    "\n",
    "agents_with_search = [\n",
    "    DialogueAgentWithTools(\n",
    "        name=name,\n",
    "        system_message=SystemMessage(content=system_message),\n",
    "        model=ChatOpenAI(model_name=\"gpt-4-turbo-preview\", temperature=0.2),\n",
    "        tools=tools,\n",
    "    )\n",
    "    for (name, tools), system_message in zip(\n",
    "        names_search.items(), agent_system_messages.values()\n",
    "    )\n",
    "]\n",
    "\n",
    "agents.extend(agents_with_search)\n",
    "agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1095b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    # 다음 발언자를 선택합니다.\n",
    "    # step을 에이전트 수로 나눈 나머지를 인덱스로 사용하여 다음 발언자를 순환적으로 선택합니다.\n",
    "    idx = (step) % len(agents)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "346b27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 30  # 최대 반복 횟수를 6으로 설정합니다.\n",
    "n = 0  # 반복 횟수를 추적하는 변수를 0으로 초기화합니다.\n",
    "\n",
    "# DialogueSimulator 객체를 생성하고, agents와 select_next_speaker 함수를 전달합니다.\n",
    "simulator = DialogueSimulator(\n",
    "    agents=agents_with_search, selection_function=select_next_speaker\n",
    ")\n",
    "\n",
    "# 시뮬레이터를 초기 상태로 리셋합니다.\n",
    "simulator.reset()\n",
    "\n",
    "# Moderator가 지정된 주제를 제시합니다.\n",
    "simulator.inject(\"Moderator\", specified_topic)\n",
    "\n",
    "# Moderator가 제시한 주제를 출력합니다.\n",
    "print(f\"(Moderator): {specified_topic}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "while n < max_iters:  # 최대 반복 횟수까지 반복합니다.\n",
    "    name, message = (\n",
    "        simulator.step()\n",
    "    )  # 시뮬레이터의 다음 단계를 실행하고 발언자와 메시지를 받아옵니다.\n",
    "    print(f\"({name}): {message}\")  # 발언자와 메시지를 출력합니다.\n",
    "    print(\"\\n\")\n",
    "    n += 1  # 반복 횟수를 1 증가시킵니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}