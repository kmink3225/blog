{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34dd98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\RAG\\16-Agent':\n",
    "  os.chdir(r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\RAG\\16-Agent')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62945a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada2e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정한다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력한다.\n",
    "logging.langsmith(\"CH17-Multi-Agent-System\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6db0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 메모리 설정\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 모델들 정의 (각 역할에 따라 다른 모델 사용 가능)\n",
    "coordinator_model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "research_model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.3)\n",
    "analysis_model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "writer_model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7)\n",
    "reviewer_model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674d31e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search = TavilySearch(\n",
    "    topic=\"general\",\n",
    "    max_results=5,\n",
    "    include_answer=False,\n",
    ")\n",
    "\n",
    "web_search.name = \"web_search\"\n",
    "web_search.description = \"웹에서 최신 정보를 검색합니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3284e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = \"tmp\"\n",
    "file_tools = FileManagementToolkit(\n",
    "    root_dir=str(working_directory),\n",
    ").get_tools()\n",
    "\n",
    "for tool in file_tools:\n",
    "    if tool.name == \"file_write\":\n",
    "        tool.description = \"파일을 작성합니다.\"\n",
    "    elif tool.name == \"file_read\":\n",
    "        tool.description = \"파일을 읽습니다.\"\n",
    "    elif tool.name == \"list_directory\":\n",
    "        tool.description = \"디렉토리를 나열합니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff530777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "loader = PDFPlumberLoader(\"data/sample_document.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "pdf_retriever = vector.as_retriever()\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    pdf_retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"내부 문서에서 정보를 검색합니다.\",\n",
    "    document_prompt=PromptTemplate.from_template(\n",
    "        \"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff8a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "class AgentRole(str, Enum):\n",
    "    \"\"\"에이전트 역할 정의\"\"\"\n",
    "    COORDINATOR = \"coordinator\"\n",
    "    RESEARCHER = \"researcher\"\n",
    "    ANALYST = \"analyst\"\n",
    "    WRITER = \"writer\"\n",
    "    REVIEWER = \"reviewer\"\n",
    "    AGGREGATOR = \"aggregator\"\n",
    "\n",
    "class Agent(BaseModel):\n",
    "    \"\"\"에이전트 정의\"\"\"\n",
    "    name: str = Field(description=\"에이전트 이름\")\n",
    "    role: AgentRole = Field(description=\"에이전트 역할\")\n",
    "    model: Any = Field(description=\"LLM 모델\")\n",
    "    tools: List[Any] = Field(default_factory=list, description=\"사용 가능한 도구\")\n",
    "    system_prompt: str = Field(description=\"시스템 프롬프트\")\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "class AgentMessage(BaseModel):\n",
    "    \"\"\"에이전트 메시지\"\"\"\n",
    "    agent_name: str = Field(description=\"발신 에이전트\")\n",
    "    timestamp: datetime = Field(default_factory=datetime.now)\n",
    "    content: str = Field(description=\"메시지 내용\")\n",
    "    metadata: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "class MultiAgentState(BaseModel):\n",
    "    \"\"\"멀티 에이전트 시스템 상태\"\"\"\n",
    "    user_input: str = Field(description=\"사용자 입력\")\n",
    "    coordinator_plan: Optional[Dict[str, Any]] = Field(default=None, description=\"코디네이터 계획\")\n",
    "    agent_results: Dict[str, str] = Field(default_factory=dict, description=\"각 에이전트 결과\")\n",
    "    messages: List[AgentMessage] = Field(default_factory=list, description=\"에이전트 간 메시지\")\n",
    "    final_output: str = Field(default=\"\", description=\"최종 출력\")\n",
    "    \n",
    "    def add_message(self, agent_name: str, content: str, metadata: Dict = None):\n",
    "        \"\"\"메시지 추가\"\"\"\n",
    "        self.messages.append(\n",
    "            AgentMessage(\n",
    "                agent_name=agent_name,\n",
    "                content=content,\n",
    "                metadata=metadata or {}\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a441bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "coordinator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"당신은 조직의 최고 코디네이터(Coordinator)입니다.\n",
    "        \n",
    "사용자의 요청을 분석하여 어떤 에이전트들이 필요한지, 각 에이전트의 역할이 무엇인지를 결정합니다.\n",
    "\n",
    "사용 가능한 에이전트:\n",
    "- researcher: 웹 검색을 통한 정보 수집\n",
    "- analyst: 수집된 정보의 분석 및 인사이트 도출\n",
    "- writer: 분석 결과를 바탕으로 문서 작성\n",
    "- reviewer: 최종 결과물의 품질 검증\n",
    "\n",
    "다음 JSON 형식으로 응답하세요:\n",
    "```json\n",
    "{{\n",
    "    \"required_agents\": [\"researcher\", \"analyst\", \"writer\"],\n",
    "    \"task_flow\": [\n",
    "        {{\n",
    "            \"agent\": \"researcher\",\n",
    "            \"task\": \"구체적인 작업 설명\",\n",
    "            \"dependencies\": []\n",
    "        }},\n",
    "        {{\n",
    "            \"agent\": \"analyst\",\n",
    "            \"task\": \"구체적인 작업 설명\",\n",
    "            \"dependencies\": [\"researcher\"]\n",
    "        }}\n",
    "    ],\n",
    "    \"success_criteria\": \"성공 기준 설명\"\n",
    "}}\n",
    "```\"\"\",\n",
    "    ),\n",
    "    (\"human\", \"사용자 요청: {input}\"),\n",
    "])\n",
    "\n",
    "def coordinator_step(state: MultiAgentState) -> Dict[str, Any]:\n",
    "    \"\"\"코디네이터 실행\"\"\"\n",
    "    import json\n",
    "    \n",
    "    response = coordinator_model.invoke(\n",
    "        coordinator_prompt.format_prompt(input=state.user_input)\n",
    "    )\n",
    "    \n",
    "    # JSON 파싱\n",
    "    plan = json.loads(response.content)\n",
    "    state.add_message(\"coordinator\", f\"계획 수립 완료: {len(plan['required_agents'])}개 에이전트 필요\")\n",
    "    \n",
    "    return {\"coordinator_plan\": plan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c231ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"당신은 데이터 조사 전문가(Research Agent)입니다.\n",
    "\n",
    "주어진 주제에 대해 웹 검색을 통해 신뢰할 수 있는 최신 정보를 수집합니다.\n",
    "\n",
    "다음을 고려하세요:\n",
    "1. 다양한 소스에서 정보 수집\n",
    "2. 정보의 신뢰도 평가\n",
    "3. 중요한 데이터와 통계 포함\n",
    "4. 출처 명시\n",
    "\n",
    "최종 결과는 다음 형식으로 제공하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc35fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"당신은 데이터 분석 전문가(Analysis Agent)입니다.\n",
    "\n",
    "리서처가 수집한 정보를 깊이 있게 분석합니다.\n",
    "\n",
    "분석 항목:\n",
    "1. **주요 트렌드**: 현재의 주요 변화\n",
    "2. **기회 요소**: 활용 가능한 기회\n",
    "3. **위험 요소**: 주의해야 할 위험\n",
    "4. **미래 전망**: 향후 발전 방향\n",
    "5. **통계 분석**: 수집된 데이터의 정량적 분석\n",
    "\n",
    "최종 분석은 다음 형식으로 제공하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99be24e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"당신은 전문 작가(Writer Agent)입니다.\n",
    "\n",
    "분석된 정보를 바탕으로 높은 품질의 보고서를 작성합니다.\n",
    "\n",
    "작성 지침:\n",
    "1. **명확성**: 쉽고 명확한 표현\n",
    "2. **구조화**: 논리적인 흐름\n",
    "3. **시각화**: 테이블, 리스트 활용\n",
    "4. **설득력**: 데이터 기반의 주장\n",
    "5. **전문성**: 산업 용어 적절한 사용\n",
    "\n",
    "최종 보고서는 다음 구조를 따르세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa20087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"당신은 품질 검토 전문가(Review Agent)입니다.\n",
    "\n",
    "최종 결과물의 품질을 검증합니다.\n",
    "\n",
    "검증 항목:\n",
    "1. **정확성**: 사실에 기반했는가\n",
    "2. **완성도**: 모든 필요한 요소를 포함했는가\n",
    "3. **일관성**: 논리적 오류는 없는가\n",
    "4. **가독성**: 읽기 쉬운가\n",
    "5. **전문성**: 전문적인 수준인가\n",
    "\n",
    "평가 결과를 다음 형식으로 제공하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4165897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "\n",
    "class MultiAgentGraph:\n",
    "    \"\"\"멀티 에이전트 시스템 그래프\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.state = None\n",
    "        \n",
    "    def coordinator_node(self, state: MultiAgentState) -> Dict[str, Any]:\n",
    "        \"\"\"코디네이터 노드\"\"\"\n",
    "        plan = coordinator_step(state)\n",
    "        return {\"coordinator_plan\": plan}\n",
    "    \n",
    "    def researcher_node(self, state: MultiAgentState) -> Dict[str, str]:\n",
    "        \"\"\"리서처 노드\"\"\"\n",
    "        if not state.coordinator_plan or \"researcher\" not in state.coordinator_plan.get(\"required_agents\", []):\n",
    "            return {\"agent_results\": state.agent_results}\n",
    "        \n",
    "        # 리서처 태스크 찾기\n",
    "        task = next(\n",
    "            (t for t in state.coordinator_plan[\"task_flow\"] if t[\"agent\"] == \"researcher\"),\n",
    "            None\n",
    "        )\n",
    "        \n",
    "        if task:\n",
    "            result = researcher_step(state, task[\"task\"])\n",
    "            state.agent_results[\"researcher\"] = result\n",
    "        \n",
    "        return {\"agent_results\": state.agent_results}\n",
    "    \n",
    "    def analyst_node(self, state: MultiAgentState) -> Dict[str, str]:\n",
    "        \"\"\"분석가 노드\"\"\"\n",
    "        if \"researcher\" not in state.agent_results:\n",
    "            return {\"agent_results\": state.agent_results}\n",
    "        \n",
    "        result = analyst_step(state, state.agent_results[\"researcher\"])\n",
    "        state.agent_results[\"analyst\"] = result\n",
    "        \n",
    "        return {\"agent_results\": state.agent_results}\n",
    "    \n",
    "    def writer_node(self, state: MultiAgentState) -> Dict[str, str]:\n",
    "        \"\"\"작가 노드\"\"\"\n",
    "        if \"analyst\" not in state.agent_results:\n",
    "            return {\"agent_results\": state.agent_results}\n",
    "        \n",
    "        result = writer_step(state, state.agent_results[\"analyst\"])\n",
    "        state.agent_results[\"writer\"] = result\n",
    "        \n",
    "        return {\"agent_results\": state.agent_results}\n",
    "    \n",
    "    def reviewer_node(self, state: MultiAgentState) -> Dict[str, str]:\n",
    "        \"\"\"검토자 노드\"\"\"\n",
    "        if \"writer\" not in state.agent_results:\n",
    "            return {\"agent_results\": state.agent_results}\n",
    "        \n",
    "        result = reviewer_step(state, state.agent_results[\"writer\"])\n",
    "        state.agent_results[\"reviewer\"] = result\n",
    "        \n",
    "        return {\"agent_results\": state.agent_results}\n",
    "    \n",
    "    def aggregator_node(self, state: MultiAgentState) -> Dict[str, str]:\n",
    "        \"\"\"집계 노드\"\"\"\n",
    "        # 최종 결과 통합\n",
    "        final_output = f\"\"\"\n",
    "# 최종 보고서\n",
    "\n",
    "## 프로세스 요약\n",
    "- **조직**: {len(state.messages)}개의 에이전트 협력\n",
    "- **단계**: Coordinator → Researcher → Analyst → Writer → Reviewer\n",
    "\n",
    "## 최종 결과\n",
    "\n",
    "{state.agent_results.get('writer', '결과 없음')}\n",
    "\n",
    "## 검토 의견\n",
    "\n",
    "{state.agent_results.get('reviewer', '검토 없음')}\n",
    "\"\"\"\n",
    "        return {\"final_output\": final_output}\n",
    "    \n",
    "    def build_graph(self):\n",
    "        \"\"\"그래프 구성\"\"\"\n",
    "        workflow = StateGraph(MultiAgentState)\n",
    "        \n",
    "        # 노드 추가\n",
    "        workflow.add_node(\"coordinator\", self.coordinator_node)\n",
    "        workflow.add_node(\"researcher\", self.researcher_node)\n",
    "        workflow.add_node(\"analyst\", self.analyst_node)\n",
    "        workflow.add_node(\"writer\", self.writer_node)\n",
    "        workflow.add_node(\"reviewer\", self.reviewer_node)\n",
    "        workflow.add_node(\"aggregator\", self.aggregator_node)\n",
    "        \n",
    "        # 엣지 구성\n",
    "        workflow.add_edge(START, \"coordinator\")\n",
    "        workflow.add_edge(\"coordinator\", \"researcher\")\n",
    "        workflow.add_edge(\"researcher\", \"analyst\")\n",
    "        workflow.add_edge(\"analyst\", \"writer\")\n",
    "        workflow.add_edge(\"writer\", \"reviewer\")\n",
    "        workflow.add_edge(\"reviewer\", \"aggregator\")\n",
    "        workflow.add_edge(\"aggregator\", END)\n",
    "        \n",
    "        return workflow.compile(checkpointer=memory)\n",
    "\n",
    "# 그래프 생성\n",
    "multi_agent_graph = MultiAgentGraph()\n",
    "multi_agent_system = multi_agent_graph.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78c7a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_agent_system(user_input: str, thread_id: str = \"main\") -> str:\n",
    "    \"\"\"멀티 에이전트 시스템 실행\"\"\"\n",
    "    from langchain_teddynote.messages import stream_graph\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    inputs = {\"user_input\": user_input}\n",
    "    \n",
    "    result = multi_agent_system.invoke(inputs, config)\n",
    "    \n",
    "    return result[\"final_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "162c57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "2024년 AI 기술 트렌드에 대한 전문 보고서를 작성해주세요.\n",
    "\n",
    "보고서는 다음을 포함해야 합니다:\n",
    "1. 현재의 주요 AI 기술 트렌드\n",
    "2. 각 기술의 시장 영향도 분석\n",
    "3. 기업에 미치는 영향\n",
    "4. 향후 6개월 전망\n",
    "\n",
    "최종 보고서는 마크다운 형식으로, \n",
    "표, 핵심 포인트 정리 등을 포함해주세요.\n",
    "\"\"\"\n",
    "\n",
    "output = run_multi_agent_system(user_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21016c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "우리 회사의 주요 경쟁사 3곳에 대한 심층 분석 보고서와 \n",
    "대응 전략을 수립해주세요.\n",
    "\n",
    "분석 범위:\n",
    "1. 경쟁사별 시장 점유율 및 최신 동향\n",
    "2. 제품/서비스 비교 분석\n",
    "3. 강점 및 약점 평가\n",
    "4. 우리 회사의 차별화 전략\n",
    "\n",
    "최종 결과물:\n",
    "- 경쟁사 분석 보고서 (competitor_analysis.md)\n",
    "- 대응 전략 가이드 (strategy_guide.md)\n",
    "\"\"\"\n",
    "\n",
    "output = run_multi_agent_system(user_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c616fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "신시장 진출의 타당성을 검토하는 종합 보고서를 작성해주세요.\n",
    "\n",
    "검토 대상: [구체적인 시장/지역/제품]\n",
    "\n",
    "포함 항목:\n",
    "1. 시장 규모 및 성장률 조사\n",
    "2. 경쟁 환경 분석\n",
    "3. 규제 및 정책 환경\n",
    "4. 진출 시 기회 및 위험\n",
    "5. 예상 수익성 분석\n",
    "6. 최종 권장사항\n",
    "\n",
    "최종 결과는 경영진 보고 형식으로 작성해주세요.\n",
    "\"\"\"\n",
    "\n",
    "output = run_multi_agent_system(user_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "240a7781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def parallel_agent_execution(tasks: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"여러 에이전트 병렬 실행\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = {}\n",
    "        \n",
    "        # 리서처 병렬 실행 (여러 주제)\n",
    "        for topic, instruction in tasks.items():\n",
    "            future = executor.submit(researcher_step, instruction)\n",
    "            futures[topic] = future\n",
    "        \n",
    "        # 결과 수집\n",
    "        for topic, future in futures.items():\n",
    "            results[topic] = future.result()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 사용 예시\n",
    "parallel_tasks = {\n",
    "    \"AI trends\": \"AI 기술 트렌드 조사\",\n",
    "    \"Market data\": \"시장 데이터 조사\",\n",
    "    \"Competitor info\": \"경쟁사 정보 조사\"\n",
    "}\n",
    "\n",
    "results = parallel_agent_execution(parallel_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc0adc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_agent_routing(state: MultiAgentState) -> str:\n",
    "    \"\"\"조건부 에이전트 라우팅\"\"\"\n",
    "    \n",
    "    # 사용자 입력의 복잡도에 따라 결정\n",
    "    if len(state.user_input.split()) > 100:\n",
    "        # 복잡한 요청: 전체 파이프라인 실행\n",
    "        return \"full_pipeline\"\n",
    "    \n",
    "    elif \"분석\" in state.user_input:\n",
    "        # 분석만 필요\n",
    "        return \"analyst_only\"\n",
    "    \n",
    "    elif \"최신 정보\" in state.user_input:\n",
    "        # 리서치만 필요\n",
    "        return \"researcher_only\"\n",
    "    \n",
    "    else:\n",
    "        # 기본 파이프라인\n",
    "        return \"default_pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df8c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_loop(\n",
    "    initial_result: str,\n",
    "    feedback_provider: str\n",
    ") -> str:\n",
    "    \"\"\"피드백 루프\"\"\"\n",
    "    \n",
    "    feedback = reviewer_agent.invoke({\n",
    "        \"messages\": [\n",
    "            (\"human\", f\"다음 결과를 검토하고 개선 사항을 제시하세요:\\n{initial_result}\")\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # 개선된 버전 생성\n",
    "    improved_result = writer_agent.invoke({\n",
    "        \"messages\": [\n",
    "            (\"human\", f\"다음 피드백을 바탕으로 문서를 개선하세요:\\n{feedback['messages'][-1].content}\")\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return improved_result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f11b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def cached_research(topic: str) -> str:\n",
    "    \"\"\"연구 결과 캐싱\"\"\"\n",
    "    return researcher_step(None, topic)\n",
    "\n",
    "# 사용\n",
    "result1 = cached_research(\"AI trends\")\n",
    "result2 = cached_research(\"AI trends\")  # 캐시에서 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e303342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_token_usage(result: str, max_tokens: int = 1500) -> str:\n",
    "    \"\"\"토큰 사용량 최적화\"\"\"\n",
    "    \n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_tokens,\n",
    "        chunk_overlap=0\n",
    "    )\n",
    "    \n",
    "    chunks = splitter.split_text(result)\n",
    "    return chunks[0]  # 가장 관련성 높은 청크만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a436a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_optimized_model_selection(task_complexity: str) -> ChatOpenAI:\n",
    "    \"\"\"작업 복잡도에 따른 모델 선택\"\"\"\n",
    "    \n",
    "    if task_complexity == \"simple\":\n",
    "        return ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "    \n",
    "    elif task_complexity == \"medium\":\n",
    "        return ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "    \n",
    "    else:  # complex\n",
    "        return ChatOpenAI(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72e3e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_agent_failure(failed_agent: str, state: MultiAgentState) -> str:\n",
    "    \"\"\"에이전트 실패 시 대응\"\"\"\n",
    "    \n",
    "    if failed_agent == \"researcher\":\n",
    "        # 대체: PDF 문서에서 정보 검색\n",
    "        return pdf_retriever.invoke(state.user_input)\n",
    "    \n",
    "    elif failed_agent == \"analyst\":\n",
    "        # 대체: 원본 데이터 직접 사용\n",
    "        return state.agent_results.get(\"researcher\", \"\")\n",
    "    \n",
    "    elif failed_agent == \"writer\":\n",
    "        # 대체: 간단한 텍스트 형식으로 작성\n",
    "        return f\"## 분석 결과\\n{state.agent_results['analyst']}\"\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f\"Unknown agent: {failed_agent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "771ed317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_exponential(multiplier=1, min=2, max=10)\n",
    ")\n",
    "def resilient_agent_call(agent_func, *args, **kwargs):\n",
    "    \"\"\"재시도 가능한 에이전트 호출\"\"\"\n",
    "    return agent_func(*args, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}