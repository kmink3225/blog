---
title: "GPT4All"
subtitle: 언어 모델
description: |
  다양한 LLM 제공자와 모델 활용법을 다룬다.
categories:
  - AI
  - RAG
  - LangChain
author: Kwangmin Kim
date: 02/10/2025
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
execute:
    eval: false
---


![](./images/gpt4all.png)

[GitHub:nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all) 은 코드, 채팅 형식의 대화를 포함한 방대한 양의 데이터로 학습된 오픈 소스 챗봇 생태계입니다.

이 예제에서는 LangChain을 사용하여 `GPT4All` 모델과 상호 작용하는 방법에 대해 설명합니다.


## 설치방법

1. 먼저, 공식 홈페이지에 접속하여 설치파일을 다운로드 받아 설치합니다
2. [공식 홈페이지](https://gpt4all.io/index.html) 바로가기
3. 파이썬 패키지를 설치합니다.
4. [pip 를 활용한 설치 방법](https://github.com/nomic-ai/gpt4all/blob/main/gpt4all-bindings/python/README.md)

```{python}
# !pip install -qU gpt4all
```

## 모델 다운로드

![](./images/gpt4all_models.png)

[gpt4all 페이지](https://gpt4all.io/index.html)에는 `Model Explorer` 섹션이 있습니다.
(더 많은 정보를 원하시면 https://github.com/nomic-ai/gpt4all 을 방문하세요.)

1. [공식 홈페이지](https://gpt4all.io/index.html) 에서 다운로드 가능한 모델을 다운로드 받습니다. 본인의 PC 사양에서 구동가능한 모델을 선택하는 것이 좋습니다.
2. 본 튜토리얼에서는 `EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf`(10.69GB) 모델을 다운로드 받아 진행하겠습니다.
3. 다운로드 받은 모델은 `models` 폴더 생성 후 해당 폴더에 다운로드 받습니다.

- `local_path` 변수에 로컬 파일 경로(`"./models/EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf"`)를 할당합니다.
- 이 경로는 사용자가 원하는 로컬 파일 경로로 대체할 수 있습니다.

```{python}
local_path = "./models/EEVE-Korean-Instruct-10.8B-v1.0-Q8_0.gguf"  # 원하는 로컬 파일 경로로 대체하세요.
```

## 모델 정보 설정

로컬에서 실행하려면 호환되는 ggml 형식의 모델을 다운로드하세요.

- 관심 있는 모델을 선택하세요.
- UI를 사용하여 다운로드하고 `.bin` 파일을 `local_path`(아래 참고)로 이동시키세요.

### GPT4ALL 모델 활용

`GPT4All`은 GPT-3와 유사한 대규모 언어 모델로, 다양한 자연어 처리 작업에 활용될 수 있습니다.

이 모듈을 사용하면 GPT4All 모델을 간편하게 로드하고 추론에 활용할 수 있습니다.

```{python}
from langchain.prompts import ChatPromptTemplate
from langchain_community.llms import GPT4All
from langchain_core.output_parsers import StrOutputParser
from langchain_core.callbacks import StreamingStdOutCallbackHandler

# 프롬프트
prompt = ChatPromptTemplate.from_template(
    """<s>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>
<s>Human: {question}</s>
<s>Assistant:
"""
)

# GPT4All 언어 모델 초기화
# model는 GPT4All 모델 파일의 경로를 지정
llm = GPT4All(
    model=local_path,
    backend="gpu",  # GPU 설정
    streaming=True,  # 스트리밍 설정
    callbacks=[StreamingStdOutCallbackHandler()],  # 콜백 설정
)

# 체인 생성
chain = prompt | llm | StrOutputParser()

# 질의 실행
response = chain.invoke({"question": "대한민국의 수도는 어디인가요?"})
```

