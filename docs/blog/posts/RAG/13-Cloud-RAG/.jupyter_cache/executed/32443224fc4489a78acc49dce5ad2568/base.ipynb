{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7fceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\RAG\\13-Cloud-RAG':\n",
    "  os.chdir(r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\RAG\\13-Cloud-RAG')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fd512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 클라이언트 생성\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "    credential=AzureKeyCredential(os.getenv(\"AZURE_SEARCH_API_KEY\"))\n",
    ")\n",
    "\n",
    "# 인덱스 스키마 정의\n",
    "fields = [\n",
    "    SearchField(\n",
    "        name=\"id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,  # 기본 키\n",
    "        filterable=True\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,  # 전체 텍스트 검색 가능\n",
    "        filterable=False\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"content_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        vector_search_dimensions=1536,  # text-embedding-3-small\n",
    "        vector_search_profile_name=\"vector-profile\"\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"metadata\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=False,\n",
    "        filterable=True\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"source\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=False,\n",
    "        filterable=True,\n",
    "        facetable=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# 벡터 검색 설정\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"hnsw-config\",\n",
    "            parameters={\n",
    "                \"m\": 4,  # 그래프 연결 수\n",
    "                \"efConstruction\": 400,  # 인덱스 구축 품질\n",
    "                \"efSearch\": 500,  # 검색 정확도\n",
    "                \"metric\": \"cosine\"  # 유사도 측정 방식\n",
    "            }\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"vector-profile\",\n",
    "            algorithm_configuration_name=\"hnsw-config\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 시맨틱 검색 설정 (선택 사항)\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=None,\n",
    "        content_fields=[SemanticField(field_name=\"content\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "semantic_search = SemanticSearch(\n",
    "    configurations=[semantic_config]\n",
    ")\n",
    "\n",
    "# 인덱스 생성\n",
    "index = SearchIndex(\n",
    "    name=os.getenv(\"AZURE_SEARCH_INDEX_NAME\"),\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search\n",
    ")\n",
    "\n",
    "# 인덱스 업로드\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f\"인덱스 생성 완료: {result.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1506211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Embeddings 클라이언트\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Search 클라이언트\n",
    "search_client = SearchClient(\n",
    "    endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "    index_name=os.getenv(\"AZURE_SEARCH_INDEX_NAME\"),\n",
    "    credential=AzureKeyCredential(os.getenv(\"AZURE_SEARCH_API_KEY\"))\n",
    ")\n",
    "\n",
    "# 문서 준비\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"content\": \"Azure AI Search는 Microsoft의 관리형 검색 서비스다.\",\n",
    "        \"source\": \"doc1.txt\",\n",
    "        \"metadata\": \"Azure\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"2\",\n",
    "        \"content\": \"RAG는 검색 증강 생성 기술이다.\",\n",
    "        \"source\": \"doc2.txt\",\n",
    "        \"metadata\": \"RAG\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"3\",\n",
    "        \"content\": \"임베딩은 텍스트를 벡터로 변환한다.\",\n",
    "        \"source\": \"doc3.txt\",\n",
    "        \"metadata\": \"Embeddings\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 임베딩 생성 및 문서 업로드\n",
    "for doc in documents:\n",
    "    # 임베딩 생성\n",
    "    doc[\"content_vector\"] = embeddings.embed_query(doc[\"content\"])\n",
    "\n",
    "# 배치 업로드\n",
    "result = search_client.upload_documents(documents=documents)\n",
    "print(f\"업로드 완료: {len(result)}개 문서\")\n",
    "\n",
    "# 각 문서 결과 확인\n",
    "for item in result:\n",
    "    print(f\"문서 ID {item.key}: {item.succeeded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0af40db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "# Azure Search VectorStore 초기화\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_SEARCH_API_KEY\"),\n",
    "    index_name=os.getenv(\"AZURE_SEARCH_INDEX_NAME\"),\n",
    "    embedding_function=embeddings.embed_query\n",
    ")\n",
    "\n",
    "# 문서 추가 (자동 임베딩)\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"LangChain은 LLM 애플리케이션 프레임워크다.\",\n",
    "        metadata={\"source\": \"langchain.txt\", \"category\": \"framework\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Azure OpenAI는 엔터프라이즈급 LLM 서비스다.\",\n",
    "        metadata={\"source\": \"azure_openai.txt\", \"category\": \"llm\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# 자동으로 임베딩 생성 및 업로드\n",
    "vector_store.add_documents(docs)\n",
    "print(f\"{len(docs)}개 문서 추가 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dced8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검색\n",
    "query = \"LLM 프레임워크는 무엇인가?\"\n",
    "results = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"검색 결과 ({len(results)}개):\\n\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "    print(f\"   메타데이터: {doc.metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9700ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 점수 포함 검색\n",
    "results_with_scores = vector_store.similarity_search_with_relevance_scores(\n",
    "    query=\"Azure 검색 서비스\",\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(\"유사도 점수:\\n\")\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"점수: {score:.4f}\")\n",
    "    print(f\"내용: {doc.page_content}\")\n",
    "    print(f\"출처: {doc.metadata.get('source', 'N/A')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940c6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# 검색 클라이언트\n",
    "search_client = SearchClient(\n",
    "    endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "    index_name=os.getenv(\"AZURE_SEARCH_INDEX_NAME\"),\n",
    "    credential=AzureKeyCredential(os.getenv(\"AZURE_SEARCH_API_KEY\"))\n",
    ")\n",
    "\n",
    "# 쿼리\n",
    "query_text = \"Azure 검색 서비스\"\n",
    "query_vector = embeddings.embed_query(query_text)\n",
    "\n",
    "# 벡터 쿼리 정의\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=query_vector,\n",
    "    k_nearest_neighbors=50,  # 벡터 검색 결과 수\n",
    "    fields=\"content_vector\"\n",
    ")\n",
    "\n",
    "# 하이브리드 검색 실행\n",
    "results = search_client.search(\n",
    "    search_text=query_text,  # 키워드 검색\n",
    "    vector_queries=[vector_query],  # 벡터 검색\n",
    "    select=[\"id\", \"content\", \"source\", \"metadata\"],\n",
    "    top=5\n",
    ")\n",
    "\n",
    "print(\"하이브리드 검색 결과:\\n\")\n",
    "for result in results:\n",
    "    print(f\"ID: {result['id']}\")\n",
    "    print(f\"점수: {result['@search.score']:.4f}\")\n",
    "    print(f\"내용: {result['content']}\")\n",
    "    print(f\"출처: {result['source']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fccfe016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType\n",
    "\n",
    "# 시맨틱 검색\n",
    "results = search_client.search(\n",
    "    search_text=\"Azure에서 제공하는 검색 서비스는 무엇인가?\",\n",
    "    vector_queries=[vector_query],\n",
    "    query_type=QueryType.SEMANTIC,  # 시맨틱 검색 활성화\n",
    "    semantic_configuration_name=\"semantic-config\",\n",
    "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    ")\n",
    "\n",
    "print(\"시맨틱 검색 결과:\\n\")\n",
    "for result in results:\n",
    "    print(f\"내용: {result['content']}\")\n",
    "    \n",
    "    # 캡션 (관련 부분 하이라이트)\n",
    "    if '@search.captions' in result:\n",
    "        captions = result['@search.captions']\n",
    "        if captions:\n",
    "            print(f\"캡션: {captions[0].text}\")\n",
    "    \n",
    "    print(f\"점수: {result['@search.score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f1cea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터 필터링\n",
    "results = vector_store.similarity_search(\n",
    "    query=\"Azure 서비스\",\n",
    "    k=5,\n",
    "    filters=\"metadata eq 'Azure'\"  # OData 필터 구문\n",
    ")\n",
    "\n",
    "print(f\"필터링된 결과 ({len(results)}개):\")\n",
    "for doc in results:\n",
    "    print(f\"- {doc.page_content}\")\n",
    "    print(f\"  메타데이터: {doc.metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2462959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND/OR 조건\n",
    "filter_expression = \"metadata eq 'Azure' and source eq 'doc1.txt'\"\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=\"검색\",\n",
    "    filter=filter_expression,\n",
    "    top=5\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f\"- {result['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54fe1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Retriever 생성\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"다음 컨텍스트를 참고하여 질문에 답변하세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    ")\n",
    "\n",
    "# RAG 체인\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행\n",
    "answer = rag_chain.invoke(\"Azure AI Search는 무엇인가?\")\n",
    "print(f\"답변: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14cc979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_documents_batch(documents, batch_size=1000):\n",
    "    \"\"\"배치 단위로 대량 문서 업로드\"\"\"\n",
    "    total_uploaded = 0\n",
    "    \n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        \n",
    "        # 임베딩 생성\n",
    "        for doc in batch:\n",
    "            if \"content_vector\" not in doc:\n",
    "                doc[\"content_vector\"] = embeddings.embed_query(doc[\"content\"])\n",
    "        \n",
    "        # 업로드\n",
    "        result = search_client.upload_documents(documents=batch)\n",
    "        \n",
    "        uploaded = sum(1 for item in result if item.succeeded)\n",
    "        total_uploaded += uploaded\n",
    "        \n",
    "        print(f\"배치 {i//batch_size + 1}: {uploaded}/{len(batch)} 업로드\")\n",
    "    \n",
    "    return total_uploaded\n",
    "\n",
    "# 사용 예시\n",
    "# large_docs = [{\"id\": str(i), \"content\": f\"문서 {i}\"} for i in range(5000)]\n",
    "# total = upload_documents_batch(large_docs, batch_size=1000)\n",
    "# print(f\"총 {total}개 문서 업로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58608f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 삭제\n",
    "index_client.delete_index(os.getenv(\"AZURE_SEARCH_INDEX_NAME\"))\n",
    "print(\"인덱스 삭제 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23ee2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 인덱스 조회\n",
    "indexes = index_client.list_indexes()\n",
    "\n",
    "print(\"인덱스 목록:\")\n",
    "for index in indexes:\n",
    "    print(f\"- {index.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c081e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 문서 삭제\n",
    "search_client.delete_documents(documents=[{\"id\": \"1\"}, {\"id\": \"2\"}])\n",
    "print(\"문서 삭제 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20315038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 통계 조회\n",
    "stats = search_client.get_document_count()\n",
    "print(f\"총 문서 수: {stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6f6b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 검색 성능 측정\n",
    "start_time = time.time()\n",
    "\n",
    "results = vector_store.similarity_search(\"테스트 쿼리\", k=10)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(f\"검색 시간: {duration:.3f}초\")\n",
    "print(f\"검색 결과: {len(results)}개\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}