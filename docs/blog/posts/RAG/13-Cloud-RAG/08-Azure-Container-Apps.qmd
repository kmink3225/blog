---
title: "Azure Container Apps"
subtitle: ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ë°°í¬
description: |
  Azure Container Appsë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ ì»¨í…Œì´ë„ˆ ë°°í¬ ë° ìŠ¤ì¼€ì¼ë§ ì „ëµì„ ë‹¤ë£¬ë‹¤.
categories:
  - AI
  - RAG
  - Azure
author: Kwangmin Kim
date: 11/09/2025
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
execute:
    eval: false
---

## Azure Container Appsë€?

Azure Container AppsëŠ” ì„œë²„ë¦¬ìŠ¤ ì»¨í…Œì´ë„ˆ í”Œë«í¼ìœ¼ë¡œ, Kubernetes ë³µì¡ë„ ì—†ì´ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤.

**ì£¼ìš” íŠ¹ì§•:**
- Kubernetes ê¸°ë°˜ì´ì§€ë§Œ ê´€ë¦¬ ë¶ˆí•„ìš”
- HTTPS Ingress ìë™ êµ¬ì„±
- Dapr í†µí•©
- KEDA ê¸°ë°˜ ìë™ ìŠ¤ì¼€ì¼ë§
- Revision ê´€ë¦¬ (Blue-Green ë°°í¬)

**Azure Functionsì™€ ë¹„êµ:**

| í•­ëª© | Functions | Container Apps |
|------|-----------|----------------|
| **ì‹¤í–‰ ì‹œê°„** | ìµœëŒ€ 10ë¶„ | ë¬´ì œí•œ |
| **Cold Start** | 3-5ì´ˆ | 1-2ì´ˆ |
| **ì»¤ìŠ¤í„°ë§ˆì´ì§•** | ì œí•œì  | ì™„ì „ ì œì–´ |
| **WebSocket** | ë¶ˆê°€ | ê°€ëŠ¥ |
| **ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤** | 0 (Consumption) | 0~30 |
| **ë¹„ìš©** | ì‹¤í–‰ ì‹œê°„ ê¸°ë°˜ | vCPU/ë©”ëª¨ë¦¬ ì‹œê°„ |

**Container Apps ê¶Œì¥ ì‹œë‚˜ë¦¬ì˜¤:**
- ì‹¤í–‰ ì‹œê°„ > 10ë¶„
- WebSocket ë˜ëŠ” gRPC í•„ìš”
- ë³µì¡í•œ ì¢…ì†ì„±
- ì§€ì†ì ì¸ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
- Multi-container (ì‚¬ì´ë“œì¹´ íŒ¨í„´)

## í™˜ê²½ ì„¤ì •

### Docker ì„¤ì¹˜

**Windows:**
```powershell
# Docker Desktop ì„¤ì¹˜
winget install Docker.DockerDesktop
```

**macOS:**
```bash
brew install --cask docker
```

**Linux:**
```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
```

### Azure CLI í™•ì¥

```bash
# Container Apps í™•ì¥ ì„¤ì¹˜
az extension add --name containerapp --upgrade

# í™•ì¸
az containerapp --version
```

## Dockerfile ì‘ì„±

### í”„ë¡œì íŠ¸ êµ¬ì¡°

```
rag-container/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ rag.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ .dockerignore
```

### requirements.txt

```txt
fastapi==0.109.0
uvicorn[standard]==0.27.0
langchain==0.1.6
langchain-openai==0.0.5
langchain-community==0.0.20
azure-search-documents==11.4.0
azure-identity==1.15.0
python-dotenv==1.0.0
```

### app/main.py

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from app.rag import RAGSystem

app = FastAPI(title="RAG API", version="1.0.0")

# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
rag = RAGSystem()

class QueryRequest(BaseModel):
    question: str
    top_k: int = 3

class QueryResponse(BaseModel):
    question: str
    answer: str
    sources: list[str]

@app.get("/")
async def root():
    """Health check"""
    return {"status": "healthy", "service": "RAG API"}

@app.get("/health")
async def health():
    """Health probe endpoint"""
    try:
        # ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸
        if rag.is_initialized():
            return {"status": "healthy"}
        else:
            return {"status": "initializing"}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

@app.post("/query", response_model=QueryResponse)
async def query(request: QueryRequest):
    """RAG ì¿¼ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        result = rag.query(
            question=request.question,
            top_k=request.top_k
        )
        return QueryResponse(
            question=request.question,
            answer=result["answer"],
            sources=result["sources"]
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/stream")
async def stream_query(request: QueryRequest):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
    from fastapi.responses import StreamingResponse
    
    async def generate():
        async for chunk in rag.stream_query(request.question):
            yield f"data: {chunk}\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")
```

### app/rag.py

```python
import os
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI
from langchain_community.vectorstores.azuresearch import AzureSearch
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

class RAGSystem:
    def __init__(self):
        self._initialized = False
        self._init_components()
    
    def _init_components(self):
        """RAG ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        # Embeddings
        self.embeddings = AzureOpenAIEmbeddings(
            azure_deployment="text-embedding-3-small",
            openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY")
        )
        
        # Vector Store
        self.vector_store = AzureSearch(
            azure_search_endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
            azure_search_key=os.getenv("AZURE_SEARCH_API_KEY"),
            index_name=os.getenv("AZURE_SEARCH_INDEX_NAME"),
            embedding_function=self.embeddings.embed_query
        )
        
        # LLM
        self.llm = AzureChatOpenAI(
            azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
            openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            temperature=0
        )
        
        # Retriever
        self.retriever = self.vector_store.as_retriever(
            search_kwargs={"k": 3}
        )
        
        # Prompt
        prompt = ChatPromptTemplate.from_template(
            """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        )
        
        # RAG Chain
        def format_docs(docs):
            return "\n\n".join([doc.page_content for doc in docs])
        
        self.rag_chain = (
            {"context": self.retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )
        
        self._initialized = True
    
    def is_initialized(self) -> bool:
        return self._initialized
    
    def query(self, question: str, top_k: int = 3) -> dict:
        """RAG ì¿¼ë¦¬ ì‹¤í–‰"""
        # ë¬¸ì„œ ê²€ìƒ‰
        docs = self.retriever.invoke(question)
        
        # ë‹µë³€ ìƒì„±
        answer = self.rag_chain.invoke(question)
        
        # ì¶œì²˜ ì¶”ì¶œ
        sources = [doc.metadata.get("source", "Unknown") for doc in docs]
        
        return {
            "answer": answer,
            "sources": sources
        }
    
    async def stream_query(self, question: str):
        """ìŠ¤íŠ¸ë¦¬ë° ì¿¼ë¦¬"""
        async for chunk in self.rag_chain.astream(question):
            yield chunk
```

### Dockerfile

```dockerfile
FROM python:3.11-slim

# ì‘ì—… ë””ë ‰í† ë¦¬
WORKDIR /app

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Python ì¢…ì†ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY ./app ./app

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### .dockerignore

```
__pycache__
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
.venv/
.git
.gitignore
.dockerignore
Dockerfile
README.md
.env
```

## ë¡œì»¬ í…ŒìŠ¤íŠ¸

### Docker ë¹Œë“œ ë° ì‹¤í–‰

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t rag-api:latest .

# ë¡œì»¬ ì‹¤í–‰
docker run -p 8000:8000 \
  -e AZURE_OPENAI_ENDPOINT="https://openai-rag.openai.azure.com/" \
  -e AZURE_OPENAI_API_KEY="your-key" \
  -e AZURE_OPENAI_DEPLOYMENT="gpt-4o" \
  -e AZURE_OPENAI_API_VERSION="2024-02-01" \
  -e AZURE_SEARCH_ENDPOINT="https://search-rag.search.windows.net" \
  -e AZURE_SEARCH_API_KEY="your-key" \
  -e AZURE_SEARCH_INDEX_NAME="rag-documents" \
  rag-api:latest

# Health check
curl http://localhost:8000/health

# ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Azure AI Searchë€?"}'
```

### docker-compose.yml (ê°œë°œìš©)

```yaml
version: '3.8'

services:
  rag-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_DEPLOYMENT=${AZURE_OPENAI_DEPLOYMENT}
      - AZURE_OPENAI_API_VERSION=2024-02-01
      - AZURE_SEARCH_ENDPOINT=${AZURE_SEARCH_ENDPOINT}
      - AZURE_SEARCH_API_KEY=${AZURE_SEARCH_API_KEY}
      - AZURE_SEARCH_INDEX_NAME=${AZURE_SEARCH_INDEX_NAME}
    volumes:
      - ./app:/app/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

ì‹¤í–‰:
```bash
docker-compose up
```

## Azure Container Registry

### ACR ìƒì„±

```bash
# ë¦¬ì†ŒìŠ¤ ê·¸ë£¹ ìƒì„±
az group create --name rg-rag-prod --location koreacentral

# Container Registry ìƒì„±
az acr create \
  --resource-group rg-rag-prod \
  --name acrragprod \
  --sku Basic \
  --location koreacentral

# ACR ë¡œê·¸ì¸
az acr login --name acrragprod
```

### ì´ë¯¸ì§€ í‘¸ì‹œ

```bash
# ì´ë¯¸ì§€ íƒœê¹…
docker tag rag-api:latest acrragprod.azurecr.io/rag-api:latest
docker tag rag-api:latest acrragprod.azurecr.io/rag-api:v1.0.0

# ì´ë¯¸ì§€ í‘¸ì‹œ
docker push acrragprod.azurecr.io/rag-api:latest
docker push acrragprod.azurecr.io/rag-api:v1.0.0

# ì´ë¯¸ì§€ í™•ì¸
az acr repository list --name acrragprod --output table
az acr repository show-tags --name acrragprod --repository rag-api --output table
```

## Container Apps Environment

### Environment ìƒì„±

```bash
# Log Analytics Workspace ìƒì„±
az monitor log-analytics workspace create \
  --resource-group rg-rag-prod \
  --workspace-name law-rag-prod \
  --location koreacentral

# Workspace ID ì¡°íšŒ
WORKSPACE_ID=$(az monitor log-analytics workspace show \
  --resource-group rg-rag-prod \
  --workspace-name law-rag-prod \
  --query customerId -o tsv)

WORKSPACE_KEY=$(az monitor log-analytics workspace get-shared-keys \
  --resource-group rg-rag-prod \
  --workspace-name law-rag-prod \
  --query primarySharedKey -o tsv)

# Container Apps Environment ìƒì„±
az containerapp env create \
  --name cae-rag-prod \
  --resource-group rg-rag-prod \
  --location koreacentral \
  --logs-workspace-id $WORKSPACE_ID \
  --logs-workspace-key $WORKSPACE_KEY
```

## Container App ë°°í¬

### ACR í†µí•©

```bash
# ACR Admin í™œì„±í™”
az acr update --name acrragprod --admin-enabled true

# ACR ìê²© ì¦ëª… ì¡°íšŒ
ACR_USERNAME=$(az acr credential show --name acrragprod --query username -o tsv)
ACR_PASSWORD=$(az acr credential show --name acrragprod --query passwords[0].value -o tsv)
```

### Container App ìƒì„±

```bash
az containerapp create \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --environment cae-rag-prod \
  --image acrragprod.azurecr.io/rag-api:latest \
  --target-port 8000 \
  --ingress external \
  --registry-server acrragprod.azurecr.io \
  --registry-username $ACR_USERNAME \
  --registry-password $ACR_PASSWORD \
  --cpu 1.0 \
  --memory 2.0Gi \
  --min-replicas 0 \
  --max-replicas 10 \
  --env-vars \
    AZURE_OPENAI_ENDPOINT="https://openai-rag.openai.azure.com/" \
    AZURE_OPENAI_DEPLOYMENT="gpt-4o" \
    AZURE_OPENAI_API_VERSION="2024-02-01" \
    AZURE_SEARCH_ENDPOINT="https://search-rag.search.windows.net" \
    AZURE_SEARCH_INDEX_NAME="rag-documents" \
  --secrets \
    azure-openai-key="your-openai-key" \
    azure-search-key="your-search-key" \
  --secret-env-vars \
    AZURE_OPENAI_API_KEY=azure-openai-key \
    AZURE_SEARCH_API_KEY=azure-search-key
```

### FQDN í™•ì¸

```bash
# Container App FQDN ì¡°íšŒ
az containerapp show \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --query properties.configuration.ingress.fqdn -o tsv

# ì¶œë ¥: ca-rag-api.politebeach-12345678.koreacentral.azurecontainerapps.io
```

### ë°°í¬ í…ŒìŠ¤íŠ¸

```bash
FQDN=$(az containerapp show \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --query properties.configuration.ingress.fqdn -o tsv)

# Health check
curl https://$FQDN/health

# ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
curl -X POST https://$FQDN/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Azure Container Appsë€?"}'
```

## ìŠ¤ì¼€ì¼ë§ ì „ëµ

### HTTP ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§

```bash
az containerapp update \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --min-replicas 1 \
  --max-replicas 10 \
  --scale-rule-name http-rule \
  --scale-rule-type http \
  --scale-rule-http-concurrency 50
```

**ì„¤ì • ì˜ë¯¸:**
- `min-replicas 1`: í•­ìƒ 1ê°œ ì¸ìŠ¤í„´ìŠ¤ ìœ ì§€ (Cold Start ë°©ì§€)
- `max-replicas 10`: ìµœëŒ€ 10ê°œê¹Œì§€ í™•ì¥
- `http-concurrency 50`: ë™ì‹œ ìš”ì²­ 50ê°œë‹¹ 1ê°œ ì¸ìŠ¤í„´ìŠ¤ ì¶”ê°€

### CPU/ë©”ëª¨ë¦¬ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§

```bash
az containerapp update \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --scale-rule-name cpu-rule \
  --scale-rule-type cpu \
  --scale-rule-metadata type=Utilization value=70
```

### ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ìŠ¤ì¼€ì¼ë§ (KEDA)

**YAML ì •ì˜:**
```yaml
scaleRules:
  - name: queue-based-scaling
    custom:
      type: azure-queue
      metadata:
        queueName: rag-requests
        queueLength: "5"
        accountName: stragprod
      auth:
        - secretRef: queue-connection
          triggerParameter: connection
```

## Revision ê´€ë¦¬

### Blue-Green ë°°í¬

```bash
# ìƒˆ Revision ë°°í¬ (íŠ¸ë˜í”½ 0%)
az containerapp update \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --image acrragprod.azurecr.io/rag-api:v2.0.0 \
  --revision-suffix v2

# Revision ëª©ë¡ í™•ì¸
az containerapp revision list \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --output table

# íŠ¸ë˜í”½ ë¶„í•  (50:50)
az containerapp ingress traffic set \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --revision-weight ca-rag-api--v1=50 ca-rag-api--v2=50

# 100% v2ë¡œ ì „í™˜
az containerapp ingress traffic set \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --revision-weight ca-rag-api--v2=100

# ì´ì „ Revision ë¹„í™œì„±í™”
az containerapp revision deactivate \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --revision ca-rag-api--v1
```

### ë¡¤ë°±

```bash
# ì¦‰ì‹œ ë¡¤ë°±
az containerapp ingress traffic set \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --revision-weight ca-rag-api--v1=100
```

## ë©€í‹° ì»¨í…Œì´ë„ˆ (ì‚¬ì´ë“œì¹´)

### Redis ìºì‹œ ì‚¬ì´ë“œì¹´

**containerapp.yaml:**
```yaml
properties:
  template:
    containers:
      - name: rag-api
        image: acrragprod.azurecr.io/rag-api:latest
        env:
          - name: REDIS_HOST
            value: localhost
          - name: REDIS_PORT
            value: "6379"
        resources:
          cpu: 1.0
          memory: 2.0Gi
      
      - name: redis
        image: redis:7-alpine
        resources:
          cpu: 0.5
          memory: 1.0Gi
```

ë°°í¬:
```bash
az containerapp create \
  --name ca-rag-with-cache \
  --resource-group rg-rag-prod \
  --environment cae-rag-prod \
  --yaml containerapp.yaml
```

### ìºì‹œ í†µí•© ì½”ë“œ

```python
import redis
from functools import lru_cache

class RAGSystemWithCache(RAGSystem):
    def __init__(self):
        super().__init__()
        self.redis_client = redis.Redis(
            host=os.getenv("REDIS_HOST", "localhost"),
            port=int(os.getenv("REDIS_PORT", 6379)),
            decode_responses=True
        )
    
    def query(self, question: str, top_k: int = 3) -> dict:
        # ìºì‹œ í™•ì¸
        cache_key = f"rag:{question}"
        cached = self.redis_client.get(cache_key)
        
        if cached:
            return json.loads(cached)
        
        # RAG ì‹¤í–‰
        result = super().query(question, top_k)
        
        # ìºì‹œ ì €ì¥ (10ë¶„)
        self.redis_client.setex(cache_key, 600, json.dumps(result))
        
        return result
```

## ëª¨ë‹ˆí„°ë§

### Application Insights í†µí•©

```bash
# Application Insights ìƒì„±
az monitor app-insights component create \
  --app rag-api-insights \
  --location koreacentral \
  --resource-group rg-rag-prod \
  --workspace law-rag-prod

# Instrumentation Key ì¡°íšŒ
INSTRUMENTATION_KEY=$(az monitor app-insights component show \
  --app rag-api-insights \
  --resource-group rg-rag-prod \
  --query instrumentationKey -o tsv)

# Container App ì—…ë°ì´íŠ¸
az containerapp update \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --set-env-vars APPLICATIONINSIGHTS_CONNECTION_STRING="InstrumentationKey=$INSTRUMENTATION_KEY"
```

### OpenTelemetry ê³„ì¸¡

**requirements.txt ì¶”ê°€:**
```txt
opentelemetry-api==1.21.0
opentelemetry-sdk==1.21.0
opentelemetry-instrumentation-fastapi==0.42b0
azure-monitor-opentelemetry-exporter==1.0.0b21
```

**main.py ìˆ˜ì •:**
```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from azure.monitor.opentelemetry.exporter import AzureMonitorTraceExporter
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor

# Tracer ì„¤ì •
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

exporter = AzureMonitorTraceExporter.from_connection_string(
    os.getenv("APPLICATIONINSIGHTS_CONNECTION_STRING")
)
trace.get_tracer_provider().add_span_processor(
    BatchSpanProcessor(exporter)
)

# FastAPI ìë™ ê³„ì¸¡
app = FastAPI()
FastAPIInstrumentor.instrument_app(app)

@app.post("/query")
async def query(request: QueryRequest):
    with tracer.start_as_current_span("rag_query") as span:
        span.set_attribute("question.length", len(request.question))
        result = rag.query(request.question)
        span.set_attribute("answer.length", len(result["answer"]))
        return result
```

### ë¡œê·¸ ì¿¼ë¦¬

```kusto
// Container App ë¡œê·¸
ContainerAppConsoleLogs_CL
| where ContainerAppName_s == "ca-rag-api"
| where TimeGenerated > ago(1h)
| order by TimeGenerated desc
| take 100

// ì‹œìŠ¤í…œ ë¡œê·¸
ContainerAppSystemLogs_CL
| where ContainerAppName_s == "ca-rag-api"
| where TimeGenerated > ago(1h)
| project TimeGenerated, Log_s

// HTTP ìš”ì²­ ë¶„ì„
requests
| where cloud_RoleName == "ca-rag-api"
| summarize 
    Count=count(),
    AvgDuration=avg(duration),
    P95Duration=percentile(duration, 95)
  by bin(timestamp, 5m)
| render timechart
```

## CI/CD íŒŒì´í”„ë¼ì¸

### GitHub Actions

**.github/workflows/deploy.yml:**
```yaml
name: Build and Deploy to Azure Container Apps

on:
  push:
    branches:
      - main

env:
  AZURE_CONTAINER_REGISTRY: acrragprod
  CONTAINER_APP_NAME: ca-rag-api
  RESOURCE_GROUP: rg-rag-prod
  IMAGE_NAME: rag-api

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      
      - name: Login to ACR
        run: |
          az acr login --name ${{ env.AZURE_CONTAINER_REGISTRY }}
      
      - name: Build and push image
        run: |
          IMAGE_TAG=${{ env.AZURE_CONTAINER_REGISTRY }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
          docker build -t $IMAGE_TAG .
          docker push $IMAGE_TAG
      
      - name: Deploy to Container Apps
        run: |
          az containerapp update \
            --name ${{ env.CONTAINER_APP_NAME }} \
            --resource-group ${{ env.RESOURCE_GROUP }} \
            --image ${{ env.AZURE_CONTAINER_REGISTRY }}.azurecr.io/${{ env.IMAGE_NAME }}:${{ github.sha }}
```

## ë³´ì•ˆ

### Managed Identity

```bash
# System-assigned identity í™œì„±í™”
az containerapp identity assign \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --system-assigned

# Principal ID ì¡°íšŒ
PRINCIPAL_ID=$(az containerapp identity show \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --query principalId -o tsv)

# Azure OpenAI ê¶Œí•œ ë¶€ì—¬
az role assignment create \
  --assignee $PRINCIPAL_ID \
  --role "Cognitive Services OpenAI User" \
  --scope /subscriptions/{subscription-id}/resourceGroups/rg-rag-prod/providers/Microsoft.CognitiveServices/accounts/openai-rag-prod

# Azure Search ê¶Œí•œ ë¶€ì—¬
az role assignment create \
  --assignee $PRINCIPAL_ID \
  --role "Search Index Data Reader" \
  --scope /subscriptions/{subscription-id}/resourceGroups/rg-rag-prod/providers/Microsoft.Search/searchServices/search-rag-prod
```

### DefaultAzureCredential ì‚¬ìš©

```python
from azure.identity import DefaultAzureCredential

credential = DefaultAzureCredential()

# OpenAI (Managed Identity)
llm = AzureChatOpenAI(
    azure_deployment="gpt-4o",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    azure_ad_token_provider=lambda: credential.get_token(
        "https://cognitiveservices.azure.com/.default"
    ).token
)

# Azure Search (Managed Identity)
from azure.search.documents import SearchClient

search_client = SearchClient(
    endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
    index_name=os.getenv("AZURE_SEARCH_INDEX_NAME"),
    credential=credential
)
```

### ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ

```bash
# VNET í†µí•©
az containerapp env create \
  --name cae-rag-secure \
  --resource-group rg-rag-prod \
  --location koreacentral \
  --infrastructure-subnet-resource-id /subscriptions/{sub-id}/resourceGroups/rg-rag-prod/providers/Microsoft.Network/virtualNetworks/vnet-rag/subnets/subnet-containerapp

# Internal Ingress (Private)
az containerapp create \
  --name ca-rag-internal \
  --resource-group rg-rag-prod \
  --environment cae-rag-secure \
  --image acrragprod.azurecr.io/rag-api:latest \
  --ingress internal \
  --target-port 8000
```

## ë¹„ìš© ìµœì í™”

### ê°€ê²© êµ¬ì¡°

**Container Apps ë¹„ìš©:**
- vCPU: $0.000024/ì´ˆ ($0.0864/vCPU-ì‹œê°„)
- ë©”ëª¨ë¦¬: $0.0000027/GB-ì´ˆ ($0.00972/GB-ì‹œê°„)
- ìš”ì²­: ì²« 200ë§Œ ê±´ ë¬´ë£Œ, ì´í›„ $0.40/100ë§Œ ê±´

**ì˜ˆì‹œ ê³„ì‚°** (1 vCPU, 2GB, min=1, max=10):

**ì‹œë‚˜ë¦¬ì˜¤ 1: ë‚®ì€ íŠ¸ë˜í”½**
- í‰ê·  ì¸ìŠ¤í„´ìŠ¤: 1ê°œ
- ì›”ê°„ ì‹œê°„: 730ì‹œê°„
- vCPU ë¹„ìš©: 1 Ã— 730 Ã— $0.0864 = $63.07
- ë©”ëª¨ë¦¬ ë¹„ìš©: 2GB Ã— 730 Ã— $0.00972 = $14.19
- **ì´ ë¹„ìš©**: ~$77/ì›”

**ì‹œë‚˜ë¦¬ì˜¤ 2: ì¤‘ê°„ íŠ¸ë˜í”½**
- í‰ê·  ì¸ìŠ¤í„´ìŠ¤: 3ê°œ
- ì›”ê°„ ì‹œê°„: 730ì‹œê°„
- vCPU ë¹„ìš©: 3 Ã— 730 Ã— $0.0864 = $189.22
- ë©”ëª¨ë¦¬ ë¹„ìš©: 3 Ã— 2GB Ã— 730 Ã— $0.00972 = $42.57
- **ì´ ë¹„ìš©**: ~$232/ì›”

### ë¹„ìš© ì ˆê° íŒ

1. **min-replicas ì¡°ì •**
```bash
# ì˜¤í”„í”¼í¬ì— 0ìœ¼ë¡œ ì„¤ì • (Cold Start í—ˆìš©)
az containerapp update \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --min-replicas 0
```

2. **ë¦¬ì†ŒìŠ¤ ìµœì í™”**
```bash
# í•„ìš”í•œ ìµœì†Œ ë¦¬ì†ŒìŠ¤ë§Œ í• ë‹¹
az containerapp update \
  --name ca-rag-api \
  --resource-group rg-rag-prod \
  --cpu 0.5 \
  --memory 1.0Gi
```

3. **Consumption Plan ì‚¬ìš©**
```bash
# Consumption í™˜ê²½ (ë” ì €ë ´)
az containerapp env create \
  --name cae-rag-consumption \
  --resource-group rg-rag-prod \
  --location koreacentral \
  --enable-workload-profiles false
```

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Azure Container Apps](https://learn.microsoft.com/en-us/azure/container-apps/)
- [Container Apps ê°€ê²©](https://azure.microsoft.com/en-us/pricing/details/container-apps/)
- [KEDA Scalers](https://keda.sh/docs/scalers/)

## ë‹¤ìŒ ë‹¨ê³„

ì»¨í…Œì´ë„ˆ ë°°í¬ê°€ ì™„ë£Œë˜ì—ˆë‹¤ë©´, ì´ì œ ì „ì²´ ì‹œìŠ¤í…œì„ í†µí•©í•˜ì:

ğŸ‘‰ [09-End-to-End-Azure-RAG.qmd](./09-End-to-End-Azure-RAG.qmd) - End-to-End Azure RAG ì‹œìŠ¤í…œ êµ¬ì¶•