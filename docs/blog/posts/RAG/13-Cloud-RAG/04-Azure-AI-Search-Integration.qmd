---
title: "Azure AI Search Integration"
subtitle: ë²¡í„° ìŠ¤í† ì–´ í†µí•© ë° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
description: |
  Azure AI Searchì™€ RAG ì‹œìŠ¤í…œ í†µí•©, ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„ ë°©ë²•ì„ ë‹¤ë£¬ë‹¤.
categories:
  - AI
  - RAG
  - Azure
author: Kwangmin Kim
date: 11/05/2025
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
execute:
    eval: false
---

## Azure AI Searchë€?

Azure AI SearchëŠ” Microsoftì˜ ê´€ë¦¬í˜• ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¡œ, **ë²¡í„° ê²€ìƒ‰**ê³¼ **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**ì„ ì§€ì›í•œë‹¤.

**RAG ì‹œìŠ¤í…œì—ì„œì˜ ì—­í• :**
- ì„ë² ë”© ë²¡í„° ì €ì¥ (Vector Store)
- ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (Semantic Search)
- í‚¤ì›Œë“œ + ë²¡í„° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
- ëŒ€ê·œëª¨ ë¬¸ì„œ ê²€ìƒ‰ (ìˆ˜ë°±ë§Œ ê°œ ë¬¸ì„œ)

**ì™œ Azure AI Searchì¸ê°€?**
- ì™„ì „ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ (ì„œë²„ ê´€ë¦¬ ë¶ˆí•„ìš”)
- ë†’ì€ ê°€ìš©ì„± (99.9% SLA)
- ìë™ ìŠ¤ì¼€ì¼ë§
- ì—”í„°í”„ë¼ì´ì¦ˆ ë³´ì•ˆ (Private Endpoint, RBAC)

## Azure AI Search ì£¼ìš” ê°œë…

### ì¸ë±ìŠ¤ (Index)
ê²€ìƒ‰ ê°€ëŠ¥í•œ ë¬¸ì„œ ì»¬ë ‰ì…˜. RDBì˜ í…Œì´ë¸”ê³¼ ìœ ì‚¬í•˜ë‹¤.

**êµ¬ì„± ìš”ì†Œ:**
- **í•„ë“œ (Fields)**: ë¬¸ì„œì˜ ì†ì„± (ì œëª©, ë‚´ìš©, ë©”íƒ€ë°ì´í„° ë“±)
- **ë²¡í„° í•„ë“œ (Vector Fields)**: ì„ë² ë”© ë²¡í„° ì €ì¥
- **ê²€ìƒ‰ ê°€ëŠ¥ í•„ë“œ (Searchable)**: ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ëŒ€ìƒ
- **í•„í„°ë§ ê°€ëŠ¥ í•„ë“œ (Filterable)**: ì¡°ê±´ í•„í„°ë§ ê°€ëŠ¥

### ê²€ìƒ‰ ìœ í˜•

| ê²€ìƒ‰ ìœ í˜• | ì„¤ëª… | ìš©ë„ |
|----------|------|------|
| **ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰** | í‚¤ì›Œë“œ ê¸°ë°˜ BM25 ì•Œê³ ë¦¬ì¦˜ | ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ |
| **ë²¡í„° ê²€ìƒ‰** | ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ | ì˜ë¯¸ì  ìœ ì‚¬ì„± |
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | í…ìŠ¤íŠ¸ + ë²¡í„° ê²°í•© | ìµœê³  ì •í™•ë„ |
| **ì‹œë§¨í‹± ê²€ìƒ‰** | AI ê¸°ë°˜ ì¬ìˆœìœ„í™” | ìì—°ì–´ ì¿¼ë¦¬ ì´í•´ |

### ë²¡í„° ì•Œê³ ë¦¬ì¦˜

**HNSW (Hierarchical Navigable Small World)**
- ê·¼ì‚¬ ìµœê·¼ì ‘ ì´ì›ƒ (Approximate Nearest Neighbor, ANN)
- ë¹ ë¥¸ ê²€ìƒ‰ ì†ë„ (ms ë‹¨ìœ„)
- ë†’ì€ ì •í™•ë„ (recall > 95%)

## Azure AI Search ë¦¬ì†ŒìŠ¤ ìƒì„±

### Azure Portalì—ì„œ ìƒì„±

**1. Azure AI Search ë§Œë“¤ê¸°:**
- [portal.azure.com](https://portal.azure.com) â†’ "ë¦¬ì†ŒìŠ¤ ë§Œë“¤ê¸°"
- "Azure AI Search" ê²€ìƒ‰ ë° ì„ íƒ

**2. ê¸°ë³¸ ì„¤ì •:**
- **êµ¬ë…**: ì‚¬ìš©í•  êµ¬ë… ì„ íƒ
- **ë¦¬ì†ŒìŠ¤ ê·¸ë£¹**: `rg-rag-prod`
- **ì„œë¹„ìŠ¤ ì´ë¦„**: `search-rag-prod` (ì „ì—­ì ìœ¼ë¡œ ê³ ìœ í•´ì•¼ í•¨)
- **ì§€ì—­**: Korea Central (ë˜ëŠ” East US)
- **ê°€ê²© ì±…ì • ê³„ì¸µ**: 
  - Free: ë¬´ë£Œ (50MB, ì¸ë±ìŠ¤ 3ê°œ)
  - Basic: $73.73/ì›” (2GB)
  - Standard S1: $250.83/ì›” (25GB)

**3. ê²€í†  + ë§Œë“¤ê¸°** â†’ ìƒì„± ì™„ë£Œ

**4. í‚¤ ë° ì—”ë“œí¬ì¸íŠ¸ í™•ì¸:**
- ìƒì„±ëœ ë¦¬ì†ŒìŠ¤ â†’ "í‚¤"
- **ê´€ë¦¬ í‚¤ (Admin Key)** ë³µì‚¬
- **URL** ë³µì‚¬ (ì˜ˆ: `https://search-rag-prod.search.windows.net`)

### Azure CLIë¡œ ìƒì„±

```bash
# Azure AI Search ë¦¬ì†ŒìŠ¤ ìƒì„±
az search service create \
    --name search-rag-prod \
    --resource-group rg-rag-prod \
    --sku basic \
    --location koreacentral

# ê´€ë¦¬ í‚¤ ì¡°íšŒ
az search admin-key show \
    --service-name search-rag-prod \
    --resource-group rg-rag-prod
```

## í™˜ê²½ ì„¤ì •

### Python SDK ì„¤ì¹˜

```bash
pip install azure-search-documents
pip install langchain-community
pip install azure-identity
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼:
```
AZURE_SEARCH_ENDPOINT=https://search-rag-prod.search.windows.net
AZURE_SEARCH_API_KEY=your-admin-key-here
AZURE_SEARCH_INDEX_NAME=rag-documents
```

## ê¸°ë³¸ ì‚¬ìš©ë²•

### ì¸ë±ìŠ¤ ìƒì„±

```{python}
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
    SearchIndex,
    SearchField,
    SearchFieldDataType,
    VectorSearch,
    HnswAlgorithmConfiguration,
    VectorSearchProfile,
    SemanticConfiguration,
    SemanticField,
    SemanticPrioritizedFields,
    SemanticSearch
)
from azure.core.credentials import AzureKeyCredential
from dotenv import load_dotenv
import os

load_dotenv()

# í´ë¼ì´ì–¸íŠ¸ ìƒì„±
index_client = SearchIndexClient(
    endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
    credential=AzureKeyCredential(os.getenv("AZURE_SEARCH_API_KEY"))
)

# ì¸ë±ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ì˜
fields = [
    SearchField(
        name="id",
        type=SearchFieldDataType.String,
        key=True,  # ê¸°ë³¸ í‚¤
        filterable=True
    ),
    SearchField(
        name="content",
        type=SearchFieldDataType.String,
        searchable=True,  # ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê°€ëŠ¥
        filterable=False
    ),
    SearchField(
        name="content_vector",
        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
        vector_search_dimensions=1536,  # text-embedding-3-small
        vector_search_profile_name="vector-profile"
    ),
    SearchField(
        name="metadata",
        type=SearchFieldDataType.String,
        searchable=False,
        filterable=True
    ),
    SearchField(
        name="source",
        type=SearchFieldDataType.String,
        searchable=False,
        filterable=True,
        facetable=True
    )
]

# ë²¡í„° ê²€ìƒ‰ ì„¤ì •
vector_search = VectorSearch(
    algorithms=[
        HnswAlgorithmConfiguration(
            name="hnsw-config",
            parameters={
                "m": 4,  # ê·¸ë˜í”„ ì—°ê²° ìˆ˜
                "efConstruction": 400,  # ì¸ë±ìŠ¤ êµ¬ì¶• í’ˆì§ˆ
                "efSearch": 500,  # ê²€ìƒ‰ ì •í™•ë„
                "metric": "cosine"  # ìœ ì‚¬ë„ ì¸¡ì • ë°©ì‹
            }
        )
    ],
    profiles=[
        VectorSearchProfile(
            name="vector-profile",
            algorithm_configuration_name="hnsw-config"
        )
    ]
)

# ì‹œë§¨í‹± ê²€ìƒ‰ ì„¤ì • (ì„ íƒ ì‚¬í•­)
semantic_config = SemanticConfiguration(
    name="semantic-config",
    prioritized_fields=SemanticPrioritizedFields(
        title_field=None,
        content_fields=[SemanticField(field_name="content")]
    )
)

semantic_search = SemanticSearch(
    configurations=[semantic_config]
)

# ì¸ë±ìŠ¤ ìƒì„±
index = SearchIndex(
    name=os.getenv("AZURE_SEARCH_INDEX_NAME"),
    fields=fields,
    vector_search=vector_search,
    semantic_search=semantic_search
)

# ì¸ë±ìŠ¤ ì—…ë¡œë“œ
result = index_client.create_or_update_index(index)
print(f"ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {result.name}")
```

### ë¬¸ì„œ ì—…ë¡œë“œ

```{python}
from azure.search.documents import SearchClient
from langchain_openai import AzureOpenAIEmbeddings

# Embeddings í´ë¼ì´ì–¸íŠ¸
embeddings = AzureOpenAIEmbeddings(
    azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY")
)

# Search í´ë¼ì´ì–¸íŠ¸
search_client = SearchClient(
    endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
    index_name=os.getenv("AZURE_SEARCH_INDEX_NAME"),
    credential=AzureKeyCredential(os.getenv("AZURE_SEARCH_API_KEY"))
)

# ë¬¸ì„œ ì¤€ë¹„
documents = [
    {
        "id": "1",
        "content": "Azure AI SearchëŠ” Microsoftì˜ ê´€ë¦¬í˜• ê²€ìƒ‰ ì„œë¹„ìŠ¤ë‹¤.",
        "source": "doc1.txt",
        "metadata": "Azure"
    },
    {
        "id": "2",
        "content": "RAGëŠ” ê²€ìƒ‰ ì¦ê°• ìƒì„± ê¸°ìˆ ì´ë‹¤.",
        "source": "doc2.txt",
        "metadata": "RAG"
    },
    {
        "id": "3",
        "content": "ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•œë‹¤.",
        "source": "doc3.txt",
        "metadata": "Embeddings"
    }
]

# ì„ë² ë”© ìƒì„± ë° ë¬¸ì„œ ì—…ë¡œë“œ
for doc in documents:
    # ì„ë² ë”© ìƒì„±
    doc["content_vector"] = embeddings.embed_query(doc["content"])

# ë°°ì¹˜ ì—…ë¡œë“œ
result = search_client.upload_documents(documents=documents)
print(f"ì—…ë¡œë“œ ì™„ë£Œ: {len(result)}ê°œ ë¬¸ì„œ")

# ê° ë¬¸ì„œ ê²°ê³¼ í™•ì¸
for item in result:
    print(f"ë¬¸ì„œ ID {item.key}: {item.succeeded}")
```

## LangChain í†µí•©

### AzureSearch VectorStore

```{python}
from langchain_community.vectorstores.azuresearch import AzureSearch

# Azure Search VectorStore ì´ˆê¸°í™”
vector_store = AzureSearch(
    azure_search_endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
    azure_search_key=os.getenv("AZURE_SEARCH_API_KEY"),
    index_name=os.getenv("AZURE_SEARCH_INDEX_NAME"),
    embedding_function=embeddings.embed_query
)

# ë¬¸ì„œ ì¶”ê°€ (ìë™ ì„ë² ë”©)
from langchain_core.documents import Document

docs = [
    Document(
        page_content="LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬ë‹¤.",
        metadata={"source": "langchain.txt", "category": "framework"}
    ),
    Document(
        page_content="Azure OpenAIëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ LLM ì„œë¹„ìŠ¤ë‹¤.",
        metadata={"source": "azure_openai.txt", "category": "llm"}
    )
]

# ìë™ìœ¼ë¡œ ì„ë² ë”© ìƒì„± ë° ì—…ë¡œë“œ
vector_store.add_documents(docs)
print(f"{len(docs)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ")
```

### ë²¡í„° ê²€ìƒ‰

```{python}
# ìœ ì‚¬ë„ ê²€ìƒ‰
query = "LLM í”„ë ˆì„ì›Œí¬ëŠ” ë¬´ì—‡ì¸ê°€?"
results = vector_store.similarity_search(query, k=3)

print(f"ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):\n")
for i, doc in enumerate(results, 1):
    print(f"{i}. {doc.page_content}")
    print(f"   ë©”íƒ€ë°ì´í„°: {doc.metadata}\n")
```

### ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰

```{python}
# ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨ ê²€ìƒ‰
results_with_scores = vector_store.similarity_search_with_relevance_scores(
    query="Azure ê²€ìƒ‰ ì„œë¹„ìŠ¤",
    k=3
)

print("ìœ ì‚¬ë„ ì ìˆ˜:\n")
for doc, score in results_with_scores:
    print(f"ì ìˆ˜: {score:.4f}")
    print(f"ë‚´ìš©: {doc.page_content}")
    print(f"ì¶œì²˜: {doc.metadata.get('source', 'N/A')}\n")
```

## í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ê²°í•©í•œë‹¤.

### í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„

```{python}
from azure.search.documents.models import VectorizedQuery

# ê²€ìƒ‰ í´ë¼ì´ì–¸íŠ¸
search_client = SearchClient(
    endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
    index_name=os.getenv("AZURE_SEARCH_INDEX_NAME"),
    credential=AzureKeyCredential(os.getenv("AZURE_SEARCH_API_KEY"))
)

# ì¿¼ë¦¬
query_text = "Azure ê²€ìƒ‰ ì„œë¹„ìŠ¤"
query_vector = embeddings.embed_query(query_text)

# ë²¡í„° ì¿¼ë¦¬ ì •ì˜
vector_query = VectorizedQuery(
    vector=query_vector,
    k_nearest_neighbors=50,  # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
    fields="content_vector"
)

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
results = search_client.search(
    search_text=query_text,  # í‚¤ì›Œë“œ ê²€ìƒ‰
    vector_queries=[vector_query],  # ë²¡í„° ê²€ìƒ‰
    select=["id", "content", "source", "metadata"],
    top=5
)

print("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼:\n")
for result in results:
    print(f"ID: {result['id']}")
    print(f"ì ìˆ˜: {result['@search.score']:.4f}")
    print(f"ë‚´ìš©: {result['content']}")
    print(f"ì¶œì²˜: {result['source']}\n")
```

### ì‹œë§¨í‹± ê²€ìƒ‰ (ê³ ê¸‰)

Azure AI Searchì˜ AI ê¸°ë°˜ ì¬ìˆœìœ„í™” ê¸°ëŠ¥ì´ë‹¤.

```{python}
from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType

# ì‹œë§¨í‹± ê²€ìƒ‰
results = search_client.search(
    search_text="Azureì—ì„œ ì œê³µí•˜ëŠ” ê²€ìƒ‰ ì„œë¹„ìŠ¤ëŠ” ë¬´ì—‡ì¸ê°€?",
    vector_queries=[vector_query],
    query_type=QueryType.SEMANTIC,  # ì‹œë§¨í‹± ê²€ìƒ‰ í™œì„±í™”
    semantic_configuration_name="semantic-config",
    query_caption=QueryCaptionType.EXTRACTIVE,
    query_answer=QueryAnswerType.EXTRACTIVE,
    top=3
)

print("ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼:\n")
for result in results:
    print(f"ë‚´ìš©: {result['content']}")
    
    # ìº¡ì…˜ (ê´€ë ¨ ë¶€ë¶„ í•˜ì´ë¼ì´íŠ¸)
    if '@search.captions' in result:
        captions = result['@search.captions']
        if captions:
            print(f"ìº¡ì…˜: {captions[0].text}")
    
    print(f"ì ìˆ˜: {result['@search.score']:.4f}\n")
```

## í•„í„°ë§

ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì œí•œí•œë‹¤.

```{python}
# ë©”íƒ€ë°ì´í„° í•„í„°ë§
results = vector_store.similarity_search(
    query="Azure ì„œë¹„ìŠ¤",
    k=5,
    filters="metadata eq 'Azure'"  # OData í•„í„° êµ¬ë¬¸
)

print(f"í•„í„°ë§ëœ ê²°ê³¼ ({len(results)}ê°œ):")
for doc in results:
    print(f"- {doc.page_content}")
    print(f"  ë©”íƒ€ë°ì´í„°: {doc.metadata}\n")
```

### ë³µí•© í•„í„°

```{python}
# AND/OR ì¡°ê±´
filter_expression = "metadata eq 'Azure' and source eq 'doc1.txt'"

results = search_client.search(
    search_text="ê²€ìƒ‰",
    filter=filter_expression,
    top=5
)

for result in results:
    print(f"- {result['content']}")
```

## Retrieverë¡œ í™œìš©

### VectorStoreRetriever

```{python}
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# Retriever ìƒì„±
retriever = vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)

# LLM
llm = AzureChatOpenAI(
    azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
    openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    temperature=0
)

# í”„ë¡¬í”„íŠ¸
prompt = ChatPromptTemplate.from_template(
    """ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
)

# RAG ì²´ì¸
def format_docs(docs):
    return "\n\n".join([doc.page_content for doc in docs])

rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# ì‹¤í–‰
answer = rag_chain.invoke("Azure AI SearchëŠ” ë¬´ì—‡ì¸ê°€?")
print(f"ë‹µë³€: {answer}")
```

## ëŒ€ëŸ‰ ë¬¸ì„œ ì—…ë¡œë“œ

### ë°°ì¹˜ ì—…ë¡œë“œ

```{python}
def upload_documents_batch(documents, batch_size=1000):
    """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ëŒ€ëŸ‰ ë¬¸ì„œ ì—…ë¡œë“œ"""
    total_uploaded = 0
    
    for i in range(0, len(documents), batch_size):
        batch = documents[i:i+batch_size]
        
        # ì„ë² ë”© ìƒì„±
        for doc in batch:
            if "content_vector" not in doc:
                doc["content_vector"] = embeddings.embed_query(doc["content"])
        
        # ì—…ë¡œë“œ
        result = search_client.upload_documents(documents=batch)
        
        uploaded = sum(1 for item in result if item.succeeded)
        total_uploaded += uploaded
        
        print(f"ë°°ì¹˜ {i//batch_size + 1}: {uploaded}/{len(batch)} ì—…ë¡œë“œ")
    
    return total_uploaded

# ì‚¬ìš© ì˜ˆì‹œ
# large_docs = [{"id": str(i), "content": f"ë¬¸ì„œ {i}"} for i in range(5000)]
# total = upload_documents_batch(large_docs, batch_size=1000)
# print(f"ì´ {total}ê°œ ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ")
```

## ì¸ë±ìŠ¤ ê´€ë¦¬

### ì¸ë±ìŠ¤ ì‚­ì œ

```{python}
# ì¸ë±ìŠ¤ ì‚­ì œ
index_client.delete_index(os.getenv("AZURE_SEARCH_INDEX_NAME"))
print("ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ")
```

### ì¸ë±ìŠ¤ ëª©ë¡ ì¡°íšŒ

```{python}
# ëª¨ë“  ì¸ë±ìŠ¤ ì¡°íšŒ
indexes = index_client.list_indexes()

print("ì¸ë±ìŠ¤ ëª©ë¡:")
for index in indexes:
    print(f"- {index.name}")
```

### ë¬¸ì„œ ì‚­ì œ

```{python}
# íŠ¹ì • ë¬¸ì„œ ì‚­ì œ
search_client.delete_documents(documents=[{"id": "1"}, {"id": "2"}])
print("ë¬¸ì„œ ì‚­ì œ ì™„ë£Œ")
```

## ëª¨ë‹ˆí„°ë§

### ì¸ë±ìŠ¤ í†µê³„

```{python}
# ì¸ë±ìŠ¤ í†µê³„ ì¡°íšŒ
stats = search_client.get_document_count()
print(f"ì´ ë¬¸ì„œ ìˆ˜: {stats}")
```

### ê²€ìƒ‰ ì¿¼ë¦¬ ì„±ëŠ¥

```{python}
import time

# ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •
start_time = time.time()

results = vector_store.similarity_search("í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬", k=10)

duration = time.time() - start_time
print(f"ê²€ìƒ‰ ì‹œê°„: {duration:.3f}ì´ˆ")
print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
```

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

**1. ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ**
```python
# í•´ê²°: ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
try:
    index = index_client.get_index(os.getenv("AZURE_SEARCH_INDEX_NAME"))
    print(f"ì¸ë±ìŠ¤ ì¡´ì¬: {index.name}")
except Exception as e:
    print(f"ì¸ë±ìŠ¤ ì—†ìŒ: {e}")
    # ì¸ë±ìŠ¤ ìƒì„±
```

**2. ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜**
```python
# í•´ê²°: ì„ë² ë”© ëª¨ë¸ ì°¨ì› í™•ì¸
test_vector = embeddings.embed_query("í…ŒìŠ¤íŠ¸")
print(f"ì„ë² ë”© ì°¨ì›: {len(test_vector)}")

# ì¸ë±ìŠ¤ ìŠ¤í‚¤ë§ˆì˜ vector_search_dimensionsì™€ ì¼ì¹˜í•´ì•¼ í•¨
```

**3. ì—…ë¡œë“œ ì‹¤íŒ¨**
```python
# í•´ê²°: ì˜¤ë¥˜ í™•ì¸
result = search_client.upload_documents(documents=docs)
for item in result:
    if not item.succeeded:
        print(f"ì‹¤íŒ¨: {item.key} - {item.error_message}")
```

## ë¹„ìš© ìµœì í™”

### ì¸ë±ìŠ¤ í¬ê¸° ì¤„ì´ê¸°

```python
# ë¶ˆí•„ìš”í•œ í•„ë“œ ì œê±°
# searchable=Falseë¡œ ì„¤ì •í•˜ì—¬ ì „ì²´ í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ ë¹„í™œì„±í™”
SearchField(
    name="metadata",
    type=SearchFieldDataType.String,
    searchable=False,  # ì €ì¥ë§Œ í•¨
    filterable=True
)
```

### ë²¡í„° ì°¨ì› ì¶•ì†Œ

```python
# text-embedding-3-small: 1536 â†’ 512
from openai import AzureOpenAI

client = AzureOpenAI(...)

response = client.embeddings.create(
    input="í…ìŠ¤íŠ¸",
    model="text-embedding-3-small",
    dimensions=512  # 1/3 í¬ê¸°
)
```

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Azure AI Search ê°œìš”](https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search)
- [ë²¡í„° ê²€ìƒ‰](https://learn.microsoft.com/en-us/azure/search/vector-search-overview)
- [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰](https://learn.microsoft.com/en-us/azure/search/hybrid-search-overview)
- [Python SDK](https://learn.microsoft.com/en-us/python/api/overview/azure/search-documents-readme)

### LangChain
- [AzureSearch VectorStore](https://python.langchain.com/docs/integrations/vectorstores/azuresearch)

## ë‹¤ìŒ ë‹¨ê³„

ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•ì´ ì™„ë£Œë˜ì—ˆë‹¤ë©´, ì´ì œ RAG ë¡œì§ì„ êµ¬í˜„í•˜ì:

ğŸ‘‰ [05-LangChain-to-LangGraph.qmd](./05-LangChain-to-LangGraph.qmd) - LangChainì—ì„œ LangGraphë¡œ ì „í™˜