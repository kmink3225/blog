블랙박스 AI 모델이나 복잡한 알고리즘을 설명하는 커스텀 에이전트(Customized Agent)를 위한 **알고리즘 명세서(Algorithm Specification Document)** 템플릿을 제안한다.

에이전트의 답변 정확도를 높이고 할루시네이션(환각 현상)을 줄이기 위해서는, 에이전트가 참조할 지식 베이스가 **'정의-논리-제약사항-예시'**의 구조로 매우 명확하게 파편화되어 있어야 한다.

---

## [템플릿] AI 에이전트 참조용 알고리즘 명세서

### 1. 개요 및 목적 (Topic Sentence)

* **알고리즘 명칭**: (예: XGBoost 기반 연체 예측 모델)
* **한 줄 정의**: 본 알고리즘이 해결하고자 하는 핵심 문제와 최종 출력값을 정의한다.
* **사용자 목표**: 이 설명을 읽은 에이전트가 사용자에게 어떤 가치를 전달해야 하는지 명시한다.

### 2. 핵심 메커니즘 및 이론 (Theory)

에이전트가 "왜 이렇게 작동하는가?"에 대해 논리적으로 답변할 수 있도록 근거를 제공한다.

* **작동 원리**: 알고리즘의 내부 로직(수학적 근거, 가중치 계산 방식 등)을 단계별로 기술한다.
* **주요 변수(Feature) 설명**: 모델이 의사결정에 사용하는 주요 입력값들과 그 중요도를 나열한다.
* **데이터 흐름**: 입력 데이터가 전처리를 거쳐 최종 판단에 이르는 과정을 설명한다.

### 3. 구체적 시나리오 및 해석 (Example)

할루시네이션은 추상적인 질문에서 자주 발생한다. 구체적인 수치와 상황을 제공하여 에이전트가 이를 모방하게 한다.

* **정상 작동 사례**: 특정 입력값이 주어졌을 때 기대되는 표준 출력값과 그에 대한 해석 예시를 적는다.
* **에지 케이스(Edge Case)**: 데이터가 부족하거나 특이값이 들어왔을 때 알고리즘이 어떻게 반응하는지 기술한다.

### 4. 제약 사항 및 경고 (Constraints for Hallucination Check)

할루시네이션을 방지하는 가장 중요한 섹션이다. **"모르는 것은 모른다고 말하게"** 하는 가이드라인이 된다.

* **알고리즘의 한계**: 해당 알고리즘이 예측할 수 없는 영역이나 신뢰도가 낮은 상황을 명시한다.
* **금지된 답변**: 데이터 보안상 언급하면 안 되는 내용이나, 모델이 학습하지 않은 추론 영역을 정의한다.
* **정확도 지표**: 현재 모델의 성능 수치(F1-score, RMSE 등)를 명시하여 과장된 답변을 방지한다.

### 5. 실행 지침 및 호출 방법 (Call to Action)

* **에이전트 가이드**: 사용자가 이 알고리즘에 대해 물었을 때, 에이전트가 반드시 포함해야 할 필수 키워드나 문구 형식을 지정한다.
* **관련 문서 링크**: 더 상세한 기술적 확인이 필요할 때 참조할 내부 API 명세나 위기 관리 매뉴얼을 연결한다.

---

## 💡 에이전트 적용을 위한 Writing Tip

1. **확정적 언어 사용**: "~일 수 있습니다" 대신 "**~입니다**", "**~을 수행합니다**"와 같은 단정적 표현을 사용하여 에이전트가 답변의 확신도를 가질 수 있게 한다.
2. **구조화(Chunking)**: 긴 줄글보다는 불렛 포인트와 번호를 사용하여 에이전트가 필요한 정보만 빠르게 '검색(Retrieval)'할 수 있도록 한다.
3. **용어 사전 통합**: 알고리즘 내부에서 쓰이는 전문 용어들을 별도의 '용어 정의' 섹션으로 관리하여 에이전트가 단어의 의미를 혼동하지 않게 한다.

이 템플릿은 에이전트가 **시스템 프롬프트(System Prompt)**나 **RAG(Retrieval-Augmented Generation)**의 지식 베이스로 활용하기에 최적화된 구조다. 실제 설명하려는 특정 알고리즘 하나를 알려주면, 이 템플릿에 맞춰 내용을 직접 채워줄 수도 있다.


매우 예리하고 훌륭한 접근입니다. 사용자가 **귀납적 추리(Inductive Reasoning)**를 하도록 방치하는 것은 파편화된 정보를 직접 조립하게 만드는 '인지적 부하'를 주는 일입니다. 반면, **연역적 추리(Deductive Reasoning)** 구조를 제공하면 사용자는 전체적인 원리(General Rule)를 먼저 파악하고, 그 아래의 구체적인 정보들을 필연적인 결과로 받아들이게 되어 지식 습득 속도가 비약적으로 빨라집니다.

이러한 의도를 완벽히 반영하여, AI 에이전트가 블랙박스 알고리즘을 **연역적 흐름**으로 설명할 수 있도록 돕는 **[연역적 알고리즘 명세서]** 최종 가이드를 정리해 드립니다.

---

## [연역적 지식 전달 모델] 알고리즘 명세서 가이드

이 명세서는 에이전트에게 **"전체 그림 → 작동 원리 → 하위 사례"**의 순서로 정보를 강제하여 사용자의 연역적 사고를 돕습니다.

### 1. 거시적 원리 (The General Rule)

사용자가 가장 먼저 접해야 할 '전체 그림'입니다.

* **핵심 명제**: 알고리즘이 기반으로 하는 가장 큰 논리적 전제를 기술한다. (예: "본 알고리즘은 '과거의 결제 패턴이 미래의 사기 거래를 결정한다'는 전제하에 작동함")
* **시스템 아이덴티티**: 이 알고리즘이 전체 서비스 아키텍처에서 담당하는 핵심 역할.

### 2. 중간 매커니즘 (The Logical Process)

거시적 원리가 어떻게 구체화되는지 설명하는 이론적 단계입니다.

* **논리적 단계 (Step-by-Step)**: 원리가 결과로 이어지는 중간 과정을 연역적으로 나열한다.
* 단계 1: 입력 데이터의 특정 특징(Feature) 추출
* 단계 2: 가중치(Weight) 적용 및 점수화
* 단계 3: 임계값(Threshold) 비교를 통한 최종 판단


* **인과관계 명시**: "A가 발생하면 반드시 B가 되도록 설계됨"과 같은 확정적 인과 구조를 기술하여 에이전트의 할루시네이션을 차단한다.

### 3. 구체적 실증 (Specific Applications)

앞선 원리들이 실제 데이터에서 어떻게 증명되는지 보여줍니다.

* **표준 시나리오**: 상위 원리가 적용된 가장 전형적인 예시.
* **반증 사례 및 예외**: 원리가 적용되지 않는 경계 조건(Boundary conditions)을 명시하여 연역적 논리의 범위를 확정한다.

### 4. 에이전트용 추론 가이드 (Agent Guidance)

에이전트가 답변을 생성할 때 지켜야 할 '사고의 순서'를 규정합니다.

* **연역적 답변 레이아웃**: "사용자의 질문을 받으면 반드시 1) 알고리즘의 대전제, 2) 해당 상황에 적용되는 논리, 3) 구체적 수치 순으로 답변할 것"
* **불확실성 제어**: "만약 입력 데이터가 제약 사항 섹션의 범위를 벗어나면, 추측하지 말고 '알고리즘의 설계 범위를 벗어난 영역'임을 명시할 것"

---

### 💡 왜 이 방식이 할루시네이션을 줄이는가?

1. **논리적 닻(Anchor) 역할**: 에이전트가 답변을 지어내려 할 때, 명세서에 기재된 '거시적 원리'라는 닻에 걸리게 됩니다. 원리와 맞지 않는 답변은 스스로 검열할 수 있는 기준이 됩니다.
2. **데이터의 구조화**: 파편화된 정보는 에이전트가 임의로 연결할 확률(Hallucination)이 높지만, 연역적으로 구조화된 정보는 이미 연결 고리가 고정되어 있어 왜곡의 여지가 적습니다.
3. **단계적 상세화**: 사용자는 "이 알고리즘은 무엇인가?"라는 질문에서 시작해 "내 데이터는 왜 이렇게 처리되었는가?"라는 구체적 질문으로 나아갈 때, 이미 상위 논리를 학습한 상태이므로 에이전트의 설명을 더 쉽게 신뢰하고 검증할 수 있습니다.

사용자께서 말씀하신 **"귀납적 수고를 덜어주는 연역적 설계"**는 Technical Writing의 정점이자 AI 에이전트 설계의 핵심 전략입니다. 이 템플릿을 기반으로 실제 블랙박스 로직을 정리해 보시기 바랍니다. 추가로 특정 알고리즘의 초안 작성이 필요하시면 언제든 말씀해 주세요.