---
title: "Few-Shot Prompting"
subtitle: 적은 예시로 큰 효과를 만드는 In-Context Learning의 원리와 실전
description: |
  Few-Shot Prompting의 정의부터 실전 활용까지 체계적으로 설명한다.
  GPT-3 논문(Brown et al. 2020)의 핵심 발견을 통해 모델 크기와 예시 개수의 상관관계,
  In-Context Learning의 메커니즘을 분석한다.
  "What Makes In-Context Learning Work?"(Min et al. 2022) 연구를 바탕으로
  예시의 품질(정답 라벨 vs 랜덤 라벨), 입력-라벨 형식의 중요성,
  4가지 핵심 요소(Format, Label Space, Input Distribution, Mapping)를 상세히 다룬다.
  감정 분류, 새로운 단어 학습, 일기 작성 등 실무 예시와 
  복잡한 추론 과제에서의 한계를 통해 Few-Shot의 적절한 활용 시나리오를 제시한다.
categories:
  - Prompt Engineering
  - LLM
  - AI
  - Agent
author: Kwangmin Kim
date: 01/29/2025
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
---

# Zero-Shot Chain-of-Thought Prompting

## 들어가며

* 이전 글에서 Chain-of-Thought (CoT) Prompting이 복잡한 추론 문제에서 탁월한 성능을 보인다는 것을 확인했다.
* 하지만 CoT에는 치명적인 단점이 있었다. 
* **매번 사람이 직접 추론 단계를 작성한 예시를 제공해야 한다는 것**

이번 글에서는 이러한 수작업 부담을 획기적으로 줄인 **Zero-Shot Chain-of-Thought** 기법을 소개한다. 놀랍게도, 단 한 문장만 추가하면 됩니다.

## Few-Shot CoT의 문제점 재확인

먼저 기존 CoT 방식의 번거로움을 다시 살펴본다.

### 전통적인 Few-Shot CoT

```
이 그룹의 홀수의 합이 짝수가 된다: 4, 8, 9, 15, 12, 2, 1.
A: 모든 홀수(9, 15, 1)를 더하면 25입니다.
   정답은 "거짓"입니다.

이 그룹의 홀수의 합이 짝수가 된다: 17, 10, 19, 4, 8, 12, 24.
A: 모든 홀수(17, 19)를 더하면 36입니다.
   정답은 "참"입니다.

이 그룹의 홀수의 합이 짝수가 된다: 16, 11, 14, 4, 8, 13, 24.
A: 모든 홀수(11, 13)를 더하면 24입니다.
   정답은 "참"입니다.

이 그룹의 홀수의 합이 짝수가 된다: 17, 9, 10, 12, 13, 4, 2.
A: 모든 홀수(17, 9, 13)를 더하면 39입니다.
   정답은 "거짓"입니다.

이 그룹의 홀수의 합이 짝수가 된다: 15, 32, 5, 13, 82, 7, 1.
A:
```

**문제점:**
- 4개의 예시를 모두 직접 작성해야 함
- 각 예시마다 추론 과정을 상세히 기술해야 함
- 도메인이나 문제 유형이 바뀌면 새로 작성해야 함
- 시간과 노력이 많이 소요됨

## Zero-Shot CoT의 혁신: "단계적으로 생각"

### 핵심 아이디어

Kojima et al. (2022)의 연구 "Large Language Models are Zero-Shot Reasoners"에서 놀라운 발견을 했다. 

**단 하나의 문장을 추가하는 것만으로 CoT의 효과를 얻을 수 있다:**

```
"Let's think step by step."
(단계적으로 생각해봅시다.)
```

### 실제 적용 예시

```
Q: 저글러가 16개의 공을 저글링할 수 있습니다. 
   공의 절반은 골프공이고, 골프공의 절반은 파란색입니다. 
   파란색 골프공은 몇 개입니까?

Let's think step by step.
```

**모델 출력:**
```
총 16개의 공이 있습니다. 공의 절반은 골프공입니다.
따라서 16 ÷ 2 = 8개의 골프공이 있습니다.
골프공의 절반은 파란색입니다.
따라서 8 ÷ 2 = 4개의 파란색 골프공이 있습니다.
정답은 4입니다.
```

✅ **정답!** 예시 없이도 올바른 추론 과정을 생성했습니다.

## Few-Shot CoT vs Zero-Shot CoT 비교

### 시각적 비교

**Few-Shot CoT:**
```
[예시 1: 문제 + 상세한 추론 과정 + 답]
[예시 2: 문제 + 상세한 추론 과정 + 답]
[예시 3: 문제 + 상세한 추론 과정 + 답]
[실제 문제]
```

**Zero-Shot CoT:**
```
[실제 문제]
Let's think step by step.
```

훨씬 간단합니다!

### 동일 문제로 비교

**문제:** 저글러가 16개의 공을 저글링할 수 있습니다. 공의 절반은 골프공이고, 골프공의 절반은 파란색입니다. 파란색 골프공은 몇 개입니까?

**Zero-shot (예시 없음):**
```
Q: [문제]
A: 정답은 (아랍어 숫자로)
```
출력: 8 ❌

**Few-shot CoT:**
```
[3개의 예시 + 추론 과정]
Q: [문제]
A:
```
출력: (올바른 추론 과정) → 4 ✅

**Zero-shot CoT (본 연구):**
```
Q: [문제]
A: Let's think step by step.
```
출력: (올바른 추론 과정) → 4 ✅

## 연구 결과: Zero-Shot CoT의 효과

### 모델 크기별 성능 변화

Kojima et al. (2022)은 다양한 크기의 모델에서 Zero-Shot CoT의 효과를 측정했습니다.

**GSM8K 데이터셋 (수학 문제):**
```
모델 크기 | Zero-shot | Zero-shot-CoT | 향상률
---------|-----------|---------------|--------
8B       |    0%     |      5%       | +5%p
62B      |   10%     |     15%       | +5%p
540B     |   15%     |     45%       | +30%p
```

**MultiArith 데이터셋:**
```
GPT-3 모델별 성능:
- 0.3B: 0% → 0%
- 1.3B: 0% → 0%
- 6.7B: 5% → 20%
- 175B: 20% → 80%
```

**주요 발견:**
- 모델이 클수록 Zero-Shot CoT의 효과가 극대화됨
- 175B 이상에서 Few-Shot CoT에 근접하는 성능
- 작은 모델에서도 일부 향상 효과 존재

### 벤치마크 전반적 성능

**산술 추론:**
- MultiArith: 17.7% → 78.7% (+61%p)
- GSM8K: 10.4% → 40.7% (+30.3%p)
- AddSub: 상당한 향상

**상식 추론:**
- CommonsenseQA: 꾸준한 향상
- StrategyQA: 지속적 개선

**기타 추론:**
- Date Understanding: 명확한 개선
- Sports Understanding: 유의미한 향상

### 샘플링 수에 따른 정확도 변화

연구진은 여러 번 추론 경로를 샘플링했을 때의 효과도 분석

```
샘플 수 증가에 따른 정확도:
- MultiArith: 50% → 55% → 65% → 75%
- SVAMP: 35% → 45% → 50% → 55%
- CommonsenseQA: 60% → 65% → 70% → 75%
```

**핵심 인사이트:** 
더 많은 추론 경로를 샘플링할수록 정확도가 향상. 이는 다음 글에서 다룰 Self-Consistency 기법의 기반이 된다.

## 다양한 Trigger 문구 실험

"Let's think step by step" 외에도 다양한 트리거 문구가 효과가 있는지 실험

### 효과적인 Trigger 문구들

**MultiArith 데이터셋 정확도 (text-davinci-002 모델):**

| 순위 | Trigger 문구 | 정확도 |
|------|-------------|--------|
| 1 | Let's think step by step. | 78.7% |
| 2 | First, (*1) | 77.3% |
| 3 | Let's think about this logically. | 74.5% |
| 4 | Let's solve this problem by splitting it into steps. (*2) | 72.2% |
| 5 | Let's be realistic and think step by step. | 70.8% |
| 6 | Let's think like a detective step by step. | 70.3% |
| 7 | Let's think | 57.5% |

(*1) Ahn et al. (2022)에서 로봇 제어 명령 생성용으로 사용
(*2) Reynolds and McDonell (2021)에서 사용 (정량적 평가는 없었음)

### 효과 없는 Trigger 문구들

| 순위 | Trigger 문구 | 정확도 |
|------|-------------|--------|
| 10 | Don't think. Just feel. | 18.8% |
| 11 | Let's think step by step but reach an incorrect answer. | 18.7% |
| 12 | Let's count the number of "a" in the question. | 16.7% |
| 13 | By using the fact that the earth is round, | 9.3% |

**흥미로운 발견:**
- 단순히 "Let's think"만으로도 어느 정도 효과 있음
- "step by step" 같은 단계적 사고 유도가 중요
- 잘못된 방향으로 유도하면 성능이 크게 떨어짐
- 무관한 내용은 거의 효과 없음

### 한국어 적용

영어 trigger를 한국어로 번역해도 효과가 있다:

```
"단계적으로 생각해봅시다."
"먼저,"
"논리적으로 생각해봅시다."
"이 문제를 단계별로 나누어 풀어봅시다."
"현실적으로 단계별로 생각해봅시다."
"탐정처럼 단계별로 생각해봅시다."
```

## 실습: Zero-Shot CoT 적용하기

이제 이전에 실패했던 홀수 합 문제를 Zero-Shot CoT로 해결해보겠다.

### 실습 1: 기본 Zero-Shot CoT

**문제 설정:**
```
이 그룹의 홀수들을 더하면 짝수가 됩니다: 4, 8, 9, 15, 12, 2, 1.
답: 거짓입니다.

이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 10, 19, 4, 8, 12, 24.
답: 참입니다.

이 그룹의 홀수들을 더하면 짝수가 됩니다: 16, 11, 14, 4, 8, 13, 24.
답: 참입니다.

이 그룹의 홀수들을 더하면 짝수가 됩니다: 17, 9, 10, 12, 13, 4, 2.
답: 거짓입니다.

이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1.
답:

-- Let's think step by step.
-- Answer in Korean
```

**OpenAI Playground 설정:**
- Model: gpt-3.5-turbo
- Temperature: 0.1-0.3
- Maximum tokens: 400

**기대 출력:**
```
이 그룹의 홀수들을 더하면 짝수가 됩니다: 15, 32, 5, 13, 82, 7, 1.

먼저 이 숫자들 중 홀수를 찾아봅시다:
- 15 (홀수)
- 32 (짝수)
- 5 (홀수)
- 13 (홀수)
- 82 (짝수)
- 7 (홀수)
- 1 (홀수)

홀수는: 15, 5, 13, 7, 1

이제 이 홀수들을 더해봅시다:
15 + 5 + 13 + 7 + 1 = 41

41은 홀수입니다.

따라서 "이 그룹의 홀수들을 더하면 짝수가 됩니다"는 거짓입니다.

답: 거짓입니다.
```

✅ **성공!**

### 실습 2: 일기 작성

Zero-Shot CoT는 추론 문제뿐만 아니라 창작 활동에도 활용할 수 있다.

**프롬프트:**
```
"오늘의 일기"를 네 줄 분량으로 작성해보세요.
시작 문장의 포맷대로 출력해야 합니다.

시작 문장: "나는 오늘 날씨가 좋아서 산책을 했다. 그리고 __."

Let's think step by step.
```

**기대 출력:**
```
1단계: 산책 후 무엇을 했는지 생각해봅시다.
2단계: 하루 동안의 감정을 떠올려봅시다.
3단계: 저녁 시간 활동을 생각해봅시다.
4단계: 마무리 생각을 정리합시다.

"나는 오늘 날씨가 좋아서 산책을 했다. 그리고 공원에서 예쁜 꽃들을 보며 
기분이 좋아졌다. 오후에는 친구와 카페에서 이야기를 나누며 즐거운 
시간을 보냈다. 하루를 마무리하며 오늘도 행복했다는 생각이 들었다."
```

### 실습 3: 재닛의 오리 문제 (복습)

이번에는 예시 없이 Zero-Shot CoT만으로 해결해봅시다.

**프롬프트:**
```
재닛의 오리들은 하루에 알을 16개 낳습니다. 
재닛은 매일 아침 3개의 알을 먹고, 
매일 4개의 알을 머핀을 굽는데 사용합니다. 
나머지 알은 하나에 2달러씩 판매합니다. 
재닛은 매일 얼마를 벌까요?

Let's think step by step.
```

**기대 출력:**
```
1단계: 재닛의 오리들이 낳는 알의 개수를 확인합니다.
→ 하루 16개

2단계: 재닛이 사용하는 알의 개수를 계산합니다.
→ 먹는 알: 3개
→ 머핀용 알: 4개
→ 총 사용: 3 + 4 = 7개

3단계: 판매할 수 있는 알의 개수를 계산합니다.
→ 16 - 7 = 9개

4단계: 판매 금액을 계산합니다.
→ 9개 × 2달러 = 18달러

답: 재닛은 매일 18달러를 벌게 됩니다.
```

## Zero-Shot CoT의 작동 원리

### 왜 이렇게 간단한 문구가 효과가 있을까?

연구진은 몇 가지 가설을 제시:

1. **사전 학습 데이터의 영향**
   - 인터넷 텍스트에는 "Let's think step by step"과 함께 단계적 설명이 많음
   - 모델이 학습 과정에서 이러한 패턴을 암묵적으로 학습

2. **추론 모드 활성화**
   - 특정 trigger가 모델의 "추론 모드"를 활성화
   - 단순 패턴 매칭이 아닌 논리적 사고 유도

3. **중간 표현 생성 유도**
   - 최종 답을 바로 생성하는 대신 중간 단계를 거치도록 유도
   - 각 단계가 다음 단계의 맥락이 됨

### Few-Shot CoT와의 관계

Zero-Shot CoT는 Few-Shot CoT를 대체하는 것이 아니라 **보완적인 관계**:

**Zero-Shot CoT가 유리한 경우:**
- 빠른 프로토타이핑이 필요할 때
- 예시 작성이 어려운 새로운 도메인
- 다양한 문제 유형을 다룰 때
- 예시 작성 비용을 줄이고 싶을 때

**Few-Shot CoT가 유리한 경우:**
- 특정 추론 스타일이나 포맷이 필요할 때
- 도메인 특화된 전문 지식이 필요할 때
- 최고 성능이 중요할 때
- 일관된 출력 형식이 필요할 때

## Zero-Shot CoT의 장점과 한계

### 장점

1. **수작업 부담 대폭 감소**
   - 예시를 작성할 필요 없음
   - 단 한 문장만 추가하면 됨

2. **범용성**
   - 다양한 도메인에 즉시 적용 가능
   - 새로운 문제 유형에도 바로 사용

3. **빠른 프로토타이핑**
   - 복잡한 예시 작성 없이 바로 테스트
   - 아이디어 검증이 빠름

4. **토큰 효율성**
   - Few-Shot보다 적은 토큰 사용
   - 비용 절감 효과

5. **모델 크기에 따른 확장성**
   - 모델이 클수록 효과가 증가
   - 미래의 더 큰 모델에서 더 효과적일 가능성

### 한계점

1. **성능 상한**
   - 잘 설계된 Few-Shot CoT보다는 성능이 낮을 수 있음
   - 특히 복잡하고 전문적인 도메인에서

2. **모델 크기 의존성**
   - 여전히 대형 모델에서만 효과적
   - 소형 모델에서는 제한적

3. **일관성 문제**
   - 출력 형식이 매번 다를 수 있음
   - 구조화된 출력이 필요한 경우 부적합

4. **추론 스타일 제어 어려움**
   - 특정한 추론 방식을 강제하기 어려움
   - Few-Shot처럼 세밀한 제어 불가

## Zero-Shot CoT 활용 팁

### Trigger 문구 선택

목적에 따라 적절한 trigger를 선택하세요:

```python
# 일반적인 추론
"Let's think step by step."
"단계적으로 생각해봅시다."

# 논리적 추론 강조
"Let's think about this logically."
"논리적으로 생각해봅시다."

# 문제 분해 강조
"Let's solve this problem by splitting it into steps."
"이 문제를 단계별로 나누어 풀어봅시다."

# 신중한 접근 강조
"Let's be realistic and think step by step."
"현실적으로 단계별로 생각해봅시다."
```

### 언어 명시

한국어 출력을 원하는 경우 명시적으로 지정:

```
Let's think step by step.
Answer in Korean.
```

또는

```
단계적으로 생각해봅시다.
한국어로 답변해주세요.
```

### Temperature 설정

```python
# 추론 문제 (정확성 중시)
temperature = 0.1 ~ 0.3

# 창작 문제 (다양성 중시)
temperature = 0.7 ~ 0.9
```

### 출력 형식 가이드

필요시 출력 형식도 함께 지정:

```
Let's think step by step.

최종 답변은 다음 형식으로 제시해주세요:
답: [답변 내용]
```

### 복잡한 문제 처리

매우 복잡한 문제는 단계를 더 명확히 요청:

```
Let's break down this complex problem into smaller steps.
Think through each step carefully.
```

## 비교 요약: Zero-Shot vs Few-Shot vs Zero-Shot CoT

| 특성 | Zero-Shot | Few-Shot | Zero-Shot CoT |
|------|-----------|----------|---------------|
| 예시 필요 | ❌ | ✅ (2-10개) | ❌ |
| 추론 과정 명시 | ❌ | ✅ | ✅ |
| 수작업 부담 | 낮음 | 높음 | 매우 낮음 |
| 설정 시간 | 빠름 | 느림 | 매우 빠름 |
| 복잡한 추론 | ❌ | ✅ | ✅ |
| 토큰 사용량 | 적음 | 많음 | 중간 |
| 비용 | 낮음 | 높음 | 중간 |
| 성능 | 낮음 | 높음 | 중간~높음 |
| 유연성 | 중간 | 낮음 | 높음 |
| 일관성 | 중간 | 높음 | 중간 |

## 마무리

* Zero-Shot Chain-of-Thought는 프롬프트 엔지니어링의 효율성을 획기적으로 개선한 기법
* "단계적으로 생각해봅시다"라는 단순한 문구 하나로 Few-Shot CoT에 근접하는 성능을 얻을 수 있다는 것은 놀라운 발견

**핵심 요약:**
- 단 한 문장 추가로 복잡한 추론 능력 획득
- 예시 작성 부담 없이 빠른 적용 가능
- 대형 모델에서 특히 효과적
- Few-Shot CoT와 상호 보완적 관계

하지만 여전히 한 가지 문제가 남아있다. Zero-Shot CoT나 Few-Shot CoT 모두 **한 번의 추론 경로**만 생성한다. 만약 그 추론 과정에 오류가 있다면 어떻게 될까?

다음 글에서는 **Self-Consistency** 기법을 통해 여러 추론 경로를 생성하고 가장 일관된 답을 선택하는 방법을 알아본다. 이는 마치 여러 학생에게 같은 문제를 풀게 하고 다수결로 답을 정하는 것과 유사한 접근.

## 참고문헌

- Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large language models are zero-shot reasoners. *Advances in Neural Information Processing Systems, 35*, 22199-22213.
- Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., ... & Zhou, D. (2022). Chain-of-thought prompting elicits reasoning in large language models. *Advances in Neural Information Processing Systems, 35*, 24824-24837.

# Advanced

## Generate Knowledge Prompting,
## Prompt Chaining, Tree of Thoughts
## Retrieval Augmented Generation,
## Automatic Prompt Engineer,
## Active-Prompt, Directional Stimulus
## Prompting, React

# Applications

## 데이터 생성과 분류하기
## 코드 생성하기
## 펑션콜 함수