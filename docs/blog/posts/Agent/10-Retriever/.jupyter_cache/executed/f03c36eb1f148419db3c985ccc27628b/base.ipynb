{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933205da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\10-Retriever':\n",
    "  os.chdir(r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\10-Retriever')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e3bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c20860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH10-Retriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef1d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c51c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[5].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5823f263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "import uuid\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"small_bigger_chunks\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# 두개의 생성된 id를 확인합니다.\n",
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d671062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecursiveCharacterTextSplitter 객체를 생성합니다.\n",
    "parent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n",
    "\n",
    "# 더 작은 청크를 생성하는 데 사용할 분할기\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea83cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    # 현재 문서의 ID를 가져옵니다.\n",
    "    _id = doc_ids[i]\n",
    "    # 현재 문서를 하위 문서로 분할\n",
    "    parent_doc = parent_text_splitter.split_documents([doc])\n",
    "\n",
    "    for _doc in parent_doc:\n",
    "        # metadata에 문서 ID 를 저장\n",
    "        _doc.metadata[id_key] = _id\n",
    "    parent_docs.extend(parent_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40cfe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 Parent 문서의 메타데이터를 확인합니다.\n",
    "parent_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1bb6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # 현재 문서의 ID를 가져옵니다.\n",
    "    _id = doc_ids[i]\n",
    "    # 현재 문서를 하위 문서로 분할\n",
    "    child_doc = child_text_splitter.split_documents([doc])\n",
    "    for _doc in child_doc:\n",
    "        # metadata에 문서 ID 를 저장\n",
    "        _doc.metadata[id_key] = _id\n",
    "    child_docs.extend(child_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52a8d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 Child 문서의 메타데이터를 확인합니다.\n",
    "child_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43fa6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"분할된 parent_docs의 개수: {len(parent_docs)}\")\n",
    "print(f\"분할된 child_docs의 개수: {len(child_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd43c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 저장소에 parent + child 문서를 추가\n",
    "retriever.vectorstore.add_documents(parent_docs)\n",
    "retriever.vectorstore.add_documents(child_docs)\n",
    "\n",
    "# docstore 에 원본 문서를 저장\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2feb9d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore의 유사도 검색을 수행합니다.\n",
    "relevant_chunks = retriever.vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")\n",
    "print(f\"검색된 문서의 개수: {len(relevant_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60646450",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in relevant_chunks:\n",
    "    print(chunk.page_content, end=\"\\n\\n\")\n",
    "    print(\">\" * 100, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8751d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "print(f\"검색된 문서의 개수: {len(relevant_docs)}\", end=\"\\n\\n\")\n",
    "print(\"=\" * 100, end=\"\\n\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5de6a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 MMR(Maximal Marginal Relevance)로 설정\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088cd141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity_score_threshold로 설정\n",
    "retriever.search_type = SearchType.similarity_score_threshold\n",
    "retriever.search_kwargs = {\"score_threshold\": 0.3}\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d99197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# 검색 유형을 similarity로 설정, k값을 1로 설정\n",
    "retriever.search_type = SearchType.similarity\n",
    "retriever.search_kwargs = {\"k\": 1}\n",
    "\n",
    "# 관련 문서 전체를 검색\n",
    "print(len(retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "135f7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일을 로드하고 텍스트를 분할하기 위한 라이브러리 임포트\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 파일 로더 초기화\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
    "\n",
    "# PDF 파일 로드 및 텍스트 분할 실행\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# 분할된 문서의 개수 출력\n",
    "print(f\"분할된 문서의 개수: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fdf4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "summary_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 문서 요약을 위한 프롬프트 템플릿 생성\n",
    "    | ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert in summarizing documents in Korean.\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Summarize the following documents in 3 sentences in bullet points format.\\n\\n{doc}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # OpenAI의 ChatGPT 모델을 사용하여 요약 생성\n",
    "    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd7174b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 배치 처리\n",
    "summaries = summary_chain.batch(split_docs, {\"max_concurrency\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a77e62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a01364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 문서의 내용을 출력합니다.\n",
    "print(split_docs[33].page_content, end=\"\\n\\n\")\n",
    "# 요약을 출력합니다.\n",
    "print(\"[요약]\")\n",
    "print(summaries[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00f14f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# 요약 정보를 저장할 벡터 저장소를 생성합니다.\n",
    "summary_vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# 부모 문서를 저장할 저장소를 생성합니다.\n",
    "store = InMemoryStore()\n",
    "\n",
    "# 문서 ID를 저장할 키 이름을 지정합니다.\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# 검색기를 초기화합니다. (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=summary_vectorstore,  # 벡터 저장소\n",
    "    byte_store=store,  # 바이트 저장소\n",
    "    id_key=id_key,  # 문서 ID 키\n",
    ")\n",
    "# 문서 ID를 생성합니다.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5909fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    # 요약된 내용을 페이지 콘텐츠로 하고, 문서 ID를 메타데이터로 포함하는 Document 객체를 생성합니다.\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "203c46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약본의 문서의 개수\n",
    "len(summary_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "487f1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(\n",
    "    summary_docs\n",
    ")  # 요약된 문서를 벡터 저장소에 추가합니다.\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6c3fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검색을 수행합니다.\n",
    "result_docs = summary_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "558ff885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개의 결과 문서를 출력합니다.\n",
    "print(result_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7477eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(\"삼성전자가 만든 생성형 AI 의 이름은?\")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "866acd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",  # 함수의 이름을 지정합니다.\n",
    "        \"description\": \"Generate hypothetical questions\",  # 함수에 대한 설명을 작성합니다.\n",
    "        \"parameters\": {  # 함수의 매개변수를 정의합니다.\n",
    "            \"type\": \"object\",  # 매개변수의 타입을 객체로 지정합니다.\n",
    "            \"properties\": {  # 객체의 속성을 정의합니다.\n",
    "                \"questions\": {  # 'questions' 속성을 정의합니다.\n",
    "                    \"type\": \"array\",  # 'questions'의 타입을 배열로 지정합니다.\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },  # 배열의 요소 타입을 문자열로 지정합니다.\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],  # 필수 매개변수로 'questions'를 지정합니다.\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78ba15df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "hypothetical_query_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # 아래 문서를 사용하여 답변할 수 있는 가상의 질문을 정확히 3개 생성하도록 요청합니다. 이 숫자는 조정될 수 있습니다.\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. \"\n",
    "        \"Potential users are those interested in the AI industry. Create questions that they would be interested in. \"\n",
    "        \"Output should be written in Korean:\\n\\n{doc}\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=\"gpt-4o-mini\").bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    # 출력에서 \"questions\" 키에 해당하는 값을 추출합니다.\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae470d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 문서에 대해 체인을 실행합니다.\n",
    "hypothetical_query_chain.invoke(split_docs[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc1342db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 목록에 대해 가설 질문을 배치 생성\n",
    "hypothetical_questions = hypothetical_query_chain.batch(\n",
    "    split_docs, {\"max_concurrency\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1b574b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_questions[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c1b4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자식 청크를 인덱싱하는 데 사용할 벡터 저장소\n",
    "hypothetical_vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# 부모 문서의 저장소 계층\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "# 검색기 (시작 시 비어 있음)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=hypothetical_vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]  # 문서 ID 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6498389",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_docs = []\n",
    "# hypothetical_questions 저장\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend(\n",
    "        # 질문 리스트의 각 질문에 대해 Document 객체를 생성하고, 메타데이터에 해당 질문의 문서 ID를 포함시킵니다.\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6669d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothetical_questions 문서를 벡터 저장소에 추가합니다.\n",
    "retriever.vectorstore.add_documents(question_docs)\n",
    "\n",
    "# 문서 ID와 문서를 매핑하여 문서 저장소에 저장합니다.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4876445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사한 문서를 벡터 저장소에서 검색합니다.\n",
    "result_docs = hypothetical_vectorstore.similarity_search(\n",
    "    \"삼성전자가 만든 생성형 AI 의 이름은?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "819c11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 검색 결과를 출력합니다.\n",
    "for doc in result_docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb89a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련된 문서를 검색하여 가져옵니다.\n",
    "retrieved_docs = retriever.invoke(result_docs[1].page_content)\n",
    "\n",
    "# 검색된 문서를 출력합니다.\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}