---
title: "긴 문맥 재정렬(LongContextReorder)"
subtitle: 검색기
description: |
  문서 검색을 위한 다양한 Retriever 패턴과 최적화 기법을 다룬다.
categories:
  - AI
  - RAG
  - LangChain
author: Kwangmin Kim
date: 12/31/2024
format: 
  html:
    code-fold: true
    toc: true
    number-sections: true
draft: False
execute:
    eval: false
---

## Lost in the Middle 현상

### 문제 정의

RAG 시스템에서 벡터 검색을 수행하면 일반적으로 유사도 점수에 따라 문서가 내림차순으로 정렬된다. 그러나 검색된 문서가 10개 이상일 때, 단순히 유사도 순서대로 LLM에 전달하는 것이 최선의 전략은 아니다.

### 핵심 발견

**성능 저하 현상**
- 모델 아키텍처와 무관하게 10개 이상의 문서를 입력할 경우 성능이 상당히 저하된다
- 특정 훈련 방식(Instruction Tuning 등)과 관계없이 모든 LLM에서 공통적으로 나타난다

**원인: 위치 편향 (Positional Bias)**

LLM은 시작과 끝 토큰에 더 높은 주의 가중치(Attention Weight)를 할당하는 학습된 편향을 가지고 있다. 이는 Transformer의 Self-Attention 메커니즘 학습 과정에서 형성된다.

**학습된 편향의 형성 과정**

1. **초기 상태**: Transformer는 초기에 단어 간의 관계만 학습한다
2. **편향 학습**: 학습 데이터셋에서 **핵심 정보가 시작과 끝에 자주 위치**했기 때문에 위치적 편향이 형성된다
3. **파라미터 조정**: 
   - 시작 토큰의 $\text{Q}$ (Query)가 다른 토큰의 $\text{K}$ (Key)와 강한 유사도를 갖도록 학습
   - 끝 토큰의 $\text{K}$ 가 다른 토큰의 $\text{Q}$ 와 강한 유사도를 갖도록 학습
4. **결과**: 중간 위치 토큰은 상대적으로 낮은 주의 가중치를 받게 되어 **'Lost in the Middle'** 현상 발생 

**은닉 표현 공간에서의 정보 경쟁**

중간 위치의 정보가 손실되는 이유는 벡터 공간의 제약에서 비롯된다.

1. **벡터화 한계**: 모든 정보를 고정 크기 벡터로 압축해야 하는 제약
2. **신호 희석 (Signal Dilution)**: 
   - 중간 위치의 관련 정보는 앞뒤 토큰들로부터의 주의 신호와 경쟁한다
   - 은닉 표현 공간에서 노이즈 정보에 의해 **희석**되거나 **덮어쓰인다**
   - 결과적으로 모델이 해당 정보를 "잊어버린" 것처럼 동작한다

**학습 데이터의 영향**

대부분의 잘 설계된 글은 중요한 정보를 시작(서론)이나 끝(결론)에 배치한다. LLM은 이러한 패턴을 내재화하여 위치 기반 휴리스틱을 학습하게 된다.

### 실무적 함의

**문제 상황**
- 쿼리와 관련된 핵심 문서가 컨텍스트 중간에 위치할 경우 LLM의 답변 정확도가 크게 저하된다
- 모델이 제공된 문서를 무시하고 사전 학습 지식에만 의존하는 경향이 나타난다

**해결 방안**
- **문서 재정렬 (Re-ordering)**: 관련성 높은 문서를 시작과 끝에 배치
- **재순위화 (Re-ranking)**: 검색 후 추가 모델로 순위 재조정
- **LongContextReorder**: 중간 문서를 시작/끝으로 교대 배치하는 LangChain 기법

## 관련 연구: Lost in the Middle

### 논문 개요

[Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172) (Liu et al., 2023)

이 논문은 최근 언어 모델들이 긴 컨텍스트를 입력받을 수 있음에도 불구하고, 컨텍스트 내 정보를 얼마나 효과적으로 활용하는지를 체계적으로 분석한 연구다.

**핵심 발견**: LLM이 문맥 중간에 위치한 정보를 검색할 때 성능이 현저히 저하되는 **'Lost in the Middle'** 현상을 발견했다.
### 실험 설계

연구팀은 **멀티 문서 질의응답(Multi-Document QA)**과 **키-값 검색(Key-Value Retrieval)** 두 가지 작업을 설계하여 모델 성능을 평가했다.

**주요 발견**

1. **정보 위치에 따른 성능 저하**
   - 관련 정보의 위치가 변경될 때 언어 모델의 성능이 크게 저하된다
   - 현재 LLM은 긴 입력 컨텍스트의 정보를 강건하게(robustly) 활용하지 못한다

2. **위치별 성능 패턴**
   - 성능 순서: **앞 부분 > 뒷 부분 > 중간 부분**
   - 시작(Beginning) 또는 끝(End) 위치: 최고 성능
   - 중간(Middle) 위치: 현저한 성능 저하

3. **범용적 현상**
   - Long Context를 명시적으로 지원하는 모델(GPT-4, Claude 등)에서도 동일하게 관찰된다
   - 모델 크기, 아키텍처와 무관하게 공통적으로 나타난다
### 평가 방법론

**실험 설계 원칙**: 관련 정보의 **위치를 체계적으로 변화**시키면서 성능을 측정한다.

**작업 1: 다중 문서 질의응답 (Multi-Document QA)**

목적: 여러 문서 중에서 정답을 포함한 문서를 식별하고 정확한 답변을 추출하는 능력을 평가한다.

- **데이터셋**: Natural Questions, HotpotQA 등 기존 QA 벤치마크 활용
- **컨텍스트 구성**:
  - **관련 문서 (Relevant Document)**: 질문에 대한 정답 포함
  - **방해 문서 (Distractor Documents)**: 무작위로 선택된 비관련 문서들
  - 두 종류를 결합하여 매우 긴 컨텍스트를 생성한다

**작업 2: 키-값 검색 (Key-Value Retrieval)**

목적: 긴 입력에서 특정 키에 해당하는 값을 정확히 추출하는 능력을 평가한다.

- **컨텍스트 구성**: 수많은 무작위 키-값 쌍으로 구성
- **평가 방식**: 
  1. 모델에게 특정 키 제시
  2. 해당 키와 정확히 일치하는 값을 출력하는지 확인
  3. 정확도(Exact Match) 측정
**'Lost in the Middle' 현상 측정 프로토콜**

두 작업 모두에서 관련 정보의 위치를 체계적으로 조작하여 성능을 측정한다.

1. **관련 정보 추출**
   - QA: 정답이 포함된 문서
   - 키-값 검색: 질문과 관련된 키-값 쌍

2. **위치 삽입 (Position Shifting)**
   - 전체 컨텍스트의 다양한 위치에 삽입한다
   - 위치: 시작(Index 0), 1/4 지점, 중간(Middle), 3/4 지점, 끝(Index N)

3. **성능 측정**
   - 각 위치별로 정답 정확도(Accuracy) 측정
   - 위치에 따른 성능 곡선 분석

### 논문의 기여

**학술적 기여**
1. LLM이 긴 컨텍스트를 처리하는 메커니즘에 대한 실증적 분석을 제공한다
2. Long Context LLM 성능 평가를 위한 새로운 벤치마크 프로토콜을 제시한다
3. 위치 편향이라는 LLM의 근본적 한계를 밝혔다

**실무적 시사점**

논문은 **문서 재정렬(Re-ordering)** 전략을 제안한다:
- 중간 부분의 문서를 시작과 끝으로 교대 배치한다
- 가장 관련성 높은 문서를 시작과 끝에 위치시킨다
- LangChain의 `LongContextReorder`가 이 전략을 구현한 것이다

### 실험 결과 요약

**위치별 성능 패턴**

| 관련 정보 위치 | 예상 성능 | 실험 결과 | 성능 저하 정도 |
|:--------------|:---------|:---------|:--------------|
| **시작 (Beginning)** | 높음 | ✅ 최고 성능 (90-95%) | - |
| **1/4 지점** | 중간 | 중간 성능 (70-80%) | 약 15% 저하 |
| **중간 (Middle)** | 낮음 | ❌ **최저 성능 (50-60%)** | **최대 40% 저하** |
| **3/4 지점** | 중간 | 중간 성능 (75-85%) | 약 10% 저하 |
| **끝 (End)** | 높음 | ✅ 높은 성능 (85-90%) | 약 5% 저하 |

**핵심 인사이트**
- 시작 위치가 가장 높은 성능을 보인다
- 중간 위치는 최대 40%의 성능 저하가 발생한다
- 끝 위치도 높은 성능을 보이지만 시작보다는 약간 낮다

### 해결 방안: 문서 재정렬

이 문제를 해결하기 위해 검색된 문서의 순서를 전략적으로 재배열하여 LLM에 입력한다.


## 실습: LongContextReorder 적용

### 환경 설정

이 실습에서는 다음을 수행한다:
1. `Chroma` 벡터 저장소로 텍스트 데이터를 저장하고 검색한다
2. 일반 검색 결과와 재정렬된 결과를 비교한다
3. RAG 체인에 `LongContextReorder`를 통합한다

```{python}
# API 키를 환경변수로 관리하기 위한 설정 파일
from dotenv import load_dotenv

# API 키 정보 로드
load_dotenv()
```

```{python}
# LangSmith 추적을 설정합니다. https://smith.langchain.com
# !pip install langchain-teddynote
from langchain_teddynote import logging

# 프로젝트 이름을 입력합니다.
logging.langsmith("CH10-Retriever")
```

### LongContextReorder 의 재순위 방식 — 핵심 로직

LongContextReorder 의 transform_documents(docs) 함수는 내부적으로 다음과 같은 단계를 거쳐 재정렬한다. 

1. retriever가 반환한 문서 리스트를 받는다. 이 리스트는 통상적으로 유사도 기준으로 정렬되어 있다 (가장 관련 높은 문서가 앞쪽). 
2. 내부적으로 리스트를 역순(reverse)으로 뒤집는다. 
3. 그 뒤 “양끝 먼저, 중간은 나중” 식의 로직으로 다시 문서를 배치한다. 구체적으로:
  * 역순된 리스트에서 인덱스 `i`가 짝수인 문서를 결과 리스트의 맨 앞(front)에 삽입.
  * 인덱스 `i`가 홀수인 문서를 결과 리스트의 맨 뒤(back)에 삽입. 

결과적으로, 원래 유사도가 높은 문서들이 앞과 뒤(즉, 컨텍스트의 처음과 끝)에 배치되고, 덜 관련 있거나 중간 순위 문서들은 가운데 쪽에 모이게 된다. 

```{python}
from langchain_core.prompts import PromptTemplate
from langchain_community.document_transformers import LongContextReorder
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings


# 임베딩을 가져옵니다.
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

texts = [
    "이건 그냥 내가 아무렇게나 적어본 글입니다.",
    "사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.",
    "아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.",
    "챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.",
    "챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.",
    "애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.",
    "ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.",
    "비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.",
    "ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.",
    "FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.",
]


# 검색기를 생성합니다. (K는 10으로 설정합니다)
retriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(
    search_kwargs={"k": 10}
)
```

검색기에 쿼리를 입력하여 검색을 수행합니다.

```{python}
query = "ChatGPT에 대해 무엇을 말해줄 수 있나요?"

# 관련성 점수에 따라 정렬된 관련 문서를 가져옵니다.
docs = retriever.invoke(query)
docs
```

```
[Document(page_content='ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.'), 
Document(page_content='ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.'), 
Document(page_content='사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.'), 
Document(page_content='챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.'), 
Document(page_content='이건 그냥 내가 아무렇게나 적어본 글입니다.'), 
Document(page_content='챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.'),
Document(page_content='비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.'),
Document(page_content='아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.'), 
Document(page_content='애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.'), 
Document(page_content='FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.')]
```

**검색 결과 분석**

ChatGPT와 관련성이 높은 문서들이 상위에 정렬되어 있으며, 유사도 점수에 따라 내림차순으로 정렬된다.

- **상위 3개**: ChatGPT 직접 관련 문서 (높은 관련성)
- **4-6번**: ChatGPT 언급 문서 (중간 관련성)
- **7-10번**: 무관한 문서 (낮은 관련성)

이제 `LongContextReorder`를 적용하여 문서 순서를 재배치한다.

### 문서 재정렬 적용

`LongContextReorder` 클래스의 인스턴스인 `reordering`을 생성합니다.

- `reordering.transform_documents(docs)`를 호출하여 문서 목록 `docs`를 재정렬
  - 덜 관련된 문서는 목록의 중간에 위치시킨다
  - 더 관련된 문서는 시작과 끝에 위치시킨다

```{python}
# 문서를 재정렬한다
# 덜 관련된 문서는 목록의 중간에 위치하고 더 관련된 요소는 시작/끝에 위치한다
reordering = LongContextReorder()
reordered_docs = reordering.transform_documents(docs)  # 순위 재조정

# ChatGPT 관련 문서가 시작과 끝에 위치하는지 확인한다
reordered_docs
```


```
[Document(page_content='ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.'), 
Document(page_content='챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.'),
Document(page_content='챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.'), 
Document(page_content='아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.'), 
Document(page_content='FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.'), 
Document(page_content='애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.'), 
Document(page_content='비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.'), 
Document(page_content='이건 그냥 내가 아무렇게나 적어본 글입니다.'), 
Document(page_content='사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.'), 
Document(page_content='ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.')]
```

**재정렬 결과 분석**

재정렬 전후를 비교하면 다음과 같은 패턴을 확인할 수 있다:

| 위치 | 재정렬 전 | 재정렬 후 | 관련성 |
|:-----|:---------|:---------|:------|
| **0-1번** | 높은 관련성 | 중간 관련성 | 시작에 중간 문서 배치 |
| **2-7번** | 중간/낮은 관련성 | 낮은 관련성 | 중간에 무관 문서 집중 |
| **8-9번** | 낮은 관련성 | **높은 관련성** | 끝에 핵심 문서 배치 |

**재정렬 전략**:
- 가장 관련성 높은 문서(1, 10번)를 끝에 배치한다
- 중간 관련성 문서(2-4번)를 시작에 배치한다
- 무관한 문서(5-8번)를 중간에 배치한다

이렇게 하면 LLM이 시작과 끝에서 관련 정보를 찾을 수 있어 성능이 향상된다.

## RAG 체인에 Context Reordering 통합

```{python}
def format_docs(docs):
    return "\n".join([doc.page_content for i, doc in enumerate(docs)])
```

```{python}
print(format_docs(docs))
```

```
ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다.
ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다.
사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다.
챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다.
이건 그냥 내가 아무렇게나 적어본 글입니다.
챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다.
비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다.
아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다.
애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다.
FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다.
```

```{python}
def format_docs(docs):
    return "\n".join(
        [
            f"[{i}] {doc.page_content} [source: teddylee777@gmail.com]"
            for i, doc in enumerate(docs)
        ]
    )


def reorder_documents(docs):
    # 재정렬
    reordering = LongContextReorder()
    reordered_docs = reordering.transform_documents(docs)
    combined = format_docs(reordered_docs)
    print(combined)
    return combined
```

재정렬된 문서를 출력합니다.

```{python}
# 재정렬된 문서를 출력
_ = reorder_documents(docs)
```

```
[0] ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다. [source: teddylee777@gmail.com]
[1] 챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다. [source: teddylee777@gmail.com]
[2] 챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다. [source: teddylee777@gmail.com]
[3] 아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다. [source: teddylee777@gmail.com]
[4] FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다. [source: teddylee777@gmail.com]
[5] 애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다. [source: teddylee777@gmail.com]
[6] 비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다. [source: teddylee777@gmail.com]
[7] 이건 그냥 내가 아무렇게나 적어본 글입니다. [source: teddylee777@gmail.com]
[8] 사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다. [source: teddylee777@gmail.com]
[9] ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다. [source: teddylee777@gmail.com]
```

```{python}
from langchain.prompts import ChatPromptTemplate
from operator import itemgetter
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda

# 프롬프트 템플릿
template = """Given this text extracts:
{context}

-----
Please answer the following question:
{question}

Answer in the following languages: {language}
"""

# 프롬프트 정의
prompt = ChatPromptTemplate.from_template(template)

# Chain 정의
chain = (
    {
        "context": itemgetter("question")
        | retriever
        | RunnableLambda(reorder_documents),  # 질문을 기반으로 문맥을 검색합니다.
        "question": itemgetter("question"),  # 질문을 추출합니다.
        "language": itemgetter("language"),  # 답변 언어를 추출합니다.
    }
    | prompt  # 프롬프트 템플릿에 값을 전달합니다.
    | ChatOpenAI(model="gpt-4o-mini")  # 언어 모델에 프롬프트를 전달합니다.
    | StrOutputParser()  # 모델의 출력을 문자열로 파싱합니다.
)
```

`question` 에 쿼리를 입력하고 `language` 에 언어를 입력합니다.

- 재정렬된 문서의 검색 결과도 확인합니다.

```{python}
answer = chain.invoke(
    {"question": "ChatGPT에 대해 무엇을 말해줄 수 있나요?", "language": "KOREAN"}
)
```

```
[0] ChatGPT의 기능은 지속적인 학습과 업데이트를 통해 더욱 발전하고 있습니다. [source: teddylee777@gmail.com]
[1] 챗GPT는 OpenAI에 의해 개발되었으며, 지속적으로 개선되고 있습니다. [source: teddylee777@gmail.com]
[2] 챗지피티는 사용자의 질문을 이해하고 적절한 답변을 생성하기 위해 대량의 데이터를 학습했습니다. [source: teddylee777@gmail.com]
[3] 아이폰, 아이패드, 맥북 등은 애플이 출시한 대표적인 제품들입니다. [source: teddylee777@gmail.com]
[4] FIFA 월드컵은 네 번째 해마다 열리며, 국제 축구에서 가장 큰 행사입니다. [source: teddylee777@gmail.com]
[5] 애플 워치와 에어팟 같은 웨어러블 기기도 애플의 인기 제품군에 속합니다. [source: teddylee777@gmail.com]
[6] 비트코인은 디지털 금이라고도 불리며, 가치 저장 수단으로서 인기를 얻고 있습니다. [source: teddylee777@gmail.com]
[7] 이건 그냥 내가 아무렇게나 적어본 글입니다. [source: teddylee777@gmail.com]
[8] 사용자와 대화하는 것처럼 설계된 AI인 ChatGPT는 다양한 질문에 답할 수 있습니다. [source: teddylee777@gmail.com]
[9] ChatGPT는 복잡한 문제를 해결하거나 창의적인 아이디어를 제안하는 데에도 사용될 수 있습니다. [source: teddylee777@gmail.com]
```

답변을 출력합니다.

```{python}
print(answer)
```

```
ChatGPT는 OpenAI에 의해 개발된 인공지능으로, 사용자의 질문을 이해하고 적절한 답변을 생성하는 데 대량의 데이터를 학습했습니다. 이 AI는 지속적인 학습과 업데이트를 통해 더욱 발전하고 있으며, 다양한 질문에 답하거나 복잡한 문제를 해결하는 데에도 사용될 수 있습니다. 또한 창의적인 아이디어를 제안하는 기능도 갖추고 있습니다. 사용자는 ChatGPT와 대화하는 것처럼 상호작용할 수 있습니다.
```

## 성능 비교 및 결론

### LongContextReorder의 효과

**기대 효과**
1. **답변 정확도 향상**: 관련 문서를 시작과 끝에 배치하여 LLM이 핵심 정보를 놓치지 않도록 한다
2. **환각(Hallucination) 감소**: 제공된 컨텍스트를 더 잘 활용하여 사실 기반 답변 생성을 촉진한다
3. **일관성 향상**: 동일한 질문에 대해 더 안정적인 답변을 제공한다

### 실무 적용 가이드

**언제 사용해야 하는가?**

✅ **사용 권장 상황**
- 검색된 문서가 10개 이상일 때
- 긴 문서를 여러 개 처리해야 할 때
- 답변 품질이 일관되지 않을 때
- 중요 정보가 중간에 묻힐 가능성이 있을 때

❌ **사용 불필요 상황**
- 검색 문서가 3-5개 이하일 때
- 모든 문서가 고도로 관련성이 있을 때
- 짧은 컨텍스트만 다룰 때

### 추가 최적화 전략

`LongContextReorder`와 함께 사용하면 좋은 기법들:

1. **하이브리드 검색**: BM25 + 벡터 검색 조합으로 다양한 관련 문서 확보
2. **재순위화(Re-ranking)**: Cross-encoder로 검색 결과 품질 향상 후 재정렬 적용
3. **청크 크기 최적화**: 문서를 적절한 크기로 분할하여 관련성 높은 청크만 검색
4. **메타데이터 필터링**: 재정렬 전에 무관한 문서를 사전 필터링

### 핵심 요약

**Lost in the Middle 문제**
- LLM은 긴 컨텍스트의 중간에 위치한 정보를 잘 활용하지 못한다
- 시작과 끝 위치에 더 높은 주의를 기울이는 학습된 편향이 원인이다

**해결책: LongContextReorder**
- 관련성 높은 문서를 시작과 끝에 배치한다
- 무관한 문서를 중간에 집중시킨다
- RAG 시스템의 답변 정확도와 일관성을 향상시킨다

**실무 적용**
- 10개 이상의 문서를 다룰 때 필수적이다
- 다른 최적화 기법(재순위화, 하이브리드 검색)과 조합하여 사용한다
- LangChain의 `LongContextReorder`로 간단히 구현할 수 있다