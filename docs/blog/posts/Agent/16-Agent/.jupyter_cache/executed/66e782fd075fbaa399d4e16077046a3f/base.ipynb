{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be568e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\16-Agent':\n",
    "  os.chdir(r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\16-Agent')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2b67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e744933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정한다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력한다.\n",
    "logging.langsmith(\"CH16-Plan-Execute-Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db0de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 메모리 설정 (계획 및 실행 이력 저장)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 모델 설정\n",
    "# Planner: 복잡한 추론이 필요하므로 GPT-4o 사용\n",
    "planner_model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Executor: 비용 절감을 위해 GPT-4o-mini 사용\n",
    "executor_model = ChatOpenAI(model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d4cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Task(BaseModel):\n",
    "    \"\"\"수행할 작업의 단위\"\"\"\n",
    "    id: int = Field(description=\"작업 ID (1부터 시작)\")\n",
    "    title: str = Field(description=\"작업 제목\")\n",
    "    description: str = Field(description=\"작업 상세 설명\")\n",
    "    required_tools: List[str] = Field(description=\"필요한 도구 목록\")\n",
    "    dependencies: List[int] = Field(\n",
    "        default_factory=list, \n",
    "        description=\"선행 작업 ID 목록\"\n",
    "    )\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Task {self.id}: {self.title}\"\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"전체 작업 계획\"\"\"\n",
    "    objective: str = Field(description=\"최종 목표\")\n",
    "    tasks: List[Task] = Field(description=\"수행할 작업 리스트\")\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        task_str = \"\\n\".join(f\"  {task}\" for task in self.tasks)\n",
    "        return f\"Goal: {self.objective}\\n\\nTasks:\\n{task_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "048f39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"당신은 전문적인 작업 계획가(Project Manager)입니다.\n",
    "        \n",
    "사용자의 요청을 분석하여 다음 규칙에 따라 상세한 작업 계획을 수립하세요:\n",
    "\n",
    "1. **작업 분해**: 복잡한 요청을 논리적인 소 작업들로 분해\n",
    "2. **순차성**: 선행 작업이 필요한 경우 dependencies에 명시\n",
    "3. **도구 식별**: 각 작업에 필요한 도구 명시 (web_search, file_management, pdf_retriever 등)\n",
    "4. **명확성**: 각 작업의 목표가 명확하고 측정 가능하도록 작성\n",
    "\n",
    "사용 가능한 도구:\n",
    "- web_search: 웹 검색 (최신 정보 필요시)\n",
    "- file_write: 파일 작성\n",
    "- file_read: 파일 읽기\n",
    "- pdf_retriever: PDF 문서 검색\n",
    "- data_analysis: 데이터 분석\n",
    "\n",
    "응답 형식은 다음 JSON 스키마를 따르세요:\n",
    "```json\n",
    "{{\n",
    "    \"objective\": \"최종 목표\",\n",
    "    \"tasks\": [\n",
    "        {{\n",
    "            \"id\": 1,\n",
    "            \"title\": \"작업 제목\",\n",
    "            \"description\": \"작업 상세 설명\",\n",
    "            \"required_tools\": [\"tool1\", \"tool2\"],\n",
    "            \"dependencies\": []\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "```\"\"\",\n",
    "    ),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcbb019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 웹 검색 도구 생성\n",
    "web_search = TavilySearch(\n",
    "    topic=\"general\",\n",
    "    max_results=5,\n",
    "    include_answer=False,\n",
    "    include_raw_content=False,\n",
    ")\n",
    "\n",
    "web_search.name = \"web_search\"\n",
    "web_search.description = (\n",
    "    \"웹에서 정보를 검색합니다. 최신 정보, 뉴스, 통계 등이 필요할 때 사용합니다.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f92615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "\n",
    "working_directory = \"tmp\"\n",
    "\n",
    "file_management_tools = FileManagementToolkit(\n",
    "    root_dir=str(working_directory),\n",
    ").get_tools()\n",
    "\n",
    "# 도구 이름과 설명 업데이트\n",
    "for tool in file_management_tools:\n",
    "    if tool.name == \"file_write\":\n",
    "        tool.description = \"파일을 작성하거나 수정합니다.\"\n",
    "    elif tool.name == \"file_read\":\n",
    "        tool.description = \"파일의 내용을 읽습니다.\"\n",
    "    elif tool.name == \"list_directory\":\n",
    "        tool.description = \"디렉토리의 파일 목록을 조회합니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6fa96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# PDF 로드 및 벡터화\n",
    "loader = PDFPlumberLoader(\"data/sample_document.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "pdf_retriever = vector.as_retriever()\n",
    "\n",
    "# Retriever 도구 생성\n",
    "retriever_tool = create_retriever_tool(\n",
    "    pdf_retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"내부 문서에서 정보를 검색합니다. 회사 정책, 보고서, 기술 문서 등을 조회할 수 있습니다.\",\n",
    "    document_prompt=PromptTemplate.from_template(\n",
    "        \"<document><context>{page_content}</context><metadata><source>{source}</source><page>{page}</page></metadata></document>\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8234620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 목록 구성\n",
    "tools = [web_search, *file_management_tools, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f7c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Executor 에이전트: 개별 작업 수행\n",
    "executor = create_react_agent(\n",
    "    executor_model,\n",
    "    tools,\n",
    "    checkpointer=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b40f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class PlanExecuteState(BaseModel):\n",
    "    \"\"\"계획 및 실행 상태\"\"\"\n",
    "    input: str = Field(description=\"사용자 입력\")\n",
    "    plan: Plan = Field(default=None, description=\"수립된 계획\")\n",
    "    past_steps: Annotated[List[tuple], add_messages] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"완료된 작업과 결과\"\n",
    "    )\n",
    "    response: str = Field(default=\"\", description=\"최종 응답\")\n",
    "\n",
    "def plan_step(state: PlanExecuteState) -> PlanExecuteState:\n",
    "    \"\"\"계획 수립 단계\"\"\"\n",
    "    # Planner가 계획 수립\n",
    "    planner_chain = planner_prompt | planner_model.with_structured_output(Plan)\n",
    "    plan = planner_chain.invoke({\"input\": state.input})\n",
    "    \n",
    "    return {**state, \"plan\": plan}\n",
    "\n",
    "def execute_step(state: PlanExecuteState) -> PlanExecuteState:\n",
    "    \"\"\"작업 실행 단계\"\"\"\n",
    "    plan = state.plan\n",
    "    past_steps = state.past_steps\n",
    "    \n",
    "    # 완료되지 않은 작업 찾기\n",
    "    completed_task_ids = {step[0] for step in past_steps}\n",
    "    next_task = None\n",
    "    \n",
    "    for task in plan.tasks:\n",
    "        # 의존성이 모두 완료되었고, 아직 수행되지 않은 작업\n",
    "        if (task.id not in completed_task_ids and \n",
    "            all(dep_id in completed_task_ids for dep_id in task.dependencies)):\n",
    "            next_task = task\n",
    "            break\n",
    "    \n",
    "    if next_task is None:\n",
    "        # 모든 작업 완료\n",
    "        return state\n",
    "    \n",
    "    # 작업 실행\n",
    "    task_instruction = f\"\"\"\n",
    "    다음 작업을 수행하세요:\n",
    "    \n",
    "    제목: {next_task.title}\n",
    "    설명: {next_task.description}\n",
    "    필요 도구: {', '.join(next_task.required_tools)}\n",
    "    \n",
    "    이전 작업 결과:\n",
    "    {chr(10).join(f\"Task {task_id}: {result}\" for task_id, result in past_steps)}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Executor가 작업 수행\n",
    "    result = executor.invoke(\n",
    "        {\"messages\": [(\"human\", task_instruction)]},\n",
    "        {\"configurable\": {\"thread_id\": f\"task_{next_task.id}\"}}\n",
    "    )\n",
    "    \n",
    "    # 결과 저장\n",
    "    past_steps.append((next_task.id, result[\"messages\"][-1].content))\n",
    "    \n",
    "    return {**state, \"past_steps\": past_steps}\n",
    "\n",
    "def generate_response_step(state: PlanExecuteState) -> PlanExecuteState:\n",
    "    \"\"\"최종 응답 생성 단계\"\"\"\n",
    "    plan = state.plan\n",
    "    past_steps = state.past_steps\n",
    "    \n",
    "    # 모든 작업이 완료되었는지 확인\n",
    "    if len(past_steps) < len(plan.tasks):\n",
    "        return state\n",
    "    \n",
    "    # 결과 통합\n",
    "    summary = f\"\"\"\n",
    "    ## 작업 완료 보고서\n",
    "    \n",
    "    **목표**: {plan.objective}\n",
    "    \n",
    "    ### 수행 작업\n",
    "    \"\"\"\n",
    "    \n",
    "    for task_id, result in past_steps:\n",
    "        task = next(t for t in plan.tasks if t.id == task_id)\n",
    "        summary += f\"\\n\\n**Task {task_id}: {task.title}**\\n{result}\\n\"\n",
    "    \n",
    "    return {**state, \"response\": summary}\n",
    "\n",
    "# 그래프 구성\n",
    "workflow = StateGraph(PlanExecuteState)\n",
    "\n",
    "workflow.add_node(\"plan\", plan_step)\n",
    "workflow.add_node(\"execute\", execute_step)\n",
    "workflow.add_node(\"respond\", generate_response_step)\n",
    "\n",
    "workflow.add_edge(START, \"plan\")\n",
    "workflow.add_edge(\"plan\", \"execute\")\n",
    "workflow.add_edge(\"execute\", \"execute\")  # 모든 작업 완료까지 반복\n",
    "workflow.add_edge(\"execute\", \"respond\")\n",
    "workflow.add_edge(\"respond\", END)\n",
    "\n",
    "# 컴파일\n",
    "plan_execute_agent = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f35fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "def run_plan_execute_agent(instruction: str, thread_id: str = \"main\"):\n",
    "    \"\"\"계획 및 실행 에이전트 실행\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    inputs = {\"messages\": [(\"human\", instruction)]}\n",
    "    \n",
    "    stream_graph(plan_execute_agent, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bee4643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "AI 에이전트 시장에 대한 종합 조사 보고서를 작성해주세요.\n",
    "\n",
    "다음 내용이 포함되어야 합니다:\n",
    "1. 현재 AI 에이전트 시장 규모 및 성장률\n",
    "2. 주요 플레이어 및 기술 트렌드\n",
    "3. 시장 기회 및 위험 요소 분석\n",
    "4. 향후 6개월 전망\n",
    "\n",
    "보고서는 마크다운 형식으로 작성하고 파일로 저장해주세요.\n",
    "\"\"\"\n",
    "\n",
    "run_plan_execute_agent(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b3b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "회사의 분기별 판매 데이터를 분석하고 시각화하는 프로젝트를 진행해주세요.\n",
    "\n",
    "다음을 순서대로 수행하세요:\n",
    "1. sales_data.csv 파일 읽기\n",
    "2. 분기별 판매액, 증감율, 주요 제품 분석\n",
    "3. 분석 결과를 정리한 요약 테이블 작성\n",
    "4. 주요 통찰력을 markdown 형식으로 정리\n",
    "5. 최종 분석 보고서를 analysis_report.md로 저장\n",
    "\"\"\"\n",
    "\n",
    "run_plan_execute_agent(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de6165e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "주요 경쟁사 3곳에 대한 경쟁 분석 리포트를 작성해주세요.\n",
    "\n",
    "1. 경쟁사1, 경쟁사2, 경쟁사3의 최신 뉴스와 제품 정보 수집\n",
    "2. 각 경쟁사의 강점, 약점, 기회, 위협(SWOT) 분석\n",
    "3. 우리 회사와의 차별화 전략 도출\n",
    "4. 비교 테이블 작성\n",
    "5. 최종 보고서를 competitor_analysis.md로 저장\n",
    "\n",
    "각 경쟁사별 분석은 병렬로 수행 가능합니다.\n",
    "\"\"\"\n",
    "\n",
    "run_plan_execute_agent(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a6560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_execute_task(task: Task, previous_results: dict) -> bool:\n",
    "    \"\"\"특정 조건에서만 Task 실행\"\"\"\n",
    "    \n",
    "    # 예: 검색 결과가 충분하면 분석 Task 스킵\n",
    "    if task.id == 4 and len(previous_results.get(\"search_results\", [])) < 3:\n",
    "        return False\n",
    "    \n",
    "    # 예: 파일이 존재하면 생성 Task 스킵\n",
    "    if task.id == 5 and \"file_exists\" in previous_results:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f4f1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def execute_task_cached(task_id: int, instruction: str) -> str:\n",
    "    \"\"\"동일한 Task는 캐시된 결과 사용\"\"\"\n",
    "    # 실행 로직\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3fd1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_exponential(multiplier=1, min=2, max=10)\n",
    ")\n",
    "def execute_task_with_retry(task: Task) -> str:\n",
    "    \"\"\"실패 시 지수 백오프로 재시도\"\"\"\n",
    "    # 실행 로직\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}