{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0af6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\16-Agent':\n",
    "  os.chdir(r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\16-Agent')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5889094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513cdf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정한다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력한다.\n",
    "logging.langsmith(\"CH15-Agentic-RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125cc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져온다.\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# TavilySearchResults 클래스의 인스턴스를 생성한다\n",
    "# k=6은 검색 결과를 6개까지 가져오겠다는 의미다\n",
    "search = TavilySearchResults(k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da7e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과를 가져옵니다.\n",
    "search.invoke(\"판교 카카오 프렌즈샵 아지트점의 전화번호는 무엇인가요?\")\n",
    "#k=6 이지만 검색 결과가 더 적으면 그 검색된 수만큼 반환이 된다. 아래의 예에선 5개가 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd0a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 텍스트 분할기를 사용하여 문서를 분할한다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# 문서를 로드하고 분할한다.\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# VectorStore를 생성한다.\n",
    "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "\n",
    "# Retriever를 생성한다. (반드시 마지막 값은 retriever type이어야한다)\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c950aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서에서 관련성 높은 문서를 가져옵니다.\n",
    "retriever.invoke(\"삼성전자가 개발한 생성형 AI 관련 내용을 문서에서 찾아줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db5521f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"pdf_search\",  # 도구의 이름을 입력한다. 도구 인지가 잘 되도록 하는 역할을 함\n",
    "    description=\"use this tool to search information from the PDF document\",  # 도구에 대한 설명을 자세히 기입해야 한다!!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c2a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools 리스트에 search와 retriever_tool을 추가한다.\n",
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "524ba5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prompt 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"Make sure to use the `pdf_search` tool for searching information from the PDF document. \"\n",
    "            \"If you can't find the information from the PDF document, use the `search` tool for searching information from the web.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"), # 추후에 추가될 multi-turn 기능을 위해 채팅 기록이 저장되어야함.\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3762d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# tool calling agent 생성\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73890071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# AgentExecutor 생성\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False) #  verbose=True: 중간단계 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92bf1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import AgentStreamParser\n",
    "\n",
    "# 각 단계별 출력을 위한 파서 생성\n",
    "agent_stream_parser = AgentStreamParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d39e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의에 대한 답변을 스트리밍으로 출력 요청\n",
    "result = agent_executor.stream(\n",
    "    {\"input\": \"2024년 프로야구 플레이오프 진출한 5개 팀을 검색하여 알려주세요.\"}\n",
    ")\n",
    "\n",
    "for step in result:\n",
    "    # 중간 단계를 parser 를 사용하여 단계별로 출력\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "309be468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의에 대한 답변을 스트리밍으로 출력 요청\n",
    "result = agent_executor.stream(\n",
    "    {\"input\": \"삼성전자가 자체 개발한 생성형 AI 관련된 정보를 문서에서 찾아주세요.\"}\n",
    ")\n",
    "\n",
    "for step in result:\n",
    "    # 중간 단계를 parser 를 사용하여 단계별로 출력\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feef3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# session_id 를 저장할 딕셔너리 생성\n",
    "store = {}\n",
    "\n",
    "\n",
    "# session_id 를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in store:  # session_id 가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "# 채팅 메시지 기록이 추가된 에이전트를 생성한다.\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # 대화 session_id\n",
    "    get_session_history,\n",
    "    # 프롬프트의 질문이 입력되는 key: \"input\"\n",
    "    input_messages_key=\"input\",\n",
    "    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16129b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질의에 대한 답변을 스트리밍으로 출력 요청\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"삼성전자가 개발한 생성형 AI 관련된 정보를 문서에서 찾아주세요.\"},\n",
    "    # session_id 설정\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "# 출력 확인\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bc8906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"이전의 답변을 영어로 번역한다.\"},\n",
    "    # session_id 설정\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "# 출력 확인\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)\n",
    "\n",
    "# 이경우 도구 호출이 필요없기 때문에 도구 호출 하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f506d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 import\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_teddynote.messages import AgentStreamParser\n",
    "\n",
    "########## 1. 도구를 정의합니다 ##########\n",
    "\n",
    "### 1-1. Search 도구 ###\n",
    "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
    "# k=6은 검색 결과를 6개까지 가져오겠다는 의미입니다\n",
    "search = TavilySearchResults(k=6)\n",
    "\n",
    "### 1-2. PDF 문서 검색 도구 (Retriever) ###\n",
    "# PDF 파일 로드. 파일의 경로 입력\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# 문서를 로드하고 분할합니다.\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# VectorStore를 생성합니다.\n",
    "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "\n",
    "# Retriever를 생성합니다.\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"pdf_search\",  # 도구의 이름을 입력합니다.\n",
    "    description=\"use this tool to search information from the PDF document\",  # 도구에 대한 설명을 자세히 기입해야 합니다!!\n",
    ")\n",
    "\n",
    "### 1-3. tools 리스트에 도구 목록을 추가합니다 ###\n",
    "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
    "tools = [search, retriever_tool]\n",
    "\n",
    "########## 2. LLM 을 정의합니다 ##########\n",
    "# LLM 모델을 생성합니다.\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "########## 3. Prompt 를 정의합니다 ##########\n",
    "\n",
    "# Prompt 를 정의합니다 - 이 부분을 수정할 수 있습니다!\n",
    "# Prompt 정의\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"Make sure to use the `pdf_search` tool for searching information from the PDF document. \"\n",
    "            \"If you can't find the information from the PDF document, use the `search` tool for searching information from the web.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "########## 4. Agent 를 정의합니다 ##########\n",
    "\n",
    "# 에이전트를 생성합니다.\n",
    "# llm, tools, prompt를 인자로 사용합니다.\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "########## 5. AgentExecutor 를 정의합니다 ##########\n",
    "\n",
    "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "\n",
    "########## 6. 채팅 기록을 수행하는 메모리를 추가합니다. ##########\n",
    "\n",
    "# session_id 를 저장할 딕셔너리 생성\n",
    "store = {}\n",
    "\n",
    "\n",
    "# session_id 를 기반으로 세션 기록을 가져오는 함수\n",
    "def get_session_history(session_ids):\n",
    "    if session_ids not in store:  # session_id 가 store에 없는 경우\n",
    "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
    "\n",
    "\n",
    "# 채팅 메시지 기록이 추가된 에이전트를 생성한다.\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # 대화 session_id\n",
    "    get_session_history,\n",
    "    # 프롬프트의 질문이 입력되는 key: \"input\"\n",
    "    input_messages_key=\"input\",\n",
    "    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "########## 7. Agent 파서를 정의합니다. ##########\n",
    "agent_stream_parser = AgentStreamParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f2116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n",
    "\n",
    "# 질의에 대한 답변을 출력합니다.\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"구글이 앤스로픽에 투자한 금액을 문서에서 찾아줘\"},\n",
    "    # 세션 ID를 설정합니다.\n",
    "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae561d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n",
    "\n",
    "# 질의에 대한 답변을 출력합니다.\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"이전의 답변을 영어로 번역해 주세요\"},\n",
    "    # 세션 ID를 설정합니다.\n",
    "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")\n",
    "\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb362b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n",
    "\n",
    "# 질의에 대한 답변을 출력합니다.\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\n",
    "        \"input\": \"2024년 프로야구 플레이오프 진출 5개팀을 검색해서 알려주세요. 한글로 답변하세요\"\n",
    "    },\n",
    "    # 세션 ID를 설정합니다.\n",
    "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
    "    config={\"configurable\": {\"session_id\": \"abc456\"}},\n",
    ")\n",
    "\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29806097",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n",
    "\n",
    "# 질의에 대한 답변을 출력합니다.\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"이전의 답변을 SNS 게시글 형태로 100자 내외로 작성하세요.\"},\n",
    "    # 세션 ID를 설정합니다.\n",
    "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
    "    config={\"configurable\": {\"session_id\": \"abc456\"}},\n",
    ")\n",
    "\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e03858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## 8. 에이전트를 실행하고 결과를 확인합니다. ##########\n",
    "\n",
    "# 질의에 대한 답변을 출력합니다.\n",
    "response = agent_with_chat_history.stream(\n",
    "    {\"input\": \"이전의 답변에 한국 시리즈 일정을 추가하세요.\"},\n",
    "    # 세션 ID를 설정합니다.\n",
    "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
    "    config={\"configurable\": {\"session_id\": \"abc456\"}},\n",
    ")\n",
    "\n",
    "for step in response:\n",
    "    agent_stream_parser.process_agent_steps(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}