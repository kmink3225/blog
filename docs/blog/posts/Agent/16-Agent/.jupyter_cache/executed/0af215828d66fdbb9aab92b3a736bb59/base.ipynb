{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed85d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import json\n",
    "\n",
    "# figure size/format\n",
    "fig_width = 7\n",
    "fig_height = 5\n",
    "fig_format = 'retina'\n",
    "fig_dpi = 96\n",
    "interactivity = ''\n",
    "is_shiny = False\n",
    "is_dashboard = False\n",
    "plotly_connected = True\n",
    "\n",
    "# matplotlib defaults / format\n",
    "try:\n",
    "  import matplotlib.pyplot as plt\n",
    "  plt.rcParams['figure.figsize'] = (fig_width, fig_height)\n",
    "  plt.rcParams['figure.dpi'] = fig_dpi\n",
    "  plt.rcParams['savefig.dpi'] = fig_dpi\n",
    "  from IPython.display import set_matplotlib_formats\n",
    "  set_matplotlib_formats(fig_format)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# plotly use connected mode\n",
    "try:\n",
    "  import plotly.io as pio\n",
    "  if plotly_connected:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "  else:\n",
    "    pio.renderers.default = \"notebook\"\n",
    "  for template in pio.templates.keys():\n",
    "    pio.templates[template].layout.margin = dict(t=30,r=0,b=0,l=0)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# disable itables paging for dashboards\n",
    "if is_dashboard:\n",
    "  try:\n",
    "    from itables import options\n",
    "    options.dom = 'fiBrtlp'\n",
    "    options.maxBytes = 1024 * 1024\n",
    "    options.language = dict(info = \"Showing _TOTAL_ entries\")\n",
    "    options.classes = \"display nowrap compact\"\n",
    "    options.paging = False\n",
    "    options.searching = True\n",
    "    options.ordering = True\n",
    "    options.info = True\n",
    "    options.lengthChange = False\n",
    "    options.autoWidth = False\n",
    "    options.responsive = True\n",
    "    options.keys = True\n",
    "    options.buttons = []\n",
    "  except Exception:\n",
    "    pass\n",
    "  \n",
    "  try:\n",
    "    import altair as alt\n",
    "    # By default, dashboards will have container sized\n",
    "    # vega visualizations which allows them to flow reasonably\n",
    "    theme_sentinel = '_quarto-dashboard-internal'\n",
    "    def make_theme(name):\n",
    "        nonTheme = alt.themes._plugins[name]    \n",
    "        def patch_theme(*args, **kwargs):\n",
    "            existingTheme = nonTheme()\n",
    "            if 'height' not in existingTheme:\n",
    "              existingTheme['height'] = 'container'\n",
    "            if 'width' not in existingTheme:\n",
    "              existingTheme['width'] = 'container'\n",
    "\n",
    "            if 'config' not in existingTheme:\n",
    "              existingTheme['config'] = dict()\n",
    "            \n",
    "            # Configure the default font sizes\n",
    "            title_font_size = 15\n",
    "            header_font_size = 13\n",
    "            axis_font_size = 12\n",
    "            legend_font_size = 12\n",
    "            mark_font_size = 12\n",
    "            tooltip = False\n",
    "\n",
    "            config = existingTheme['config']\n",
    "\n",
    "            # The Axis\n",
    "            if 'axis' not in config:\n",
    "              config['axis'] = dict()\n",
    "            axis = config['axis']\n",
    "            if 'labelFontSize' not in axis:\n",
    "              axis['labelFontSize'] = axis_font_size\n",
    "            if 'titleFontSize' not in axis:\n",
    "              axis['titleFontSize'] = axis_font_size  \n",
    "\n",
    "            # The legend\n",
    "            if 'legend' not in config:\n",
    "              config['legend'] = dict()\n",
    "            legend = config['legend']\n",
    "            if 'labelFontSize' not in legend:\n",
    "              legend['labelFontSize'] = legend_font_size\n",
    "            if 'titleFontSize' not in legend:\n",
    "              legend['titleFontSize'] = legend_font_size  \n",
    "\n",
    "            # The header\n",
    "            if 'header' not in config:\n",
    "              config['header'] = dict()\n",
    "            header = config['header']\n",
    "            if 'labelFontSize' not in header:\n",
    "              header['labelFontSize'] = header_font_size\n",
    "            if 'titleFontSize' not in header:\n",
    "              header['titleFontSize'] = header_font_size    \n",
    "\n",
    "            # Title\n",
    "            if 'title' not in config:\n",
    "              config['title'] = dict()\n",
    "            title = config['title']\n",
    "            if 'fontSize' not in title:\n",
    "              title['fontSize'] = title_font_size\n",
    "\n",
    "            # Marks\n",
    "            if 'mark' not in config:\n",
    "              config['mark'] = dict()\n",
    "            mark = config['mark']\n",
    "            if 'fontSize' not in mark:\n",
    "              mark['fontSize'] = mark_font_size\n",
    "\n",
    "            # Mark tooltips\n",
    "            if tooltip and 'tooltip' not in mark:\n",
    "              mark['tooltip'] = dict(content=\"encoding\")\n",
    "\n",
    "            return existingTheme\n",
    "            \n",
    "        return patch_theme\n",
    "\n",
    "    # We can only do this once per session\n",
    "    if theme_sentinel not in alt.themes.names():\n",
    "      for name in alt.themes.names():\n",
    "        alt.themes.register(name, make_theme(name))\n",
    "      \n",
    "      # register a sentinel theme so we only do this once\n",
    "      alt.themes.register(theme_sentinel, make_theme('default'))\n",
    "      alt.themes.enable('default')\n",
    "\n",
    "  except Exception:\n",
    "    pass\n",
    "\n",
    "# enable pandas latex repr when targeting pdfs\n",
    "try:\n",
    "  import pandas as pd\n",
    "  if fig_format == 'pdf':\n",
    "    pd.set_option('display.latex.repr', True)\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "# interactivity\n",
    "if interactivity:\n",
    "  from IPython.core.interactiveshell import InteractiveShell\n",
    "  InteractiveShell.ast_node_interactivity = interactivity\n",
    "\n",
    "# NOTE: the kernel_deps code is repeated in the cleanup.py file\n",
    "# (we can't easily share this code b/c of the way it is run).\n",
    "# If you edit this code also edit the same code in cleanup.py!\n",
    "\n",
    "# output kernel dependencies\n",
    "kernel_deps = dict()\n",
    "for module in list(sys.modules.values()):\n",
    "  # Some modules play games with sys.modules (e.g. email/__init__.py\n",
    "  # in the standard library), and occasionally this can cause strange\n",
    "  # failures in getattr.  Just ignore anything that's not an ordinary\n",
    "  # module.\n",
    "  if not isinstance(module, types.ModuleType):\n",
    "    continue\n",
    "  path = getattr(module, \"__file__\", None)\n",
    "  if not path:\n",
    "    continue\n",
    "  if path.endswith(\".pyc\") or path.endswith(\".pyo\"):\n",
    "    path = path[:-1]\n",
    "  if not os.path.exists(path):\n",
    "    continue\n",
    "  kernel_deps[path] = os.stat(path).st_mtime\n",
    "print(json.dumps(kernel_deps))\n",
    "\n",
    "# set run_path if requested\n",
    "if r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\16-Agent':\n",
    "  os.chdir(r'C:\\Users\\kmkim\\Desktop\\projects\\blog\\docs\\blog\\posts\\Agent\\16-Agent')\n",
    "\n",
    "# reset state\n",
    "%reset\n",
    "\n",
    "# shiny\n",
    "# Checking for shiny by using False directly because we're after the %reset. We don't want\n",
    "# to set a variable that stays in global scope.\n",
    "if False:\n",
    "  try:\n",
    "    import htmltools as _htmltools\n",
    "    import ast as _ast\n",
    "\n",
    "    _htmltools.html_dependency_render_mode = \"json\"\n",
    "\n",
    "    # This decorator will be added to all function definitions\n",
    "    def _display_if_has_repr_html(x):\n",
    "      try:\n",
    "        # IPython 7.14 preferred import\n",
    "        from IPython.display import display, HTML\n",
    "      except:\n",
    "        from IPython.core.display import display, HTML\n",
    "\n",
    "      if hasattr(x, '_repr_html_'):\n",
    "        display(HTML(x._repr_html_()))\n",
    "      return x\n",
    "\n",
    "    # ideally we would undo the call to ast_transformers.append\n",
    "    # at the end of this block whenver an error occurs, we do \n",
    "    # this for now as it will only be a problem if the user \n",
    "    # switches from shiny to not-shiny mode (and even then likely\n",
    "    # won't matter)\n",
    "    import builtins\n",
    "    builtins._display_if_has_repr_html = _display_if_has_repr_html\n",
    "\n",
    "    class _FunctionDefReprHtml(_ast.NodeTransformer):\n",
    "      def visit_FunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "      def visit_AsyncFunctionDef(self, node):\n",
    "        node.decorator_list.insert(\n",
    "          0,\n",
    "          _ast.Name(id=\"_display_if_has_repr_html\", ctx=_ast.Load())\n",
    "        )\n",
    "        return node\n",
    "\n",
    "    ip = get_ipython()\n",
    "    ip.ast_transformers.append(_FunctionDefReprHtml())\n",
    "\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "def ojs_define(**kwargs):\n",
    "  import json\n",
    "  try:\n",
    "    # IPython 7.14 preferred import\n",
    "    from IPython.display import display, HTML\n",
    "  except:\n",
    "    from IPython.core.display import display, HTML\n",
    "\n",
    "  # do some minor magic for convenience when handling pandas\n",
    "  # dataframes\n",
    "  def convert(v):\n",
    "    try:\n",
    "      import pandas as pd\n",
    "    except ModuleNotFoundError: # don't do the magic when pandas is not available\n",
    "      return v\n",
    "    if type(v) == pd.Series:\n",
    "      v = pd.DataFrame(v)\n",
    "    if type(v) == pd.DataFrame:\n",
    "      j = json.loads(v.T.to_json(orient='split'))\n",
    "      return dict((k,v) for (k,v) in zip(j[\"index\"], j[\"data\"]))\n",
    "    else:\n",
    "      return v\n",
    "\n",
    "  v = dict(contents=list(dict(name=key, value=convert(value)) for (key, value) in kwargs.items()))\n",
    "  display(HTML('<script type=\"ojs-define\">' + json.dumps(v) + '</script>'), metadata=dict(ojs_define = True))\n",
    "globals()[\"ojs_define\"] = ojs_define\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b88d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API í‚¤ ì •ë³´ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a0b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•œë‹¤. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•œë‹¤.\n",
    "logging.langsmith(\"CH17-Multi-Agent-System\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0177cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from typing import Annotated, Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì„¤ì • (ê³µìœ  ë©”ëª¨ë¦¬)\n",
    "memory = MemorySaver()\n",
    "\n",
    "# ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "supervisor_model = ChatOpenAI(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7fbcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬\n",
    "web_search = TavilySearch(\n",
    "    topic=\"general\",\n",
    "    max_results=5,\n",
    "    include_answer=False,\n",
    ")\n",
    "\n",
    "# ì—°êµ¬ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "researcher_prompt = \"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ ì—°êµ¬ì›(Researcher)ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ì—­í• :**\n",
    "- ì›¹ì—ì„œ ìµœì‹  ì •ë³´, í†µê³„, ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰\n",
    "- ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ì •ë³´ ìˆ˜ì§‘\n",
    "- íŒ©íŠ¸ ì²´í¬ ë° ê²€ì¦\n",
    "\n",
    "**ì‘ì—… ì§€ì¹¨:**\n",
    "1. ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì‹ ì¤‘í•˜ê²Œ ì„ íƒ\n",
    "2. ì—¬ëŸ¬ ì†ŒìŠ¤ êµì°¨ ê²€ì¦\n",
    "3. ì¶œì²˜ë¥¼ ëª…í™•íˆ ê¸°ë¡\n",
    "4. ìš”ì•½ì€ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹:**\n",
    "- ê²€ìƒ‰ ê²°ê³¼: [ì†ŒìŠ¤] ë‚´ìš©\n",
    "- ì£¼ìš” ë°œê²¬: í•µì‹¬ ì •ë³´ ìš”ì•½\n",
    "- ì¶œì²˜ ë§í¬: URL ëª©ë¡\"\"\"\n",
    "\n",
    "# ì—°êµ¬ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "researcher = create_react_agent(\n",
    "    model,\n",
    "    [web_search],\n",
    "    state_modifier=SystemMessage(content=researcher_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1352e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "\n",
    "# íŒŒì¼ ê´€ë¦¬ ë„êµ¬\n",
    "file_tools = FileManagementToolkit(root_dir=\"tmp\").get_tools()\n",
    "\n",
    "# ë¶„ì„ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "analyst_prompt = \"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€(Analyst)ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ì—­í• :**\n",
    "- ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„ ë° í•´ì„\n",
    "- íŠ¸ë Œë“œ, íŒ¨í„´, ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
    "- í†µê³„ì  ë¶„ì„ ë° ì‹œê°í™”\n",
    "\n",
    "**ì‘ì—… ì§€ì¹¨:**\n",
    "1. ë°ì´í„°ì˜ ì‹ ë¢°ì„± í‰ê°€\n",
    "2. ì •ëŸ‰ì /ì •ì„±ì  ë¶„ì„ ë³‘í–‰\n",
    "3. ë¹„êµ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí‚¹\n",
    "4. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹:**\n",
    "- ì£¼ìš” ë°œê²¬ì‚¬í•­\n",
    "- ë°ì´í„° ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸\n",
    "- ì‹œì‚¬ì  ë° ê¶Œì¥ì‚¬í•­\n",
    "- ë¶„ì„ ê·¼ê±°\"\"\"\n",
    "\n",
    "# ë¶„ì„ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "analyst = create_react_agent(\n",
    "    model,\n",
    "    file_tools,\n",
    "    state_modifier=SystemMessage(content=analyst_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33367b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ì„± ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "writer_prompt = \"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ ì‘ê°€(Writer)ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ì—­í• :**\n",
    "- ì—°êµ¬ ë° ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê³ ì„œë¡œ ì‘ì„±\n",
    "- ëª…í™•í•˜ê³  ì„¤ë“ë ¥ ìˆëŠ” ë¬¸ì„œ ì‘ì„±\n",
    "- ëŒ€ìƒ ë…ìì— ë§ëŠ” í†¤ì•¤ë§¤ë„ˆ ì¡°ì ˆ\n",
    "\n",
    "**ì‘ì—… ì§€ì¹¨:**\n",
    "1. ë…¼ë¦¬ì  êµ¬ì¡°ë¡œ ë¬¸ì„œ êµ¬ì„±\n",
    "2. ì „ë¬¸ ìš©ì–´ ì ì ˆíˆ ì‚¬ìš©\n",
    "3. ì‹œê° ìë£Œ(í‘œ, ì°¨íŠ¸) í™œìš©\n",
    "4. ìš”ì•½ ë° ê²°ë¡  ëª…í™•íˆ ì œì‹œ\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹:**\n",
    "- Markdown í˜•ì‹\n",
    "- ì„¹ì…˜ë³„ í—¤ë”© êµ¬ì¡°\n",
    "- ìš”ì  ì •ë¦¬ í…Œì´ë¸”\n",
    "- ì°¸ê³  ìë£Œ ë§í¬\"\"\"\n",
    "\n",
    "# ì‘ì„± ì—ì´ì „íŠ¸ ìƒì„±\n",
    "writer = create_react_agent(\n",
    "    model,\n",
    "    file_tools,\n",
    "    state_modifier=SystemMessage(content=writer_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d4af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½”ë“œ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "coder_prompt = \"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ ê°œë°œì(Coder)ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ì—­í• :**\n",
    "- ë°ì´í„° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±\n",
    "- ë¶„ì„ ì½”ë“œ êµ¬í˜„\n",
    "- ìë™í™” ë„êµ¬ ê°œë°œ\n",
    "\n",
    "**ì‘ì—… ì§€ì¹¨:**\n",
    "1. ê¹¨ë—í•˜ê³  ìœ ì§€ë³´ìˆ˜ ê°€ëŠ¥í•œ ì½”ë“œ\n",
    "2. ì ì ˆí•œ ì£¼ì„ ë° ë¬¸ì„œí™”\n",
    "3. ì—ëŸ¬ ì²˜ë¦¬ ë° ê²€ì¦\n",
    "4. ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ ì‘ì„±\n",
    "\n",
    "**ì¶œë ¥ í˜•ì‹:**\n",
    "- Python ì½”ë“œ ë¸”ë¡\n",
    "- ì‹¤í–‰ ë°©ë²• ì„¤ëª…\n",
    "- ì…ì¶œë ¥ ì˜ˆì‹œ\n",
    "- ì˜ì¡´ì„± ëª©ë¡\"\"\"\n",
    "\n",
    "# ì½”ë“œ ì—ì´ì „íŠ¸ ìƒì„±\n",
    "coder = create_react_agent(\n",
    "    model,\n",
    "    file_tools,\n",
    "    state_modifier=SystemMessage(content=coder_prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1025fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class RouteDecision(BaseModel):\n",
    "    \"\"\"ì‘ì—… ë¼ìš°íŒ… ê²°ì •\"\"\"\n",
    "    next_agent: Literal[\"researcher\", \"analyst\", \"writer\", \"coder\", \"FINISH\"]\n",
    "    reasoning: str\n",
    "\n",
    "supervisor_prompt = \"\"\"ë‹¹ì‹ ì€ í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €(Supervisor)ì…ë‹ˆë‹¤.\n",
    "\n",
    "íŒ€ì›:\n",
    "- **researcher**: ì›¹ ê²€ìƒ‰ ë° ì •ë³´ ìˆ˜ì§‘ ì „ë¬¸\n",
    "- **analyst**: ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì „ë¬¸\n",
    "- **writer**: ë¬¸ì„œ ì‘ì„± ë° ë³´ê³ ì„œ ì‘ì„± ì „ë¬¸\n",
    "- **coder**: ì½”ë“œ ì‘ì„± ë° ìë™í™” ì „ë¬¸\n",
    "\n",
    "**ì‘ì—… ë¶„ë°° ì›ì¹™:**\n",
    "1. ìµœì‹  ì •ë³´ í•„ìš” â†’ researcher\n",
    "2. ë°ì´í„° ë¶„ì„ í•„ìš” â†’ analyst\n",
    "3. ë¬¸ì„œ ì‘ì„± í•„ìš” â†’ writer\n",
    "4. ì½”ë“œ êµ¬í˜„ í•„ìš” â†’ coder\n",
    "5. ëª¨ë“  ì‘ì—… ì™„ë£Œ â†’ FINISH\n",
    "\n",
    "**í˜„ì¬ ìƒí™©:**\n",
    "{context}\n",
    "\n",
    "**ë‹¤ìŒ ì‘ì—…ì„ ë‹´ë‹¹í•  íŒ€ì›ì„ ì„ íƒí•˜ê³  ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.**\"\"\"\n",
    "\n",
    "def create_supervisor_chain():\n",
    "    \"\"\"Supervisor ì²´ì¸ ìƒì„±\"\"\"\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", supervisor_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "    \n",
    "    return prompt | supervisor_model.with_structured_output(RouteDecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cc2293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MultiAgentState(TypedDict):\n",
    "    \"\"\"Multi-Agent ì‹œìŠ¤í…œ ìƒíƒœ\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    next_agent: str\n",
    "    research_results: str\n",
    "    analysis_results: str\n",
    "    code_results: str\n",
    "    final_report: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27f2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"ì—°êµ¬ ì—ì´ì „íŠ¸ ë…¸ë“œ\"\"\"\n",
    "    result = researcher.invoke(state)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": result[\"messages\"],\n",
    "        \"research_results\": result[\"messages\"][-1].content,\n",
    "    }\n",
    "\n",
    "def analyst_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"ë¶„ì„ ì—ì´ì „íŠ¸ ë…¸ë“œ\"\"\"\n",
    "    # ì—°êµ¬ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€\n",
    "    context = f\"ì—°êµ¬ ê²°ê³¼:\\n{state.get('research_results', '')}\"\n",
    "    \n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=f\"{context}\\n\\nìœ„ ì •ë³´ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.\")\n",
    "    ]\n",
    "    \n",
    "    result = analyst.invoke({\"messages\": messages})\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": result[\"messages\"],\n",
    "        \"analysis_results\": result[\"messages\"][-1].content,\n",
    "    }\n",
    "\n",
    "def writer_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"ì‘ì„± ì—ì´ì „íŠ¸ ë…¸ë“œ\"\"\"\n",
    "    # ì—°êµ¬ ë° ë¶„ì„ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¶”ê°€\n",
    "    context = f\"\"\"\n",
    "    ì—°êµ¬ ê²°ê³¼:\n",
    "    {state.get('research_results', '')}\n",
    "    \n",
    "    ë¶„ì„ ê²°ê³¼:\n",
    "    {state.get('analysis_results', '')}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=f\"{context}\\n\\nìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\")\n",
    "    ]\n",
    "    \n",
    "    result = writer.invoke({\"messages\": messages})\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": result[\"messages\"],\n",
    "        \"final_report\": result[\"messages\"][-1].content,\n",
    "    }\n",
    "\n",
    "def coder_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"ì½”ë“œ ì—ì´ì „íŠ¸ ë…¸ë“œ\"\"\"\n",
    "    result = coder.invoke(state)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": result[\"messages\"],\n",
    "        \"code_results\": result[\"messages\"][-1].content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbcca19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Supervisor ë…¸ë“œ - ë‹¤ìŒ ì—ì´ì „íŠ¸ ê²°ì •\"\"\"\n",
    "    supervisor_chain = create_supervisor_chain()\n",
    "    \n",
    "    # í˜„ì¬ ìƒí™© ì»¨í…ìŠ¤íŠ¸\n",
    "    context = f\"\"\"\n",
    "    ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…:\n",
    "    - ì—°êµ¬: {'âœ…' if state.get('research_results') else 'âŒ'}\n",
    "    - ë¶„ì„: {'âœ…' if state.get('analysis_results') else 'âŒ'}\n",
    "    - ì½”ë“œ: {'âœ…' if state.get('code_results') else 'âŒ'}\n",
    "    - ë³´ê³ ì„œ: {'âœ…' if state.get('final_report') else 'âŒ'}\n",
    "    \n",
    "    ìµœê·¼ ë©”ì‹œì§€:\n",
    "    {state['messages'][-1].content if state['messages'] else 'ì—†ìŒ'}\n",
    "    \"\"\"\n",
    "    \n",
    "    decision = supervisor_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"input\": state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"next_agent\": decision.next_agent,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff334e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def route_to_agent(state: MultiAgentState) -> str:\n",
    "    \"\"\"ë‹¤ìŒ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…\"\"\"\n",
    "    return state.get(\"next_agent\", \"FINISH\")\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "workflow = StateGraph(MultiAgentState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"supervisor\", supervisor_node)\n",
    "workflow.add_node(\"researcher\", researcher_node)\n",
    "workflow.add_node(\"analyst\", analyst_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_node(\"coder\", coder_node)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    route_to_agent,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"analyst\": \"analyst\",\n",
    "        \"writer\": \"writer\",\n",
    "        \"coder\": \"coder\",\n",
    "        \"FINISH\": END,\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê° ì—ì´ì „íŠ¸ì—ì„œ Supervisorë¡œ ëŒì•„ê°€ê¸°\n",
    "workflow.add_edge(\"researcher\", \"supervisor\")\n",
    "workflow.add_edge(\"analyst\", \"supervisor\")\n",
    "workflow.add_edge(\"writer\", \"supervisor\")\n",
    "workflow.add_edge(\"coder\", \"supervisor\")\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "multi_agent_system = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2364b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "def run_multi_agent_system(instruction: str, thread_id: str = \"main\"):\n",
    "    \"\"\"Multi-Agent ì‹œìŠ¤í…œ ì‹¤í–‰\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    inputs = {\n",
    "        \"messages\": [HumanMessage(content=instruction)],\n",
    "        \"next_agent\": \"supervisor\"\n",
    "    }\n",
    "    \n",
    "    for step in multi_agent_system.stream(inputs, config):\n",
    "        node_name = list(step.keys())[0]\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ğŸ“ Current Agent: {node_name}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        if node_name == \"supervisor\":\n",
    "            next_agent = step[node_name].get(\"next_agent\", \"\")\n",
    "            print(f\"â¡ï¸ Next Agent: {next_agent}\")\n",
    "        else:\n",
    "            messages = step[node_name].get(\"messages\", [])\n",
    "            if messages:\n",
    "                print(messages[-1].content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "096d26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "AI ì—ì´ì „íŠ¸ ì‹œì¥ì— ëŒ€í•œ ì¢…í•© ì¡°ì‚¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”:\n",
    "1. ìµœì‹  ì‹œì¥ ë™í–¥ ë° í†µê³„ ì¡°ì‚¬ (ì›¹ ê²€ìƒ‰)\n",
    "2. ìˆ˜ì§‘ëœ ë°ì´í„° ë¶„ì„ (íŠ¸ë Œë“œ, ê¸°íšŒ, ìœ„í˜‘)\n",
    "3. Pythonìœ¼ë¡œ ê°„ë‹¨í•œ ì‹œê°í™” ì½”ë“œ ì‘ì„±\n",
    "4. ìµœì¢… ë³´ê³ ì„œ ì‘ì„± (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)\n",
    "\n",
    "ë³´ê³ ì„œëŠ” executive summary, ì‹œì¥ ë¶„ì„, ê¸°ìˆ  íŠ¸ë Œë“œ, ê²°ë¡  ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "run_multi_agent_system(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c4f982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "ì£¼ìš” ê²½ìŸì‚¬ 3ê³³(OpenAI, Anthropic, Google)ì˜ AI ì—ì´ì „íŠ¸ ì œí’ˆì„ ë¹„êµ ë¶„ì„í•˜ëŠ” í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "ë‹¨ê³„:\n",
    "1. ê° ê²½ìŸì‚¬ì˜ ìµœì‹  ì œí’ˆ ì •ë³´ ìˆ˜ì§‘\n",
    "2. ê¸°ëŠ¥, ê°€ê²©, ì„±ëŠ¥ ë¹„êµ ë¶„ì„\n",
    "3. ë¹„êµ í‘œ ìƒì„± Python ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±\n",
    "4. ê²½ìŸ ë¶„ì„ ë³´ê³ ì„œ ì‘ì„± (ê°•ì /ì•½ì /ê¸°íšŒ/ìœ„í˜‘)\n",
    "\n",
    "ìµœì¢… ê²°ê³¼ë¬¼ì€ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œì™€ Python ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "run_multi_agent_system(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "452ffd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "ì£¼ê°„ AI ë‰´ìŠ¤ë ˆí„°ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ìš”êµ¬ì‚¬í•­:\n",
    "1. ì´ë²ˆ ì£¼ AI ê´€ë ¨ ì£¼ìš” ë‰´ìŠ¤ 5ê°œ ìˆ˜ì§‘\n",
    "2. ê° ë‰´ìŠ¤ì˜ ìš”ì•½ ë° ì‹œì‚¬ì  ë¶„ì„\n",
    "3. ë‰´ìŠ¤ë ˆí„° HTML í…œí”Œë¦¿ ìƒì„± ì½”ë“œ ì‘ì„±\n",
    "4. ìµœì¢… ë‰´ìŠ¤ë ˆí„° ì‘ì„± (ì œëª©, ë³¸ë¬¸, ë§í¬)\n",
    "\n",
    "ì¶œë ¥: newsletter.html íŒŒì¼\n",
    "\"\"\"\n",
    "\n",
    "run_multi_agent_system(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b14a260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentMessage(BaseModel):\n",
    "    \"\"\"ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€\"\"\"\n",
    "    from_agent: str\n",
    "    to_agent: str\n",
    "    content: str\n",
    "    priority: int = 0\n",
    "\n",
    "def send_message(from_agent: str, to_agent: str, content: str, state: MultiAgentState):\n",
    "    \"\"\"ì—ì´ì „íŠ¸ ê°„ ì§ì ‘ ë©”ì‹œì§€ ì „ì†¡\"\"\"\n",
    "    message = AgentMessage(\n",
    "        from_agent=from_agent,\n",
    "        to_agent=to_agent,\n",
    "        content=content\n",
    "    )\n",
    "    \n",
    "    # ë©”ì‹œì§€ íì— ì¶”ê°€\n",
    "    state.setdefault(\"message_queue\", []).append(message)\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "987bbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_specialized_agent(domain: str, tools: list):\n",
    "    \"\"\"ë„ë©”ì¸ë³„ íŠ¹í™” ì—ì´ì „íŠ¸ ë™ì  ìƒì„±\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ {domain} ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ì „ë¬¸ ë¶„ì•¼ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”.\n",
    "    \"\"\"\n",
    "    \n",
    "    return create_react_agent(\n",
    "        model,\n",
    "        tools,\n",
    "        state_modifier=SystemMessage(content=prompt)\n",
    "    )\n",
    "\n",
    "# ì‹¤í–‰ ì¤‘ ìƒˆ ì—ì´ì „íŠ¸ ì¶”ê°€\n",
    "if \"ë²•ë¥  ìë¬¸ì´ í•„ìš”í•¨\":\n",
    "    legal_agent = create_specialized_agent(\"ë²•ë¥ \", legal_tools)\n",
    "    workflow.add_node(\"legal_expert\", legal_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8560cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class AgentMetrics(BaseModel):\n",
    "    \"\"\"ì—ì´ì „íŠ¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­\"\"\"\n",
    "    agent_name: str\n",
    "    task_count: int = 0\n",
    "    success_count: int = 0\n",
    "    avg_time: float = 0.0\n",
    "    last_execution: datetime = None\n",
    "\n",
    "def track_agent_performance(agent_name: str, execution_time: float, success: bool):\n",
    "    \"\"\"ì—ì´ì „íŠ¸ ì„±ëŠ¥ ì¶”ì \"\"\"\n",
    "    metrics = AgentMetrics(agent_name=agent_name)\n",
    "    \n",
    "    metrics.task_count += 1\n",
    "    if success:\n",
    "        metrics.success_count += 1\n",
    "    \n",
    "    # í‰ê·  ì‹œê°„ ì—…ë°ì´íŠ¸\n",
    "    metrics.avg_time = (metrics.avg_time * (metrics.task_count - 1) + execution_time) / metrics.task_count\n",
    "    metrics.last_execution = datetime.now()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cef0fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class TaskQueue:\n",
    "    \"\"\"ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì‘ì—… í\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "    \n",
    "    def add_task(self, priority: int, agent_name: str, task: dict):\n",
    "        \"\"\"ì‘ì—… ì¶”ê°€ (ìš°ì„ ìˆœìœ„ ë†’ì„ìˆ˜ë¡ ë¨¼ì € ì‹¤í–‰)\"\"\"\n",
    "        heapq.heappush(self.queue, (-priority, agent_name, task))\n",
    "    \n",
    "    def get_next_task(self):\n",
    "        \"\"\"ë‹¤ìŒ ì‘ì—… ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
    "        if self.queue:\n",
    "            priority, agent_name, task = heapq.heappop(self.queue)\n",
    "            return agent_name, task\n",
    "        return None, None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}