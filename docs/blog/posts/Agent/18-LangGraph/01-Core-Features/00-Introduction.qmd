---
title: "LangGraph 소개"
subtitle: "모듈형 RAG를 위한 플로우 엔지니어링 개요"
description: |
    LangGraph의 개념과 설계 철학, 기존 RAG 파이프라인의 한계 및 LangGraph가 제안하는 해결책을 다룬다.  
categories:
    - AI
    - RAG
    - LangGraph
author: Kwangmin Kim
date: 07/15/2025
format: 
    html:
        code-fold: true
        toc: true
        number-sections: true
draft: false
execute:
    eval: false
---

## LangGraph의 탄생배경

- RAG를 도입하면서 현실에서 다음과 같은 문제에 반복적으로 봉착한다.  
    - LLM이 생성한 답변이 실제 근거가 없는 hallucination인지 판단하기 어렵다.  
    - 문서 기반 검색(Retrieval)에서 얻은 정보가 질문의 맥락보다 외부 사전지식에 의존해 잘못된 답변을 만들 수 있다.  
    - 문서 검색으로 원하는 정보를 찾지 못하면 외부(웹, 논문 등)를 추가 탐색해야 하는데, 이 과정에서 신뢰할 수 없는 정보가 포함되면 최종 답변이 오염된다.  

- 가상의 예시: 기업 소개 문서로 QA를 수행할 때 매출액을 묻는 경우를 생각한다.  
    1. 기업 소개 문서에는 매출액 정보가 없다.  
    2. 시스템은 먼저 문서 검색을 수행하고 결과가 없으면 웹 검색으로 보강하려 시도한다.  
    3. 웹 검색에서 나온 정보가 출처가 불분명하거나 잘못된 경우, LLM은 그 정보를 근거로 답변을 만들어 hallucination을 발생시킬 수 있다.  
    4. 추가 검색-재검증 과정을 무한 반복하면 토큰 비용이 급증하고 응답 지연이 커진다.  

- 이처럼 단순한 action chain이 여러 도구와 의사결정 루프를 거치며 복잡해지면 파이프라인 유지와 디버깅이 어려워진다.  
    - 반복적 검색과 재작성 루프는 토큰 소모와 응답 지연을 키운다.  
    - 중간 결정(예: 결과 신뢰도 기준을 만족하지 않으면 검색을 중단) 로직이 늘어나면 파이프라인이 비선형적으로 복잡해진다.  
    - 각 단계의 작은 변화가 전체 답변 품질에 큰 영향을 끼쳐 예측 불가능성이 커진다.  

- Conventional RAG의 한계:  
    - 사전에 한정된 데이터 소스(PDF, DB, 테이블 등)에 의존한다.  
    - 고정된 청크 크기와 색인 전략을 사용한다.  
    - 쿼리 입력 형식과 검색 방법이 고정되어 유연성 부족하다.  
    - LLM/Agent의 불확실성으로 인해 신뢰성 확보가 어렵다.  
    - 고정된 프롬프트 템플릿으로 다양한 상황 대처가 어렵다.  
    - 이전 단계로 되돌아가 결과를 수정하거나 재검증하기 어렵다.  

## LangGraph 란?

- LangGraph는 RAG 파이프라인을 그래프 기반 워크플로우로 모델링하여 유연성과 투명성을 높이는 프레임워크이다.  
- LangChain처럼 도구 생태계를 활용할 수 있으면서도 LangChain에 종속되지 않는 경량 그래프 추상화를 제공한다.  
- 핵심 목표는 다음과 같다.  
    - 각 처리 단위를 독립적인 노드로 분리해 재사용성과 테스트 가능한 유닛으로 만든다.  
    - 노드 간의 흐름을 엣지로 정의해 조건부 분기와 반복, 병렬 처리를 자연스럽게 표현한다.  
    - 상태(state)를 명시적으로 관리해 중간 결과를 검증하거나 과거 실행을 재생(replay)할 수 있게 만든다.  

### 설계 아이디어와 장점  

- 모듈화: 데이터 적재, 전처리, 임베딩, 검색, 평가, 응답 생성 등 각 단계를 독립 노드로 구성해 조합 가능하게 한다.  
- 가시성: 그래프 구조로 흐름을 표현하면 어느 단계에서 문제가 발생했는지 추적하기 쉬워진다.  
- 유연성: 조건부 엣지로 다양한 분기 전략을 구현하고, human-in-the-loop을 손쉽게 끼워 넣을 수 있다.  
- 복구/재현성: 체크포인터를 통해 특정 시점으로 돌아가 중간 상태를 수정하고 재실행할 수 있다.  

### 예시 노드 목록  

 - **Checkpointer**: 과거 실행의 스냅샷을 저장하고 특정 시점으로 되돌려 재실행하거나 재검증하는 기능.  

## 구체적 가상 예시: 기업 매출 질문 시나리오  

- 상황: 내부 company_profile.pdf에 기업 개요와 연혁은 있지만 최신 매출액 정보는 없다.  
- 목표: 사용자 질문에 근거 기반 답변을 제공하되, 문서에 없을 경우 안전하게 외부 근거를 보강한다.  

- 권장 플로우(요약):  
  1. `document_loader` → `split` → `embedding` → `store`로 문서 색인 준비.  
  2. 사용자 질의 도착 → `query_rewrite`로 명확화(예: 기간, 통화 단위 추가).  
  3. `retriever`로 관련 청크 검색 → `relevance_evaluator`로 신뢰도 판단.  
  4. 관련도가 기준 이상이면 LLM 응답 생성 → `quality_evaluator`로 검증 후 반환.  
  5. 관련도가 낮거나 정보가 부족하면 `web_surfing`으로 외부 검색 시도 → `source_verifier`로 출처 신뢰성 점검.  
  6. 외부 출처가 신뢰할 수 있으면 LLM이 출처를 명시해 답변 생성, 그렇지 않으면 사용자에게 불확실성을 알리고 human-in-the-loop로 판단 요청.  

### 세부 동작과 안전장치  

- 신뢰도 기준: 검색 점수와 출처 메타데이터(도메인, 발행일, 공식성)를 결합해 임계값을 설정한다.  
- 토큰/비용 제어: 외부 검색은 최대 N번으로 제한하고, 재검색 루프는 체크포인터로 중단/재개할 수 있게 설계한다.  
- 출처 투명성: LLM 응답에 반드시 참조 출처를 병기하도록 강제한다.  
- Human fallback: 자동화가 불확실할 때는 검증 요청을 생성해 사람이 판단하도록 한다.  

### 간단한 pseudocode (개념 설명용)  

```python
# flow: document indexing
def index_documents(docs):  
    chunks = split(docs)  
    embeds = embed(chunks)  
    store(embeds)  

# flow: query handling
def handle_query(query):  
    query = query_rewrite(query)  
    results = retriever(query)  
    if relevance_evaluator(results):  
        answer = llm_generate(results, query)  
        if quality_evaluator(answer):  
            return answer_with_sources(answer, results)  
    external = web_surfing(query, max_attempts=2)  
    verified = source_verifier(external)  
    if verified:  
        return answer_with_sources(llm_generate(results+external, query), results+external)  
    return request_human_review(query, results, external)  
```

위 pseudocode는 개념을 설명하기 위한 간단한 예이며, 실제 구현에서는 비동기 처리, 에러 핸들링, 체크포인터 관리, 로깅 등이 필요하다.  

- **Node**: 특정 작업(task)을 수행하는 단위 함수 또는 컴포넌트.  
    - 입력과 출력을 명확히 정의하고 상태를 읽고 쓸 수 있다.  
- **Edge**: 노드 간의 실행 흐름을 정의하는 연결선.  
    - 단순 순차 실행뿐 아니라 조건부 분기, 반복, 병렬화를 표현한다.  
- **State**: 워크플로우 전반에서 공유되거나 노드별로 보존되는 값.  
    - 예: 쿼리 변형 히스토리, 검색 결과, LLM 응답, 평가 메타데이터 등.  
- **Conditional Edge**: 조건에 따라 다른 경로로 분기시키는 엣지.  
- **Human-in-the-loop**: 분기나 검증 단계에서 사람이 개입해 결정하는 지점.  
- **Checkpointer**: 과거 실행의 스냅샷을 저장하고 특정 시점으로 되돌려 재실행하거나 재검증하는 기능.  


## 세부기능


### 상태 (State)

* 노드와 노드 간에 정보를 전달할 때 상태 객체에 담아 전달한다.
* TypedDict: 일반 파이썬 dict에 타입헌팅을 추가한 개념이지만 쉽게 dictionary 생각해도 좋다.
    * key:value에서 value의 data type을 지정해주는 것
    * 예: `question: Annoated[list, add_messages]`
* 모든 값을 다 채우지 않아도 된다.
* 새로운 노드에서 값을 덮어쓰기(Overwrite)방식으로 채운다.

```python

from typing import Annotated, TypedDict
from langgraph.graph.message import add_messages

# GraphState 상태를 저장하는 용도로 사용합니다.

class GraphState(TypedDict):
        question: Annoated[list, add_messages] # 질문(Query Rewrite 누적) - 메세지 자동 추가
        context: Annoated[str, 'Context'] # 문서의 검색 결과 - overwrite
        answer: Annoated[str, 'Answer'] # 답변 - overwrite
        messages: Annoated[list, add_messages] # 메세지 - 메세지 자동 추가
        relevance: Annoated[str, 'Relevance'] # 관련성 - overwrite
```

* Redcuer (add_message 혹은 operator.add): 자동으로 list에 메세지를 추가해주는 기능
    *  list안에 chatbot의 경우 질문과 답변이 누적해서 쌓이게 되는데 append 메서드를 사용하지 않고 반환값에 annoatation과 함께 list로 감싸기만 하면 자동으로 메시지가 쌓이게 된다.
    * reducer (add_messages 혹은 operator.add): 자동으로 list에 메시지를 추가
        * `left' (Messages): 기본 메시지 리스트
        * 'right' (Messages): 병합할 메시지 리스트 또는 단일 메시지
    * 예를 들어, GraphState 클래스의 `messages: Annoated[list, add_messages] # 메세지 - 메세지 자동 추가` 가 입력이 되면 다음의 코드가 자동으로 실행이 된다.

```python
from langchain_core.messages import AIMessage, HumanMessage
from langgraph.graph import add_messages

# 기본 사용 예시

msgs1 = [HumanMessage(content="hello?", id = "1")]
msgs2 = [AIMessage(content="glad to see you~", id = "2")]

result1 = add_messages(msgs1, msgs2)
print(result1)
```

* RAG 사례
    * 노드4에서 '문서'에 대하여 답변 관련성 점수를 부여
    * score가 bad인 경우 (선택할 수 있는 행동 3가지)
        * 노드1: 질문을 재작성 요청
        * 노드2: 문서를 다시 검색 및 검색을 통한 정보 보완
        * 노드3: 답변을 재작성 요청

| Key      | 1. 노드1 (Question) | 2. 노드2 (Retrieve) | 3. 노드3 (Answer) | 4. 노드4 (Evaluate) |
| -------- | -------------- | -------------- | ------------ | -------------- |
| context  |                | **문서1**       | 문서1        | 문서1            |
| question | **질문1**       | 질문1           | 질문1        | 질문1            |
| answer   |                |                | **답변1**     | 답변1            |
| score    |                |                |              | **BAD**         |

* 노드1: 질문을 재작성 요청 하는 경우 (노드4 → 노드1)

| Key      | 5. 노드1 (Question) |6. 노드2 (Retrieve) | 7. 노드3 (Answer) | 8. 노드4 (Evaluate) |
| -------- | -------------- | -------------- | ------------ | -------------- |
| context  | 문서1           | **문서2**      | 문서2          | 문서2            |
| question | **질문2**       | 질문2          | 질문2          | 질문2            |
| answer   | 답변1           | 답변1          | **답변2**    | 답변2            |
| score    | BAD1           | BAD1           | BAD1         | **GOOD**        |

* 노드2: 문서 검색을 재요청 하는 경우 (노드4 → 노드2)

| Key      | 1. 노드1 (Question) | 5. 노드2 (Retrieve) | 6. 노드3 (Answer) | 7. 노드4 (Evaluate) |
| -------- | -------------- | ------------------ | ------------ | -------------- |
| context  |                | **문서2**           | 문서2        | 문서2            |
| question | 질문1            | 질문1             | 질문1         | 질문1            |
| answer   |                | 답변1               | **답변2**    | 답변2            |
| score    |                | BAD                | BAD          | **GOOD**           |


* 노드3: 답변을 재작성 요청 하는 경우 (노드4 → 노드3) 

| Key      | 1. 노드1 (Question) | 2. 노드2 (Retrieve) | 5. 노드3 (Answer) | 6. 노드4 (Evaluate) |
| -------- | -------------- | -------------- | ---------------- | -------------- |
| context  |                | 문서1            | 문서1              | 문서1            |
| question | 질문1            | 질문1            | 질문1              | 질문1            |
| answer   |                |                | **답변2**              | 답변2            |
| score    |                |                | BAD              | **GOOD**           |


### 노드 (Node)

* 함수로 정의

```python
# 문서에서 검색하여 관련성 있는 split를 찾는다.
def retrieve_document(state: GraphState) -> GraphState
    # Question 에 대한 문서 검색을 retriever로 수행
    retrieved_docs = pdf_retriever.invoke(state["qeustion"])
    # 검색된 문서를 context 키에 저장
    return GraphState(context = format_docs(retrieved_docs))  

# Chian을 사용하여 답변 생성
def llm_answer(state: GraphState) -> GraphState:    
    return GraphState(
        answer=pdf_chain.invoke({"question": state["question"], "context":state['context']})
    )
```

* 입력인자: 상태 (State) 객체 `state: GraphState`

| Key      | 1. 노드1 (Question) |
| -------- | -------------- |
| context  |                |
| question | **질문1**       |
| answer   |                |   
| score    |                |   

* 반환 (return): 
    * 대부분 상태 (State) 객체 `context = format_docs(retrieved_docs)`
    * Conditional Edge의 경우 다를 수 있음

| Key      | 2. 노드2 (Retrieve) |
| -------- | -------------- |
| context  | **문서1**       |
| question | 질문1       |
| answer   |                |   
| score    |                |   

* 결국 Agent의 성능이 좋으려면 세부 노드를 정교하게 만들어놓고 각 노드들간의 상태를 주고받아 정교한 통제를 할 수 있어야한다.
* graph 생성 후 노드 추가
    * 이전에 정의한 함수를 graph에 추가
    * add_node ("노드이름", 함수)

```python
from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# langgraph.graph에서 StateGraph와 END를 가져온다.
workflow = StateGraph(GraphState)

# 노드들을 정의한다.
workflow.add_node("retrieve", retrieve_document) # 에이전트 노드 추가
workflow.add_node("llm_answer", llm_answer) # 정보 검색 노드를 추가

```

### 엣지(Edge)

* 노드에서 노드간의 연결
* add_edge("from 노드이름", "to 노드이름")

```python
# 노드연결
workflow.add_edge("retreive", "llm_answer") # 검색 -> 답변
workflow.add_edge("llm_answer", "relevance_check") # 답변 -> 관련성 체크
```


### 조건부 엣지 (Conditional Edge)

* 노드에 조건부 엣지를 추가하여 분기를 수행할 수 있다.
* add_conditional_edge("노드이름",조건부 판단 함수, dict로 다음 단계 결정)
* 흐름
    * "relevance_check"노드에서 나온결과를 is_relevant함수에 입력
    * 반환된 값은 "grounded", "notGrounded", "notSure" 중 하나
        * value에 해당하는 값이 END면 Graph종료
        * "llm_answer"와 같이 노드이름이면 해당 노드로 연결

```python
#조건부 엣지를 추가

workflow.add_conditional_edge(
    "relevance_check", # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달
    is_relevant,
    {
        "grounded": END # 관련성이 있으면 종료합니다.
        "notGrounded": "llm_answer" # 관련성이 없으면 다시 답변 생성
        "notSure": "llm_answer" # 관련성 체크 결과가 모호하다면 다시 답변을 생성
    }
)
```

* 시작점 지정: `set_entry_point("노드이름")` 지정한 시작점부터 graph가 시작

```python
workflow.set_entry_point("retrieve")
```

### CheckPointer (Memory)

* 그래프 생성을 하는데 단순하게 그래프 생성하는 것은 compile만 하면 되는데 체크포인터는 메모리 기능이 있음
* 각 노드간의 실행결과를 추적하기 위한 메모리(대화에 대한 기록과 유사)
* 체크포인터를 활용하여 특정 시점 (snapshot)으로 되돌리기 기능도 가능
* `compile(checkpointer=meemory)` 지정하여 그래프 생성

```python
# 기록을 위한 메모리 저장소 설정
memory = MemorySaver()

# 그래프 컴파일
app = workflow.compile(checkpointer=memory)
```

### Graph Visualization

* 생성한 그래프 시각화: get_graph(xray=True).draw_mermaid_png()

```python
display(
    Image(app.get_graph(xray=True).draw_mermaid_png())
)
```

### Graph Execution

* RunnableConfig
    * recursion_limit: 최대 노드 실행 개수를 지정
    * thread_id: 그래프 실행 아디리르 기록하고, 추후 추적하기 위한 목적으로 활용
* 상태로 시작
    * 여기서 question에만 질문만 입력하고 상태를 첫 번째 노드에게 전달
* invoke(상태,config) 전달하여 실행