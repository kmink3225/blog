---
title: "Azure AI Search Integration"
subtitle: 벡터 스토어 통합 및 하이브리드 검색
description: |
  Azure AI Search와 RAG 시스템 통합, 벡터 인덱스 생성, 하이브리드 검색 구현 방법을 다룬다.
categories:
  - AI
  - RAG
  - Azure
author: Kwangmin Kim
date: 11/05/2025
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
execute:
    eval: false
---

## 들어가며

* agent의 최적화는 Deep Learning  model처럼 스크립트화 시켜서 학습과정을 자동화시키기 힘들다.
* agent는 다양한 외부 시스템과 상호작용하며, 이러한 상호작용은 고정된 패턴이 아니기 때문에 최적화가 어렵다.
* 따라서, agent의 최적화는 주로 경험적 방법과 실험을 통해 이루어진다.
* 체계적으로 agent의 성능을 평가하고, 다양한 설정과 전략을 실험하여 최적의 구성을 찾아가는 과정이 필요하다.
* 단계를 나누어 agent의 성능을 분석하고, 각 단계에서의 개선점을 찾아내는 것이 중요하다.

## RAG 성능 파라미터 규명

현재 코드 분석 결과, 다음 파라미터들이 RAG 성능에 영향을 미칩니다:

### 파라미터 분류표

| 카테고리 | 파라미터 | 현재 값 | 범위 | RAG 영향 |
|---------|---------|--------|------|---------|
| **청킹** | `chunk_size` | 1500 | 500~3000 | 검색 단위 크기 |
| | `chunk_overlap` | 400 | 100~800 | 문맥 연결 |
| | `contextual_chunking` | true | on/off | 섹션 헤더 추가 |
| | `separators` | 다중 | 커스텀 | 분할 기준 |
| **임베딩** | `model` | ada-002 | 3개 모델 | 의미 검색 품질 |
| | `dimension` | null | 모델별 | 임베딩 차원 |
| **인덱스** | `name` | 환경변수 | 문자열 | 인덱스 분리 |
| | `rebuild_on_config_change` | false | on/off | 자동 재구축 |
| **검색** | `k` | 6 | 3~15 | 반환 문서 수 |
| | `search_type` | hybrid | 3가지 | 검색 방식 |
| | `mmr_diversity` | 0.5 | 0~1 | 다양성 |
| | `similarity_threshold` | 0.7 | 0.5~0.9 | 컷오프 |
| | `reranker_enabled` | false | on/off | 재정렬 |
| **프롬프트** | `template_name` | chatbot_... | 문자열 | 프롬프트 선택 |
| | `version` | v1 | 문자열 | 버전 관리 |
| **대화** | `history_turns` | 6 | 0~20 | 컨텍스트 턴 |
| | `max_context_length` | 8000 | 문자 수 | 컨텍스트 제한 |
| **LLM** | `model` | gpt-4o-mini | 다수 | 응답 모델 |
| | `temperature` | 0.7 | 0~1 | 창의성 |
| | `max_tokens` | 4000 | 1000~8000 | 응답 길이 |
| | `top_p` | 1.0 | 0~1 | 샘플링 |


### 핵심 튜닝 대상 (높은 영향도):

```
1. chunk_size      → 문서 세분화 정도 결정
2. chunk_overlap   → 문맥 연결 품질 결정
3. embedding_model → 의미 검색 품질 결정
4. retrieval_k     → 컨텍스트 양 결정
5. search_type     → 검색 방식 결정
```

## 설정 파일로 관리

```yml
# RAG 설정 프로파일: default
# 현재 운영 중인 기본 설정

name: default
description: "현재 운영 중인 기본 설정"

# ============================================================
# 청킹 설정 (문서 분할)
# ============================================================
chunking:
  # 청크 크기 (문자 수)
  # - 작을수록: 세밀한 검색, 하지만 맥락 손실 가능
  # - 클수록: 맥락 보존, 하지만 노이즈 증가 가능
  # 권장 범위: 500 ~ 3000
  chunk_size: 1500
  
  # 청크 간 중복 크기
  # - 클수록: 문맥 연결 좋음, 하지만 중복 증가
  # 권장 범위: 100 ~ 800 (chunk_size의 20~30%)
  chunk_overlap: 400
  
  # 컨텍스트 청킹 활성화
  # - on: 각 청크에 소속 섹션 헤더 추가 (검색 품질 향상)
  # - off: 원본 텍스트만 사용
  contextual_chunking: true
  
  # 텍스트 분할 구분자 (우선순위 순)
  separators:
    - "\n\n\n"  # 큰 섹션 구분
    - "\n\n"    # 문단 구분
    - "\n"      # 줄 구분
    - ". "      # 문장 구분
    - "? "
    - "! "
    - ", "
    - " "
    - ""

# ============================================================
# 임베딩 설정 (의미 검색)
# ============================================================
embedding:
  # 임베딩 모델 (Azure deployment name)
  # 옵션: text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large
  # - ada-002: 1536차원, 가성비 좋음
  # - 3-small: 1536차원, 최신, 성능 향상
  # - 3-large: 3072차원, 최고 성능, 비용 높음
  model: ${AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME:text-embedding-ada-002}
  
  # 임베딩 차원 (null이면 모델 기본값)
  dimension: null
  
  # Azure OpenAI API 버전
  api_version: ${AZURE_OPENAI_API_VERSION:2024-08-01-preview}

# ============================================================
# 벡터 스토어 인덱스 설정
# ============================================================
index:
  # Azure Search 인덱스 이름
  # 실험별로 다른 인덱스 사용 가능
  # 네이밍 규칙: {document}_{strategy}_{version}
  name: ${AZURE_SEARCH_INDEX_NAME:default-index}
  
  # 설정 변경 시 인덱스 재구축 여부
  rebuild_on_config_change: false

# ============================================================
# 검색 설정 (Retrieval)
# ============================================================
retrieval:
  # 검색 시 반환할 문서 수
  # - 적을수록: 정확한 문서만, 하지만 정보 부족 가능
  # - 많을수록: 풍부한 정보, 하지만 노이즈 증가
  # 권장 범위: 3 ~ 15
  k: 6
  
  # 검색 방식
  # - similarity: 벡터 유사도만 사용
  # - hybrid: BM25 키워드 + 벡터 유사도 결합 (권장)
  # - mmr: Maximum Marginal Relevance (다양성 고려)
  search_type: hybrid
  
  # MMR 다양성 가중치 (search_type이 mmr일 때만 적용)
  # 0.0: 관련성만 고려
  # 1.0: 다양성만 고려
  # 권장: 0.5 ~ 0.7
  mmr_diversity: 0.5
  
  # 유사도 임계값 (이 값 미만은 제외)
  # 권장 범위: 0.5 ~ 0.9
  similarity_threshold: 0.7
  
  # 재정렬 (Reranking) 설정
  reranker_enabled: false
  reranker_model: null

# ============================================================
# 프롬프트 템플릿 설정
# ============================================================
prompt:
  # 프롬프트 템플릿 파일명 (.yml 확장자 제외)
  # 사용 가능: chatbot_data_standardization_rules, code_analyzer, data_standardizer
  template_name: chatbot_data_standardization_rules
  
  # 프롬프트 버전 (버전 관리 및 A/B 테스트용)
  version: v1
  
  # 시스템 메시지 오버라이드 (null이면 템플릿 사용)
  system_message_override: null

# ============================================================
# 대화 컨텍스트 설정
# ============================================================
conversation:
  # 컨텍스트에 포함할 최근 대화 턴 수
  # - 많을수록: 맥락 이해 향상, 하지만 토큰 비용 증가
  # 권장 범위: 0 ~ 20
  history_turns: 6
  
  # 이전 응답의 출처를 컨텍스트에 포함할지 여부
  include_sources_in_context: false
  
  # 최대 컨텍스트 길이 (문자 수)
  max_context_length: 8000

# ============================================================
# LLM 설정 (응답 생성)
# ============================================================
llm:
  # 사용할 LLM 모델 (Azure deployment name)
  # 옵션: gpt-4o-mini, gpt-4o, gpt-4, gpt-35-turbo, gpt-5-mini
  model: gpt-4o-mini
  
  # Temperature (응답의 창의성/다양성)
  # 0.0: 결정적, 일관된 응답
  # 1.0: 다양하고 창의적인 응답
  # 권장: 0.3 ~ 0.7 (질의응답)
  temperature: 0.7
  
  # 최대 응답 토큰 수
  # 권장 범위: 1000 ~ 8000
  max_tokens: 4000
  
  # Nucleus sampling (top_p)
  top_p: 1.0
  
  # Azure OpenAI API 버전
  api_version: ${AZURE_OPENAI_API_VERSION:2024-08-01-preview}
```

## UI에서 인덱스 선택 + 비교

## 평가 메트릭 고안

## 테스트 질문 세트 ⭐ 중요!

## 실험 로깅