---
title: "GPT4All"
subtitle: 임베딩
description: |
  텍스트를 벡터로 변환하는 다양한 임베딩 모델을 다룬다.
categories:
  - AI
  - RAG
  - LangChain
author: Kwangmin Kim
date: 12/31/2024
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
execute:
    eval: false
---


[GPT4All](https://gpt4all.io/index.html)은 무료로 사용할 수 있는 로컬 실행 기반의 개인정보 보호를 고려한 챗봇입니다.

GPU나 인터넷 연결이 필요하지 않으며, GPT4All Falcon, Wizard 등 인기 있는 모델과 자체 모델을 제공합니다.

이 노트북에서는 LangChain과 함께 [GPT4All embeddings](https://docs.gpt4all.io/gpt4all_python_embedding.html#gpt4all.gpt4all.Embed4All)를 사용하는 방법을 설명합니다.


```{python}
# API KEY를 환경변수로 관리하기 위한 설정 파일
from dotenv import load_dotenv

# API KEY 정보로드
load_dotenv()
```

```{python}
# LangSmith 추적을 설정합니다. https://smith.langchain.com
# !pip install langchain-teddynote
from langchain_teddynote import logging

# 프로젝트 이름을 입력합니다.
logging.langsmith("CH08-Embeddings")
```

## GPT4All의 Python 바인딩 설치

GPT4All의 Python 바인딩을 설치하려면 다음 명령을 실행하세요

```{python}
# 설치
# !pip install -qU  gpt4all > /dev/null
```

- `GPT4AllEmbeddings` 클래스를 `langchain_community.embeddings` 모듈에서 임포트합니다.

`GPT4AllEmbeddings`는 GPT4All 모델을 사용하여 텍스트 데이터를 벡터로 임베딩하는 기능을 제공하는 클래스입니다. 이 클래스는 LangChain 프레임워크의 임베딩 인터페이스를 구현하여, LangChain의 다양한 기능과 함께 사용할 수 있습니다.

```{python}
from langchain_community.embeddings import GPT4AllEmbeddings
```

GPT4All은 CPU에 최적화된 대조 학습 문장 변환기를 사용하여 임의 길이의 텍스트 문서에 대한 고품질 임베딩 생성을 지원합니다. 이러한 임베딩은 OpenAI를 사용하는 많은 작업에서 품질이 비슷합니다.

`GPT4AllEmbeddings` 클래스의 인스턴스를 생성합니다.

- `GPT4AllEmbeddings`는 GPT4All 모델을 사용하여 텍스트 데이터를 벡터로 변환하는 임베딩 모델입니다.
- 이 코드에서는 `gpt4all_embd` 변수에 `GPT4AllEmbeddings` 인스턴스를 할당합니다.
- 이후 `gpt4all_embd`를 사용하여 텍스트 데이터를 벡터로 변환할 수 있습니다.

```{python}
gpt4all_embd = GPT4AllEmbeddings()  # GPT4All 임베딩 객체를 생성합니다.
```

```{python}
gpt4all_embd = GPT4AllEmbeddings()  # GPT4All 임베딩 객체를 생성합니다.
```

- `text` 변수에 "임베딩 테스트를 하기 위한 샘플 문장입니다." 라는 문자열을 할당합니다.

```{python}
text = (
    "임베딩 테스트를 하기 위한 샘플 문장입니다."  # 테스트용 문서 텍스트를 정의합니다.
)
```

## Embed the Textual Data

텍스트 데이터를 임베딩하는 과정은 다음과 같습니다.

먼저, 텍스트 데이터를 토큰화하여 숫자 형태로 변환합니다.

이때, 사전 학습된 토크나이저(tokenizer)를 활용하여 텍스트를 토큰 단위로 분리하고, 각 토큰을 고유한 정수로 매핑합니다.

다음으로, 토큰화된 데이터를 임베딩 레이어에 입력하여 고차원의 밀집 벡터(dense vector) 형태로 변환합니다.

이 과정에서 각 토큰은 해당 토큰의 의미와 문맥을 포착하는 실수 값들의 벡터로 표현됩니다.

마지막으로, 임베딩된 벡터는 다양한 자연어 처리 작업에 활용될 수 있습니다.

예를 들어, 문서 분류, 감성 분석, 기계 번역 등의 작업에서 입력 데이터로 사용되어 모델의 성능을 향상시킬 수 있습니다.

이러한 텍스트 데이터 임베딩 과정은 자연어 처리 분야에서 매우 중요한 역할을 하며, 대량의 텍스트 데이터를 효과적으로 처리하고 분석하는 데 필수적입니다.

`gpt4all_embd` 객체의 `embed_query` 메서드를 사용하여 주어진 텍스트(`text`)를 임베딩합니다.

- `text` 변수에 임베딩할 텍스트가 저장되어 있습니다.
- `gpt4all_embd` 객체는 GPT4All 모델을 사용하여 텍스트 임베딩을 수행하는 객체입니다.
- `embed_query` 메서드는 주어진 텍스트를 벡터 형태로 변환하여 반환합니다.
- 임베딩 결과는 `query_result` 변수에 저장됩니다.

```{python}
query_result = gpt4all_embd.embed_query(
    text
)  # 주어진 텍스트에 대한 쿼리 임베딩을 생성합니다.
```

embed_documents 함수를 사용하면 여러 개의 텍스트 조각을 임베딩할 수 있습니다.

또한 이러한 임베딩을 Nomic의 Atlas(https://docs.nomic.ai/index.html)와 매핑하여 데이터의 시각적 표현을 확인할 수 있습니다.

임베딩된 차원의 크기를 확인합니다.

```{python}
# 임베딩된 차원의 크기를 확인합니다.
len(query_result)
```

`gpt4all_embd` 객체의 `embed_documents` 메서드를 사용하여 `text` 문서를 임베딩합니다.

- `text` 문서를 리스트로 감싸서 `embed_documents` 메서드의 인자로 전달합니다.
- `embed_documents` 메서드는 문서의 임베딩 벡터를 계산하여 반환합니다.
- 반환된 임베딩 벡터는 `doc_result` 변수에 저장됩니다.

```{python}
# 주어진 텍스트를 임베딩하여 문서 벡터를 생성합니다.
doc_result = gpt4all_embd.embed_documents([text])
```

```{python}
# 임베딩된 차원의 크기를 확인합니다.
len(doc_result[0])
```

