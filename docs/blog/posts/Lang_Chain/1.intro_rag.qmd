---
title: "RAG과 LangChain 소개"
subtitle: "Retrieval-Augmented Generation과 LangChain 프레임워크 이해"
description: |
  LangChain 프레임워크와 RAG(Retrieval-Augmented Generation) 기술의 개념, 필요성, 구현 방법에 대해 알아본다.
categories:
  - RAG
author: Kwangmin Kim
date: 06/07/2025
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
---

# Lang Chain 소개

## LangChain이란?

- **정의**: LLM(Large Language Model) 기반 애플리케이션 개발을 위한 오픈소스 프레임워크
- **주요 목적**: 복잡한 LLM 애플리케이션을 쉽게 구축할 수 있도록 지원

## LangChain의 핵심 기능

- **체인(Chain)**: 여러 컴포넌트를 연결하여 복잡한 워크플로우 구성
- **프롬프트 템플릿**: 동적으로 프롬프트 생성 및 관리
- **메모리**: 대화 히스토리 및 컨텍스트 유지
- **에이전트**: 도구 사용 및 의사결정 자동화
- **문서 로더**: 다양한 형식의 문서 처리
- **벡터 스토어**: 임베딩 기반 검색 시스템

## LangChain 사용 사례

- **챗봇**: 문맥을 이해하는 대화형 AI 시스템
- **문서 QA**: 문서 기반 질의응답 시스템  
- **데이터 분석**: 자연어로 데이터 분석 수행
- **코드 생성**: 자연어 명령으로 코드 자동 생성
- **RAG 시스템**: 검색 기반 답변 생성 시스템

# RAG 소개

## RAG가 인기 있게 된 이유

- **LLM의 한계 극복**: 학습 데이터 시점 이후 정보 부족 문제 해결
- **실시간 정보 활용**: 최신 정보를 동적으로 검색하여 활용
- **도메인 특화**: 특정 분야의 전문 지식 기반 답변 생성
- **비용 효율성**: 전체 모델 재학습 없이 지식 확장 가능
- **신뢰성 향상**: 검색된 문서 기반으로 답변의 근거 제공

## Chat GPT 도래 및 성공

- **2022년 11월 출시**: OpenAI ChatGPT 공개 후 폭발적 인기
- **사용자 급증**: 출시 2개월 만에 1억 사용자 돌파
- **산업 변화**: AI 기반 대화형 인터페이스의 새로운 표준 제시
- **기술 혁신**: Transformer 기반 대화형 AI의 상용화 성공
- **생성형 AI 붐**: GPT 성공으로 생성형 AI 시장 급성장

## Chat GPT의 문제점

- **할루시네이션(Hallucination)**: 그럴듯하지만 잘못된 정보 생성
- **지식 컷오프**: 학습 데이터 시점 이후 정보 부족
- **일관성 부족**: 같은 질문에 다른 답변 제공 가능
- **도메인 특화 한계**: 전문 분야 지식의 정확도 부족
- **출처 불명**: 답변 근거가 되는 정보 출처 제공 불가

## RAG 적용시 Chat GPT의 문제점 해결 방안들

- **실시간 정보 검색**: 최신 문서에서 관련 정보 검색하여 제공
- **근거 기반 답변**: 검색된 문서를 바탕으로 답변 생성
- **도메인 지식 확장**: 특정 분야 문서 데이터베이스 구축
- **일관성 개선**: 동일한 문서 소스 기반으로 일관된 답변
- **출처 추적**: 답변에 사용된 문서 출처 명시

## RAG 기대 효과

- **정확도 향상**: 검증된 문서 기반으로 답변 품질 개선
- **신뢰성 확보**: 출처가 명확한 근거 기반 답변 제공
- **전문성 강화**: 도메인 특화 지식 기반 전문 상담 가능
- **비용 절감**: 모델 재학습 없이 지식 업데이트
- **확장성**: 새로운 문서 추가만으로 지식 확장 가능

## RAG 적용 방법

Chat GPT의 할루시네이션을 줄이고 방대한 지식 기반으로 답변하는 도메인 특화 chatbot 구축 가능

즉, RAG란 chat gpt에게 잘 정제된 데이터를 제공하여 더 정확하고 신뢰할 수 있는 답변을 제공하는 방법이다.

**주요 과제들:**
- Chat GPT의 RAG 과정은 비공개되어 user가 통제할 수 없는 부분이기 때문에 사용자들은 문서를 chat gpt가 잘 검색할 수 있는 형태로 변경하는 것이 중요
- 어려운 점은 각 문서마다 파일 형식이 다르고 이를 gpt가 처리가능한 형태로 전처리하는 과정이 공수가 많이 들어감
- 고유의 RAG를 만들어줘야 함

## RAG Process

**기본 워크플로우:**
```
query -> RAG(document -> chunk -> embedding -> vector store (DB) -> Retriever) -> Prompt Engineering -> LLM
```

**세부 단계:**
1. **문서 수집**: 도메인 특화 문서 데이터 수집
2. **청킹(Chunking)**: 문서를 검색 가능한 단위로 분할
3. **임베딩**: 텍스트를 벡터로 변환
4. **벡터 스토어**: 임베딩 벡터를 데이터베이스에 저장
5. **검색(Retrieval)**: 쿼리와 유사한 문서 청크 검색
6. **프롬프트 엔지니어링**: 검색 결과를 포함한 프롬프트 구성
7. **답변 생성**: LLM이 최종 답변 생성

이 고유의 RAG를 만들어주는 것이 중요하지만 매우 고되고 어려운 과정이다. 내가 구현하려고 하는 답변 기능이 안되는 이유는 정말 수백가지에 달하기 때문이다.

하지만 분명한건 RAG를 잘 적용하여 원하는 기능을 구현하는 사례들이 많이 나오고 있고 효과적인 방법론들이 존재한다:

**고급 RAG 기법들:**
- **코사인 유사도 최적화**: 벡터 검색 정확도 개선
- **HyDE Retrieval**: 가상 문서 생성을 통한 검색 성능 향상
- **FT Embedding**: 도메인 특화 임베딩 모델 파인튜닝
- **Chunk Embedding 실험**: 최적 청킹 전략 탐색
- **Reranking**: 검색 결과 재순위화
- **Classification Step**: 쿼리 유형 분류를 통한 검색 최적화
- **Prompt Engineering**: 효과적인 프롬프트 설계
- **Tool Use**: 외부 도구 활용 확장
- **Query Expansion**: 쿼리 확장 및 개선

## RAG 구현 난이도

RAG 구현은 사실상 LLM을 Tuning하는 것과 같다.

**LLM Tuning 방법 난이도 비교:**
- **Prompt Engineering** (매우 쉬움): 프롬프트만 수정하여 성능 개선
- **RAG** (쉬움): 외부 지식 소스 연결하여 답변 품질 향상
- **PEFT** (어려움): Parameter-Efficient Fine-Tuning 적용
- **Full Fine Tuning** (매우 어려움): 전체 모델 파라미터 재학습

**RAG의 장점:**
- 상대적으로 구현 난이도가 낮음
- 기존 모델 파라미터 수정 불필요
- 지식 업데이트가 용이함
- 비용 효율적인 성능 개선 방법

## RAG 구현 방법

### 기본 RAG 파이프라인 구축

**문서 처리:**
- 다양한 형식(PDF, DOCX, TXT, HTML) 문서 로딩
- 텍스트 추출 및 전처리
- 의미 있는 단위로 청킹 분할

**벡터화 및 저장:**
- OpenAI Embeddings 또는 오픈소스 임베딩 모델 사용
- FAISS, Chroma, Pinecone 등 벡터 데이터베이스 구축
- 효율적인 유사도 검색 인덱스 생성

### 검색 시스템 구현

**검색 전략:**
- 코사인 유사도 기반 벡터 검색
- 키워드 기반 하이브리드 검색
- 의미적 유사도와 키워드 매칭 결합

**검색 최적화:**
- Top-K 검색 결과 개수 조정
- 검색 임계값(threshold) 설정
- 문서 메타데이터 활용 필터링

### 프롬프트 엔지니어링

**프롬프트 구조:**
- 시스템 메시지: 역할 및 지침 명시
- 컨텍스트: 검색된 문서 내용 포함
- 질문: 사용자 쿼리
- 답변 형식: 원하는 출력 형태 지정

**프롬프트 개선:**
- Few-shot 예시 추가
- 체인 오브 생각(Chain of Thought) 적용
- 답변 검증 및 출처 표기 요구

### 평가 및 개선

**성능 평가:**
- 답변 정확도 측정
- 검색 정밀도(Precision) 및 재현율(Recall)
- 사용자 만족도 조사

**지속적 개선:**
- A/B 테스트를 통한 파라미터 최적화
- 사용자 피드백 기반 모델 업데이트
- 새로운 문서 데이터 정기 추가







