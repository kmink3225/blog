---
title: "Azure AI Foundry Quota 및 제한 사항"
subtitle: "Azure OpenAI 모델 할당량 관리 가이드"
description: |
  Azure AI Foundry의 Quota 시스템, TPM/RPM 제한, 사용량 계층 및 할당량 증가 요청 방법을 정리한다.
categories:
  - AI
  - Cloud
  - Azure
author: Kwangmin Kim
date: 12/17/2025
format: 
  html:
    code-fold: true
    toc: true
    number-sections: true
draft: False
---


## 배경지식  

Quota의 개념을 알기위해선 먼저 Tenant가 무엇인지 이해해야한다.  

### Tenant의 개념  

* **테넌트(Tenant)**는 Azure의 최상위 조직 단위를 뜻한다.  
  - **Microsoft Entra ID (구 Azure Active Directory)의 인스턴스**  
  - 조직 전체를 나타내는 최상위 컨테이너  
  - 고유한 도메인 이름을 가짐 (예: `yourcompany.onmicrosoft.com`)  
* 왜 조직 단위인가?  
  - **중앙 집중식 관리**: IT 관리자가 모든 직원 계정 관리  
  - **접근 제어**: 누가 어떤 리소스에 접근할 수 있는지 조직 차원에서 통제  
  - **보안 정책**: 조직 전체에 MFA, 비밀번호 정책 등 일괄 적용  
  - **비용 관리**: 조직의 모든 Azure 사용량을 하나의 청구서로 관리  
* 개인이 Azure를 쓸 때도 기술적으로는 1인 조직의 Entra ID가 자동 생성된다.  

::: {.callout-note}  
**Microsoft Entra ID는 개인이 아닌 조직 단위**의 ID 관리 시스템이다.  
- **개인 계정** = 개인 휴대폰 번호  
- **Entra ID** = 회사 대표번호 시스템 (내선번호 체계)  

### 개인 vs 조직  

**개인 Microsoft 계정**  
- `yourname@outlook.com`, `yourname@hotmail.com`  
- 개인용 OneDrive, Xbox, Skype 등에 사용  
- 조직과 무관  

**Microsoft Entra ID (조직)**  
- `yourname@yourcompany.com`  
- 회사/조직의 ID 관리 시스템  
- 조직의 모든 직원, 앱, 리소스를 관리  

* 예시: **삼성전자**가 Azure를 사용한다면,  

```  
Entra ID 테넌트: samsung.onmicrosoft.com  
├── 사용자: kim@samsung.com  
├── 사용자: lee@samsung.com  
├── 사용자: park@samsung.com  
└── Azure 구독들  
    ├── 개발팀 구독  
    ├── 운영팀 구독  
    └── 마케팅팀 구독  
```  
:::  

* Azure 계층 구조  

```  
테넌트 (Tenant)  
  └── 구독 (Subscription)  
       └── 리소스 그룹 (Resource Group)  
            └── 리소스 (Resource)  
```  

* 테넌트가 포함하는 것  
  - **사용자 계정**: 조직의 모든 직원 계정  
  - **그룹**: 사용자들의 그룹  
  - **애플리케이션**: 등록된 앱들  
  - **구독**: 여러 개의 Azure 구독  
  - **보안 정책**: 조직 전체 보안 규칙  
* 예시: **삼성전자**라는 회사가 있다면:  
  - **테넌트**: `samsung.onmicrosoft.com`  
  - **구독 1**: 개발팀 구독  
  - **구독 2**: 운영팀 구독  
  - **구독 3**: 마케팅팀 구독  

→ 모든 구독이 하나의 테넌트 아래에 있음  

## Quota 개요  

### Quota의 개념  

* **Quota**는 Azure에서 리소스 사용량에 대한 **할당량(제한)**을 의미한다.  
* Quota = 사용 가능한 리소스의 최대량  
  - **무엇을 제한하나**: API 호출 속도, 토큰 처리량, 리소스 개수 등  
  - **왜 필요한가**: 공정한 리소스 분배, 시스템 과부하 방지, 비용 관리  
  - **어디에 적용되나**: Azure 구독(Subscription) 레벨  

### Azure AI Foundry에서의 Quota  

- 각 모델은 사용 가능한 지역마다 독립적인 할당량 풀을 보유한다  
- 예: gpt-4.1 Global Standard가 5M TPM 할당량을 가지면, 각 지역마다 5M TPM이 할당된다  

1. **TPM (Tokens Per Minute)**: 분당 처리 가능한 토큰 수  
   - 예: gpt-4o는 기본 450K TPM 할당  
2. **RPM (Requests Per Minute)**: 분당 처리 가능한 요청 수  
   - 예: gpt-4o는 기본 2.7K RPM 할당  
3. **리소스 개수 제한**  
   - 지역당 Azure OpenAI 리소스 30개  
   - 리소스당 배포 32개  

### Quota의 범위  

- Quota는 테넌트 레벨이 아닌 **Azure 구독(Subscription) 레벨**에서 적용된다  
  - **테넌트 레벨이라면**: 회사 전체에 할당량 1개  
  - **구독 레벨 (실제)**: 각 구독마다 독립적인 할당량  
  - 예를 들어, 개발팀 구독에서 100만 TPM을 다 써도 운영팀 구독의 100만 TPM에는 영향 없음.  
- 지역별, 구독별, 모델별 또는 배포 유형별로 제한이 설정된다  
- 동일 구독 내에서 여러 지역에 리소스를 분산하면 더 많은 총 TPM/RPM 사용 가능하다  
  - 다시 말해서, Azure의 Quota(예: TPM/RPM)는 **구독(Subscription) × 지역(Region) 단위**로 각각 별도로 할당된다.  
  -  **즉, 지역별로 할당량 풀이 따로 존재**하므로,  
    - 한 지역의 할당량을 다 써도 다른 지역의 리소스는 별도의 할당량으로 추가 사용이 가능하다.  
  - 그러므로, **Azure Open AI 리소스를 여러 지역에 만들어 이용해야 더 많은 누적 TPM/RPM을 확보할 수 있다.**  
  - 예를 들어,  
    - 구독 A의 Korea Central에 gpt-4o 리소스 1개 (450K TPM)  
    - 같은 구독 A의 East US 2에 gpt-4o 리소스 1개 (450K TPM)  
   
  → 이 경우, 두 지역의 TPM이 합쳐져서 총 900K TPM까지 사용 가능하다.  

## 주요 제한 사항  

### 리소스 제한  

- Azure OpenAI 리소스: 지역당 구독당 30개  
- Foundry 리소스: 지역당 구독당 100개  
- 리소스당 최대 프로젝트: 250개  
- 리소스당 최대 배포: 32개 (Standard), 5개 (Fine-tuned)  

### 모델별 기본 제한  

- DALL-E 2: 2개 동시 요청  
- DALL-E 3: 2 capacity units (6 RPM)  
- GPT-image-1: 3 capacity units (9 RPM)  
- Sora: 60 RPM  
- Sora 2: 2개 병렬 작업  
- Speech-to-text: 3 RPM  

### Fine-tuning 제한  

- 리소스당 최대 학습 작업: 100개  
- 동시 실행 학습 작업: 1개  
- 최대 대기열 학습 작업: 20개  
- 리소스당 최대 파일 수: 50개  
- 총 파일 크기: 1GB  
- 최대 학습 시간: 720시간  
- 최대 학습 크기: (토큰 수 × 에폭 수) = 20억  

### API 제한  

- /embeddings 최대 입력 수: 2,048  
- /chat/completions 최대 메시지: 2,048  
- /chat/completions 최대 함수: 128  
- /chat/completions 최대 도구: 128  
- Provisioned Throughput Units (PTU) 최대: 100,000  
- Assistants/Thread당 최대 파일: 10,000  
- Assistants 최대 파일 크기: 512MB (API), 200MB (Portal)  
- Assistants 토큰 제한: 2,000,000  

## 배포 유형별 TPM/RPM 할당량  

### GPT-5 시리즈  

#### Global Standard  
- gpt-5: 1M TPM / 10K RPM  
- gpt-5-mini: 1M TPM / 10K RPM  
- gpt-5-nano: 5M TPM / 150K RPM  

#### Data Zone Standard  
- gpt-5: 300K TPM / 3K RPM  
- gpt-5-mini: 300K TPM / 3K RPM  
- gpt-5-nano: 2M TPM / 50K RPM  

### GPT-4.1 시리즈  

#### Global Standard  
- Enterprise/MCA-E: 5M TPM / 5K RPM  
- Default: 1M TPM / 1K RPM  
- gpt-4.1-nano Enterprise: 150M TPM / 150K RPM  
- gpt-4.1-nano Default: 5M TPM / 5K RPM  

#### Data Zone Standard  
- Enterprise/MCA-E: 2M TPM / 2K RPM  
- Default: 300K TPM / 300 RPM  
- gpt-4.1-nano Enterprise: 50M TPM / 50K RPM  
- gpt-4.1-nano Default: 2M TPM / 2K RPM  

### GPT-4o 시리즈  

#### Global Standard  
- gpt-4o Enterprise: 30M TPM / 180K RPM  
- gpt-4o Default: 450K TPM / 2.7K RPM  
- gpt-4o-mini Enterprise: 150M TPM / 1.5M RPM  
- gpt-4o-mini Default: 2M TPM / 12K RPM  

#### Data Zone Standard  
- gpt-4o Enterprise: 10M TPM / 60K RPM  
- gpt-4o Default: 300K TPM / 1.8K RPM  
- gpt-4o-mini Enterprise: 20M TPM / 120K RPM  
- gpt-4o-mini Default: 1M TPM / 6K RPM  

### o-시리즈 (추론 모델)  

#### Global Standard  
- o3-mini Enterprise: 50M TPM / 5K RPM  
- o3-mini Default: 5M TPM / 500 RPM  
- o1 Enterprise: 30M TPM / 5K RPM  
- o1 Default: 3M TPM / 500 RPM  

#### Data Zone Standard  
- o3 Default: 10M TPM / 10K RPM  
- o3-mini Enterprise: 20M TPM / 2K RPM  
- o3-mini Default: 2M TPM / 200 RPM  

## Batch API 제한  

### Global Batch  

- gpt-4.1: 5B (billion) 대기 토큰 / 200M 24시간 토큰 / 50M 일일 토큰  
- gpt-4.1-mini: 15B 대기 / 1B 24시간 / 50M 일일  
- gpt-4o: 5B 대기 / 200M 24시간 / 50M 일일  
- gpt-5: 5B 대기 / 200M 24시간 / 50M 일일  
- Global Standard 대비 50% 할인  

### Data Zone Batch  

- gpt-4.1: 500M 대기 / 30M 24시간 / 30M 일일  
- gpt-4o: 500M 대기 / 30M 24시간 / 30M 일일  
- gpt-5: 5B 대기 / 200M 24시간 / 50M 일일  

### Batch 파일 제한  

- 리소스당 최대 파일: 500개  
- 최대 입력 파일 크기: 200MB  
- 파일당 최대 요청 수: 100,000개  

## Usage Tiers (사용량 계층)  

### 개념  

- Global Standard와 Data Zone Standard 배포에만 적용된다  
- 사용량 계층은 모델별로 정의된 토큰 임계값이다  
- 임계값 초과 시 응답 지연 시간 변동성이 증가할 수 있다  
- 테넌트 단위로 모든 구독, 모든 지역의 총 토큰 사용량을 합산한다  

### 주요 모델별 임계값  

- gpt-5: 32억 토큰  
- gpt-5-mini: 160억 토큰  
- gpt-5-nano: 800억 토큰  
- gpt-4.1: 300억 토큰  
- gpt-4.1-mini: 1,500억 토큰  
- gpt-4.1-nano: 5,500억 토큰  
- gpt-4o: 120억 토큰  
- gpt-4o-mini: 850억 토큰  
- o3-mini: 500억 토큰  
- o1: 40억 토큰  

### Usage Tier 초과 시 대응  

- **Quota 증가 요청**: Azure Portal에서 할당량 증가 신청  
- **PTU로 업그레이드**: Provisioned Throughput Units로 전환하여 전용 리소스 확보  
- **사용량 모니터링**: Azure Portal에서 정기적으로 사용 지표 검토  

## 구독 유형별 제한  

### Enterprise 및 MCA-E  

- 가장 높은 기본 할당량 제공  
- 예: gpt-4o Enterprise는 30M TPM (Default는 450K TPM)  
- GPT-5-pro는 MCA-E와 Default 구독만 사용 가능  

### 제한된 구독 유형  

- **Azure for Students**: 대부분 1K TPM (o-시리즈, GPT-4.1, GPT-4.5는 0)  
- **MSDN**: gpt-4o-mini 200K, GPT-3.5 200K, GPT-4 50K (o-시리즈는 0)  
- **Pay-as-you-go**: gpt-4o-mini 200K, GPT-4 50K (o-시리즈는 0)  
- **Free Trial/Azure Pass**: 모든 모델 0  
- 일부 구독은 East US2와 Sweden Central의 Global Standard만 사용 가능  

## Autoscale 기능  

### 개념  

- 리소스 사용량에 따라 자동으로 호출 제한을 증가/감소시킨다  
- 기본적으로 비활성화 상태이며 수동으로 활성화해야 한다  
- 유료 구독 계층에서만 사용 가능하다  

### 지원 서비스  

- Azure Vision, Language (일부), Anomaly Detector  
- Content Moderator, Custom Vision, Immersive Reader  
- LUIS, Metrics Advisor, Personalizer, QnA Maker  
- Document Intelligence  
- **Azure OpenAI는 Autoscale 미지원** (별도 Quota 관리 필요)  

### 동작 방식  

- 429 오류 발생 시 5분마다 가용 용량 확인  
- 용량이 충분하면 점진적으로 TPS 증가 (최대 1000 TPS)  
- 1시간 이상 높은 사용률 지속 시 최대 한도 도달  
- 용량 부족 시 5분 후 재확인  

### 비용 영향  

- 가격 정책 변경 없음 (성공한 API 호출만 과금)  
- 호출 제한 증가로 더 많은 트랜잭션 처리 가능 → 요금 증가 가능  
- 클라이언트 버그로 인한 과다 호출 시 비용 급증 위험  
- 개발 및 테스트는 고정 제한 리소스에서 수행 권장  

## Shared Quota (공유 할당량)  

### 개념  

- Foundry가 제공하는 공유 할당량 풀이다  
- 여러 사용자가 여러 지역에서 동시에 사용 가능하다  
- 가용성에 따라 일시적으로 할당량 접근 가능하다  
- 사용 시간은 제한적이며 사용 사례에 따라 다르다  

### 사용 목적  

- 모델 카탈로그의 추론 테스트용  
- **임시 테스트 엔드포인트만** 생성 가능 (프로덕션 부적합)  
- 프로덕션은 반드시 전용 할당량 요청 필요  

### 과금 방식  

- 사용량 기반 과금 (Pay-as-you-go)  
- 공유 할당량 사용도 일반 API 호출과 동일하게 과금  

## Quota 관리 및 증가 요청  

### Foundry Portal에서 Quota 확인  

1. Microsoft Foundry Portal 로그인  
2. Management Center (하단 왼쪽) 선택  
3. Quota 메뉴 클릭  
4. 지역별 모델 할당량 확인  
5. Show all quota 토글로 전체/할당된 할당량만 표시  
6. Group by 드롭다운으로 그룹화 방식 변경  

### Quota 할당 편집  

- 모델 배포 라인의 연필 아이콘 클릭  
- 할당량 재분배 (한 배포에서 다른 배포로 이동)  
- Request quota 버튼으로 Standard 배포 유형 증가 요청  

### Quota 증가 요청  

- [Quota 증가 요청 양식](https://aka.ms/oai/stuquotarequest) 제출  
- 수요가 높아 선착순 처리  
- 기존 할당량을 소비하는 트래픽 생성 고객에게 우선순위  
- 조건 미충족 시 거절 가능  

### 지역별 Quota 가용성 확인  

- Foundry Portal의 Quota 뷰에서 확인  
- Capacity API로 구독별 모델 가용 용량 조회 가능  
- 특정 모델/버전의 모든 지역 및 배포 유형별 가용 용량 반환  

## Rate Limit 관리 모범 사례  

### 제한 내 유지 방법  

- 애플리케이션에 재시도 로직 구현  
- 워크로드 급격한 변화 방지, 점진적 증가  
- 다양한 부하 증가 패턴 테스트  
- 필요시 배포에 할당된 할당량 증가 (다른 배포에서 이동)  

### 타임아웃 설정 권장사항  

- **추론 모델 (o-시리즈)**: 최대 29분  
- **비추론 모델 스트리밍**: 최대 60초  
- **비추론 모델 비스트리밍**: 최대 29분  
- 트래픽 패턴에 맞춰 위 값보다 낮게 조정  
- 명시적으로 설정하지 않으면 라이브러리 기본값 사용  

### 429 오류 발생 시  

- 재시도 로직 활용 (지수 백오프)  
- Quota 증가 요청  
- PTU (Provisioned Throughput) 고려  
- 사용량 모니터링 및 워크로드 조정  

## 참고 자료  

- [Azure AI Foundry Quota 관리](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/quota?view=foundry-classic)  
- [Autoscale 기능](https://learn.microsoft.com/en-us/azure/ai-services/autoscale)  
- [Azure OpenAI Quotas & Limits](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/quotas-limits?view=foundry-classic)  
- [Foundry Models Quotas & Limits](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/quotas-limits?view=foundry-classic)  
