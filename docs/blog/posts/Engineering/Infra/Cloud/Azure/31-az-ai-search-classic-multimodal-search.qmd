---
title: "Azure AI Search Multimodal Search"
subtitle: "텍스트와 이미지를 통합하는 검색 파이프라인"
description: |
  Azure AI Search의 Multimodal Search 기능을 설명한다. PDF 문서에서 텍스트와 이미지를 추출하고 벡터화하여 검색 가능한 인덱스를 구축하는 5단계 파이프라인, 3가지 추출 옵션, 2가지 임베딩 방식을 다룬다.
categories:
  - Engineering
  - Infra
  - Cloud
  - Azure
  - RAG
author: Kwangmin Kim
date: 12/25/2026
format: 
  html:
    code-fold: true
    toc: true
    number-sections: true
draft: false
---

# 개요

**Multimodal Search**는 텍스트, 이미지, 비디오, 오디오 등 여러 콘텐츠 형식에서 정보를 수집, 이해, 검색하는 기능이다. Azure AI Search는 텍스트와 이미지가 포함된 문서를 처리하여 두 형식을 결합한 검색을 지원한다.

## 왜 Multimodal Search인가?

전통적으로 멀티모달 검색은 텍스트와 이미지 처리를 위한 **별도의 시스템**이 필요하며, 사용자 지정 코드와 복잡한 구성이 요구된다. 이는 높은 비용, 복잡성, 유지보수 부담을 야기한다.

**Azure AI Search의 해결책**: 이미지를 텍스트와 동일한 검색 파이프라인에 통합하여 단일 멀티모달 파이프라인으로 처리한다.

### 주요 장점

- **통합 파이프라인**: 차트, 스크린샷, 인포그래픽, 스캔 양식 등의 시각적 데이터를 텍스트와 함께 처리
- **RAG 시나리오 최적화**: 이미지의 구조적 논리를 해석하여 RAG 애플리케이션과 AI 에이전트가 중요한 시각적 세부 정보를 활용 가능
- **정확한 인용**: 원본 형식(텍스트/이미지)에 관계없이 원래 소스로 추적 가능한 답변 제공

**실제 사례**: "HR 양식 승인 프로세스는 무엇인가요?"라는 질문에 대해, 프로세스 설명이 PDF의 다이어그램에만 있어도 답변 가능

# Multimodal Search 작동 원리

## 5단계 파이프라인

Azure AI Search는 **Azure Portal의 "데이터 가져오기" 마법사**를 통해 멀티모달 파이프라인 구축을 간소화한다.

### 단계별 처리 흐름

\`\`\`mermaid
graph TD
    A[1. 콘텐츠 추출] --> B[2. 텍스트 청킹]
    A --> C[3. 이미지 설명 생성]
    B --> D[4. 임베딩 생성]
    C --> D
    A --> E[5. 이미지 저장]
    D --> F[검색 인덱스]
    E --> G[지식 저장소]
\`\`\`

### 각 단계 상세

#### 콘텐츠 추출

3가지 기본 제공 기술 중 선택:
- **Document Extraction Skill**: 기본 추출
- **Document Layout Skill**: 위치 메타데이터 포함 (페이지 번호, 경계 영역)
- **Azure Content Understanding Skill**: 의미 기반 청킹, 페이지 간 테이블 처리

#### 텍스트 청킹

**Text Split Skill**이 추출된 텍스트를 관리 가능한 청크로 분할하여 임베딩 기술이 처리할 수 있게 준비한다.

#### 이미지 설명 생성 (선택)

**GenAI Prompt Skill**이 LLM을 호출하여 각 이미지에 대한 간결한 자연어 설명을 생성한다.
- 예: "관리자 승인으로 시작하는 5단계 HR 액세스 워크플로"

#### 임베딩 생성

텍스트와 이미지의 벡터 표현을 생성하여 유사성 검색 및 하이브리드 검색 지원:
- **Azure OpenAI Embedding Skill**
- **Microsoft Foundry Embedding Model**
- **Azure Vision Multimodal Embedding Skill**

#### 이미지 저장

**지식 저장소(Knowledge Store)**에 추출된 이미지를 저장하여 클라이언트 애플리케이션이 직접 반환할 수 있게 한다. 이미지 위치는 인덱스에 저장되어 쿼리 시 편리하게 검색 가능하다.

## Azure Portal 마법사

**빠른 시작**: [Azure Portal에서 멀티모달 검색](https://learn.microsoft.com/ko-kr/azure/search/search-get-started-portal-image-search)

마법사를 통해 다음을 구성:
- 데이터 원본
- 추출 및 보강 설정
- 텍스트, 이미지 참조, 벡터 임베딩이 포함된 멀티모달 인덱스

# 콘텐츠 추출 옵션 비교

Azure AI Search는 3가지 기본 제공 추출 기술을 제공한다.

## 기술별 기능 비교

| 기능 | Document Extraction | Document Layout | Azure Content Understanding |
|------|-------------------|----------------|---------------------------|
| **텍스트 위치 메타데이터** | ❌ | ✅ (페이지, 경계 다각형) | ✅ (페이지, 경계 다각형) |
| **이미지 위치 메타데이터** | ✅ | ✅ | ✅ |
| **테이블 추출** | ❌ | ❌ | ✅ (페이지 간 포함) |
| **교차 페이지 의미 단위** | N/A | ❌ (단일 페이지만) | ✅ |
| **기본 제공 청킹** | ❌ (Text Split 사용) | ✅ (단락 경계) | ✅ (의미 기반) |
| **지원 파일 형식** | PDF만 | 다중 형식 (DI Layout) | PDF, DOCX, XLSX, PPTX |
| **과금 기준** | Azure AI Search 가격 | Document Layout 가격 | Content Understanding 가격 |

## 권장 시나리오

### Document Extraction
- **사용 사례**: 빠른 프로토타이핑, 위치 정보가 불필요한 프로덕션 파이프라인
- **장점**: 구성 간단, 비용 효율적
- **제약**: 위치 메타데이터 없음, PDF만 지원

### Document Layout
- **사용 사례**: 정확한 페이지 번호, 페이지 강조 표시, 다이어그램 오버레이가 필요한 RAG 파이프라인
- **장점**: 위치 메타데이터 포함, 다중 파일 형식
- **제약**: 단일 페이지 단위 처리

### Azure Content Understanding
- **사용 사례**: 페이지 간 테이블, 의미 기반 청킹, 일관된 다중 형식 처리
- **장점**: 가장 포괄적, 의미 기반 청킹, 교차 페이지 처리
- **제약**: 높은 비용

# 임베딩 옵션

Azure AI Search는 이미지 처리를 위한 2가지 보완적 접근법을 제공한다.

## 이미지 언어화 + 텍스트 임베딩

### 처리 흐름
\`\`\`
이미지 → GenAI Prompt Skill → 자연어 설명 → 텍스트 임베딩
\`\`\`

### 특징
- **LLM 기반**: 각 이미지에 대해 LLM 호출 (인덱싱 시)
- **의미 풍부**: 다이어그램의 관계와 엔터티 해석
- **인용 가능**: LLM이 응답에서 그대로 인용 가능한 캡션 제공
- **RAG 최적화**: 접지된 데이터로 관련 스니펫 반환

### 장점
- 다이어그램, 흐름도 등 설명적 시각 자료에 최적
- AI 에이전트와 RAG 애플리케이션에 풍부한 컨텍스트 제공

### 단점
- 모든 이미지마다 LLM 호출 필요
- 인덱싱 시간 증가
- 비용 상승

## 직접 멀티모달 임베딩

### 처리 흐름
\`\`\`
이미지/텍스트 → Multimodal Embedding Model → 공유 벡터 공간
\`\`\`

### 특징
- **직접 벡터화**: 이미지와 텍스트를 동일한 벡터 공간에 직접 매핑
- **LLM 불필요**: 인덱싱 시 LLM 호출 없음
- **시각적 유사성**: "이것과 비슷한 것 찾기" 시나리오에 적합

### 장점
- 구성 간단
- 빠른 인덱싱
- 비용 효율적
- 시각적 유사성 검색에 최적

### 단점
- 순수 수학적 표현 (의미 설명 없음)
- 인용이나 상세 설명용 컨텍스트 부족

## 두 방법의 결합

많은 솔루션은 **두 인코딩 경로를 병행**한다:

| 콘텐츠 유형 | 추천 방식 |
|-----------|---------|
| 다이어그램, 흐름도, 설명적 시각 자료 | 이미지 언어화 + 텍스트 임베딩 |
| 스크린샷, 제품 사진, 아트워크 | 직접 멀티모달 임베딩 |

Azure AI Search 인덱스와 스킬셋 파이프라인을 커스터마이징하여 **두 벡터 집합을 저장**하고 나란히 검색 가능하다.

# 쿼리 옵션

## 텍스트 쿼리 (GenAI Prompt 기반)

GenAI Prompt Skill로 구동되는 파이프라인에서는 **하이브리드 쿼리** 실행 가능:
- 일반 텍스트와 언어화된 이미지 모두 검색
- 필터로 특정 콘텐츠 유형(텍스트만/이미지만) 범위 지정
- 전체 텍스트 검색 + 벡터 검색 + 의미 순위 결합

### 제약사항
**이미지-벡터 쿼리 미지원**: GenAI Prompt는 텍스트-벡터 쿼리만 지원

## 이미지 쿼리 (멀티모달 임베딩)

이미지를 쿼리 입력으로 사용하려면 멀티모달 임베딩 모델 필수:
- **AML Skill** 또는
- **Azure Vision Multimodal Embedding Skill**

이들 기술만 쿼리 시 이미지를 벡터로 변환하는 **벡터라이저**를 제공한다.

### 구성
[검색 인덱스에서 벡터라이저 구성](https://learn.microsoft.com/ko-kr/azure/search/vector-search-how-to-configure-vectorizer) 참조

# 실습 리소스

## 빠른 시작

- **Azure Portal 마법사**: [빠른 시작: Azure Portal에서 멀티모달 검색](https://learn.microsoft.com/ko-kr/azure/search/search-get-started-portal-image-search)
  - 마법사와 검색 탐색기로 멀티모달 인덱스 생성 및 테스트

## 튜토리얼

### 이미지 언어화 기반

1. **[생성 AI로 이미지 설명하기](https://learn.microsoft.com/ko-kr/azure/search/tutorial-document-extraction-image-verbalization)** (Document Extraction)
   - Document Extraction Skill로 텍스트/이미지 추출
   - 다이어그램 언어화
   - 설명과 텍스트를 검색 인덱스에 임베딩

2. **[구조화된 문서 레이아웃에서 이미지 언어화](https://learn.microsoft.com/ko-kr/azure/search/tutorial-document-layout-image-verbalization)** (Document Layout)
   - 레이아웃 기반 블록 및 다이어그램 언어화
   - 위치 메타데이터 캡처
   - 정확한 인용 및 페이지 강조 표시

### 직접 멀티모달 임베딩

3. **[이미지 및 텍스트 벡터화](https://learn.microsoft.com/ko-kr/azure/search/tutorial-document-extraction-multimodal-embeddings)** (Document Extraction)
   - Vision 멀티모달 모델로 텍스트/이미지 직접 임베딩
   - 스캔 PDF의 시각적 유사성 검색

4. **[구조화된 문서 레이아웃에서 벡터화](https://learn.microsoft.com/ko-kr/azure/search/tutorial-document-layout-multimodal-embeddings)** (Document Layout)
   - 레이아웃 기반 청킹 + 통합 임베딩
   - 하이브리드 의미/키워드 검색
   - 정확한 적중 위치 반환

# 튜토리얼 상세: Document Extraction + Multimodal Embeddings

이 섹션은 **Azure Vision 4.0 Multimodal Embedding**을 사용한 구현 방법을 단계별로 설명한다.

## 필수 구성 요소

### Azure 리소스

1. **Azure AI Search** (Basic 이상)
   - 역할 기반 액세스 제어 및 관리 ID 구성
   - 무료 계층 미지원

2. **Microsoft Foundry 리소스**
   - Azure Vision Multimodal 4.0 API 액세스
   - 지역 제약: Multimodal 4.0 지원 지역 확인 필요

3. **Azure Storage**
   - 샘플 데이터 저장
   - 지식 저장소 (추출된 이미지)
   - 검색 서비스에 Storage Blob Data Reader 역할 할당

### 도구

- Visual Studio Code + REST 클라이언트

## 데이터 준비

### 샘플 데이터

36페이지 PDF 문서: [Accelerating Sustainability with AI](https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Accelerating-Sustainability-with-AI-2025.pdf)
- 차트, 인포그래픽, 스캔 페이지 포함

### 스토리지 구성

```bash
# 1. Blob Container 생성
Container Name: sustainable-ai-pdf

# 2. PDF 업로드

# 3. 역할 할당 (관리 ID 사용)
- Storage Blob Data Reader (인덱서용)
- Storage Blob Data Contributor (지식 저장소용)
- Storage Table Data Contributor (지식 저장소용)
```

### 연결 문자열 (관리 ID)

```json
{
  "credentials": {
    "connectionString": "ResourceId=/subscriptions/{subscription-id}/resourceGroups/{resource-group}/providers/Microsoft.Storage/storageAccounts/{storage-account}/;"
  }
}
```

## 모델 준비

### Foundry 역할 할당

```bash
# Azure Portal > Foundry 리소스 > 액세스 제어(IAM)
역할: Cognitive Services 사용자
할당 대상: 검색 서비스 관리 ID
```

**중요**: Foundry 리소스는 Multimodal 4.0 API 지원 지역에 있어야 함

## 인덱스 스키마

### 필드 정의

```json
{
  "name": "doc-extraction-multimodal-embedding-index",
  "fields": [
    {
      "name": "content_id",
      "type": "Edm.String",
      "key": true,
      "analyzer": "keyword"
    },
    {
      "name": "text_document_id",
      "type": "Edm.String",
      "filterable": true
    },
    {
      "name": "image_document_id",
      "type": "Edm.String",
      "filterable": true
    },
    {
      "name": "document_title",
      "type": "Edm.String",
      "searchable": true
    },
    {
      "name": "content_text",
      "type": "Edm.String",
      "searchable": true
    },
    {
      "name": "content_embedding",
      "type": "Collection(Edm.Single)",
      "dimensions": 1024,
      "vectorSearchProfile": "hnsw"
    },
    {
      "name": "content_path",
      "type": "Edm.String",
      "retrievable": true
    },
    {
      "name": "location_metadata",
      "type": "Edm.ComplexType",
      "fields": [
        {
          "name": "page_number",
          "type": "Edm.Int32"
        },
        {
          "name": "bounding_polygons",
          "type": "Edm.String"
        }
      ]
    }
  ]
}
```

### 벡터 검색 구성

```json
{
  "vectorSearch": {
    "profiles": [
      {
        "name": "hnsw",
        "algorithm": "defaulthnsw",
        "vectorizer": "demo-vectorizer"
      }
    ],
    "algorithms": [
      {
        "name": "defaulthnsw",
        "kind": "hnsw",
        "hnswParameters": {
          "m": 4,
          "efConstruction": 400,
          "metric": "cosine"
        }
      }
    ],
    "vectorizers": [
      {
        "name": "demo-vectorizer",
        "kind": "aiServicesVision",
        "aiServicesVisionParameters": {
          "resourceUri": "{{cognitiveServicesUrl}}",
          "authIdentity": null,
          "modelVersion": "2023-04-15"
        }
      }
    ]
  }
}
```

**핵심 포인트**:
- `dimensions: 1024` - Azure Vision Multimodal 4.0의 벡터 차원
- `vectorizer: aiServicesVision` - 쿼리 시 이미지 벡터화 지원

## 스킬셋 구성

### 전체 파이프라인

```mermaid
graph LR
    A[Document Extraction] --> B[Text Split]
    A --> C[Vision Vectorize Text]
    A --> D[Vision Vectorize Image]
    B --> C
    C --> E[Index Projection]
    D --> E
    A --> F[Shaper]
    F --> G[Knowledge Store]
```

### 주요 스킬

#### 1. Document Extraction Skill

```json
{
  "@odata.type": "#Microsoft.Skills.Util.DocumentExtractionSkill",
  "parsingMode": "default",
  "dataToExtract": "contentAndMetadata",
  "configuration": {
    "imageAction": "generateNormalizedImages",
    "normalizedImageMaxWidth": 2000,
    "normalizedImageMaxHeight": 2000
  },
  "context": "/document",
  "inputs": [
    {
      "name": "file_data",
      "source": "/document/file_data"
    }
  ],
  "outputs": [
    {
      "name": "content",
      "targetName": "extracted_content"
    },
    {
      "name": "normalized_images",
      "targetName": "normalized_images"
    }
  ]
}
```

**출력**:
- `extracted_content`: 문서의 모든 텍스트
- `normalized_images`: 정규화된 이미지 배열 (최대 2000x2000)

#### 2. Text Split Skill

```json
{
  "@odata.type": "#Microsoft.Skills.Text.SplitSkill",
  "context": "/document",
  "defaultLanguageCode": "en",
  "textSplitMode": "pages",
  "maximumPageLength": 2000,
  "pageOverlapLength": 200,
  "unit": "characters",
  "inputs": [
    {
      "name": "text",
      "source": "/document/extracted_content"
    }
  ],
  "outputs": [
    {
      "name": "textItems",
      "targetName": "pages"
    }
  ]
}
```

**청킹 전략**:
- 2000자 청크
- 200자 오버랩 (문맥 유지)

#### 3. Azure Vision Vectorize Skill (Text)

```json
{
  "@odata.type": "#Microsoft.Skills.Vision.VectorizeSkill",
  "name": "text-embedding-skill",
  "context": "/document/pages/*",
  "modelVersion": "2023-04-15",
  "inputs": [
    {
      "name": "text",
      "source": "/document/pages/*"
    }
  ],
  "outputs": [
    {
      "name": "vector",
      "targetName": "text_vector"
    }
  ]
}
```

#### 4. Azure Vision Vectorize Skill (Image)

```json
{
  "@odata.type": "#Microsoft.Skills.Vision.VectorizeSkill",
  "name": "image-embedding-skill",
  "context": "/document/normalized_images/*",
  "modelVersion": "2023-04-15",
  "inputs": [
    {
      "name": "image",
      "source": "/document/normalized_images/*"
    }
  ],
  "outputs": [
    {
      "name": "vector",
      "targetName": "image_vector"
    }
  ]
}
```

**Azure Vision Multimodal Embedding**:
- 동일한 스킬, 입력만 다름 (text vs image)
- 1024차원 벡터 생성
- 공유 벡터 공간 (텍스트-이미지 간 코사인 유사도 계산 가능)

#### 5. Shaper Skill

```json
{
  "@odata.type": "#Microsoft.Skills.Util.ShaperSkill",
  "context": "/document/normalized_images/*",
  "inputs": [
    {
      "name": "imagePath",
      "source": "='{{imageProjectionContainer}}/'+$(/document/normalized_images/*/imagePath)"
    },
    {
      "name": "location_metadata",
      "sourceContext": "/document/normalized_images/*",
      "inputs": [
        {
          "name": "page_number",
          "source": "/document/normalized_images/*/pageNumber"
        },
        {
          "name": "bounding_polygons",
          "source": "/document/normalized_images/*/boundingPolygon"
        }
      ]
    }
  ],
  "outputs": [
    {
      "name": "output",
      "targetName": "new_normalized_images"
    }
  ]
}
```

### Index Projections

```json
{
  "indexProjections": {
    "selectors": [
      {
        "targetIndexName": "doc-extraction-multimodal-embedding-index",
        "parentKeyFieldName": "text_document_id",
        "sourceContext": "/document/pages/*",
        "mappings": [
          {
            "name": "content_embedding",
            "source": "/document/pages/*/text_vector"
          },
          {
            "name": "content_text",
            "source": "/document/pages/*"
          },
          {
            "name": "document_title",
            "source": "/document/document_title"
          }
        ]
      },
      {
        "targetIndexName": "doc-extraction-multimodal-embedding-index",
        "parentKeyFieldName": "image_document_id",
        "sourceContext": "/document/normalized_images/*",
        "mappings": [
          {
            "name": "content_embedding",
            "source": "/document/normalized_images/*/image_vector"
          },
          {
            "name": "content_path",
            "source": "/document/normalized_images/*/new_normalized_images/imagePath"
          },
          {
            "name": "location_metadata",
            "source": "/document/normalized_images/*/new_normalized_images/location_metadata"
          },
          {
            "name": "document_title",
            "source": "/document/document_title"
          }
        ]
      }
    ],
    "parameters": {
      "projectionMode": "skipIndexingParentDocuments"
    }
  }
}
```

**동작 원리**:
- 텍스트 청크당 1개 문서 생성 (`text_document_id`)
- 이미지당 1개 문서 생성 (`image_document_id`)
- 부모 문서(원본 PDF)는 인덱싱 건너뛰기

### Knowledge Store

```json
{
  "knowledgeStore": {
    "storageConnectionString": "{{storageConnection}}",
    "projections": [
      {
        "files": [
          {
            "storageContainer": "{{imageProjectionContainer}}",
            "source": "/document/normalized_images/*"
          }
        ]
      }
    ]
  }
}
```

**저장 내용**:
- 정규화된 이미지 파일 (JPEG)
- 파일명: `{document-id}_{image-index}.jpg`

## 인덱서 실행

### 구성

```json
{
  "name": "doc-extraction-multimodal-embedding-indexer",
  "dataSourceName": "doc-extraction-multimodal-embedding-ds",
  "targetIndexName": "doc-extraction-multimodal-embedding-index",
  "skillsetName": "doc-extraction-multimodal-embedding-skillset",
  "parameters": {
    "batchSize": 1,
    "configuration": {
      "allowSkillsetToReadFileData": true
    }
  }
}
```

### 처리 시간 예상 (36페이지 PDF)

| 단계 | 시간 |
|-----|------|
| 문서 추출 | 2-3초 |
| 텍스트 분할 | <1초 |
| 텍스트 임베딩 (18 청크) | 1-2초 |
| 이미지 임베딩 (25 이미지) | 4-8초 |
| 인덱싱 | 1-2초 |
| **총계** | **8-16초** |

## 쿼리 예제

### 1. 텍스트 쿼리 (하이브리드)

```http
POST /indexes/doc-extraction-multimodal-embedding-index/docs/search?api-version=2025-11-01-preview
Content-Type: application/json

{
  "search": "energy sustainability",
  "vectorQueries": [
    {
      "kind": "text",
      "text": "energy sustainability",
      "k": 10,
      "fields": "content_embedding"
    }
  ],
  "select": "content_id, document_title, content_text, content_path"
}
```

**결과**: 텍스트와 이미지 모두 반환 (공유 벡터 공간)

### 2. 이미지만 필터링

```http
POST /indexes/doc-extraction-multimodal-embedding-index/docs/search?api-version=2025-11-01-preview
Content-Type: application/json

{
  "search": "*",
  "filter": "image_document_id ne null",
  "select": "content_id, document_title, content_path, location_metadata"
}
```

### 3. 이미지 쿼리 (이미지로 검색)

```http
POST /indexes/doc-extraction-multimodal-embedding-index/docs/search?api-version=2025-11-01-preview
Content-Type: application/json

{
  "vectorQueries": [
    {
      "kind": "image",
      "image": "{base64-encoded-image}",
      "k": 5,
      "fields": "content_embedding"
    }
  ]
}
```

**작동 원리**:
1. 쿼리 이미지 → Azure Vision 벡터라이저 → 1024차원 벡터
2. 인덱스의 모든 벡터(텍스트+이미지)와 코사인 유사도 계산
3. 상위 k개 결과 반환

## 주요 특징 정리

### Content_text 필드

- **텍스트 문서**: 추출된 텍스트 청크
- **이미지 문서**: null (이미지는 벡터로만 표현)

### Content_embedding 필드

- **차원**: 1024
- **텍스트와 이미지 공유**: 동일한 벡터 공간
- **유사도 계산**: 텍스트-텍스트, 이미지-이미지, 텍스트-이미지 모두 가능

### Content_path 필드

- **텍스트 문서**: null
- **이미지 문서**: Knowledge Store 이미지 경로
- **형식**: `{container}/{document-id}_{image-index}.jpg`

### Location_metadata 필드

- **이미지만 해당**: 페이지 번호, 경계 다각형
- **활용**: RAG 응답에서 이미지 위치 표시, 페이지 강조

## 제약사항

### Document Extraction 제약

- **텍스트 위치 메타데이터 없음**: 텍스트 청크의 페이지 번호 미제공
- **PDF만 지원**: DOCX, XLSX 등 미지원
- **해결**: Document Layout Skill 사용 권장

### Azure Vision Multimodal 제약

- **지역 제한**: Multimodal 4.0 API 지원 지역만 가능
- **지원 지역**: [Azure Vision 문서 확인](https://learn.microsoft.com/ko-kr/azure/ai-services/computer-vision/overview-image-analysis#region-availability)

## 비용 분석 (36페이지 PDF 예제)

| 항목 | 단가 | 수량 | 비용 |
|------|------|------|------|
| 이미지 추출 | $0.001/image | 25 | $0.025 |
| 텍스트 임베딩 | $0.0001/1K char | 36K | $0.004 |
| 이미지 임베딩 | $0.002/image | 25 | $0.050 |
| 인덱싱 | 포함 | - | - |
| **총계** | | | **$0.079** |

**확장 예측** (1000개 문서):
- 1000 × $0.079 = **$79**
- 재인덱싱 불필요 (증분 업데이트)

## 샘플 애플리케이션

**[Multimodal RAG GitHub Repository](https://aka.ms/azs-multimodal-sample-app-repo)**
- 텍스트 조각과 이미지 주석을 모두 표시하는 엔드투엔드 RAG 애플리케이션
- 엔터프라이즈 비즈니스 도구 빠른 시작에 이상적
- 데이터 수집 및 인덱싱의 코드 기반 프로세스 예시

# 핵심 구성 요소 정리

## 파이프라인 선택 가이드

| 요구사항 | 추천 구성 |
|---------|----------|
| 빠른 프로토타이핑, 기본 기능 | Document Extraction + 이미지 언어화 |
| 정확한 페이지 참조, 위치 정보 필요 | Document Layout + 이미지 언어화 |
| 시각적 유사성 검색 | Document Extraction + 멀티모달 임베딩 |
| 정확한 위치 + 시각적 검색 | Document Layout + 멀티모달 임베딩 |
| 페이지 간 테이블, 의미 청킹 | Content Understanding + 적절한 임베딩 |
| 설명적 다이어그램 + 시각 자료 혼합 | 두 임베딩 방식 병행 |

## 비용 고려사항

- **Document Extraction**: 이미지 추출 시 Azure AI Search 요금 부과
- **Document Layout**: Document Intelligence Layout 가격 적용
- **Content Understanding**: Azure Content Understanding 가격 (가장 높음)
- **GenAI Prompt**: 이미지당 LLM 호출 비용
- **Azure Vision Multimodal**: 이미지/텍스트 임베딩 API 호출 비용

## 성능 특성

| 단계 | 평균 처리 시간 |
|-----|-------------|
| 이미지 추출 | 문서당 1-3초 |
| 이미지 언어화 (LLM) | 이미지당 2-5초 |
| 텍스트 임베딩 | 청크당 50-150ms |
| 멀티모달 임베딩 | 이미지당 150-300ms |

# 참고 문서

- [Azure AI Search 공식 문서](https://learn.microsoft.com/ko-kr/azure/search/)
- [RAG (검색 보강 생성) 개요](https://learn.microsoft.com/ko-kr/azure/search/retrieval-augmented-generation-overview)
- [하이브리드 검색 개요](https://learn.microsoft.com/ko-kr/azure/search/hybrid-search-overview)
- [벡터 검색 개요](https://learn.microsoft.com/ko-kr/azure/search/vector-search-overview)
- [의미 순위 개요](https://learn.microsoft.com/ko-kr/azure/search/semantic-search-overview)
- [Tutorial - 이미지 및 텍스트 벡터화](https://learn.microsoft.com/ko-kr/azure/search/tutorial-document-extraction-multimodal-embeddings)
'@