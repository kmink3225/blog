---
title: Python Abstract Base Classes (ABC)
subtitle: Defining Interfaces and Abstract Classes
description: | 
  파이썬 추상 베이스 클래스(Abstract Base Classes, ABC)는 클래스의 인터페이스를 정의하고 강제하는 메커니즘이다. abc 모듈을 사용하여 추상 메서드와 추상 프로퍼티를 정의할 수 있으며, 이를 통해 객체지향 프로그래밍의 다형성과 인터페이스 계약을 보장할 수 있다. ABC를 사용하면 코드의 구조를 명확히 하고 런타임에 인터페이스 준수 여부를 검증할 수 있다.
categories:
  - Engineering
  - Python
author: Kwangmin Kim
date: 07/02/2023
draft: false
format: 
  html:
    toc: true
    number-sections: True
    code-fold: true
    page-layout: full
execute: 
  warning: false
  message: false
  eval: false
  echo: true
---


## 정규 표현식이란

정규 표현식(Regular Expression)은 텍스트에서 특정 패턴을 찾아내기 위한 문자열 표기법이다.  
쉽게 말하면, "이런 생김새를 가진 문자열을 찾아라"는 명령을 하나의 압축된 기호 조합으로 표현한 것이다.  

예를 들어, 전화번호처럼 생긴 문자열을 찾고 싶을 때를 생각해보자.  
단순히 `"010"`으로 검색하면 `"010"`이 들어간 모든 문자열이 걸린다.  
하지만 `010-1234-5678` 형태 전체를 정확히 잡아내려면,  
숫자 세 자리, 하이픈, 숫자 네 자리, 하이픈, 숫자 네 자리라는 **구조** 자체를 패턴으로 표현해야 한다.  
이 구조를 표현하는 도구가 바로 정규 표현식이다.  

정규 표현식은 1950년대 미국 수학자 Stephen Cole Kleene이 정규 언어(regular language) 개념을  
형식화하면서 이론적 기반이 마련되었다.  
이후 Unix 텍스트 처리 유틸리티들과 함께 실용적 도구로 자리잡았고,  
현재는 거의 모든 프로그래밍 언어에서 표준 기능으로 지원된다.  
Python에서는 표준 라이브러리인 `re` 패키지가 이 역할을 담당한다.  

## 정규 표현식이 해결하는 문제

정규 표현식은 크게 세 가지 문제를 해결한다.  

첫째, **탐색(Search)** 이다.  
비정형 텍스트 안에서 특정 패턴을 가진 부분 문자열을 찾아낸다.  
소설 전체에서 주인공 이름이 몇 번 등장하는지 세는 것이 이 범주에 해당한다.  

둘째, **치환(Replace)** 이다.  
패턴에 매칭된 문자열을 다른 문자열로 교체한다.  
로그 파일에서 날짜 포맷을 `YYYYMMDD`에서 `YYYY-MM-DD`로 일괄 변환하는 작업이 대표적이다.  

셋째, **검증(Validation)** 이다.  
입력값이 정해진 형식에 맞는지 판단한다.  
사용자가 입력한 텍스트가 이메일 주소 형식인지 확인하는 것이 이에 해당한다.  

이 세 가지가 조합되면, 정규 표현식 하나로 "패턴을 찾고, 그것을 바꾸고, 형식이 맞는지 확인하는"  
텍스트 처리의 핵심 작업 대부분을 커버할 수 있다.  

## 실생활 활용 예시로 이해하는 정규 표현식의 필요성

PPT에서 제시된 6가지 활용 예시를 단순 나열이 아니라,  
각각 왜 정규 표현식이 필요한 문제인지 관점에서 살펴본다.  

### 소설에서 주인공 이름 등장 횟수 세기

단순히 Python `str.count("홍길동")`으로도 셀 수 있다.  
그런데 실제 텍스트에서는 `홍길동이`, `홍길동을`, `홍길동의` 처럼 조사가 붙은 형태로 등장한다.  
더 나아가 `홍 길동`처럼 공백이 끼어든 경우도 있을 수 있다.  
정규 표현식을 쓰면 이런 변형들을 하나의 패턴으로 묶어서 한 번에 탐색할 수 있다.  
즉, "완전히 동일한 문자열 탐색"이 아니라 "패턴에 부합하는 문자열 탐색"이 필요한 순간,  
정규 표현식이 단순 문자열 검색보다 훨씬 강력한 도구가 된다.  

### 문장에서 전화번호만 추출하기

텍스트 안에 전화번호가 몇 개 들어있는데, 그것만 뽑아내고 싶다.  
전화번호는 `010-1234-5678`일 수도 있고, `02-123-4567`일 수도 있고,  
심지어 `010.1234.5678`처럼 구분자가 다른 경우도 있다.  
이 모든 변형을 하나의 패턴으로 정의하고 `re.findall()`로 추출하면,  
텍스트 전체를 루프 돌면서 조건문으로 하나하나 걸러낼 필요가 없다.  
정규 표현식은 이런 "구조적으로 유사한 여러 형태"를 동시에 잡아내는 데 강점이 있다.  

### 이메일 주소 형식 검증

사용자가 입력한 문자열이 이메일 형식(`user@domain.com`)인지 확인하려면  
`@`가 있는지, 도메인이 있는지, 최상위 도메인이 2자 이상인지 등 여러 조건을 동시에 판단해야 한다.  
이것을 `if`문으로 하나하나 체크하면 코드가 복잡해지고, 예외 케이스를 빠뜨리기 쉽다.  
정규 표현식은 이 모든 조건을 단일 패턴 문자열 하나로 압축할 수 있다.  
PPT에서 보여준 `r'\b[\w.%+-]+@[\w.-]+\.[A-Z|a-z]{2,}\b'`가 바로 이 역할을 한다.  
패턴 하나로 `re.fullmatch()`를 호출하면, 복잡한 조건 분기 없이 형식 검증이 완료된다.  

### 특정 패턴 앞뒤의 문맥 단어 파악

로그 파일에서 `ERROR` 키워드 앞뒤에 어떤 메시지가 붙는지 분석하고 싶을 때,  
정규 표현식의 그룹화 기능을 사용하면 패턴과 함께 그 주변 문자열도 동시에 캡처할 수 있다.  
이것은 단순 탐색을 넘어 **구조적 파싱**에 가까운 작업이다.  

### 주민등록번호에서 생년월일 변환

`930101-1234567`이라는 문자열에서 앞 6자리를 분해하고,  
7번째 자리를 보고 19xx년생인지 20xx년생인지 판단한 뒤,  
`1993-01-01` 형태로 재조합해야 한다.  
이 과정은 "패턴으로 추출 → 로직 적용 → 새 문자열로 재구성"이라는 세 단계를 거친다.  
정규 표현식의 `re.sub()`에 변환 함수를 넘기면 이 세 단계를 하나의 호출로 처리할 수 있다.  
이 패턴은 Part 6에서 실제 코드와 함께 자세히 다룬다.  

### 로그 파일 분석 및 알람 발송

프로덕션 환경에서 수백만 줄의 로그 파일을 실시간으로 감시하면서  
`CRITICAL`, `FATAL`, `OutOfMemoryError`처럼 심각한 키워드가 포함된 라인을 감지하고  
메일로 알람을 보내는 시스템을 구현한다고 가정하자.  
이때 정규 표현식은 **필터링 엔진** 역할을 한다.  
패턴을 `re.compile()`로 미리 컴파일해두면 수백만 줄을 빠르게 스캔하면서  
조건에 맞는 라인만 골라낼 수 있다.  
이것이 단순한 `in` 연산자 검색과 다른 점은, 복잡한 조건 조합을 단일 패턴으로 처리할 수 있다는 점이다.  

## Python에서 정규 표현식을 사용하는 방법 개요

Python에서 정규 표현식을 사용하려면 표준 라이브러리인 `re` 모듈을 import한다.  
별도 설치 없이 Python 설치와 함께 제공된다.  

```python
import re

text = "Contact us at support@example.me or info@company.com for more information."
email_pattern = r'\b[\w.%+-]+@[\w.-]+\.[A-Z|a-z]{2,}\b'

emails = re.findall(email_pattern, text)
print(emails)  # ['support@example.me', 'info@company.com']
```

위 코드에서 `email_pattern`이 정규 표현식이다.  
`r'...'`는 Python의 raw string으로, 백슬래시를 이스케이프 문자가 아닌 리터럴 문자로 처리한다.  
정규 표현식에서 `\w`, `\b` 같은 특수 문자를 올바르게 쓰려면 raw string을 사용하는 것이 관례다.  

`re.findall()`은 텍스트 전체에서 패턴에 매칭되는 모든 부분을 리스트로 반환한다.  
결과를 보면 이메일 주소 두 개가 정확히 추출된 것을 확인할 수 있다.  
패턴의 구체적인 의미는 Part 2와 Part 3에서 문자 하나하나 해부한다.  

## 정리

정규 표현식은 "특정 패턴을 가진 문자열"을 다루는 모든 문제에 적용 가능한 범용 도구다.  
단순 문자열 검색으로 해결되지 않는 문제, 즉 형태는 다양하지만 구조는 동일한 문자열을  
탐색하거나 변환하거나 검증해야 할 때 정규 표현식이 가장 효율적인 해법이 된다.  
Python `re` 패키지는 이 모든 기능을 표준 라이브러리 수준에서 제공한다.  

아래는 Part 2 내용이다.

---

````qmd
---
title: "정규 표현식 - Part 2: 메타 문자의 동작 원리"
author: "Kwangmin Kim"
date: today
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
---

## 메타 문자란 무엇인가

정규 표현식을 구성하는 문자는 크게 두 종류로 나뉜다.  
하나는 **리터럴 문자(literal character)** 로, `a`, `b`, `1`, `2`처럼 그 자체를 의미하는 문자다.  
다른 하나는 **메타 문자(meta character)** 로, 특별한 의미나 기능을 가진 기호다.  

메타 문자는 "이 자리에 어떤 문자가 올 수 있는가"를 정의하거나,  
"이 패턴이 문자열의 어느 위치에서 매칭되어야 하는가"를 제어한다.  
즉, 메타 문자는 패턴의 **구조와 규칙**을 기술하는 언어의 문법 요소다.  

정규 표현식이 단순 문자열 검색보다 강력한 이유가 바로 이 메타 문자 덕분이다.  
`"010"`을 검색하면 `"010"`만 찾지만,  
`\d{3}`이라는 패턴을 쓰면 `"010"`, `"123"`, `"999"` 등 세 자리 숫자 전부를 한 번에 잡아낸다.  

메타 문자는 역할에 따라 크게 세 그룹으로 구분할 수 있다.  
위치를 제어하는 **앵커(anchor)**, 문자 집합을 정의하는 **문자 클래스(character class)**,  
그리고 선택 논리를 담당하는 **논리 연산자** 가 그것이다.  
이번 파트에서는 `^`, `$`, `[]`, `[^]`, `.`, `|`를 이 관점에서 하나씩 해부한다.  

## 위치를 제어하는 앵커: `^`와 `$`

### `^` - 문장의 시작에 매칭

`^`는 문자열 또는 줄의 **시작 위치** 에 매칭된다.  
중요한 점은 `^`가 어떤 문자를 매칭하는 게 아니라 **위치** 를 매칭한다는 것이다.  

```python
import re

text1 = "Hello, world"
text2 = "world, Hello"

print(re.search(r'^Hello', text1))  # 매칭됨: 'Hello'가 문자열 시작에 있음
print(re.search(r'^Hello', text2))  # None: 'Hello'가 시작이 아닌 중간에 있음
```

`^Hello`는 "문자열이 Hello로 시작하는가"를 묻는 패턴이다.  
`re.search()`는 문자열 어디에서든 패턴을 찾으려 하지만,  
`^`가 있으면 시작 위치 외에는 매칭을 허용하지 않는다.  

이 앵커는 예를 들어 로그 파일에서 특정 레벨로 시작하는 줄만 골라낼 때 유용하다.  
`^ERROR`, `^WARN`처럼 쓰면 해당 레벨로 시작하는 라인만 정확히 필터링할 수 있다.  

### `$` - 문장의 끝에 매칭

`$`는 문자열 또는 줄의 **끝 위치** 에 매칭된다.  
`^`와 대칭적으로, 패턴이 문자열의 끝에 위치해야 매칭이 성공한다.  

```python
import re

text1 = "report.csv"
text2 = "report.csv.bak"

print(re.search(r'\.csv$', text1))  # 매칭됨: .csv로 끝남
print(re.search(r'\.csv$', text2))  # None: .csv로 끝나지 않음
```

파일 확장자 검증처럼 "특정 문자열로 끝나는가"를 확인할 때 `$`를 사용한다.  
`^`와 `$`를 함께 쓰면 "전체 문자열이 이 패턴과 일치하는가"를 검증할 수 있다.  
예를 들어 `^\d{5}$`는 정확히 다섯 자리 숫자로만 이루어진 문자열인지 확인하는 패턴이다.  

## 문자 집합을 정의하는 클래스: `[]`와 `[^]`

### `[]` - 문자 집합

`[]`는 "이 괄호 안에 있는 문자 중 하나와 매칭"을 의미한다.  
`[abc]`는 `a`, `b`, `c` 중 정확히 한 글자와 매칭된다.  

```python
import re

print(re.findall(r'[aeiou]', "hello world"))  # ['e', 'o', 'o']
print(re.findall(r'[a-z]', "Hello World"))    # ['e', 'l', 'l', 'o', 'o', 'r', 'l', 'd']
print(re.findall(r'[0-9]', "abc123def456"))   # ['1', '2', '3', '4', '5', '6']
```

`[a-z]`처럼 하이픈(`-`)을 사용하면 범위를 지정할 수 있다.  
`[a-z]`는 소문자 알파벳 전체, `[0-9]`는 모든 숫자, `[A-Za-z0-9]`는 영문자와 숫자 전체를 의미한다.  

`[]` 안에서는 대부분의 메타 문자가 일반 문자로 취급된다는 점이 중요하다.  
예를 들어 `[.]`은 점 문자 자체를 의미하고, 임의의 문자를 의미하는 메타 `.`이 아니다.  
단, `]`, `\`, `^`, `-`는 `[]` 안에서도 특별한 의미를 가지므로 이스케이프가 필요하다.  

한국어 처리 시에도 범위 지정이 가능하다.  
`[가-힣]`은 한글 음절 전체를 커버하는 패턴으로 실무에서 자주 사용된다.  

### `[^]` - 부정 문자 집합(여집합)

`[^]`는 `[]`의 반대다.  
`[^abc]`는 `a`, `b`, `c`가 **아닌** 문자 하나와 매칭된다.  
`^`가 `[]` 안의 첫 번째 위치에 올 때만 부정의 의미를 가진다는 점에 주의해야 한다.  

```python
import re

print(re.findall(r'[^aeiou]', "hello"))   # ['h', 'l', 'l'] - 모음이 아닌 문자
print(re.findall(r'[^0-9]', "abc123"))    # ['a', 'b', 'c'] - 숫자가 아닌 문자
print(re.findall(r'[^,]+', "a,b,c,d"))   # ['a', 'b', 'c', 'd'] - 쉼표가 아닌 문자들
```

마지막 예시 `[^,]+`는 CSV 처리에서 핵심적으로 사용하는 패턴이다.  
"쉼표가 아닌 문자 하나 이상"을 의미하므로, 쉼표로 구분된 각 필드를 추출하는 데 쓸 수 있다.  
Part 6의 CSV 처리 예시에서 이 패턴이 실제로 어떻게 활용되는지 확인할 수 있다.  

## 임의 문자와 선택: `.`와 `|`

### `.` - 개행을 제외한 임의의 한 글자

`.`은 줄바꿈 문자(`\n`)를 제외한 어떤 문자와도 매칭된다.  
"이 자리에 어떤 문자든 올 수 있다"는 의미로, 일종의 와일드카드다.  

```python
import re

print(re.findall(r'a.c', "abc axc a1c a c"))  # ['abc', 'axc', 'a1c', 'a c']
print(re.findall(r'a.c', "a\nc"))              # [] - 개행 문자는 매칭 안 됨
```

`a.c`는 "a로 시작하고, 중간에 어떤 문자든 하나 있고, c로 끝나는 3글자"를 의미한다.  
`.`은 강력하지만 그만큼 과도하게 매칭될 위험도 있다.  
특히 `.*`처럼 반복자와 결합하면 의도치 않게 너무 많은 범위를 잡아버리는  
**greedy matching** 문제가 발생할 수 있다.  
이 문제는 Part 3의 반복자 설명에서 다룬다.  

만약 개행 문자까지 포함해서 매칭하고 싶다면 `re.DOTALL` 플래그를 사용한다.  
이는 Part 4에서 자세히 다룬다.  

실제로 `.` 자체(점 문자)를 매칭하고 싶을 때는 반드시 `\.`로 이스케이프해야 한다.  
이메일 패턴에서 `\.com`처럼 쓰는 이유가 바로 이것이다.  

### `|` - 선택 연산자 (OR)

`|`는 "앞의 패턴 또는 뒤의 패턴"을 의미하는 논리 OR 연산자다.  
`abc|def`는 `abc` 또는 `def`와 매칭된다.  

```python
import re

text = "I have a cat and a dog"
print(re.findall(r'cat|dog', text))   # ['cat', 'dog']

log = "ERROR: disk full\nWARN: high memory\nINFO: server started"
print(re.findall(r'ERROR|WARN', log)) # ['ERROR', 'WARN']
```

`|`의 범위는 생각보다 넓다.  
`cat|dog food`는 `cat` 또는 `dog food`를 의미하지, `cat food` 또는 `dog food`가 아니다.  
`|`의 적용 범위를 제한하려면 괄호로 그룹화해야 한다.  
`(cat|dog) food`로 쓰면 비로소 `cat food` 또는 `dog food`를 의미한다.  
괄호를 이용한 그룹화는 Part 3에서 자세히 다룬다.  

로그 레벨 필터링, 여러 확장자 동시 검색, 다양한 날짜 형식 처리 등  
실무에서 `|`는 단독보다는 그룹화와 함께 사용하는 경우가 훨씬 많다.  

## 메타 문자 조합 예시: 이메일 패턴 해부

Part 1에서 등장한 이메일 패턴을 메타 문자 관점에서 분해해보면 각 요소의 역할이 명확해진다.  

```python
r'\b[\w.%+-]+@[\w.-]+\.[A-Z|a-z]{2,}\b'
```

이 패턴을 구간별로 쪼개면 다음과 같다.  

`\b` : 단어 경계 (이메일 주소가 다른 문자열 중간에 붙어있는 경우를 걸러낸다)  
`[\w.%+-]+` : 영문자, 숫자, `_`, `.`, `%`, `+`, `-` 중 하나 이상 (로컬 파트)  
`@` : 리터럴 @ 문자  
`[\w.-]+` : 영문자, 숫자, `_`, `.`, `-` 중 하나 이상 (도메인 파트)  
`\.` : 리터럴 점 문자 (`.com`의 점)  
`[A-Z|a-z]{2,}` : 대소문자 알파벳 2자 이상 (최상위 도메인)  
`\b` : 단어 경계  

여기서 `[\w.%+-]`는 문자 집합 `[]` 안에 여러 조건을 OR로 나열한 것이다.  
`\w`는 특수 문자로 Part 4에서 다루지만, 영문자, 숫자, 언더스코어를 의미한다.  
`{2,}`는 반복자로 "2회 이상"을 의미하며 Part 3에서 다룬다.  

이처럼 메타 문자들은 단독으로 쓰이기보다 서로 조합되어 복잡한 패턴을 형성한다.  
각 메타 문자의 역할을 정확히 이해하면, 복잡해 보이는 정규 표현식도  
레고 블록 조립하듯 분해해서 읽을 수 있다.  

## 정리

메타 문자는 정규 표현식의 핵심 문법 요소다.  
`^`와 `$`는 패턴이 매칭될 위치를 제어하고,  
`[]`와 `[^]`는 한 자리에 올 수 있는 문자의 집합을 정의하며,  
`.`는 임의의 한 글자를 나타내고,  
`|`는 여러 패턴 중 하나를 선택하는 논리 OR을 표현한다.  
이 여섯 가지 메타 문자만 정확히 이해해도 실무에서 마주치는  
정규 표현식의 절반 이상을 읽고 작성할 수 있다.  
나머지 절반인 그룹화와 반복자는 Part 3에서 다룬다.  
````

아래는 Part 3 내용이다.

---

````qmd
---
title: "정규 표현식 - Part 3: 그룹화와 반복자"
author: "Kwangmin Kim"
date: today
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
---

## 반복자와 그룹화가 필요한 이유

Part 2에서 다룬 메타 문자들은 "이 자리에 어떤 문자가 올 수 있는가"를 정의했다.  
그런데 실제 패턴에서는 "이 문자가 몇 번 반복되는가"를 표현해야 하는 경우가 훨씬 많다.  

전화번호 `010-1234-5678`을 예로 들면,  
첫 번째 구간은 숫자 3자리, 두 번째 구간은 숫자 3~4자리, 세 번째 구간은 숫자 4자리다.  
`\d\d\d-\d\d\d\d-\d\d\d\d`처럼 `\d`를 반복해서 쓸 수도 있지만,  
이것은 가독성이 낮고, 반복 횟수가 바뀌면 패턴 전체를 수정해야 한다.  
반복자를 쓰면 `\d{3}-\d{3,4}-\d{4}`로 훨씬 간결하게 표현할 수 있다.  

그룹화는 "이 부분 패턴을 하나의 단위로 묶겠다"는 선언이다.  
반복자를 단일 문자가 아닌 패턴 전체에 적용하거나,  
매칭된 결과의 특정 부분만 추출하거나,  
`re.sub()`에서 매칭된 그룹을 재조합해서 새 문자열을 만들 때 그룹화가 필수적이다.  

반복자와 그룹화는 단독으로 쓰이기보다 항상 함께 사용되며,  
이 두 요소가 결합될 때 정규 표현식의 실질적인 표현력이 폭발적으로 늘어난다.  

## 반복자: 패턴의 반복 횟수를 제어한다

### `*` - 0회 이상

`*`는 바로 앞의 패턴이 0번 이상 반복될 수 있음을 의미한다.  
"없어도 되고, 있으면 몇 개든 괜찮다"는 뜻이다.  

```python
import re

print(re.findall(r'ab*c', "ac abc abbc abbbc"))
# ['ac', 'abc', 'abbc', 'abbbc']
# b가 0개(ac), 1개(abc), 2개(abbc), 3개(abbbc) 모두 매칭
```

`ab*c`에서 `*`는 `b`에만 적용된다.  
`a`와 `c`는 반드시 있어야 하고, 그 사이의 `b`는 0개 이상이면 된다.  

`x[yz]*`처럼 문자 집합에도 `*`를 적용할 수 있다.  
이 패턴은 `x`, `xy`, `xz`, `xyyyy`, `xzyzyz` 등 모두 매칭된다.  

`*`의 특성 중 가장 주의해야 할 점은 0회 매칭도 성공으로 처리한다는 것이다.  
이 때문에 `.*`는 빈 문자열을 포함한 모든 것과 매칭되어 의도치 않은 결과를 만들 수 있다.  

### `+` - 1회 이상

`+`는 바로 앞의 패턴이 1번 이상 반복될 때 매칭된다.  
`*`와의 차이는 "반드시 하나 이상 존재해야 한다"는 점이다.  

```python
import re

print(re.findall(r'ab+c', "ac abc abbc abbbc"))
# ['abc', 'abbc', 'abbbc']
# b가 0개인 'ac'는 매칭 안 됨

print(re.findall(r'\d+', "abc 123 def 4567"))
# ['123', '4567']
# 숫자가 1개 이상인 구간을 통째로 추출
```

`\d+`는 실무에서 가장 많이 쓰이는 패턴 중 하나다.  
숫자가 연속된 구간 전체를 하나의 토큰으로 추출할 때 사용한다.  
`\d`만 쓰면 숫자 하나씩 따로 추출되지만, `\d+`는 연속된 숫자 전체를 하나로 묶어준다.  

### `?` - 0회 또는 1회

`?`는 바로 앞의 패턴이 없거나 하나만 있을 때 매칭된다.  
"있어도 되고 없어도 되지만, 있다면 정확히 하나"라는 의미다.  

```python
import re

print(re.findall(r'bc?c', "bc bcc bccc"))
# ['bc', 'bcc']
# 'bc'는 중간 c가 0개, 'bcc'는 1개 -> 매칭
# 'bccc'는 중간 c가 2개 -> 매칭 안 됨

print(re.findall(r'https?://', "http://example.com https://secure.com"))
# ['http://', 'https://']
# s가 있거나 없거나 둘 다 매칭
```

`https?://`는 URL 패턴에서 자주 사용된다.  
`http://`와 `https://`를 동시에 잡아낼 수 있다.  
`s?`가 s가 있어도 되고 없어도 된다는 의미이기 때문이다.  

### `{m, n}` - 정확한 반복 횟수 지정

`{m, n}`은 앞의 패턴이 최소 m회, 최대 n회 반복될 때 매칭된다.  
`*`, `+`, `?`보다 반복 범위를 명확하게 지정할 수 있어 실무에서 더 안전한 패턴을 작성할 때 유용하다.  

```python
import re

print(re.findall(r'a{3,5}', "aa aaa aaaa aaaaa aaaaaa"))
# ['aaa', 'aaaa', 'aaaaa', 'aaaaa']
# 2개짜리 'aa'는 매칭 안 됨, 6개짜리는 앞 5개만 매칭

print(re.findall(r'\d{3}-\d{3,4}-\d{4}', "010-1234-5678 02-123-4567"))
# ['010-1234-5678', '02-123-4567']
```

변형 형태로 `{m}`은 정확히 m회, `{m,}`은 m회 이상을 의미한다.  
`{3}`은 정확히 3회, `{3,}`은 3회 이상, `{3,5}`는 3회 이상 5회 이하다.  

전화번호 패턴 `\d{3}-\d{3,4}-\d{4}`를 보면,  
가운데 구간이 `{3,4}`인 이유는 지역번호 없는 번호(`010-123-4567`)와  
일반 번호(`010-1234-5678`) 모두를 커버해야 하기 때문이다.  
이처럼 `{m,n}`은 현실의 데이터가 가진 자연스러운 변동 폭을 패턴에 반영할 때 핵심적인 역할을 한다.  

## Greedy vs Lazy: 반복자의 숨겨진 동작 방식

반복자를 이해할 때 반드시 알아야 하는 개념이 **greedy(탐욕적) 매칭**이다.  
기본적으로 `*`, `+`, `?`, `{m,n}`은 모두 greedy하게 동작한다.  
즉, 조건을 만족하는 범위 내에서 **최대한 많이** 매칭하려 한다.  

```python
import re

html = "<b>bold</b> and <i>italic</i>"

print(re.findall(r'<.*>', html))
# ['<b>bold</b> and <i>italic</i>']
# 처음 '<'부터 마지막 '>'까지 통째로 매칭됨

print(re.findall(r'<.*?>', html))
# ['<b>', '</b>', '<i>', '</i>']
# 각 태그를 개별적으로 매칭
```

`<.*>`는 `<`를 만난 순간 `.*`가 가능한 한 끝까지 전진하고,  
그 상태에서 뒤에 `>`가 있는지 확인한다.  
결과적으로 문자열 전체를 삼켜버리는 현상이 발생한다.  

반복자 뒤에 `?`를 붙이면 **lazy(게으른) 매칭**으로 전환된다.  
`.*?`는 조건을 만족하는 범위 내에서 **최소한만** 매칭하려 한다.  
`<.*?>`는 `<`를 만나면 `>`가 나오는 가장 가까운 위치에서 멈추므로 각 HTML 태그를 개별적으로 잡아낸다.  

HTML 파싱, JSON 파싱, 로그 분석 등 구분자가 있는 텍스트를 다룰 때  
greedy와 lazy의 차이를 모르면 의도하지 않은 범위까지 매칭되는 버그가 발생한다.  
실무에서 정규 표현식이 "이상하게 동작한다"고 느낄 때  
가장 먼저 확인해야 할 것이 바로 이 greedy 매칭 문제다.  

## 그룹화: 패턴을 하나의 단위로 묶는다

### `()` - 하위 그룹 정의

`()`는 괄호 안의 패턴을 하나의 단위(그룹)로 묶는다.  
그룹화의 목적은 크게 세 가지다.  

첫째, 반복자를 단일 문자가 아닌 패턴 전체에 적용할 때 사용한다.  

```python
import re

print(re.findall(r'(ab)+', "ab abab ababab"))
# ['ab', 'ab', 'ab']
# 'ab'라는 두 글자 패턴이 1회 이상 반복되는 경우를 매칭
```

`ab+`는 `a` 다음에 `b`가 1개 이상인 패턴이지만,  
`(ab)+`는 `ab` 전체가 1개 이상 반복되는 패턴이다.  
괄호 없이 `+`를 쓰면 바로 앞의 문자 하나에만 적용된다는 점을 주의해야 한다.  

둘째, 매칭된 결과에서 특정 부분만 추출할 때 사용한다.  

```python
import re

text = "이름: 홍길동, 전화: 010-1234-5678"
pattern = re.compile(r'이름: (\w+), 전화: (\d{3}-\d{3,4}-\d{4})')
match = pattern.search(text)

if match:
    print(match.group(0))  # '이름: 홍길동, 전화: 010-1234-5678' (전체 매칭)
    print(match.group(1))  # '홍길동' (첫 번째 그룹)
    print(match.group(2))  # '010-1234-5678' (두 번째 그룹)
```

`group(0)`은 패턴 전체가 매칭된 문자열이고,  
`group(1)`, `group(2)`는 첫 번째, 두 번째 괄호 그룹이 매칭된 부분이다.  
이 방식으로 하나의 패턴으로 여러 필드를 동시에 추출할 수 있다.  

셋째, `re.sub()`에서 매칭된 그룹을 재조합해 새 문자열을 만들 때 사용한다.  
이 활용법은 다음 절의 backreference와 Part 6의 실전 예시에서 자세히 다룬다.  

### `\n` - Backreference (역참조)

`\n`은 n번째 그룹이 매칭한 문자열을 패턴 내에서 다시 참조한다.  
`\1`은 첫 번째 그룹, `\2`는 두 번째 그룹이 캡처한 값을 그대로 재사용한다는 의미다.  

```python
import re

# 연속으로 중복된 단어 탐지
print(re.findall(r'(\w+) \1', "the the quick brown fox fox"))
# ['the', 'fox']
# '(\w+)'가 단어를 캡처하고, '\1'이 동일한 단어가 다시 나오는지 확인

# re.sub에서 그룹 순서 바꾸기
input_string = "서울-대구-대전-부산"
result = re.sub(r'(\w+)-(\w+)-(\w+)-(\w+)', r'\1-\3-\2-\4', input_string)
print(result)  # '서울-대전-대구-부산'
# 2번째 그룹(대구)과 3번째 그룹(대전)의 순서가 바뀜
```

첫 번째 예시는 자연어 처리에서 오탈자 탐지에 응용할 수 있다.  
같은 단어가 연속으로 두 번 나오는 경우를 찾아내는 패턴으로,  
backreference 없이는 표현하기 매우 어렵다.  

두 번째 예시가 PPT에서 "순서 바꾸기" 활용 사례로 소개된 패턴이다.  
`re.sub()`의 두 번째 인자(치환 문자열)에서 `\1`, `\2`, `\3`, `\4`는  
각 그룹이 캡처한 값으로 치환된다.  
원래 `\1-\2-\3-\4` 순서를 `\1-\3-\2-\4`로 바꾸면  
2번째와 3번째 요소의 순서가 뒤바뀐 결과가 나온다.  

이 패턴은 날짜 형식 변환(`YYYY-MM-DD`를 `DD/MM/YYYY`로 바꾸는 것처럼),  
성명 순서 변환(성, 이름을 이름, 성으로 바꾸는 것처럼) 등  
구조는 동일하지만 요소의 순서나 구분자를 바꿔야 하는 모든 상황에 적용 가능하다.  

## 반복자와 그룹화의 결합: 실전 패턴 분석

PPT의 CSV 처리 예시에 사용된 패턴을 분해해서 읽어보면  
반복자와 그룹화가 어떻게 결합되는지 명확하게 볼 수 있다.  

```python
pattern = re.compile(r'[^,]+,[^,]+,[^,]+,([^,]+),[^,]+,([^,]+)')
```

이 패턴은 쉼표로 구분된 6개 필드 중 4번째와 6번째만 캡처하는 패턴이다.  
분해하면 다음과 같다.  

`[^,]+` : 쉼표가 아닌 문자 1개 이상 (하나의 CSV 필드)  
`,` : 구분자 쉼표  
`([^,]+)` : 캡처 그룹으로 묶인 CSV 필드  

패턴 전체를 순서대로 읽으면,  
1번째 필드(캡처 없음), 쉼표, 2번째 필드(캡처 없음), 쉼표, 3번째 필드(캡처 없음), 쉼표,  
4번째 필드(**캡처**), 쉼표, 5번째 필드(캡처 없음), 쉼표, 6번째 필드(**캡처**)다.  

이처럼 그룹화는 "전체 패턴 중 내가 관심 있는 부분만 선택적으로 추출"하는 역할을 한다.  
캡처하고 싶지 않은 그룹은 괄호 없이 쓰고,  
캡처하고 싶은 그룹만 `()`로 묶으면 된다.  

## 정리

반복자는 패턴의 반복 횟수를 제어한다.  
`*`는 0회 이상, `+`는 1회 이상, `?`는 0회 또는 1회,  
`{m,n}`은 m회 이상 n회 이하로 반복 범위를 명확하게 지정한다.  
반복자는 기본적으로 greedy하게 동작하므로,  
구분자가 있는 패턴에서는 lazy 매칭(`?` 추가)을 고려해야 한다.  

그룹화는 패턴의 일부를 하나의 단위로 묶어 반복자 적용, 부분 추출, 순서 재조합을 가능하게 한다.  
`()`로 그룹을 정의하고, `\n`으로 n번째 그룹을 역참조하는 backreference 기법은  
단순 탐색을 넘어 구조적인 텍스트 변환 작업의 핵심 도구다.  
Part 4에서는 특수 문자와 Python `re` 패키지의 함수들을 다룬다.  
````

아래는 Part 4 내용이다.

---

````qmd
---
title: "정규 표현식 - Part 4: 특수 문자와 Python re 패키지 사용법"
author: "Kwangmin Kim"
date: today
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
---

## 특수 문자란 무엇인가

Part 2에서 다룬 메타 문자가 "패턴의 구조를 정의하는 문법 요소"라면,  
특수 문자(special sequence)는 "자주 쓰이는 문자 집합을 미리 축약해둔 단축키"다.  

예를 들어 숫자 하나를 매칭하려면 `[0-9]`라고 써야 하지만,  
`\d`라는 특수 문자를 쓰면 동일한 의미를 한 글자로 표현할 수 있다.  
영문자, 숫자, 언더스코어 전체를 매칭하려면 `[a-zA-Z0-9_]`라고 써야 하지만  
`\w` 하나로 동일한 의미를 표현한다.  

특수 문자는 반복자, 메타 문자와 결합하면 훨씬 간결하고 가독성 높은 패턴을 작성할 수 있게 해준다.  
`\d{3}-\d{3,4}-\d{4}`가 `[0-9]{3}-[0-9]{3,4}-[0-9]{4}`보다  
읽기 쉬운 이유가 바로 특수 문자 덕분이다.  

## 핵심 특수 문자 해설

### `\w` - 단어 문자

`\w`는 영문자(대소문자), 숫자, 언더스코어(`_`)에 해당하는 문자를 의미한다.  
정확히는 `[a-zA-Z0-9_]`와 동일하다.  

```python
import re

print(re.findall(r'\w+', "hello_world 123 !@#"))
# ['hello_world', '123']
# 공백과 특수문자는 \w에 해당하지 않으므로 제외됨

print(re.findall(r'\w+', "이름: 홍길동, 나이: 30"))
# ['이름', '홍길동', '나이', '30']
# Python re는 기본적으로 유니코드를 지원하므로 한글도 \w에 매칭됨
```

`\w`의 대문자 버전인 `\W`는 반대 의미다.  
`\W`는 영문자, 숫자, 언더스코어가 **아닌** 문자, 즉 공백, 특수문자, 구분자 등을 의미한다.  
이 대소문자 반전 규칙은 `\d`/`\D`, `\s`/`\S`, `\b`/`\B`에도 동일하게 적용된다.  

### `\d` - 숫자 문자

`\d`는 모든 숫자(`0`~`9`)를 의미하며 `[0-9]`와 동일하다.  

```python
import re

print(re.findall(r'\d+', "가격: 12,500원, 수량: 3개"))
# ['12', '500', '3']
# 숫자가 연속된 구간을 각각 추출

print(re.findall(r'\d{4}-\d{2}-\d{2}', "오늘 날짜는 2024-02-15입니다."))
# ['2024-02-15']
# 날짜 형식 추출
```

`\d`는 숫자 추출, 날짜 파싱, 전화번호 추출 등 데이터 전처리에서  
가장 빈번하게 등장하는 특수 문자다.  
`\D`는 숫자가 아닌 문자를 의미하며, 숫자만 남기고 나머지를 제거할 때 유용하다.  

```python
import re

# 전화번호에서 숫자만 추출 (하이픈 등 구분자 제거)
phone = "010-1234-5678"
digits_only = re.sub(r'\D', '', phone)
print(digits_only)  # '01012345678'
```

### `\s` - 공백 문자

`\s`는 스페이스(` `), 탭(`\t`), 개행(`\n`), 캐리지 리턴(`\r`) 등  
모든 종류의 공백 문자를 의미한다.  

```python
import re

text = "hello   world\t!\nbye"
print(re.sub(r'\s+', ' ', text))
# 'hello world ! bye'
# 연속된 공백(스페이스, 탭, 개행 포함)을 단일 스페이스로 정규화

print(re.split(r'\s+', "one  two\tthree\nfour"))
# ['one', 'two', 'three', 'four']
# 공백 기준으로 분리
```

`\s+`는 텍스트 정규화에서 핵심 패턴이다.  
웹 크롤링으로 수집한 텍스트, 사용자 입력, 로그 파일 등에는  
불규칙한 공백이 다수 포함되어 있는데,  
`re.sub(r'\s+', ' ', text)`로 모든 연속 공백을 단일 스페이스로 정리할 수 있다.  

### `\b` - 단어 경계

`\b`는 단어 문자(`\w`)와 비단어 문자(`\W`)의 **경계 위치**를 의미한다.  
`^`, `$`처럼 문자를 소비하지 않고 위치만 매칭하는 앵커다.  

```python
import re

text = "to top tomorrow stop"

print(re.findall(r'\bto\b', text))   # ['to']
print(re.findall(r'\bto', text))     # ['to', 'to', 'to'] - 'to'로 시작하는 모든 경우
print(re.findall(r'to\b', text))     # ['to', 'to'] - 'to'로 끝나는 모든 경우
```

`\bto\b`는 단어 전체가 `to`인 경우만 매칭한다.  
`top`, `tomorrow`, `stop` 안에 들어있는 `to`는 매칭되지 않는다.  

`\b` 없이 `to`만 쓰면 `top`, `tomorrow`, `stop` 안의 `to`까지 모두 매칭된다.  
이메일 패턴에서 `\b`를 패턴 양끝에 붙이는 이유가 바로 이것이다.  
이메일 주소가 더 긴 문자열의 일부로 붙어있는 경우를 걸러내기 위해서다.  

### `\A`와 `\Z` - 문자열의 절대적 시작과 끝

`\A`는 문자열의 시작, `\Z`는 문자열의 끝을 의미한다.  
언뜻 `^`, `$`와 동일해 보이지만, 멀티라인 모드에서 차이가 발생한다.  

`^`와 `$`는 `re.MULTILINE` 플래그를 사용하면 각 줄의 시작과 끝에 매칭된다.  
반면 `\A`와 `\Z`는 플래그에 관계없이 항상 **전체 문자열**의 시작과 끝에만 매칭된다.  

```python
import re

text = "first line\nsecond line\nthird line"

print(re.findall(r'^.*line', text, re.MULTILINE))
# ['first line', 'second line', 'third line']
# 각 줄의 시작에서 매칭

print(re.findall(r'\A.*line', text, re.MULTILINE))
# ['first line']
# 전체 문자열의 시작에서만 매칭 (. 은 개행 미포함이므로 첫 줄만)
```

전체 문자열이 특정 패턴과 정확히 일치하는지 검증할 때는  
`^`와 `$`보다 `\A`와 `\Z`를 쓰는 것이 더 안전하다.  
멀티라인 데이터를 다룰 때 `^`와 `$`가 예상치 못한 위치에서 매칭되는 문제를 방지할 수 있기 때문이다.  

## Python re 패키지의 핵심 함수들

특수 문자를 이해했다면, 이제 Python `re` 패키지가 제공하는  
네 가지 핵심 탐색 함수의 차이를 정확히 이해해야 한다.  
이 네 함수는 동일한 패턴을 쓰더라도 "어느 위치에서, 몇 개를 찾는가"에 따라  
완전히 다른 결과를 반환한다.  

### `re.search()` - 문자열 어디에서든 첫 번째 매칭

`re.search(pattern, string)`은 문자열 전체를 스캔하면서  
패턴에 매칭되는 **첫 번째** 위치를 찾으면 Match 객체를 반환한다.  
매칭되는 위치가 없으면 `None`을 반환한다.  

```python
import re

text = "The quick brown fox jumps over the lazy dog."

result = re.search(r'the', text, re.IGNORECASE)
print(result)         # <re.Match object; span=(0, 3), match='The'>
print(result.group()) # 'The'
print(result.span())  # (0, 3)
```

`re.search()`는 패턴이 문자열의 어느 위치에 있든 찾아낸다.  
결과로 반환되는 Match 객체는 매칭된 문자열과 위치 정보를 담고 있다.  
`result.group()`은 매칭된 문자열, `result.span()`은 시작과 끝 인덱스를 반환한다.  

### `re.match()` - 문자열의 시작에서만 매칭

`re.match(pattern, string)`은 문자열의 **시작 위치에서만** 패턴을 검사한다.  
패턴이 문자열 첫 글자부터 일치해야만 매칭이 성공한다.  

```python
import re

text = "The quick brown fox jumps over the lazy dog."

result_search = re.search(r'the', text, re.IGNORECASE)
result_match  = re.match(r'the', text, re.IGNORECASE)

print(result_search)  # <re.Match object; span=(0, 3), match='The'>
print(result_match)   # <re.Match object; span=(0, 3), match='The'>

result_match2 = re.match(r'fox', text)
print(result_match2)  # None - 'fox'가 문자열 시작에 없기 때문
```

`re.match(r'the', text)`가 성공한 이유는 `text`가 `"The"`로 시작하고  
`re.IGNORECASE` 플래그로 대소문자를 무시했기 때문이다.  

`re.match()`는 `^` 앵커를 패턴 앞에 붙인 것과 동일한 효과를 가진다.  
파일의 첫 줄이 특정 헤더로 시작하는지 검증하거나,  
입력값이 특정 문자로 시작하는지 확인할 때 적합하다.  

### `re.fullmatch()` - 전체 문자열이 패턴과 완전히 일치

`re.fullmatch(pattern, string)`은 문자열 전체가 패턴과 정확히 일치해야 매칭이 성공한다.  
패턴에 맞지 않는 부분이 앞이나 뒤에 하나라도 남아있으면 `None`을 반환한다.  

```python
import re

# 이메일 형식 검증
email_pattern = r'[\w.%+-]+@[\w.-]+\.[a-zA-Z]{2,}'

print(re.fullmatch(email_pattern, "user@example.com"))
# <re.Match object; ...> - 전체가 이메일 형식

print(re.fullmatch(email_pattern, "user@example.com 입니다"))
# None - 이메일 뒤에 추가 문자열이 있으므로 실패

print(re.search(email_pattern, "user@example.com 입니다"))
# <re.Match object; ...> - re.search는 부분 매칭이므로 성공
```

`re.fullmatch()`가 진가를 발휘하는 상황은 **입력값 검증**이다.  
사용자가 폼에 입력한 값이 정확히 이메일 형식인지, 전화번호 형식인지 검증할 때  
`re.search()`나 `re.match()`를 쓰면 앞뒤에 다른 문자열이 붙어도 통과될 수 있다.  
`re.fullmatch()`는 이런 부분 매칭의 허점을 원천 차단한다.  

세 함수의 차이를 한 줄로 요약하면 다음과 같다.  
`re.search()`는 "어디든 있으면 찾아라", `re.match()`는 "처음부터 시작해야 한다",  
`re.fullmatch()`는 "전체가 이 패턴 그 자체여야 한다"는 의미다.  

### `re.findall()` - 매칭되는 모든 결과 반환

`re.findall(pattern, string)`은 문자열 전체에서 패턴에 매칭되는  
**모든 결과를 리스트로 반환**한다.  

```python
import re

text = "The quick brown fox jumps over the lazy dog."

# 그룹 없는 경우: 매칭된 문자열 리스트 반환
print(re.findall(r'the', text, re.IGNORECASE))
# ['The', 'the']

# 그룹 하나인 경우: 그룹에 해당하는 문자열 리스트 반환
print(re.findall(r'(t\w+)', text, re.IGNORECASE))
# ['The', 'the']

# 그룹 여러 개인 경우: 튜플 리스트 반환
text2 = "이름:홍길동 나이:30 이름:김철수 나이:25"
print(re.findall(r'이름:(\w+) 나이:(\d+)', text2))
# [('홍길동', '30'), ('김철수', '25')]
```

그룹이 여러 개일 때 `re.findall()`은 튜플 리스트를 반환한다는 점이 중요하다.  
각 튜플의 원소는 순서대로 각 그룹이 캡처한 값이다.  
이 특성을 활용하면 구조화된 텍스트에서 여러 필드를 한 번에 추출해  
DataFrame으로 변환하는 작업을 간결하게 처리할 수 있다.  

```python
import re
import pandas as pd

text = "이름:홍길동 나이:30 이름:김철수 나이:25"
matches = re.findall(r'이름:(\w+) 나이:(\d+)', text)
df = pd.DataFrame(matches, columns=['이름', '나이'])
print(df)
#     이름  나이
# 0  홍길동  30
# 1  김철수  25
```

## Flags: 매칭 동작을 제어하는 옵션

Flags는 정규 표현식 엔진의 동작 방식을 변경하는 옵션이다.  
패턴 자체를 수정하지 않고도 매칭 규칙을 유연하게 조정할 수 있다.  

### `re.IGNORECASE` (`re.I`) - 대소문자 무시

`re.IGNORECASE`를 사용하면 패턴의 알파벳이 대소문자를 구분하지 않고 매칭된다.  

```python
import re

text = "Python python PYTHON"
print(re.findall(r'python', text))                    # ['python']
print(re.findall(r'python', text, re.IGNORECASE))     # ['Python', 'python', 'PYTHON']
print(re.findall(r'python', text, re.I))              # ['Python', 'python', 'PYTHON']
```

웹 크롤링 텍스트나 사용자 입력처럼 대소문자가 불규칙한 데이터를 다룰 때  
`re.IGNORECASE`는 필수적인 옵션이다.  
패턴에 `[Pp][Yy][Tt][Hh][Oo][Nn]`처럼 모든 경우를 나열하는 것보다  
훨씬 간결하고 유지보수하기 쉽다.  

### `re.MULTILINE` (`re.M`) - 멀티라인 모드

기본 모드에서 `^`와 `$`는 전체 문자열의 시작과 끝에만 매칭된다.  
`re.MULTILINE`을 사용하면 `^`와 `$`가 각 줄의 시작과 끝에도 매칭된다.  

```python
import re

log = """ERROR: disk full
WARNING: high memory usage
ERROR: network timeout
INFO: server started"""

# re.MULTILINE 없이: 전체 문자열 시작의 ERROR만 찾음
print(re.findall(r'^ERROR.*', log))
# ['ERROR: disk full']

# re.MULTILINE 적용: 각 줄 시작의 ERROR를 찾음
print(re.findall(r'^ERROR.*', log, re.MULTILINE))
# ['ERROR: disk full', 'ERROR: network timeout']
```

여러 줄로 이루어진 로그 파일이나 텍스트 파일을 처리할 때  
`re.MULTILINE`은 거의 필수적으로 사용된다.  
`re.MULTILINE` 없이 멀티라인 텍스트에서 `^`를 쓰면  
첫 번째 줄만 처리된다는 사실을 모르고 버그를 만드는 경우가 실무에서 자주 발생한다.  

### `re.DOTALL` (`re.S`) - 개행 포함 와일드카드

기본 모드에서 `.`은 개행 문자(`\n`)를 제외한 모든 문자에 매칭된다.  
`re.DOTALL`을 사용하면 `.`이 개행 문자를 포함한 모든 문자에 매칭된다.  

```python
import re

html = "<div>\n    <p>내용</p>\n</div>"

# re.DOTALL 없이: 개행이 포함된 범위는 매칭 안 됨
print(re.search(r'<div>.*</div>', html))
# None

# re.DOTALL 적용: 개행 포함해서 매칭
print(re.search(r'<div>.*</div>', html, re.DOTALL))
# <re.Match object; ...>
```

HTML, XML, JSON처럼 여러 줄에 걸쳐 구조가 이어지는 텍스트를 파싱할 때  
`re.DOTALL`이 필요하다.  
단, `.*`와 `re.DOTALL`의 조합은 매우 greedy하게 동작하므로  
lazy 매칭(`.*?`)을 함께 사용하는 경우가 많다.  

### Flags 조합

여러 플래그를 동시에 적용하려면 `|` 연산자로 조합한다.  

```python
import re

text = "First Line\nSECOND LINE\nthird line"

results = re.findall(r'^second.*', text, re.IGNORECASE | re.MULTILINE)
print(results)  # ['SECOND LINE']
```

`re.IGNORECASE | re.MULTILINE`은 대소문자 무시와 멀티라인 모드를 동시에 적용한다.  
`re.compile()`로 패턴 객체를 생성할 때 플래그를 지정하면  
이후 모든 탐색에 동일한 플래그가 적용되어 매번 인자로 넘길 필요가 없다.  
이 방식은 Part 5에서 자세히 다룬다.  

## 정리

특수 문자는 자주 쓰이는 문자 집합의 축약 표현이다.  
`\w`는 단어 문자, `\d`는 숫자, `\s`는 공백, `\b`는 단어 경계를 의미하며  
대문자 버전(`\W`, `\D`, `\S`, `\B`)은 각각의 반대 집합이다.  

Python `re` 패키지의 네 가지 탐색 함수는 역할이 명확히 다르다.  
`re.search()`는 위치 무관 첫 번째 매칭, `re.match()`는 시작 위치 매칭,  
`re.fullmatch()`는 전체 일치 검증, `re.findall()`은 모든 매칭 결과 추출이다.  

Flags는 패턴을 수정하지 않고 매칭 동작을 제어하는 옵션이다.  
`re.IGNORECASE`는 대소문자 무시, `re.MULTILINE`은 줄 단위 앵커 처리,  
`re.DOTALL`은 개행 포함 와일드카드를 활성화한다.  
Part 5에서는 `re.compile()`로 패턴 객체를 만들어 재사용하는 방법과  
Match 객체의 세부 활용법을 다룬다.  
````

아래는 Part 5 내용이다.

---

````qmd
---
title: "정규 표현식 - Part 5: re.compile과 re.Match 객체 활용"
author: "Kwangmin Kim"
date: today
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
---

## re.compile()이 필요한 이유

Part 4에서 다룬 `re.search()`, `re.findall()` 같은 함수들은  
매번 호출될 때마다 내부적으로 두 가지 작업을 수행한다.  
첫째, 패턴 문자열을 파싱해서 내부 표현으로 **컴파일**한다.  
둘째, 컴파일된 패턴으로 문자열을 **스캔**한다.  

문제는 동일한 패턴을 반복적으로 사용할 때다.  
수만 줄의 로그 파일을 처리하거나, 대용량 텍스트 데이터를 반복 스캔할 때  
매번 패턴을 새로 컴파일하면 불필요한 연산이 누적된다.  

`re.compile(pattern, flags=0)`은 패턴을 한 번만 컴파일해서  
`re.Pattern` 객체로 저장해두고, 이후 탐색 시 컴파일 단계를 건너뛴다.  
패턴이 복잡할수록, 호출 횟수가 많을수록 이 차이가 실질적인 성능 이득으로 이어진다.  

```python
import re
import time

log_lines = ["ERROR: disk full"] * 100000

# re.compile 없이 반복 호출
start = time.time()
for line in log_lines:
    re.search(r'^ERROR:\s+\w+', line)
print(f"compile 없음: {time.time() - start:.4f}초")

# re.compile로 미리 컴파일
pattern = re.compile(r'^ERROR:\s+\w+')
start = time.time()
for line in log_lines:
    pattern.search(line)
print(f"compile 사용: {time.time() - start:.4f}초")
```

실제로 Python 내부에는 최근 사용한 패턴을 캐싱하는 메커니즘이 있어서  
단순 반복 호출에서는 성능 차이가 크지 않을 수 있다.  
그러나 캐시 크기를 초과하거나, 여러 패턴을 번갈아 사용하는 상황에서는  
`re.compile()`의 명시적 캐싱이 유리하다.  

성능 외에도 `re.compile()`을 써야 하는 더 중요한 이유가 있다.  
패턴과 flags를 한 곳에 묶어서 관리할 수 있고,  
패턴에 이름을 붙여서 코드의 의도를 명확하게 표현할 수 있다.  

```python
import re

# 패턴을 변수명으로 의미 부여
PHONE_PATTERN  = re.compile(r'01[016789]-\d{3,4}-\d{4}')
EMAIL_PATTERN  = re.compile(r'[\w.%+-]+@[\w.-]+\.[a-zA-Z]{2,}')
DATE_PATTERN   = re.compile(r'\d{4}-\d{2}-\d{2}')
SSN_PATTERN    = re.compile(r'\d{6}-[1-4]\d{6}')

# 여러 곳에서 재사용
text = "연락처: 010-1234-5678, 이메일: user@example.com"
print(PHONE_PATTERN.search(text).group())   # '010-1234-5678'
print(EMAIL_PATTERN.search(text).group())   # 'user@example.com'
```

패턴을 모듈 상단에 상수처럼 모아두면  
패턴 수정이 필요할 때 한 곳만 고치면 되고,  
코드를 처음 보는 사람도 각 패턴의 역할을 즉시 파악할 수 있다.  
이것은 성능보다 훨씬 실질적인 `re.compile()`의 사용 이유다.  

## re.Pattern 객체의 메서드

`re.compile()`이 반환하는 `re.Pattern` 객체는  
`re.search()`, `re.match()`, `re.findall()`, `re.sub()` 등  
Part 4에서 다룬 모든 함수를 메서드로 제공한다.  
동작 방식은 동일하고, 패턴 인자를 별도로 넘기지 않는다는 점만 다르다.  

```python
import re

pattern = re.compile(r'\d+')

# re 모듈 함수 방식
print(re.findall(r'\d+', "abc 123 def 456"))    # ['123', '456']

# Pattern 객체 메서드 방식 (동일한 결과)
print(pattern.findall("abc 123 def 456"))        # ['123', '456']
```

`re.Pattern` 객체 메서드에는 `re` 모듈 함수에 없는 추가 파라미터가 있다.  
바로 `pos`와 `endpos`다.  

### pos와 endpos: 탐색 범위 제한

`Pattern.search(string, pos, endpos)`에서  
`pos`는 탐색을 시작할 인덱스, `endpos`는 탐색을 끝낼 인덱스를 지정한다.  
문자열 전체가 아닌 특정 구간만 스캔하고 싶을 때 사용한다.  

```python
import re

pattern = re.compile(r'\d+')
text = "abc 123 def 456 ghi 789"
#      0123456789...

# 전체 탐색
print(pattern.findall(text))           # ['123', '456', '789']

# 인덱스 4부터 15까지만 탐색
print(pattern.findall(text, 4, 15))    # ['123', '456']

# 첫 번째 매칭 후 그 위치부터 이어서 탐색
match1 = pattern.search(text)
print(match1.group(), match1.end())    # '123' 7

match2 = pattern.search(text, match1.end())
print(match2.group(), match2.end())    # '456' 15
```

`pos`와 `endpos`는 대용량 텍스트를 청크 단위로 나누어 처리하거나,  
이전 매칭 위치에서 이어서 탐색해야 하는 스트리밍 처리 시나리오에서 유용하다.  
`re` 모듈 함수(`re.search()`, `re.findall()`)는 이 파라미터를 지원하지 않으므로  
이런 경우에는 반드시 `re.compile()`을 사용해야 한다.  

## re.Match 객체: 매칭 결과를 담는 컨테이너

`re.search()`와 `re.match()`는 매칭이 성공하면 `re.Match` 객체를 반환한다.  
이 객체는 단순히 매칭 성공 여부만 알려주는 것이 아니라,  
매칭된 문자열, 위치 정보, 그룹 캡처 결과 등 풍부한 정보를 담고 있다.  

### 조건 분기에서의 활용

Match 객체는 매칭이 성공하면 `True`, 실패하면 `None`을 반환한다는 특성 덕분에  
`if`문에서 바로 조건 분기로 사용할 수 있다.  

```python
import re

def validate_email(text):
    pattern = re.compile(r'[\w.%+-]+@[\w.-]+\.[a-zA-Z]{2,}')
    if pattern.search(text):
        return True
    return False

print(validate_email("user@example.com"))   # True
print(validate_email("not_an_email"))       # False
```

`if pattern.search(text):`는 Match 객체가 있으면 True, None이면 False로 평가된다.  
별도로 `is not None`을 체크할 필요가 없다.  

### group(): 매칭된 문자열과 캡처 그룹 접근

`match.group()`은 매칭된 문자열에 접근하는 핵심 메서드다.  
인자 없이 호출하거나 `0`을 넘기면 패턴 전체가 매칭된 문자열을 반환한다.  
양의 정수를 넘기면 해당 번호의 캡처 그룹이 매칭한 문자열을 반환한다.  

```python
import re

text = "전화번호: 010-1234-5678"
pattern = re.compile(r'(01[016789])-(\d{3,4})-(\d{4})')
match = pattern.search(text)

if match:
    print(match.group())    # '010-1234-5678' (전체 매칭)
    print(match.group(0))   # '010-1234-5678' (group()과 동일)
    print(match.group(1))   # '010' (첫 번째 그룹: 국번)
    print(match.group(2))   # '1234' (두 번째 그룹: 중간 번호)
    print(match.group(3))   # '5678' (세 번째 그룹: 끝 번호)
    print(match.groups())   # ('010', '1234', '5678') (모든 그룹을 튜플로)
```

`match.groups()`는 모든 캡처 그룹의 결과를 튜플로 한 번에 반환한다.  
여러 그룹을 추출해서 딕셔너리나 DataFrame으로 변환할 때 편리하다.  

그룹에 이름을 붙이는 **named group** 방식도 있다.  
`(?P<name>pattern)` 형식으로 그룹에 이름을 지정하면  
`match.group('name')` 또는 `match.groupdict()`로 이름 기반 접근이 가능하다.  

```python
import re

text = "2024-02-15"
pattern = re.compile(r'(?P<year>\d{4})-(?P<month>\d{2})-(?P<day>\d{2})')
match = pattern.fullmatch(text)

if match:
    print(match.group('year'))    # '2024'
    print(match.group('month'))   # '02'
    print(match.group('day'))     # '15'
    print(match.groupdict())      # {'year': '2024', 'month': '02', 'day': '15'}
```

숫자 인덱스 방식(`group(1)`, `group(2)`)은 그룹 순서가 바뀌면 코드도 수정해야 하지만,  
named group 방식은 그룹 순서에 독립적이어서 패턴이 복잡해질수록 유지보수가 쉽다.  

### start(), end(), span(): 매칭 위치 정보

Match 객체는 매칭된 문자열의 위치 정보도 제공한다.  
`match.start()`는 매칭 시작 인덱스, `match.end()`는 매칭 끝 인덱스(exclusive),  
`match.span()`은 `(start, end)` 튜플을 반환한다.  

```python
import re

text = "The quick brown fox"
match = re.search(r'brown', text)

print(match.start())   # 10
print(match.end())     # 15
print(match.span())    # (10, 15)

# 위치 정보 활용: 매칭 전후 문맥 추출
context_start = max(0, match.start() - 5)
context_end   = min(len(text), match.end() + 5)
print(text[context_start:context_end])   # 'ck brown fox'
```

위치 정보는 단순히 무엇이 매칭됐는지가 아니라  
**어디에** 매칭됐는지가 중요한 경우에 활용된다.  
예를 들어 텍스트 에디터에서 검색된 단어를 하이라이팅할 때,  
매칭된 위치를 기준으로 전후 문맥을 추출할 때,  
매칭 위치를 기반으로 문자열 슬라이싱을 할 때 `start()`와 `end()`가 필수적이다.  

그룹 번호를 인자로 넘기면 해당 그룹의 위치 정보도 추출할 수 있다.  

```python
import re

text = "전화번호: 010-1234-5678"
pattern = re.compile(r'(01[016789])-(\d{3,4})-(\d{4})')
match = pattern.search(text)

if match:
    print(match.span(0))   # 전체 매칭 위치
    print(match.span(1))   # 첫 번째 그룹(국번) 위치
    print(match.span(2))   # 두 번째 그룹(중간 번호) 위치
    print(match.span(3))   # 세 번째 그룹(끝 번호) 위치
```

## re.finditer(): Match 객체를 순회하는 이터레이터

`re.findall()`은 매칭된 문자열의 리스트를 반환하지만,  
위치 정보가 필요하거나 대용량 텍스트를 처리할 때는  
`re.finditer()`가 더 적합하다.  

`re.finditer()`는 매칭된 각 결과를 Match 객체로 감싸서  
이터레이터 형태로 반환한다.  
결과 전체를 메모리에 올리지 않고 하나씩 처리할 수 있어  
대용량 텍스트 처리에서 메모리 효율이 높다.  

```python
import re

text = "에러 발생: 2024-01-15 서버 다운, 재발생: 2024-02-03 메모리 부족"
pattern = re.compile(r'\d{4}-\d{2}-\d{2}')

for match in pattern.finditer(text):
    print(f"날짜: {match.group()}, 위치: {match.span()}")
# 날짜: 2024-01-15, 위치: (7, 17)
# 날짜: 2024-02-03, 위치: (27, 37)
```

`re.findall()`은 결과를 한꺼번에 리스트로 만들어 반환하므로  
매칭 결과가 많을수록 메모리를 많이 사용한다.  
반면 `re.finditer()`는 한 번에 하나씩 Match 객체를 생성하므로  
수백만 줄의 로그 파일처럼 대용량 텍스트를 처리할 때 메모리 사용량을 크게 줄일 수 있다.  
단순히 매칭된 문자열만 필요하면 `re.findall()`,  
위치 정보나 그룹 정보가 필요하거나 대용량 처리가 필요하면 `re.finditer()`를 선택한다.  

## 실전 패턴: compile + Match 객체의 결합

PPT의 핸드폰 번호 추출 예시를 `re.compile()`과 Match 객체를 완전히 활용하는 형태로  
재구성하면 각 요소의 역할이 더 명확하게 드러난다.  

```python
import re

# 패턴을 모듈 수준에서 한 번만 컴파일
PHONE_PATTERN = re.compile(r'(01[016789])-(\d{3,4})-(\d{4})')

personal_info = """
이름: 홍길동
주소: 서울시 강남구
전화번호: 010-1234-5678
주민등록번호: 930101-1234567
"""

match = PHONE_PATTERN.search(personal_info)

if match:
    full_number  = match.group(0)   # '010-1234-5678'
    area_code    = match.group(1)   # '010'
    middle       = match.group(2)   # '1234'
    last         = match.group(3)   # '5678'
    position     = match.span()     # (24, 37) 또는 실제 위치

    print(f"전체 번호: {full_number}")
    print(f"국번: {area_code}")
    print(f"중간 번호: {middle}")
    print(f"끝 번호: {last}")
    print(f"텍스트 내 위치: {position}")
```

`PHONE_PATTERN`을 상수로 모듈 상단에 정의하면  
이 패턴이 여러 함수나 루프에서 재사용될 때 컴파일 비용이 한 번만 발생한다.  
그룹화를 통해 번호 전체뿐 아니라 국번, 중간 번호, 끝 번호를 각각 독립적으로 추출할 수 있고,  
`match.span()`으로 텍스트 내 위치도 파악할 수 있다.  
이 구조는 단순한 번호 추출을 넘어,  
마스킹 처리, 포맷 변환, 위치 기반 편집 등 다양한 후처리 작업의 기반이 된다.  

## 정리

`re.compile()`은 성능 최적화보다 **코드 구조화**의 도구로 이해하는 것이 더 정확하다.  
패턴에 의미 있는 이름을 부여하고, 플래그를 패턴과 함께 묶고,  
`pos`/`endpos`로 탐색 범위를 제어하는 기능은 `re.compile()` 없이는 사용할 수 없다.  

Match 객체는 단순한 매칭 성공 신호가 아니다.  
`group()`으로 전체 또는 부분 캡처 결과에 접근하고,  
`start()`, `end()`, `span()`으로 매칭 위치를 파악하며,  
`groups()`, `groupdict()`로 모든 그룹을 한 번에 추출하는  
풍부한 인터페이스를 제공한다.  

`re.finditer()`는 `re.findall()`의 메모리 효율적 대안으로,  
위치 정보가 필요하거나 대용량 텍스트를 처리할 때 선택해야 한다.  
Part 6에서는 지금까지 배운 모든 요소를 결합한 실전 활용 사례 4가지를 완전히 해부한다.  
````

아래는 Part 6 내용이다.

---

````qmd
---
title: "정규 표현식 - Part 6: 실전 활용 사례 완전 해부"
author: "Kwangmin Kim"
date: today
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
---

## 실전 사례를 통해 배우는 패턴 설계 사고법

Part 2부터 Part 5까지 정규 표현식의 구성 요소를 하나씩 해부했다.  
이번 파트에서는 PPT에서 제시된 실전 활용 사례 4가지를 완전히 해부한다.  
단순히 코드를 나열하는 것이 아니라,  
"왜 이 패턴이 이렇게 설계되었는가"라는 설계 과정을 역추적하는 방식으로 설명한다.  

정규 표현식 패턴을 작성하는 사고 과정은 항상 동일하다.  
첫째, 대상 데이터의 구조를 분석한다.  
둘째, 구조를 구간으로 분리하고 각 구간의 규칙을 정의한다.  
셋째, 각 구간을 메타 문자, 특수 문자, 반복자로 표현한다.  
넷째, 캡처가 필요한 구간에 그룹화를 적용한다.  
이 4단계 사고 과정을 각 사례에 적용하면서 따라가 보자.  

## 사례 1: 핸드폰 번호 추출

### 데이터 구조 분석

한국 핸드폰 번호의 구조는 `01x-xxx(x)-xxxx` 형태다.  
구체적으로 분해하면 다음과 같다.  

첫 번째 구간: `010`, `011`, `016`, `017`, `018`, `019` 중 하나 (3자리)  
구분자: `-`  
두 번째 구간: 숫자 3자리 또는 4자리  
구분자: `-`  
세 번째 구간: 숫자 4자리  

### 패턴 설계 과정

첫 번째 구간은 `01`로 시작하고, 세 번째 자리가 `0`, `1`, `6`, `7`, `8`, `9` 중 하나다.  
`[016789]`라는 문자 집합으로 표현하면 `01[016789]`가 첫 번째 구간의 패턴이 된다.  
`01.`처럼 `.`을 쓰면 `012`, `013`, `014`, `015`도 매칭되므로  
문자 집합을 명시적으로 지정하는 것이 정확하다.  

두 번째 구간은 3자리 또는 4자리 숫자다.  
`\d{3,4}`로 표현한다.  
`\d{3}|\d{4}`로 쓸 수도 있지만, `{m,n}` 표기가 더 간결하다.  

세 번째 구간은 정확히 4자리 숫자이므로 `\d{4}`다.  

구분자 `-`는 리터럴 문자 그대로 쓴다.  
`[\-]`나 `\-`로 이스케이프할 필요 없이 `-`를 문자 집합 밖에서 쓰면  
하이픈 자체를 의미한다.  

```python
import re

PHONE_PATTERN = re.compile(r'01[016789]-\d{3,4}-\d{4}')

personal_info = """
이름: 홍길동
주소: 서울시 강남구
전화번호: 010-1234-5678
주민등록번호: 930101-1234567
"""

match = PHONE_PATTERN.search(personal_info)
if match:
    print(f"핸드폰 번호: {match.group()}")
    # 핸드폰 번호: 010-1234-5678
```

### 왜 주민등록번호가 걸리지 않는가

`930101-1234567`에서 `1234567`은 7자리인데,  
패턴의 세 번째 구간 `\d{4}`는 정확히 4자리만 매칭한다.  
또한 첫 번째 구간 `01[016789]`는 `93`으로 시작하는 주민번호와 매칭되지 않는다.  
패턴의 시작 조건 자체가 `01`로 고정되어 있기 때문이다.  
이처럼 패턴의 첫 구간을 엄격하게 정의하면 유사한 형태의 다른 데이터를 자연스럽게 걸러낼 수 있다.  

### 그룹화를 추가한 확장 패턴

번호 전체가 아니라 각 구간을 독립적으로 추출하거나 마스킹해야 한다면  
그룹화를 추가한다.  

```python
import re

PHONE_PATTERN = re.compile(r'(01[016789])-(\d{3,4})-(\d{4})')

text = "문의: 010-1234-5678 또는 011-987-6543"

for match in PHONE_PATTERN.finditer(text):
    area   = match.group(1)   # 국번
    middle = match.group(2)   # 중간 번호
    last   = match.group(3)   # 끝 번호
    print(f"국번: {area}, 중간: {middle}, 끝: {last}")
# 국번: 010, 중간: 1234, 끝: 5678
# 국번: 011, 중간: 987, 끝: 6543
```

## 사례 2: CSV 파일에서 특정 필드 추출

### 데이터 구조 분석

CSV 파일의 각 행은 쉼표로 구분된 필드들의 연속이다.  
목표는 6개 필드 중 4번째와 6번째 필드만 추출하는 것이다.  

```
필드1,필드2,필드3,필드4,필드5,필드6
```

### 패턴 설계 과정

각 필드는 "쉼표가 아닌 문자가 1개 이상 연속된 구간"이다.  
`[^,]+`가 하나의 필드를 표현하는 패턴이다.  
`[^,]`는 쉼표가 아닌 모든 문자를 의미하고, `+`는 1개 이상 반복을 의미한다.  

캡처가 필요한 4번째와 6번째 필드만 `()`로 묶는다.  
나머지 필드는 괄호 없이 `[^,]+`로 쓰면  
"패턴은 매칭하되 캡처하지 않는다"는 의미가 된다.  

```python
import re

pattern = re.compile(r'[^,]+,[^,]+,[^,]+,([^,]+),[^,]+,([^,]+)')

with open('log_file.csv', 'r') as file:
    for line in file:
        match = pattern.match(line.strip())
        if match:
            fourth_value = match.group(1)
            sixth_value  = match.group(2)
            print(f"4번째 값: {fourth_value}, 6번째 값: {sixth_value}")
        else:
            print("패턴과 매치되지 않는 라인이 있습니다.")
```

### 이 방식의 설계 의도와 한계

`re.compile(r'[^,]+,[^,]+,[^,]+,([^,]+),[^,]+,([^,]+)')`에서  
캡처하지 않는 필드를 `[^,]+`로 명시한 이유는  
"이 라인이 정확히 6개 필드를 가진 구조인지"를 패턴 자체가 검증하도록 하기 위해서다.  
`re.match()`는 문자열의 시작부터 패턴을 확인하므로,  
필드 수가 맞지 않으면 매칭 자체가 실패해 `else` 분기로 빠진다.  
이것은 단순 추출이 아니라 **구조 검증과 추출을 동시에** 수행하는 설계다.  

단, 필드 값 안에 쉼표가 포함된 경우(`"값,포함",다음필드`)는  
이 패턴으로 처리할 수 없다.  
따옴표로 감싸진 필드를 포함하는 복잡한 CSV는  
`csv` 모듈이나 `pandas.read_csv()`를 사용하는 것이 더 적합하다.  
정규 표현식은 구조가 단순하고 예외 케이스가 없는 CSV에 적합하다.  

## 사례 3: 순서 바꾸기 - re.sub와 backreference의 결합

### 데이터 구조 분석

`"서울-대구-대전-부산"` 형태의 문자열에서  
2번째와 3번째 요소의 순서를 바꾸어  
`"서울-대전-대구-부산"`으로 변환하는 것이 목표다.  

### 패턴 설계 과정

4개의 요소를 각각 그룹으로 캡처하고,  
`re.sub()`의 치환 문자열에서 그룹 순서를 재배열한다.  

각 요소는 하이픈으로 구분된 "단어 문자 1개 이상"이므로 `(\w+)`가 적합하다.  
4개 요소를 하이픈으로 연결한 전체 패턴은 `(\w+)-(\w+)-(\w+)-(\w+)`다.  

치환 문자열 `r'\1-\3-\2-\4'`에서 `\1`, `\2`, `\3`, `\4`는  
각각 1번째, 2번째, 3번째, 4번째 그룹이 캡처한 값을 참조한다.  
순서를 `\1-\3-\2-\4`로 쓰면 2번째와 3번째가 교환된다.  

```python
import re

input_string = "서울-대구-대전-부산"
result = re.sub(r'(\w+)-(\w+)-(\w+)-(\w+)', r'\1-\3-\2-\4', input_string)
print(result)   # '서울-대전-대구-부산'
```

### 이 패턴의 설계 철학

이 패턴이 강력한 이유는 데이터를 직접 조작하지 않는다는 점이다.  
문자열을 분리(`split`)해서 리스트로 만들고, 인덱스를 교환하고, 다시 합치는  
절차적 방식 대신, 패턴 하나로 "어떤 구조에서 어떤 구조로 변환한다"는 선언적 방식을 사용한다.  

이 방식은 다음과 같은 다양한 변환 작업에 그대로 적용할 수 있다.  

```python
import re

# 날짜 형식 변환: YYYY-MM-DD -> DD/MM/YYYY
date = "2024-02-15"
result = re.sub(r'(\d{4})-(\d{2})-(\d{2})', r'\3/\2/\1', date)
print(result)   # '15/02/2024'

# 성명 순서 변환: 성, 이름 -> 이름 성
name = "Kim Minsu"
result = re.sub(r'(\w+) (\w+)', r'\2 \1', name)
print(result)   # 'Minsu Kim'

# CSV 컬럼 순서 변환
row = "A001,홍길동,30,서울"
result = re.sub(r'(\w+),(\w+),(\d+),(\w+)', r'\2,\1,\4,\3', row)
print(result)   # '홍길동,A001,서울,30'
```

패턴 구조는 동일하고 그룹 번호 순서만 바꾸면  
어떤 요소 재배열 문제든 동일한 방식으로 해결할 수 있다.  

## 사례 4: 개인정보 마스킹과 주민번호 생년월일 변환

### 설계 목표

PPT는 두 가지 마스킹 작업을 하나의 예시에서 보여준다.  
첫째, 전화번호의 중간 번호를 `****`로 마스킹한다.  
둘째, 주민등록번호의 뒷 6자리를 `******`로 마스킹한다.  

이 두 작업의 공통점은 `re.sub()`의 두 번째 인자로  
**문자열이 아닌 함수**를 넘긴다는 점이다.  
이것이 단순 치환과 구분되는 고급 패턴이다.  

### re.sub()에 함수를 넘기는 원리

`re.sub(pattern, repl, string)`에서 `repl`이 함수일 경우,  
패턴에 매칭되는 각 부분에 대해 그 함수가 호출된다.  
함수의 인자는 Match 객체이고, 반환값이 치환 문자열이 된다.  

이 구조를 활용하면 매칭된 내용을 분석한 뒤  
상황에 따라 다른 문자열로 치환하는 **조건부 치환**이 가능하다.  
단순 `\1-****-\3`처럼 고정된 문자열 치환으로는 불가능한 동적 변환이다.  

```python
import re

def mask_phone_numbers(match):
    # match.group(1): 국번 (010)
    # match.group(2): 중간 번호 (1234) <- 마스킹 대상
    # match.group(3): 끝 번호 (5678)
    return f"{match.group(1)}-****-{match.group(3)}"

def mask_ssn(match):
    # match.group(1): 앞 6자리 (930101)
    # match.group(2): 7번째 자리 성별 코드 (1)
    # 뒤 6자리는 캡처하지 않고 패턴으로만 소비
    return f"{match.group(1)}-{match.group(2)}******"

personal_info = """
이름: 홍길동
주소: 서울시 강남구
전화번호: 010-1234-5678
주민등록번호: 930101-1234567
"""

phone_pattern = re.compile(r'(01[016789])-(\d{3,4})-(\d{4})')
ssn_pattern   = re.compile(r'(\d{6})-(\d)\d{6}')

masked_info = phone_pattern.sub(mask_phone_numbers, personal_info)
masked_info = ssn_pattern.sub(mask_ssn, masked_info)

print(masked_info)
# 이름: 홍길동
# 주소: 서울시 강남구
# 전화번호: 010-****-5678
# 주민등록번호: 930101-1******
```

### 패턴 설계 해부: 주민번호 패턴

`r'(\d{6})-(\d)\d{6}'`를 구간별로 분해하면 다음과 같다.  

`(\d{6})` : 앞 6자리 생년월일을 캡처 (그룹 1)  
`-` : 구분자 하이픈  
`(\d)` : 7번째 자리 성별 코드를 캡처 (그룹 2)  
`\d{6}` : 뒤 6자리는 **캡처 없이** 패턴만 소비  

마지막 `\d{6}`을 괄호로 묶지 않은 이유가 핵심이다.  
마스킹 함수에서 이 부분은 `match.group()`으로 접근할 필요가 없고,  
어차피 `******`로 고정 치환될 것이기 때문에 캡처를 생략했다.  
캡처 그룹 수를 최소화하면 패턴이 간결해지고 `group()` 인덱스 관리도 쉬워진다.  

### 사례 5: 주민번호에서 생년월일 변환

마스킹보다 한 단계 더 복잡한 사례다.  
`"900101-4234567"` 형태의 주민번호를 `"1990-01-01"` 형태의 날짜로 변환한다.  
7번째 자리가 `1` 또는 `2`이면 19xx년생, `3` 또는 `4`이면 20xx년생이라는  
조건부 로직이 들어가야 하므로 `re.sub()`에 함수를 넘기는 방식이 필수다.  

```python
import re

def generate_birthday(match):
    # match.group(1): 연도 2자리 (90)
    # match.group(2): 월 2자리 (01)
    # match.group(3): 일 2자리 (01)
    # match.group(4): 성별 코드 (4)
    year_prefix = '19' if match.group(4) in ('1', '2') else '20'
    return f"{year_prefix}{match.group(1)}-{match.group(2)}-{match.group(3)}"

# 패턴: (연도2자리)(월2자리)(일2자리)-(성별코드)(뒷6자리)
pattern = re.compile(r'(\d{2})(\d{2})(\d{2})-(\d)\d{6}')

test_cases = [
    "930101-1234567",   # 1993년생 남성
    "050315-4234567",   # 2005년생 여성
    "851220-2345678",   # 1985년생 여성
]

for ssn in test_cases:
    result = pattern.sub(generate_birthday, ssn)
    print(f"{ssn} -> {result}")
# 930101-1234567 -> 1993-01-01
# 050315-4234567 -> 2005-03-15
# 851220-2345678 -> 1985-12-20
```

### generate_birthday 함수의 설계 의도

`match.group(4)`로 성별 코드를 읽어 세기 판별 로직을 넣는 부분이 핵심이다.  
이것은 정규 표현식만으로는 표현할 수 없는 조건부 로직이다.  
정규 표현식은 "어떤 구조를 찾을 것인가"를 담당하고,  
Python 함수는 "찾은 결과를 어떻게 변환할 것인가"를 담당한다.  
`re.sub()`에 함수를 넘기는 패턴은 이 두 역할의 분리를 구현한 것이다.  

연도 2자리(`93`, `05`)가 그룹 1에 캡처되고,  
`year_prefix`가 `'19'` 또는 `'20'`으로 결정된 뒤,  
`f"{year_prefix}{match.group(1)}-{match.group(2)}-{match.group(3)}"`으로 조합된다.  
문자열 조작 없이 그룹 캡처 결과를 f-string으로 재조합하는 이 방식은  
코드가 데이터 구조를 그대로 반영하므로 읽기 쉽고 수정하기도 쉽다.  

## HTML 태그 제거: re.DOTALL과 lazy 매칭의 결합

PPT 마지막 사례인 HTML 태그 제거는 앞선 사례들보다 단순하지만,  
`<.*?>`라는 패턴이 왜 `<.*>`가 아닌지 이해하는 것이 핵심이다.  

```python
import re

def remove_html_tags(input):
    pattern = re.compile(r'<.*?>')
    return re.sub(pattern, '', input)

input = "<p>This is <b>Python</b> and <i>Regular Expression</i>.</p>"
result = remove_html_tags(input)
print(result)   # 'This is Python and Regular Expression.'
```

`<.*>`를 쓰면 greedy 매칭으로 인해  
`<p>` 부터 마지막 `</p>` 까지 전체가 하나로 매칭되어 모든 텍스트가 사라진다.  
`<.*?>`의 `?`가 lazy 매칭을 활성화해서  
`<`를 만난 순간 `>`가 나오는 가장 가까운 위치에서 멈추게 만든다.  
결과적으로 각 태그를 개별적으로 잡아내어 빈 문자열로 치환한다.  

멀티라인 HTML에서 태그가 여러 줄에 걸쳐 있는 경우에는 `re.DOTALL`이 추가로 필요하다.  

```python
import re

def remove_html_tags(input):
    pattern = re.compile(r'<.*?>', re.DOTALL)
    return re.sub(pattern, '', input)

multiline_html = "<div>\n    <p>내용</p>\n</div>"
result = remove_html_tags(multiline_html)
print(result)   # '\n    내용\n'
```

`re.DOTALL` 없이는 `.`이 개행을 건너지 못하므로  
여러 줄에 걸친 태그가 매칭되지 않는다.  
`re.DOTALL`을 추가하면 개행을 포함한 태그도 처리할 수 있다.  
단, 실제 프로덕션 환경에서 HTML 파싱은 `BeautifulSoup`이나  
`lxml` 같은 전용 파서를 사용하는 것이 더 안정적이다.  
정규 표현식은 단순하고 예측 가능한 HTML 구조에만 신뢰할 수 있다.  

## 정규 표현식 테스트 도구

패턴을 작성하고 즉시 검증하려면 온라인 도구를 활용하는 것이 효율적이다.  
PPT에서 소개한 `https://regexr.com/`은 가장 널리 사용되는 정규 표현식 테스트 도구다.  

이 도구를 사용하면 패턴을 입력하는 즉시 매칭 결과가 하이라이팅되고,  
각 메타 문자 위에 마우스를 올리면 의미가 설명된다.  
실무에서 복잡한 패턴을 처음 작성할 때는 코드에 바로 넣기보다  
이 도구에서 먼저 검증한 뒤 코드에 옮기는 것이 디버깅 시간을 크게 줄인다.  

유사한 도구로 `https://regex101.com/`도 많이 사용되며,  
Python, JavaScript, PHP 등 언어별 엔진을 선택해서 테스트할 수 있어  
언어마다 미묘하게 다른 정규 표현식 동작을 확인할 때 유용하다.  

## 시리즈 전체 정리

6개 파트에 걸쳐 정규 표현식의 이론부터 실전까지 다루었다.  
전체 흐름을 한 번에 정리하면 다음과 같다.  

Part 1에서는 정규 표현식이 단순 문자열 검색과 다른 이유와  
탐색, 치환, 검증이라는 세 가지 핵심 용도를 다루었다.  

Part 2에서는 패턴의 구조를 정의하는 메타 문자  
`^`, `$`, `[]`, `[^]`, `.`, `|`의 동작 원리를 해부했다.  

Part 3에서는 반복 횟수를 제어하는 반복자 `*`, `+`, `?`, `{m,n}`과  
패턴을 단위로 묶고 재조합하는 그룹화 `()`와 backreference `\n`을 다루었다.  
greedy와 lazy 매칭의 차이도 이 파트의 핵심 내용이다.  

Part 4에서는 문자 집합의 축약 표현인 특수 문자 `\w`, `\d`, `\s`, `\b`와  
Python `re` 패키지의 네 가지 탐색 함수,  
그리고 매칭 동작을 제어하는 flags를 다루었다.  

Part 5에서는 `re.compile()`로 패턴을 구조화하는 방법과  
Match 객체의 `group()`, `start()`, `end()`, `span()` 인터페이스를 다루었다.  

Part 6에서는 핸드폰 번호 추출, CSV 필드 추출, 순서 바꾸기,  
개인정보 마스킹, 주민번호 변환, HTML 태그 제거라는 6가지 실전 사례를  
패턴 설계 과정을 역추적하는 방식으로 완전히 해부했다.  

정규 표현식은 처음에는 암호처럼 보이지만,  
메타 문자, 특수 문자, 반복자, 그룹화라는 4가지 구성 요소로 분해해서 읽으면  
어떤 복잡한 패턴도 단계적으로 이해할 수 있다.  
패턴을 직접 작성할 때는 항상 데이터 구조를 구간으로 분리하고,  
각 구간의 규칙을 순서대로 표현하는 4단계 사고 과정을 따르면  
시행착오를 최소화할 수 있다.  
````