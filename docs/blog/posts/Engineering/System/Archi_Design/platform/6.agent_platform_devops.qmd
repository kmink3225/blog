---
title: "AI Agent í”Œë«í¼ ìš´ì˜ ìë™í™”ì™€ DevOps"
subtitle: "CI/CD, ëª¨ë‹ˆí„°ë§, ë°°í¬ ì „ëµ, ë³´ì•ˆ"
description: |
  AI Agent í”Œë«í¼ì˜ ìš´ì˜ ìë™í™”ì™€ DevOps ì „ëµì„ ë‹¤ë£¬ë‹¤.
  CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•, ë³€ê²½ ê°ì§€ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ìë™í™”,
  Blue-Green/Canary ë°°í¬ ì „ëµ, Agentë³„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ,
  êµ¬ì¡°í™”ëœ ë¡œê¹…, ì•Œë¦¼ ì‹œìŠ¤í…œ, API í‚¤ ê´€ë¦¬ ë“±
  ì‹¤ì œ ìš´ì˜ì— í•„ìš”í•œ ëª¨ë“  ìë™í™” ì „ëµì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•œë‹¤.
categories:
  - Engineering
  - System
  - Architecture Design
  - AI
  - Platform
  - DevOps
author: Kwangmin Kim
date: 01/31/2026
format: 
  html:
    code-fold: true
    toc: true
    number-sections: true
draft: false
---

# ë“¤ì–´ê°€ë©°

## ì™œ ìš´ì˜ ìë™í™”ê°€ ì¤‘ìš”í•œê°€?

Phase 4 í”Œë«í¼ì„ êµ¬ì¶•í•œ í›„ ì´ì œ ì‹¤ì œ ìš´ì˜ ì‹œ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤:

**ì§ˆë¬¸ë“¤**:
- "Agent ì½”ë“œë¥¼ ìˆ˜ì •í–ˆëŠ”ë°, ì–´ëŠ ê²ƒì„ í…ŒìŠ¤íŠ¸í•´ì•¼ í•˜ë‚˜ìš”?"
- "ìƒˆ Agentë¥¼ ë°°í¬í•˜ëŠ”ë° ê¸°ì¡´ ì„œë¹„ìŠ¤ê°€ ë‹¤ìš´ë˜ë©´ ì–´ë–¡í•˜ì£ ?"
- "Agentê°€ ëŠë ¤ì¡ŒëŠ”ë° ì–´ë””ì„œ ë³‘ëª©ì´ ìƒê¸°ëŠ”ì§€ ëª¨ë¥´ê² ì–´ìš”"
- "LLM API í‚¤ê°€ ë…¸ì¶œë˜ì§€ ì•Šê²Œ í•˜ë ¤ë©´?"

**ì´ ê¸€ì˜ ëª©í‘œ**:
- CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (ë³€ê²½ ê°ì§€ + ìë™ í…ŒìŠ¤íŠ¸)
- ë¬´ì¤‘ë‹¨ ë°°í¬ ì „ëµ (Blue-Green, Canary)
- ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ (ë©”íŠ¸ë¦­, ëŒ€ì‹œë³´ë“œ, ì•Œë¦¼)
- ë¡œê¹… ì „ëµ (êµ¬ì¡°í™”, ë¶„ì„, ì¶”ì )
- ë³´ì•ˆ ê´€ë¦¬ (ì¸ì¦, API í‚¤, ê¶Œí•œ)

## ì•ì„  ê¸€ ìš”ì•½

**5ë²ˆ ê¸€** ([ë°ì´í„° í‘œì¤€í™” ê³„ì¸µ](5.agent_platform_data_standardization.qmd)):
- í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬ (PromptRegistry)
- ë²¡í„° ë°ì´í„° ìë™ ì—…ë°ì´íŠ¸
- í‘œì¤€ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ
- í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬

**í•µì‹¬ ì§ˆë¬¸**: "êµ¬ì¶•í•œ í”Œë«í¼ì„ ì–´ë–»ê²Œ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜í•˜ê³  ìë™í™”í•  ê²ƒì¸ê°€?"

# CI/CD íŒŒì´í”„ë¼ì¸

## ë¬¸ì œ: ìˆ˜ë™ ë°°í¬ì˜ í•œê³„

### ì´ˆê¸° ë°©ì‹ (Phase 1-2)

```bash
# âŒ ë‚˜ìœ ì˜ˆ: ìˆ˜ë™ ë°°í¬
# 1. ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸
pytest tests/

# 2. ìˆ˜ë™ìœ¼ë¡œ ì„œë²„ SSH
ssh production-server

# 3. ì½”ë“œ pull
git pull origin main

# 4. ì„œë¹„ìŠ¤ ì¬ì‹œì‘
systemctl restart agent-platform

# 5. ì—ëŸ¬ ë°œìƒ ì‹œ ìˆ˜ë™ ë¡¤ë°±
git reset --hard HEAD~1
systemctl restart agent-platform
```

**ë¬¸ì œì **:
1. **í…ŒìŠ¤íŠ¸ ëˆ„ë½**: ê°œë°œìê°€ ê¹œë¹¡í•˜ë©´ ë¯¸í…ŒìŠ¤íŠ¸ ì½”ë“œ ë°°í¬
2. **ë‹¤ìš´íƒ€ì„**: ì¬ì‹œì‘ ì¤‘ ì„œë¹„ìŠ¤ ì¤‘ë‹¨
3. **ë¡¤ë°± ì§€ì—°**: ë¬¸ì œ ë°œê²¬ â†’ ìˆ˜ë™ ë¡¤ë°± â†’ 10ë¶„ ì´ìƒ ì†Œìš”
4. **ë¶ˆì¼ì¹˜**: ë¡œì»¬ í™˜ê²½ê³¼ í”„ë¡œë•ì…˜ í™˜ê²½ ì°¨ì´

## GitHub Actions ê¸°ë°˜ CI/CD

### íŒŒì¼ êµ¬ì¡°

```bash
.github/
â””â”€â”€ workflows/
    â”œâ”€â”€ test.yml           # PR ì‹œ í…ŒìŠ¤íŠ¸
    â”œâ”€â”€ deploy-dev.yml     # ê°œë°œ í™˜ê²½ ìë™ ë°°í¬
    â””â”€â”€ deploy-prod.yml    # í”„ë¡œë•ì…˜ ìˆ˜ë™ ìŠ¹ì¸ ë°°í¬
```

### test.yml: ë³€ê²½ ê°ì§€ + ì„ íƒì  í…ŒìŠ¤íŠ¸

```yaml
# .github/workflows/test.yml
name: Test Affected Components

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      core_changed: ${{ steps.changes.outputs.core }}
      shared_changed: ${{ steps.changes.outputs.shared }}
      affected_agents: ${{ steps.changes.outputs.agents }}
    
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 2  # ì´ì „ ì»¤ë°‹ê³¼ ë¹„êµ
      
      - name: Detect changes
        id: changes
        run: |
          # ë³€ê²½ëœ íŒŒì¼ ëª©ë¡
          CHANGED=$(git diff --name-only HEAD~1)
          
          # core/ ë˜ëŠ” shared/ ë³€ê²½ ì‹œ ì „ì²´ í…ŒìŠ¤íŠ¸
          if echo "$CHANGED" | grep -qE '^(core|shared)/'; then
            echo "core=true" >> $GITHUB_OUTPUT
            echo "shared=true" >> $GITHUB_OUTPUT
            echo "agents=all" >> $GITHUB_OUTPUT
          else
            # agents/ ë³€ê²½ ì‹œ í•´ë‹¹ Agentë§Œ
            AGENTS=$(echo "$CHANGED" | grep '^agents/' | cut -d'/' -f2 | sort -u | tr '\n' ',')
            echo "core=false" >> $GITHUB_OUTPUT
            echo "shared=false" >> $GITHUB_OUTPUT
            echo "agents=$AGENTS" >> $GITHUB_OUTPUT
          fi
          
          echo "Changed files:"
          echo "$CHANGED"
          echo "Affected agents: $AGENTS"

  test-core:
    needs: detect-changes
    if: needs.detect-changes.outputs.core_changed == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install poetry
          poetry install
      
      - name: Test core module
        run: |
          poetry run pytest core/tests/ -v --cov=core --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: core

  test-shared:
    needs: detect-changes
    if: needs.detect-changes.outputs.shared_changed == 'true'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install poetry
          poetry install
      
      - name: Test shared module
        run: |
          poetry run pytest shared/tests/ -v --cov=shared

  test-agents:
    needs: detect-changes
    if: needs.detect-changes.outputs.affected_agents != ''
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        agent: ${{ fromJson(needs.detect-changes.outputs.affected_agents == 'all' && '["data_standardization", "code_analysis", "knowledge_qna"]' || format('["{0}"]', needs.detect-changes.outputs.affected_agents)) }}
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install poetry
          poetry install
      
      - name: Test agent - ${{ matrix.agent }}
        run: |
          poetry run pytest agents/${{ matrix.agent }}/tests/ -v
      
      - name: Evaluate agent performance
        run: |
          poetry run python scripts/evaluate_agent.py ${{ matrix.agent }}

  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install poetry
          poetry install
      
      - name: Lint with ruff
        run: poetry run ruff check .
      
      - name: Check import rules
        run: poetry run lint-imports
      
      - name: Type check with mypy
        run: poetry run mypy core/ shared/ agents/

  integration-test:
    needs: [test-core, test-shared, test-agents]
    if: always() && (needs.test-core.result == 'success' || needs.test-core.result == 'skipped') && (needs.test-shared.result == 'success' || needs.test-shared.result == 'skipped') && (needs.test-agents.result == 'success' || needs.test-agents.result == 'skipped')
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install poetry
          poetry install
      
      - name: Run integration tests
        run: |
          poetry run pytest tests/integration/ -v
      
      - name: Test agent chaining
        run: |
          poetry run python scripts/test_chaining.py
```

### deploy-prod.yml: í”„ë¡œë•ì…˜ ë°°í¬

```yaml
# .github/workflows/deploy-prod.yml
name: Deploy to Production

on:
  workflow_dispatch:  # ìˆ˜ë™ íŠ¸ë¦¬ê±°
    inputs:
      deployment_type:
        description: 'Deployment strategy'
        required: true
        type: choice
        options:
          - blue-green
          - canary
      
      canary_percentage:
        description: 'Canary traffic percentage (if canary selected)'
        required: false
        default: '10'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Login to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ghcr.io/${{ github.repository }}/agent-platform:${{ github.sha }}
            ghcr.io/${{ github.repository }}/agent-platform:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment: production  # ìŠ¹ì¸ í•„ìš”
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Configure kubectl
        uses: azure/k8s-set-context@v3
        with:
          kubeconfig: ${{ secrets.KUBE_CONFIG }}
      
      - name: Deploy with Blue-Green
        if: inputs.deployment_type == 'blue-green'
        run: |
          # ìƒˆ ë²„ì „ ë°°í¬ (green)
          kubectl apply -f k8s/deployment-green.yaml
          
          # Health check
          kubectl wait --for=condition=ready pod -l version=green --timeout=300s
          
          # íŠ¸ë˜í”½ ì „í™˜
          kubectl patch service agent-platform -p '{"spec":{"selector":{"version":"green"}}}'
          
          # ê¸°ì¡´ ë²„ì „ ì œê±° (blue)
          kubectl delete deployment agent-platform-blue
      
      - name: Deploy with Canary
        if: inputs.deployment_type == 'canary'
        run: |
          # Canary ë°°í¬
          kubectl apply -f k8s/deployment-canary.yaml
          
          # íŠ¸ë˜í”½ ë¹„ìœ¨ ì¡°ì •
          kubectl patch virtualservice agent-platform -p '{
            "spec": {
              "http": [{
                "match": [{"uri": {"prefix": "/"}}],
                "route": [
                  {"destination": {"host": "agent-platform-stable"}, "weight": '$((100 - ${{ inputs.canary_percentage }}))'},
                  {"destination": {"host": "agent-platform-canary"}, "weight": ${{ inputs.canary_percentage }}}
                ]
              }]
            }
          }'
          
          echo "Canary deployed with ${{ inputs.canary_percentage }}% traffic"
      
      - name: Notify Slack
        uses: slackapi/slack-github-action@v1
        with:
          webhook-url: ${{ secrets.SLACK_WEBHOOK }}
          payload: |
            {
              "text": "âœ… Production deployment successful",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Deployment*: ${{ inputs.deployment_type }}\n*Commit*: ${{ github.sha }}\n*Actor*: ${{ github.actor }}"
                  }
                }
              ]
            }
```

## Docker ì»¨í…Œì´ë„ˆí™”

### Dockerfile

```dockerfile
# Dockerfile
FROM python:3.11-slim as base

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY pyproject.toml poetry.lock ./
RUN pip install poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ
COPY core/ ./core/
COPY shared/ ./shared/
COPY agents/ ./agents/
COPY platform-api/ ./platform-api/
COPY config/ ./config/

# í™˜ê²½ ë³€ìˆ˜
ENV ENV=production
ENV PYTHONPATH=/app

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# ì‹¤í–‰
CMD ["uvicorn", "platform-api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### docker-compose.yml (ë¡œì»¬ ê°œë°œ)

```yaml
# docker-compose.yml
version: '3.8'

services:
  platform-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - ENV=development
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./core:/app/core
      - ./shared:/app/shared
      - ./agents:/app/agents
    depends_on:
      - vector-db
      - monitoring
  
  vector-db:
    image: chromadb/chroma:latest
    ports:
      - "8001:8000"
    volumes:
      - chroma-data:/chroma/chroma
  
  monitoring:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
  
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards

volumes:
  chroma-data:
  prometheus-data:
  grafana-data:
```

# ë°°í¬ ì „ëµ

## Blue-Green ë°°í¬

### ê°œë…

```
[Before]
Blue (í˜„ì¬ ë²„ì „)  â† íŠ¸ë˜í”½ 100%
Green (ìƒˆ ë²„ì „)   â† ëŒ€ê¸°

[After]
Blue (ì´ì „ ë²„ì „)  â† ëŒ€ê¸° (ë¡¤ë°±ìš©)
Green (ìƒˆ ë²„ì „)   â† íŠ¸ë˜í”½ 100%
```

### Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸

```yaml
# k8s/deployment-blue.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-platform-blue
  labels:
    app: agent-platform
    version: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: agent-platform
      version: blue
  template:
    metadata:
      labels:
        app: agent-platform
        version: blue
    spec:
      containers:
      - name: platform
        image: ghcr.io/org/agent-platform:stable
        ports:
        - containerPort: 8000
        env:
        - name: ENV
          value: "production"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/deployment-green.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-platform-green
  labels:
    app: agent-platform
    version: green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: agent-platform
      version: green
  template:
    metadata:
      labels:
        app: agent-platform
        version: green
    spec:
      containers:
      - name: platform
        image: ghcr.io/org/agent-platform:${{ github.sha }}  # ìƒˆ ë²„ì „
        ports:
        - containerPort: 8000
        env:
        - name: ENV
          value: "production"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: agent-platform
spec:
  selector:
    app: agent-platform
    version: blue  # íŠ¸ë˜í”½ ë¼ìš°íŒ… ëŒ€ìƒ (blue â†’ green ì „í™˜)
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer
```

### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/deploy-blue-green.sh

set -e

NAMESPACE="production"
IMAGE_TAG=$1

echo "ğŸš€ Starting Blue-Green deployment..."

# 1. Green ë°°í¬
echo "ğŸ“¦ Deploying Green version: $IMAGE_TAG"
kubectl set image deployment/agent-platform-green \
  platform=ghcr.io/org/agent-platform:$IMAGE_TAG \
  -n $NAMESPACE

# 2. Green ì¤€ë¹„ ëŒ€ê¸°
echo "â³ Waiting for Green to be ready..."
kubectl rollout status deployment/agent-platform-green -n $NAMESPACE

# 3. Green Health Check
echo "ğŸ¥ Running health checks on Green..."
GREEN_POD=$(kubectl get pod -n $NAMESPACE -l version=green -o jsonpath='{.items[0].metadata.name}')
kubectl exec -n $NAMESPACE $GREEN_POD -- curl -f http://localhost:8000/health

# 4. Smoke Test
echo "ğŸ§ª Running smoke tests..."
python scripts/smoke_test.py --target green

# 5. íŠ¸ë˜í”½ ì „í™˜ (Blue â†’ Green)
echo "ğŸ”„ Switching traffic from Blue to Green..."
kubectl patch service agent-platform -n $NAMESPACE \
  -p '{"spec":{"selector":{"version":"green"}}}'

echo "âœ… Traffic switched to Green"

# 6. ëª¨ë‹ˆí„°ë§ ëŒ€ê¸° (5ë¶„)
echo "ğŸ“Š Monitoring Green for 5 minutes..."
sleep 300

# 7. ì—ëŸ¬ìœ¨ í™•ì¸
ERROR_RATE=$(curl -s "http://prometheus:9090/api/v1/query?query=rate(http_requests_total{status=~'5..'}[5m])" | jq -r '.data.result[0].value[1]')

if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
  echo "âŒ High error rate detected: $ERROR_RATE"
  echo "ğŸ”™ Rolling back to Blue..."
  kubectl patch service agent-platform -n $NAMESPACE \
    -p '{"spec":{"selector":{"version":"blue"}}}'
  exit 1
fi

# 8. Blue ì œê±°
echo "ğŸ—‘ï¸ Removing old Blue deployment..."
kubectl delete deployment agent-platform-blue -n $NAMESPACE

echo "âœ… Blue-Green deployment completed successfully!"
```

## Canary ë°°í¬

### ê°œë…

```
[Phase 1: 10% Canary]
Stable (v1.0) â† 90% íŠ¸ë˜í”½
Canary (v1.1) â† 10% íŠ¸ë˜í”½

[Phase 2: 50% Canary]
Stable (v1.0) â† 50% íŠ¸ë˜í”½
Canary (v1.1) â† 50% íŠ¸ë˜í”½

[Phase 3: 100% Canary]
Stable (v1.0) â† ì œê±°
Canary (v1.1) â† 100% íŠ¸ë˜í”½ â†’ Stableë¡œ ìŠ¹ê²©
```

### Istio VirtualService

```yaml
# k8s/virtualservice-canary.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: agent-platform
spec:
  hosts:
  - agent-platform.example.com
  http:
  - match:
    - uri:
        prefix: /api/agents
    route:
    - destination:
        host: agent-platform-stable
        subset: v1
      weight: 90  # Stable ë²„ì „
    - destination:
        host: agent-platform-canary
        subset: v2
      weight: 10  # Canary ë²„ì „
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s

---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: agent-platform
spec:
  host: agent-platform
  subsets:
  - name: v1
    labels:
      version: stable
  - name: v2
    labels:
      version: canary
```

### ìë™ Canary ì§„í–‰ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/canary_rollout.py
import time
import requests
from typing import Dict, Any

class CanaryRollout:
    """ìë™ Canary ë°°í¬
    
    ë‹¨ê³„:
    1. 10% â†’ 5ë¶„ ëª¨ë‹ˆí„°ë§
    2. 25% â†’ 10ë¶„ ëª¨ë‹ˆí„°ë§
    3. 50% â†’ 15ë¶„ ëª¨ë‹ˆí„°ë§
    4. 100% â†’ Stableë¡œ ìŠ¹ê²©
    """
    
    STAGES = [
        {'percentage': 10, 'duration': 300},   # 5ë¶„
        {'percentage': 25, 'duration': 600},   # 10ë¶„
        {'percentage': 50, 'duration': 900},   # 15ë¶„
        {'percentage': 100, 'duration': 0}
    ]
    
    def __init__(
        self,
        prometheus_url: str,
        k8s_api: str,
        error_threshold: float = 0.01
    ):
        self.prometheus_url = prometheus_url
        self.k8s_api = k8s_api
        self.error_threshold = error_threshold
    
    def update_traffic_weight(self, canary_percentage: int):
        """íŠ¸ë˜í”½ ë¹„ìœ¨ ì—…ë°ì´íŠ¸"""
        stable_weight = 100 - canary_percentage
        
        # Istio VirtualService ì—…ë°ì´íŠ¸
        patch = {
            'spec': {
                'http': [{
                    'route': [
                        {'destination': {'subset': 'v1'}, 'weight': stable_weight},
                        {'destination': {'subset': 'v2'}, 'weight': canary_percentage}
                    ]
                }]
            }
        }
        
        response = requests.patch(
            f"{self.k8s_api}/virtualservices/agent-platform",
            json=patch
        )
        response.raise_for_status()
        
        print(f"âœ… Traffic updated: Stable {stable_weight}%, Canary {canary_percentage}%")
    
    def get_error_rate(self, version: str) -> float:
        """ì—ëŸ¬ìœ¨ ì¡°íšŒ"""
        query = f'rate(http_requests_total{{version="{version}",status=~"5.."}}[5m])'
        
        response = requests.get(
            f"{self.prometheus_url}/api/v1/query",
            params={'query': query}
        )
        
        data = response.json()
        if data['data']['result']:
            return float(data['data']['result'][0]['value'][1])
        return 0.0
    
    def get_latency_p95(self, version: str) -> float:
        """P95 ë ˆì´í„´ì‹œ ì¡°íšŒ"""
        query = f'histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{{version="{version}"}}[5m]))'
        
        response = requests.get(
            f"{self.prometheus_url}/api/v1/query",
            params={'query': query}
        )
        
        data = response.json()
        if data['data']['result']:
            return float(data['data']['result'][0]['value'][1])
        return 0.0
    
    def check_health(self, version: str) -> Dict[str, Any]:
        """Canary ìƒíƒœ í™•ì¸"""
        error_rate = self.get_error_rate(version)
        latency_p95 = self.get_latency_p95(version)
        
        stable_error_rate = self.get_error_rate('stable')
        stable_latency = self.get_latency_p95('stable')
        
        health = {
            'error_rate': error_rate,
            'latency_p95': latency_p95,
            'error_rate_delta': error_rate - stable_error_rate,
            'latency_delta': latency_p95 - stable_latency,
            'healthy': True
        }
        
        # Health check ì¡°ê±´
        if error_rate > self.error_threshold:
            health['healthy'] = False
            health['reason'] = f"High error rate: {error_rate:.4f}"
        
        if latency_p95 > stable_latency * 1.5:
            health['healthy'] = False
            health['reason'] = f"High latency: {latency_p95:.2f}s"
        
        return health
    
    def rollout(self):
        """Canary ë°°í¬ ì‹¤í–‰"""
        print("ğŸš€ Starting Canary rollout...")
        
        for stage in self.STAGES:
            percentage = stage['percentage']
            duration = stage['duration']
            
            print(f"\nğŸ“Š Stage: {percentage}% traffic to Canary")
            
            # íŠ¸ë˜í”½ ë¹„ìœ¨ ì—…ë°ì´íŠ¸
            self.update_traffic_weight(percentage)
            
            if duration > 0:
                print(f"â³ Monitoring for {duration}s...")
                
                # 1ë¶„ë§ˆë‹¤ Health check
                for i in range(duration // 60):
                    time.sleep(60)
                    
                    health = self.check_health('canary')
                    print(f"   [{i+1}/{duration//60}] Error: {health['error_rate']:.4f}, "
                          f"Latency: {health['latency_p95']:.2f}s")
                    
                    if not health['healthy']:
                        print(f"âŒ Canary unhealthy: {health['reason']}")
                        print("ğŸ”™ Rolling back...")
                        self.rollback()
                        return False
        
        print("\nâœ… Canary rollout completed successfully!")
        return True
    
    def rollback(self):
        """ë¡¤ë°± (Stable 100%)"""
        self.update_traffic_weight(0)
        print("âœ… Rolled back to Stable version")

if __name__ == "__main__":
    rollout = CanaryRollout(
        prometheus_url="http://prometheus:9090",
        k8s_api="http://kubernetes/api/v1",
        error_threshold=0.01
    )
    
    success = rollout.rollout()
    exit(0 if success else 1)
```

# ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

## Prometheus ë©”íŠ¸ë¦­

### ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°

```python
# shared/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
from functools import wraps
import time

# ë©”íŠ¸ë¦­ ì •ì˜
agent_requests_total = Counter(
    'agent_requests_total',
    'Total number of agent requests',
    ['agent_name', 'status']
)

agent_duration_seconds = Histogram(
    'agent_duration_seconds',
    'Agent execution duration in seconds',
    ['agent_name'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0]
)

agent_confidence = Histogram(
    'agent_confidence',
    'Agent confidence score',
    ['agent_name'],
    buckets=[0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 1.0]
)

llm_tokens_total = Counter(
    'llm_tokens_total',
    'Total LLM tokens used',
    ['agent_name', 'provider', 'model']
)

llm_cost_total = Counter(
    'llm_cost_total',
    'Total LLM cost in USD',
    ['agent_name', 'provider']
)

active_agents = Gauge(
    'active_agents',
    'Number of currently active agents',
    ['agent_name']
)

class MetricsCollector:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    
    @staticmethod
    def track_agent_execution(agent_name: str):
        """Agent ì‹¤í–‰ ì¶”ì  ë°ì½”ë ˆì´í„°"""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # í™œì„± Agent ì¦ê°€
                active_agents.labels(agent_name=agent_name).inc()
                
                start = time.time()
                status = 'success'
                
                try:
                    result = func(*args, **kwargs)
                    
                    # ì‹ ë¢°ë„ ê¸°ë¡
                    confidence = result.get('confidence', 0.0)
                    agent_confidence.labels(agent_name=agent_name).observe(confidence)
                    
                    return result
                    
                except Exception as e:
                    status = 'failure'
                    raise
                
                finally:
                    # ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
                    duration = time.time() - start
                    agent_duration_seconds.labels(agent_name=agent_name).observe(duration)
                    
                    # ìš”ì²­ ìˆ˜ ê¸°ë¡
                    agent_requests_total.labels(
                        agent_name=agent_name,
                        status=status
                    ).inc()
                    
                    # í™œì„± Agent ê°ì†Œ
                    active_agents.labels(agent_name=agent_name).dec()
            
            return wrapper
        return decorator
    
    @staticmethod
    def track_llm_usage(agent_name: str, provider: str, model: str, tokens: int, cost: float):
        """LLM ì‚¬ìš©ëŸ‰ ê¸°ë¡"""
        llm_tokens_total.labels(
            agent_name=agent_name,
            provider=provider,
            model=model
        ).inc(tokens)
        
        llm_cost_total.labels(
            agent_name=agent_name,
            provider=provider
        ).inc(cost)

# BaseAgentì— í†µí•©
class BaseAgent(ABC):
    def execute(self, input: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ìë™ ìˆ˜ì§‘"""
        
        @MetricsCollector.track_agent_execution(self.metadata.name)
        def _execute_with_metrics():
            # ê¸°ì¡´ ë¡œì§
            result = self.process(input)
            
            # LLM ì‚¬ìš©ëŸ‰ ê¸°ë¡
            if hasattr(self, 'llm'):
                stats = self.llm.get_stats()
                MetricsCollector.track_llm_usage(
                    agent_name=self.metadata.name,
                    provider=self.llm.provider,
                    model=self.llm.model,
                    tokens=stats['total_tokens'],
                    cost=stats['total_cost']
                )
            
            return result
        
        return _execute_with_metrics()

# ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘
def start_metrics_server(port: int = 9090):
    """Prometheus ë©”íŠ¸ë¦­ ì„œë²„ ì‹œì‘"""
    start_http_server(port)
    print(f"ğŸ“Š Metrics server started on port {port}")
```

### Prometheus ì„¤ì •

```yaml
# config/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'agent-platform'
    static_configs:
      - targets: ['platform-api:9090']
    
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        target_label: __address__
        regex: (.+):(?:\d+);(\d+)
        replacement: ${1}:${2}

# ì•Œë¦¼ ê·œì¹™
rule_files:
  - '/etc/prometheus/rules/*.yml'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']
```

### ì•Œë¦¼ ê·œì¹™

```yaml
# config/prometheus/rules/agent-alerts.yml
groups:
  - name: agent-alerts
    interval: 30s
    rules:
      # ì—ëŸ¬ìœ¨ ë†’ìŒ
      - alert: HighAgentErrorRate
        expr: |
          rate(agent_requests_total{status="failure"}[5m])
          / rate(agent_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate for agent {{ $labels.agent_name }}"
          description: "Error rate is {{ $value | humanizePercentage }}"
      
      # ë ˆì´í„´ì‹œ ë†’ìŒ
      - alert: HighAgentLatency
        expr: |
          histogram_quantile(0.95,
            rate(agent_duration_seconds_bucket[5m])
          ) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency for agent {{ $labels.agent_name }}"
          description: "P95 latency is {{ $value }}s"
      
      # LLM ë¹„ìš© ì´ˆê³¼
      - alert: HighLLMCost
        expr: |
          increase(llm_cost_total[1h]) > 100
        labels:
          severity: critical
        annotations:
          summary: "High LLM cost"
          description: "Cost in last hour: ${{ $value }}"
      
      # Agent ë‹¤ìš´
      - alert: AgentDown
        expr: |
          up{job="agent-platform"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Agent platform is down"
          description: "Instance {{ $labels.instance }} is down"
```

## Grafana ëŒ€ì‹œë³´ë“œ

### ëŒ€ì‹œë³´ë“œ JSON

```json
// config/grafana/dashboards/agent-platform.json
{
  "dashboard": {
    "title": "AI Agent Platform Overview",
    "panels": [
      {
        "title": "Agent Request Rate",
        "targets": [{
          "expr": "sum(rate(agent_requests_total[5m])) by (agent_name)"
        }],
        "type": "graph"
      },
      {
        "title": "Agent Error Rate",
        "targets": [{
          "expr": "sum(rate(agent_requests_total{status='failure'}[5m])) by (agent_name) / sum(rate(agent_requests_total[5m])) by (agent_name)"
        }],
        "type": "graph",
        "alert": {
          "conditions": [{
            "evaluator": {"type": "gt", "params": [0.05]}
          }]
        }
      },
      {
        "title": "Agent Latency (P95)",
        "targets": [{
          "expr": "histogram_quantile(0.95, sum(rate(agent_duration_seconds_bucket[5m])) by (agent_name, le))"
        }],
        "type": "graph"
      },
      {
        "title": "LLM Cost (Hourly)",
        "targets": [{
          "expr": "sum(increase(llm_cost_total[1h])) by (agent_name)"
        }],
        "type": "graph"
      },
      {
        "title": "Agent Confidence Distribution",
        "targets": [{
          "expr": "sum(rate(agent_confidence_bucket[5m])) by (agent_name, le)"
        }],
        "type": "heatmap"
      }
    ]
  }
}
```

# ë¡œê¹… ì „ëµ

## êµ¬ì¡°í™”ëœ ë¡œê¹…

```python
# shared/logging/structured_logger.py
import logging
import json
from datetime import datetime
from typing import Dict, Any, Optional
from pythonjsonlogger import jsonlogger

class StructuredLogger:
    """êµ¬ì¡°í™”ëœ ë¡œê¹…
    
    ëª¨ë“  ë¡œê·¸ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
    {
        "timestamp": "2026-02-02T10:30:00Z",
        "level": "INFO",
        "logger": "agent.data_standardization",
        "message": "Agent executed successfully",
        "agent_name": "data_standardization",
        "duration_ms": 1250,
        "confidence": 0.95,
        "trace_id": "abc123"
    }
    """
    
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # JSON formatter
        handler = logging.StreamHandler()
        formatter = jsonlogger.JsonFormatter(
            fmt='%(timestamp)s %(level)s %(name)s %(message)s',
            rename_fields={'levelname': 'level', 'name': 'logger'}
        )
        handler.setFormatter(formatter)
        
        self.logger.addHandler(handler)
    
    def log(
        self,
        level: str,
        message: str,
        extra: Optional[Dict[str, Any]] = None
    ):
        """ë¡œê·¸ ê¸°ë¡"""
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'message': message
        }
        
        if extra:
            log_data.update(extra)
        
        getattr(self.logger, level.lower())(message, extra=log_data)
    
    def log_agent_execution(
        self,
        agent_name: str,
        status: str,
        duration_ms: float,
        confidence: float,
        trace_id: str
    ):
        """Agent ì‹¤í–‰ ë¡œê·¸"""
        self.log('info', f"Agent {agent_name} executed", extra={
            'agent_name': agent_name,
            'status': status,
            'duration_ms': duration_ms,
            'confidence': confidence,
            'trace_id': trace_id,
            'event_type': 'agent_execution'
        })
    
    def log_error(
        self,
        agent_name: str,
        error: str,
        trace_id: str
    ):
        """ì—ëŸ¬ ë¡œê·¸"""
        self.log('error', f"Agent {agent_name} failed", extra={
            'agent_name': agent_name,
            'error': error,
            'trace_id': trace_id,
            'event_type': 'agent_error'
        })

# BaseAgentì— í†µí•©
class BaseAgent(ABC):
    def __init__(self, metadata: AgentMetadata):
        self.metadata = metadata
        self.logger = StructuredLogger(f"agent.{metadata.name}")
    
    def execute(self, input: Dict[str, Any]) -> Dict[str, Any]:
        import uuid
        trace_id = str(uuid.uuid4())
        
        self.logger.log('info', f"Starting execution", extra={
            'agent_name': self.metadata.name,
            'trace_id': trace_id,
            'input_task': input.get('task')
        })
        
        try:
            result = self.process(input)
            
            self.logger.log_agent_execution(
                agent_name=self.metadata.name,
                status='success',
                duration_ms=result['metadata']['execution']['duration_ms'],
                confidence=result['confidence'],
                trace_id=trace_id
            )
            
            return result
            
        except Exception as e:
            self.logger.log_error(
                agent_name=self.metadata.name,
                error=str(e),
                trace_id=trace_id
            )
            raise
```

## ELK Stack í†µí•©

### Filebeat ì„¤ì •

```yaml
# config/filebeat.yml
filebeat.inputs:
  - type: container
    paths:
      - '/var/lib/docker/containers/*/*.log'
    processors:
      - add_kubernetes_metadata:
          in_cluster: true

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "agent-platform-%{+yyyy.MM.dd}"

setup.template.name: "agent-platform"
setup.template.pattern: "agent-platform-*"
```

### Elasticsearch ì¿¼ë¦¬

```python
# shared/logging/log_analyzer.py
from elasticsearch import Elasticsearch
from typing import List, Dict, Any
from datetime import datetime, timedelta

class LogAnalyzer:
    """ë¡œê·¸ ë¶„ì„"""
    
    def __init__(self, es_host: str = "elasticsearch:9200"):
        self.es = Elasticsearch([es_host])
    
    def get_agent_errors(
        self,
        agent_name: str,
        hours: int = 24
    ) -> List[Dict[str, Any]]:
        """Agent ì—ëŸ¬ ì¡°íšŒ"""
        query = {
            "query": {
                "bool": {
                    "must": [
                        {"match": {"agent_name": agent_name}},
                        {"match": {"level": "ERROR"}},
                        {"range": {
                            "timestamp": {
                                "gte": f"now-{hours}h"
                            }
                        }}
                    ]
                }
            },
            "sort": [{"timestamp": "desc"}],
            "size": 100
        }
        
        result = self.es.search(index="agent-platform-*", body=query)
        return [hit['_source'] for hit in result['hits']['hits']]
    
    def get_slow_executions(
        self,
        threshold_ms: float = 5000,
        hours: int = 24
    ) -> List[Dict[str, Any]]:
        """ëŠë¦° ì‹¤í–‰ ì¡°íšŒ"""
        query = {
            "query": {
                "bool": {
                    "must": [
                        {"match": {"event_type": "agent_execution"}},
                        {"range": {"duration_ms": {"gte": threshold_ms}}},
                        {"range": {"timestamp": {"gte": f"now-{hours}h"}}}
                    ]
                }
            },
            "sort": [{"duration_ms": "desc"}],
            "size": 50
        }
        
        result = self.es.search(index="agent-platform-*", body=query)
        return [hit['_source'] for hit in result['hits']['hits']]
    
    def trace_execution(self, trace_id: str) -> List[Dict[str, Any]]:
        """Trace IDë¡œ ì „ì²´ ì‹¤í–‰ ì¶”ì """
        query = {
            "query": {
                "match": {"trace_id": trace_id}
            },
            "sort": [{"timestamp": "asc"}]
        }
        
        result = self.es.search(index="agent-platform-*", body=query)
        return [hit['_source'] for hit in result['hits']['hits']]
```

# ë³´ì•ˆ ê´€ë¦¬

## API í‚¤ ê´€ë¦¬

### Kubernetes Secrets

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: agent-platform-secrets
type: Opaque
data:
  openai-api-key: <base64-encoded>
  anthropic-api-key: <base64-encoded>
  database-password: <base64-encoded>

---
# Deploymentì—ì„œ ì‚¬ìš©
apiVersion: apps/v1
kind: Deployment
metadata:
  name: agent-platform
spec:
  template:
    spec:
      containers:
      - name: platform
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: agent-platform-secrets
              key: openai-api-key
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: agent-platform-secrets
              key: anthropic-api-key
```

### Secrets ë¡œí…Œì´ì…˜

```python
# scripts/rotate_secrets.py
import boto3
import kubernetes
from datetime import datetime

class SecretsRotator:
    """API í‚¤ ìë™ ë¡œí…Œì´ì…˜"""
    
    def __init__(self):
        self.k8s = kubernetes.client.CoreV1Api()
        self.secrets_manager = boto3.client('secretsmanager')
    
    def rotate_openai_key(self):
        """OpenAI API í‚¤ ë¡œí…Œì´ì…˜"""
        # 1. ìƒˆ í‚¤ ìƒì„± (OpenAI ëŒ€ì‹œë³´ë“œì—ì„œ)
        new_key = self._generate_new_openai_key()
        
        # 2. Kubernetes Secret ì—…ë°ì´íŠ¸
        self.k8s.patch_namespaced_secret(
            name="agent-platform-secrets",
            namespace="production",
            body={
                "data": {
                    "openai-api-key": self._base64_encode(new_key)
                }
            }
        )
        
        # 3. Pod ì¬ì‹œì‘ (ìƒˆ í‚¤ ì ìš©)
        self.k8s.delete_collection_namespaced_pod(
            namespace="production",
            label_selector="app=agent-platform"
        )
        
        # 4. ì´ì „ í‚¤ ë¹„í™œì„±í™” (24ì‹œê°„ í›„)
        self._schedule_key_revocation(old_key, delay_hours=24)
        
        print(f"âœ… OpenAI API key rotated at {datetime.utcnow()}")
```

## ì¸ì¦ ë° ê¶Œí•œ

### FastAPI JWT ì¸ì¦

```python
# platform-api/middleware/auth.py
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import jwt
from datetime import datetime, timedelta

security = HTTPBearer()

SECRET_KEY = "your-secret-key"
ALGORITHM = "HS256"

def create_access_token(data: dict, expires_delta: timedelta = timedelta(hours=24)):
    """JWT í† í° ìƒì„±"""
    to_encode = data.copy()
    expire = datetime.utcnow() + expires_delta
    to_encode.update({"exp": expire})
    
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """JWT í† í° ê²€ì¦"""
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        username = payload.get("sub")
        
        if username is None:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid authentication credentials"
            )
        
        return username
        
    except jwt.ExpiredSignatureError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Token has expired"
        )
    except jwt.JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials"
        )

# API ì—”ë“œí¬ì¸íŠ¸ì— ì ìš©
from fastapi import FastAPI

app = FastAPI()

@app.post("/api/agents/{agent_name}/execute")
def execute_agent(
    agent_name: str,
    input_data: Dict,
    username: str = Depends(verify_token)  # ì¸ì¦ í•„ìˆ˜
):
    """Agent ì‹¤í–‰ (ì¸ì¦ í•„ìš”)"""
    orchestrator = AgentOrchestrator()
    result = orchestrator.run(agent_name, input_data)
    
    # ê°ì‚¬ ë¡œê·¸
    logger.info(f"User {username} executed agent {agent_name}")
    
    return result
```

### Rate Limiting

```python
# platform-api/middleware/rate_limit.py
from fastapi import Request, HTTPException
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/agents/{agent_name}/execute")
@limiter.limit("100/hour")  # ì‹œê°„ë‹¹ 100íšŒ ì œí•œ
def execute_agent(request: Request, agent_name: str, input_data: Dict):
    """Rate limiting ì ìš©"""
    orchestrator = AgentOrchestrator()
    return orchestrator.run(agent_name, input_data)
```

# í•µì‹¬ ì„¤ê³„ ê²°ì • ìš”ì•½

## CI/CD

1. **ë³€ê²½ ê°ì§€**: core/shared ë³€ê²½ ì‹œ ì „ì²´ í…ŒìŠ¤íŠ¸, agents/ ë³€ê²½ ì‹œ í•´ë‹¹ Agentë§Œ
2. **ìë™ ë°°í¬**: ê°œë°œ í™˜ê²½ì€ ìë™, í”„ë¡œë•ì…˜ì€ ìˆ˜ë™ ìŠ¹ì¸
3. **ì»¨í…Œì´ë„ˆí™”**: Dockerë¡œ ì¼ê´€ëœ í™˜ê²½
4. **Kubernetes**: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë° ìŠ¤ì¼€ì¼ë§

## ë°°í¬ ì „ëµ

1. **Blue-Green**: ë¹ ë¥¸ ì „í™˜, ì‰¬ìš´ ë¡¤ë°±
2. **Canary**: ì ì§„ì  ë°°í¬ (10% â†’ 25% â†’ 50% â†’ 100%)
3. **ìë™ ë¡¤ë°±**: ì—ëŸ¬ìœ¨/ë ˆì´í„´ì‹œ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ

## ëª¨ë‹ˆí„°ë§

1. **Prometheus**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ìš”ì²­ë¥ , ë ˆì´í„´ì‹œ, ë¹„ìš©)
2. **Grafana**: ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
3. **ì•Œë¦¼**: Slack/Email í†µí•©
4. **ìë™ ë©”íŠ¸ë¦­**: BaseAgentê°€ ìë™ ìˆ˜ì§‘

## ë¡œê¹…

1. **êµ¬ì¡°í™” ë¡œê¹…**: JSON í˜•ì‹
2. **Trace ID**: ì „ì²´ ì‹¤í–‰ ì¶”ì 
3. **ELK Stack**: ë¡œê·¸ ìˆ˜ì§‘, ê²€ìƒ‰, ë¶„ì„
4. **ë¡œê·¸ ë ˆë²¨**: INFO (í”„ë¡œë•ì…˜), DEBUG (ê°œë°œ)

## ë³´ì•ˆ

1. **Kubernetes Secrets**: API í‚¤ ì €ì¥
2. **JWT ì¸ì¦**: API ì ‘ê·¼ ì œì–´
3. **Rate Limiting**: ë‚¨ìš© ë°©ì§€
4. **Secrets ë¡œí…Œì´ì…˜**: ì£¼ê¸°ì  í‚¤ ê°±ì‹ 

## ì‹œë¦¬ì¦ˆ ì™„ë£Œ

ì´ ê¸€ë¡œ **AI Agent í”Œë«í¼ ì•„í‚¤í…ì²˜ ì‹œë¦¬ì¦ˆ**ë¥¼ ë§ˆë¬´ë¦¬í•œë‹¤:

1. **ê´€ì  ì„ íƒ**: Platform Engineering + Software Architecture
2. **ì„¤ê³„ ì›ì¹™**: 5ëŒ€ ì›ì¹™ + Phase 1-4 ì „ëµ
3. **ì €ì¥ì†Œ ì „ëµ**: Monorepo + ëª¨ë“ˆ ë¶„ë¦¬
4. **ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„**: BaseAgent + Template Method Pattern
5. **ë°ì´í„° í‘œì¤€í™”**: í”„ë¡¬í”„íŠ¸/ë²¡í„°/ë©”íƒ€ë°ì´í„° ê´€ë¦¬
6. **ìš´ì˜ ìë™í™”**: CI/CD + ëª¨ë‹ˆí„°ë§ + ë°°í¬ + ë³´ì•ˆ

## ì°¸ê³ ë¬¸í—Œ

**DevOps**:
- Kim, G., et al. (2016). "The DevOps Handbook." IT Revolution Press.
- Humble, J., & Farley, D. (2010). "Continuous Delivery." Addison-Wesley.
- Forsgren, N., et al. (2018). "Accelerate: The Science of Lean Software and DevOps." IT Revolution Press.

**Kubernetes**:
- Burns, B., et al. (2019). "Kubernetes: Up and Running." O'Reilly.
- Kubernetes Documentation. https://kubernetes.io/docs/

**Monitoring**:
- Beyer, B., et al. (2016). "Site Reliability Engineering." O'Reilly.
- Prometheus Documentation. https://prometheus.io/docs/
- Grafana Documentation. https://grafana.com/docs/

**Security**:
- OWASP Top 10. https://owasp.org/www-project-top-ten/
- Kubernetes Security Best Practices. https://kubernetes.io/docs/concepts/security/
