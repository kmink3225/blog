{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Hugging Face: PLM 생태계의 중심\"\n",
        "subtitle: \"실무에서 바로 사용할 수 있는 사전 학습 모델의 허브\"\n",
        "description: |\n",
        "  Hugging Face는 현재 NLP 분야에서 가장 중요한 라이브러리이자 플랫폼이다. 수만 개의 사전 학습 모델을 제공하며, 몇 줄의 코드만으로 최신 PLM을 활용할 수 있게 해준다. 토크나이저부터 파인튜닝, 배포까지 전체 ML 워크플로우를 지원하는 Hugging Face의 핵심 기능들과 실무 활용 전략을 상세히 분석한다.\n",
        "categories:\n",
        "  - NLP\n",
        "  - Deep Learning\n",
        "author: Kwangmin Kim\n",
        "date: 2025-01-27\n",
        "format: \n",
        "  html:\n",
        "    page-layout: full\n",
        "    code-fold: true\n",
        "    toc: true\n",
        "    number-sections: true\n",
        "draft: False\n",
        "---"
      ],
      "id": "511ceeba"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 한국어 금융 뉴스 긍정, 부정 분류\n",
        "\n",
        "dataset: [https://github.com/ukairia777/finance_sentiment_corpus](https://github.com/ukairia777/finance_sentiment_corpus)\n"
      ],
      "id": "229c89e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "\n",
        "# 데이터 다운로드\n",
        "\n",
        "!wget https://raw.githubusercontent.com/ukairia777/finance_sentiment_corpus/main/finance_data.csv"
      ],
      "id": "52e7168a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('finance_data.csv')\n",
        "print('샘플의 개수 :', len(df)) # 샘플의 개수 : 4846\n",
        "\n",
        "df.head()\n",
        "df['labels'] = df['labels'].replace(['neutral', 'positive', 'negative'],[0, 1, 2])\n",
        "df.head()\n",
        "\n",
        "df.to_csv('finance_data.csv', index=False, encoding='utf-8-sig') # 값을 변경한 데이터프레임을 다시 csv로 저장합니다.\n",
        "\n",
        "# csv 파일로부터 datasets을 로드할 수 있습니다.\n",
        "from datasets import load_dataset\n",
        "\n",
        "all_data = load_dataset(\n",
        "        \"csv\",\n",
        "        data_files={\n",
        "            \"train\": \"finance_data.csv\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "#현재 train에 모든 데이터가 저장되어져 있습니다.\n",
        "all_data\n",
        "\n",
        "#DatasetDict({\n",
        "#    train: Dataset({\n",
        "#        features: ['labels', 'sentence', 'kor_sentence'],\n",
        "#        num_rows: 4846\n",
        "#    })\n",
        "#})"
      ],
      "id": "efffc904",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이를 dataset의 train_test_split() 기능을 사용하여 8:2 비율로 분리하고 훈련 데이터와 테스트 데이터로 저장합니다.\n"
      ],
      "id": "5d276d8c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cs = all_data['train'].train_test_split(0.2)\n",
        "train_cs = cs[\"train\"]\n",
        "test_cs = cs[\"test\"]\n",
        "\n",
        "print(train_cs)\n",
        "print(test_cs)"
      ],
      "id": "de1b4d76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "검증 데이터를 위해 훈련 데이터를 다시 8:2로 훈련 데이터와 검증 데이터로 저장합니다.\n"
      ],
      "id": "4e906aa5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 훈련 데이터를 다시 8:2로 분리 후 훈련 데이터와 검증 데이터로 저장\n",
        "cs = train_cs.train_test_split(0.2)\n",
        "train_cs = cs[\"train\"]\n",
        "valid_cs = cs[\"test\"]"
      ],
      "id": "d9c2a5c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "데이터셋의 구조는 다음과 같습니다. 훈련 데이터, 검증 데이터, 테스트 데이터로 구성되며 우리가 사용할 열은 kor_text열과 labels열입니다.\n"
      ],
      "id": "b05bf277"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(train_cs)\n",
        "print(valid_cs)\n",
        "print(test_cs)\n",
        "\n",
        "print('두번째 샘플 출력 :', train_cs['kor_sentence'][1])\n",
        "print('두번째 샘플의 레이블 출력 :', train_cs['labels'][1])"
      ],
      "id": "ac0868d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터셋 전처리\n"
      ],
      "id": "776d11d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import csv\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# BERT 사용을 위함\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# for padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "\n",
        "# 전처리 및 평가 지표\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, hamming_loss"
      ],
      "id": "98b2641d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 [CLS] 문장 [SEP] 구조를 만듭니다. [CLS]는 분류를 하기 위해 BERT가 사용하는 첫번째 입력 토큰이며, [SEP]는 입력 문장의 종료를 나타내기 위해 사용하는 스페셜 토큰입니다.\n"
      ],
      "id": "9b6ebcbf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 `[CLS] 문장 [SEP]` 구조를 만듭니다.\n",
        "\n",
        "train_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', train_cs['kor_sentence']))\n",
        "validation_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', valid_cs['kor_sentence']))\n",
        "test_sentences = list(map(lambda x: '[CLS] ' + str(x) + ' [SEP]', test_cs['kor_sentence']))\n",
        "\n",
        "train_labels = train_cs['labels']\n",
        "validation_labels = valid_cs['labels']\n",
        "test_labels = test_cs['labels']\n",
        "\n",
        "test_sentences[:5]"
      ],
      "id": "d562a3b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "['[CLS] 덴마크 로열유니브루가 소유한 칼나필리오타우로그루페(칼나필리스타우라스그룹)는 7개월 동안 맥주 판매량이 14.5% 급증한 4050만ℓ를 기록하며 시장점유율을 23.74%에서 25.18%로 끌어올렸다. [SEP]',\n",
        " '[CLS] 순이자 수입은 152.2 mn으로 2008년 101.0 mn에서 증가하였다. [SEP]',\n",
        " '[CLS] 인도된 충전기 수가 6590만대로 41% 증가하면서 순매출액은 전년 대비 25.5% 증가한 59.6m를 기록했다. [SEP]',\n",
        " '[CLS] 뉴스, 의견 또는 배포에 대한 보상 없음. [SEP]',\n",
        " '[CLS] 국내 및 지역에서의 강력한 브랜드 가시성은 가정 판매, 차량 및 소비자 광고에서 가장 중요합니다. [SEP]']\n",
        "\n",
        "\n",
        " 중립 = 0\n",
        "긍정 = 1\n",
        "부정 = 2\n"
      ],
      "id": "82ddba5d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "test_labels[:5]"
      ],
      "id": "f1e5240c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1, 1, 1, 0, 0]\n",
        "\n",
        "\n",
        "## BERT 토크나이저를 이용한 전처리\n",
        "\n",
        "BERT를 사용하기 위해서는 토크나이저와 모델이 반드시 맵핑 관계여야만 합니다. 다시 말해 아래의 이름에 들어가는 모델이름은 반드시 동일해야 합니다.\n",
        "\n",
        "`BertTokenizer.from_pretrained('모델이름')`\n",
        "`BertForSequenceClassification.from_pretrained(\"모델이름\")`\n",
        "\n",
        "토크나이저는 내부적으로 Vocabulary를 갖고 있어 정수 인코딩을 수행해주는 모듈입니다.\n"
      ],
      "id": "6b13543a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 한국어 BERT 중 하나인 'klue/bert-base'를 사용.\n",
        "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "def data_to_tensor (sentences, labels):\n",
        "  # 정수 인코딩 과정. 각 텍스트를 토큰화한 후에 Vocabulary에 맵핑되는 정수 시퀀스로 변환한다.\n",
        "  # ex) ['안녕하세요'] ==> ['안', '녕', '하세요'] ==> [231, 52, 45]\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "  # pad_sequences는 패딩을 위한 모듈. 주어진 최대 길이를 위해서 뒤에서 0으로 채워준다.\n",
        "  # ex) [231, 52, 45] ==> [231, 52, 45, 0, 0, 0]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\") \n",
        "\n",
        "  attention_masks = []\n",
        "\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i > 0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  tensor_inputs = torch.tensor(input_ids)\n",
        "  tensor_labels = torch.tensor(labels)\n",
        "  tensor_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return tensor_inputs, tensor_labels, tensor_masks"
      ],
      "id": "d22cf96b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "훈련 데이터, 검증 데이터, 텍스트 데이터에 대해서 data_to_tensor 함수를 통해서 정수 인코딩 된 데이터, 레이블, 어텐션 마스크를 얻습니다.\n"
      ],
      "id": "9b59cbfa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_inputs, train_labels, train_masks = data_to_tensor(train_sentences, train_labels)\n",
        "validation_inputs, validation_labels, validation_masks = data_to_tensor(validation_sentences, validation_labels)\n",
        "test_inputs, test_labels, test_masks = data_to_tensor(test_sentences, test_labels)\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_masks[0])\n",
        "\n",
        "tokenizer.decode([2]) # [CLS]\n",
        "tokenizer.decode([3]) # [SEP]"
      ],
      "id": "993e2f4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "배치 크기는 32로 하고 파이토치의 데이터로더(배치 단위로 데이터를 꺼내올 수 있도록 하는 모듈)로 변환합니다.\n"
      ],
      "id": "3515f815"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "print('훈련 데이터의 크기:', len(train_labels))\n",
        "print('검증 데이터의 크기:', len(validation_labels))\n",
        "print('테스트 데이터의 크기:', len(test_labels))"
      ],
      "id": "c8bc1c55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPU가 정상 셋팅되었는지 확인.  \n",
        "Colab에서 GPU를 사용하기 위해서는 아래와 같이 설정이 되어있어야만 합니다.  \n",
        "\n",
        "* 런타임 > 런타임 유형 변경 > 하드웨어 가속기 > 'GPU' 선택\n"
      ],
      "id": "01586027"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "id": "d063c3c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 로드\n",
        "\n",
        "BERT를 사용하여 텍스트를 분류하는 BERT 아키텍처는 BertForSequenceClassification.from_pretrained(\"모델이름\")을 넣어서 가능합니다. 레이블 수로 num_labels라는 인자값에 레이블의 수를 기재해줍니다.\n"
      ],
      "id": "66c61fa4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_labels = 3\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels)\n",
        "model.cuda()\n",
        "\n",
        "# 옵티마이저 선택\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "\n",
        "# 몇 번의 에포크(전체 데이터에 대한 학습 횟수)를 할 것인지 선택\n",
        "epochs = 2\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))  # hh:mm:ss\n",
        "\n",
        "def metrics(predictions, labels):\n",
        "    y_pred = predictions\n",
        "    y_true = labels\n",
        "\n",
        "    # 사용 가능한 메트릭들을 사용한다.\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1_macro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "    f1_weighted_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    # 메트릭 결과에 대해서 리턴\n",
        "    metrics = {'accuracy': accuracy,\n",
        "               'f1_macro': f1_macro_average,\n",
        "               'f1_micro': f1_micro_average,\n",
        "               'f1_weighted': f1_weighted_average}\n",
        "\n",
        "    return metrics"
      ],
      "id": "7475d591",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 학습\n"
      ],
      "id": "25148ea6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 랜덤 시드값.\n",
        "seed_val = 777\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "for epoch_i in range(0, epochs):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # gradient clipping if it is over a threshold\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "id": "2e7fe1bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 검증 데이터에 대한 평가\n"
      ],
      "id": "c9d93307"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    for b in logits:\n",
        "        # 3개의 값 중 가장 큰 값을 예측한 인덱스로 결정\n",
        "        # ex) [ 3.5134246  -0.30875662 -2.111316  ] ==> 0\n",
        "        accum_logits.append(np.argmax(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(b)\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))"
      ],
      "id": "e95545d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델 저장과 로드\n"
      ],
      "id": "0c268741"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pwd\n",
        "# 폴더 생성\n",
        "%mkdir model\n",
        "\n",
        "path = '/content/model/'\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), path+\"BERT_news_positive_negative_model.pt\")\n",
        "\n",
        "# 모델 로드\n",
        "model.load_state_dict(torch.load(path+\"BERT_news_positive_negative_model.pt\"))"
      ],
      "id": "f44bac51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 테스트 데이터에 대한 평가\n"
      ],
      "id": "141ddbed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "accum_logits, accum_label_ids = [], []\n",
        "\n",
        "for step, batch in tqdm(enumerate(test_dataloader)):\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    for b in logits:\n",
        "        # 3개의 값 중 가장 큰 값을 예측한 인덱스로 결정\n",
        "        # ex) [ 3.5134246  -0.30875662 -2.111316  ] ==> 0\n",
        "        accum_logits.append(np.argmax(b))\n",
        "\n",
        "    for b in label_ids:\n",
        "        accum_label_ids.append(b)\n",
        "\n",
        "accum_logits = np.array(accum_logits)\n",
        "accum_label_ids = np.array(accum_label_ids)\n",
        "results = metrics(accum_logits, accum_label_ids)\n",
        "\n",
        "print(\"Accuracy: {0:.4f}\".format(results['accuracy']))\n",
        "print(\"F1 (Macro) Score: {0:.4f}\".format(results['f1_macro']))\n",
        "print(\"F1 (Micro) Score: {0:.4f}\".format(results['f1_micro']))\n",
        "print(\"F1 (Weighted) Score: {0:.4f}\".format(results['f1_weighted']))"
      ],
      "id": "6440a0d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 예측\n"
      ],
      "id": "9be8bf8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512,\n",
        "                return_all_scores=True, function_to_apply='softmax')\n",
        "result = pipe('SK하이닉스가 매출이 급성장하였다')\n",
        "print(result)\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=model.cuda(), tokenizer=tokenizer, device=0, max_length=512, function_to_apply='softmax')\n",
        "result = pipe('SK하이닉스가 매출이 급성장하였다')\n",
        "print(result)\n",
        "\n",
        "label_dict = {'LABEL_0' : '중립', 'LABEL_1' : '긍정', 'LABEL_2' : '부정'}\n",
        "\n",
        "def prediction(text):\n",
        "  result = pipe(text)\n",
        "  \n",
        "  return [label_dict[result[0]['label']]]\n",
        "\n",
        "prediction('패스트캠퍼스가 매출이 급성장하였다')\n",
        "prediction('ChatGPT의 등장으로 인공지능 스타트업들은 비상이다')\n",
        "prediction('인공지능 기술의 발전으로 누군가는 기회를 얻을 것이고, 누군가는 얻지 못할 것이다')"
      ],
      "id": "ed2d90ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "현재 데이터셋의 경우 레이블이 3개이지만 만약 레이블이 2개(긍정, 부정)인 이진 분류 문제였다면?\n",
        "모델 로드 시에 num_labels를 바꿔주면 된다.\n"
      ],
      "id": "61627e18"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "num_labels = 2\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=num_labels)\n",
        "model.cuda()"
      ],
      "id": "9d357d71",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "airflow",
      "language": "python",
      "display_name": "Python (airflow)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}