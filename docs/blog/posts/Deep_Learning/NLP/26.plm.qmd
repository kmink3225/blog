---
title: "PLM: Pre-trained Language Model"
subtitle: "실무에서의 현실적 모델 선택과 적용 전략"
description: |
  사전 학습 언어 모델(PLM)의 기술적 발전은 눈부시지만, 모든 프로젝트에 최신 모델을 적용할 수는 없다. 기업 규모, 프로젝트 특성, 비용, 성능 요구사항에 따라 적절한 모델을 선택하는 것이 성공의 핵심이다. LSTM부터 T5, ChatGPT까지의 발전 과정을 살펴보고, 실무에서 마주하는 현실적 제약들 속에서 최적의 모델을 선택하는 전략을 제시한다.
categories:
  - NLP
  - Deep Learning
author: Kwangmin Kim
date: 2025-01-26
format: 
  html:
    page-layout: full
    code-fold: true
    toc: true
    number-sections: true
draft: False
---

# 요약

사전 학습 언어 모델(PLM)은 지속적으로 발전하고 있지만, **무조건 최신 모델이 항상 정답은 아니다**. 기업의 규모, 프로젝트의 특성, 예산 제약, 성능 요구사항에 따라 적절한 모델을 선택하는 것이 실무에서는 더욱 중요하다.

## 모델 발전의 딜레마

기술적으로는 LSTM → BERT → T5 → ChatGPT로 발전할수록 성능이 향상되지만, 실무에서는 다음과 같은 현실적 제약이 있다:

* **비용과 리소스**: 최신 모델일수록 막대한 컴퓨팅 비용과 인프라 필요
* **개발 복잡성**: 고성능 모델은 구현과 튜닝의 난이도가 높음
* **운영 효율성**: 실시간 서비스에서는 지연시간이 비즈니스 성패를 좌우
* **도메인 적합성**: 범용 모델보다 특화된 작은 모델이 더 효과적인 경우 존재

## 현실적 선택 기준

1. **스타트업/중소기업**: 1.3B 이하 오픈소스 모델(BERT, KoGPT)이 현실적 마지노선
2. **중견기업**: 하이브리드 접근법(API + 자체 모델)으로 비용 효율성 추구
3. **대기업**: 자체 인프라와 전문 인력을 바탕으로 최신 모델 적용

## 효과적인 전략들

* **API 활용**: ChatGPT API로 데이터 생성 후 작은 모델 학습
* **모델 조합**: 검색엔진 + ChatGPT + 프롬프트 엔지니어링
* **단계적 접근**: 작은 모델로 시작해서 필요에 따라 확장
* **도메인 특화**: 범용성보다는 특정 문제에 최적화

결국, 문제의 복잡도와 요구사항에 맞는 적절한 모델을 선택하는 것이 성공의 핵심이다.

# NLP 모델 발전 과정

```
RNN Language Model
├── Seq2Seq
├── Beam Search
├── Subword Tokenization
├── Attention
├── Transformer Encoder (Vaswani et al., 2017)
|   ├── Positional Encoding
|   ├── Multi-Head Attention
|   └── Feed Forward Neural Network
|
├── Transformer Decoder (Vaswani et al., 2017)
|
├── GPT 시리즈 (OpenAI,2018~)
|   ├── GPT-1~4
|   └── ChatGPT (OpenAI,2022~)
|
├── BERT 시리즈 (Google,2018~)
|   ├── BERT
|   ├── RoBERTa (Facebook, 2019)
|   ├── ALBERT (Google, 2019)
|   ├── DistilBERT (Hugging Face, 2019)
|   └── ELECTRA (Google, 2020)
|
└── 후속 발전 모델들
    ├── T5, XLNet, DeBERTa
    └── GPT-2/3/4, ChatGPT, PaLM 등
```

# 실무에서의 모델 선택 전략

## 성능 vs 현실 사이의 간극

PLM 기술은 매년 눈부신 발전을 보이고 있다. 논문에서는 항상 더 큰 모델이 더 좋은 성능을 보여주고, 최신 모델들이 이전 모델들의 단점을 보완하며 SOTA를 경신한다. 하지만 실무에서는 이야기가 다르다.

### 기술 발전과 현실적 제약

**기술적 우수성과 실용성은 별개의 문제다**. T5가 BERT보다 우수하고, ChatGPT가 T5보다 뛰어나다고 해서 모든 프로젝트에 ChatGPT를 써야 하는 것은 아니다. 다음과 같은 현실적 제약들이 존재한다:

* **컴퓨팅 비용**: GPT-4 API 호출 비용 vs 자체 BERT 모델 운영 비용
* **지연시간**: 실시간 챗봇에서 3초 응답 vs 100ms 응답의 차이
* **데이터 보안**: 민감한 데이터를 외부 API로 전송할 수 없는 경우
* **커스터마이징**: 도메인 특화 요구사항에 대한 대응 가능성
* **안정성**: 서비스 중단 없이 24/7 운영 가능한지

### 모델별 현실적 접근성

```
[ 기업 규모별 현실적 모델 선택 ]

스타트업 (직원 ~50명)
├── BERT, KoGPT: 무료 오픈소스, 자체 서버 운영 가능
├── OpenAI API: 초기 프로토타입용, 월 예산 ~$1,000
└── 하이브리드: API로 데이터 생성 → 작은 모델 학습

중견기업 (직원 ~500명)  
├── DistilBERT, ALBERT: 효율성 최적화된 모델
├── T5-Small/Base: 적당한 성능과 비용의 균형
├── API + 자체모델: 복잡한 태스크는 API, 단순한 것은 자체 모델
└── 클라우드 GPU: AWS/GCP의 관리형 서비스 활용

대기업 (직원 1,000명+)
├── T5-Large, GPT-3.5 수준: 자체 인프라로 운영
├── 전용 하드웨어: A100 클러스터, TPU 등
├── 자체 모델 개발: 도메인 특화 대규모 모델
└── 하이브리드 전략: 용도별로 다양한 모델 조합
```

## 프로젝트 특성별 모델 선택

### 문서 분류 프로젝트 사례

**상황**: 고객 문의사항을 10개 카테고리로 자동 분류하는 시스템

**옵션별 비교**:

```python
# 옵션 1: BERT-Base (110M)
장점: 
- 분류 태스크에 최적화된 구조
- 빠른 추론 속도 (10-50ms)
- 완전한 온프레미스 운영 가능
- 충분한 성능 (95%+ 정확도)

단점:
- 새로운 카테고리 추가 시 재학습 필요
- 복잡한 추론이나 설명 생성 불가

비용: 월 $100 (AWS t3.medium 인스턴스)
```

```python
# 옵션 2: GPT-4 API
장점:
- Few-shot learning으로 빠른 적응
- 분류 근거까지 자연어로 설명 가능
- 새 카테고리 추가가 프롬프트 수정만으로 가능
- 복잡한 경계 케이스도 잘 처리

단점:
- 높은 API 비용 (요청당 $0.03-0.06)
- 외부 의존성으로 인한 서비스 리스크
- 응답 속도 변동성 (200ms-2s)

비용: 월 $3,000-5,000 (일 10,000건 처리 시)
```

### 실제 선택 기준

**언제 작은 모델을 선택해야 하는가?**

1. **명확한 태스크 정의**: 감정 분석, 개체명 인식 등 잘 정의된 문제
2. **빠른 응답 필요**: 실시간 추천, 챗봇 등
3. **대용량 배치 처리**: 비용 효율성이 핵심인 경우 (단순 반복 작업)
   - 예: 일일 수백만 건의 뉴스 기사 분류
   - 예: 고객 리뷰의 감정 분석 (긍정/부정/중립)
   - 예: 이메일 스팸 필터링
   - 이유: API 비용($0.03/건 × 100만건 = $30,000/일) vs 자체 모델($100/월)
4. **데이터 보안**: 금융, 의료 등 민감한 정보
5. **예산 제약**: 스타트업의 MVP(Minimum Viable Product) 단계

**언제 큰 모델을 선택해야 하는가?**

1. **복잡한 추론**: 다단계 논리적 사고가 필요한 경우
2. **유연성 중요**: 요구사항이 자주 변하는 환경
3. **높은 품질 요구**: 고객 대면 서비스, 브랜드 이미지가 중요한 경우
4. **다양한 태스크**: 하나의 모델로 여러 기능을 처리해야 하는 경우
5. **소량 고품질 처리**: 일일 수천~수만 건의 프리미엄 서비스 (고품질의 창의적 작업)
   - 예: 법률 문서 분석 및 요약
   - 예: 개인 맞춤형 투자 조언 생성
   - 예: 고급 마케팅 콘텐츠 작성
6. **충분한 예산**: ROI가 명확하게 보장되는 경우

## 현실적 하이브리드 전략

### 계층적 모델 활용

많은 기업들이 실제로 사용하는 전략은 **단일 모델이 아닌 계층적 접근법**이다. 태스크의 복잡도에 따라 적절한 모델을 라우팅하는 방식이다.

**핵심은 복잡도 분류 모델(라우터)**이다. 이 작은 모델이 전체 시스템의 효율성을 결정한다:

**복잡도별 태스크 분류:**

- **Simple (단순)**: 정형화된 정보 검색, 단순 분류
  - FAQ 검색, 카테고리 분류, 키워드 추출
  - BERT, DistilBERT 등 가벼운 모델로 충분

- **Medium (중간)**: 텍스트 변환, 기본적인 생성
  - 문서 요약, 번역, 제품 설명 생성, 이메일 자동 응답
  - 템플릿 기반 보고서 작성, 간단한 QA
  - T5, BART 등 encoder-decoder 모델 적합

- **Complex (복잡)**: 창의적 사고, 복합적 추론
  - 마케팅 콘텐츠 창작, 코드 생성, 복잡한 분석
  - 다단계 논리 추론, 개인화된 조언
  - GPT-4, Claude 등 대규모 모델 필요

```python
# 1단계: 질문 복잡도 분류 모델 (라우터)
class ComplexityClassifier:
    def __init__(self):
        # 가벼운 BERT 모델로 빠른 분류 (10-20ms)
        self.model = DistilBERT_for_classification()
        
    def predict_complexity(self, query):
        features = self.extract_features(query)
        return self.model.predict(features)
    
    def extract_features(self, query):
        return {
            'length': len(query.split()),
            'question_words': count_wh_words(query),
            'conjunctions': count_conjunctions(query),
            'domain_keywords': check_domain_keywords(query),
            'sentiment_complexity': analyze_sentiment_depth(query)
        }

def smart_routing(user_query):
    # 1단계: 빠른 분류기로 복잡도 판단
    classifier = ComplexityClassifier()
    complexity = classifier.predict_complexity(user_query)
    
    if complexity == "simple":
        # 단순 반복의 간단한 질문은 BERT 기반 FAQ 검색
        # 예: "운영시간이 언제인가요?", "배송비는 얼마인가요?"
        return faq_bert_model.search(user_query)
    
    elif complexity == "medium":
        # 중간 복잡도는 T5 모델 사용
        # 예: 제품 설명 요약, 기본적인 문서 생성, 간단한 QA
        return t5_model.generate_response(user_query)
    
    else:  # complex
        # 복잡한 질문만 GPT-4 API 호출
        # 예: 창의적 글쓰기, 복잡한 분석, 다단계 추론
        return openai_api.complete(user_query)
```

**복잡도 분류 모델의 학습 데이터 예시:**

```python
# 학습 데이터셋 구축
training_data = [
    # Simple (단순) - 정형화된 질문
    ("운영시간이 언제인가요?", "simple"),
    ("배송비는 얼마인가요?", "simple"), 
    ("환불 정책을 알려주세요", "simple"),
    ("계정을 삭제하고 싶어요", "simple"),
    
    # Medium (중간) - 변환/생성이 필요한 질문
    ("이 제품의 장단점을 요약해주세요", "medium"),
    ("고객 불만사항을 정중한 답변으로 작성해주세요", "medium"),
    ("이 기사를 3문장으로 요약해주세요", "medium"),
    ("영어를 한국어로 번역해주세요", "medium"),
    
    # Complex (복잡) - 창의적/분석적 사고 필요
    ("우리 회사에 맞는 마케팅 전략을 제안해주세요", "complex"),
    ("이 데이터를 분석해서 인사이트를 도출해주세요", "complex"),
    ("소설의 첫 장을 써주세요", "complex"),
    ("복잡한 법률 문제를 분석해주세요", "complex")
]

# 분류기 성능 최적화 포인트
accuracy_requirements = {
    'simple_recall': 0.95,  # 단순 질문을 놓치면 안됨 (비용 증가)
    'complex_precision': 0.90,  # 복잡한 질문을 잘못 분류하면 품질 저하
    'medium_balance': 0.85   # 중간 복잡도는 어느쪽으로 가도 큰 문제없음
}
```

**라우터 모델의 실제 운영 고려사항:**

```python
class ProductionComplexityClassifier:
    def __init__(self):
        self.model = DistilBERT()  # 20MB, 추론 10-15ms
        self.fallback_rules = self.load_rule_based_backup()
        self.confidence_threshold = 0.7
        
    def predict_with_confidence(self, query):
        prediction, confidence = self.model.predict_proba(query)
        
        # 확신이 낮으면 안전한 쪽(더 큰 모델)으로
        if confidence < self.confidence_threshold:
            return "medium"  # 애매하면 중간 모델로
            
        # 키워드 기반 안전장치
        if self.check_safety_keywords(query):
            return "complex"  # 민감한 키워드는 무조건 큰 모델
            
        return prediction
    
    def check_safety_keywords(self, query):
        # 법률, 의료, 금융 등 민감한 영역은 큰 모델로
        sensitive_keywords = ['법률', '의료', '투자', '세금', '계약']
                 return any(keyword in query for keyword in sensitive_keywords)
```

**라우터 시스템의 비용 효율성 분석:**

```python
# 월 100,000건 처리 시 비용 비교
routing_costs = {
    # 라우터 없이 모든 요청을 GPT-4로 처리
    'all_gpt4': {
        'api_cost': 100000 * 0.03,  # $3,000
        'router_cost': 0,
        'total': 3000
    },
    
    # 라우터 사용 (70% simple, 20% medium, 10% complex)
    'with_router': {
        'simple_cost': 70000 * 0.001,   # BERT 자체 호스팅: $70
        'medium_cost': 20000 * 0.01,    # T5 자체 호스팅: $200  
        'complex_cost': 10000 * 0.03,   # GPT-4 API: $300
        'router_cost': 100000 * 0.0005, # DistilBERT: $50
        'total': 620  # 80% 비용 절약!
    }
}

# 성능 vs 비용 트레이드오프
performance_metrics = {
    'accuracy': {
        'all_gpt4': 0.95,        # 모든 요청 고품질
        'with_router': 0.92      # 라우팅 오류로 약간 감소
    },
    'latency': {
        'all_gpt4': '800ms',     # 모든 요청이 느림
        'with_router': '200ms'   # 70%는 빠른 응답
    },
    'cost_per_query': {
        'all_gpt4': '$0.03',
        'with_router': '$0.006'  # 5배 저렴
    }
}
```

### API를 활용한 데이터 생성 전략

**ChatGPT API로 학습 데이터 생성하기**:

```python
# 1. 고품질 데이터 생성 (일회성 비용)
def generate_training_data():
    prompts = [
        "고객 불만사항 100개를 생성해줘. 다양한 톤과 상황을 포함해서.",
        "제품 문의사항 50개를 생성해줘. 기술적 질문과 일반적 질문을 섞어서.",
    ]
    
    training_data = []
    for prompt in prompts:
        response = openai.Completion.create(
            model="gpt-4",
            prompt=prompt,
            max_tokens=2000
        )
        training_data.append(response.choices[0].text)
    
    return training_data

# 2. 생성된 데이터로 작은 모델 학습
def train_custom_model(training_data):
    # BERT나 DistilBERT를 fine-tuning
    model = AutoModel.from_pretrained("bert-base-multilingual-cased")
    # ... 학습 코드
    return model
```

**이 방식의 장점**:
- 초기에만 API 비용 발생 (월 $500-1000)
- 이후 자체 모델로 무제한 사용 가능
- 도메인 특화된 고품질 데이터 확보
- 완전한 통제권과 커스터마이징 가능

### 단계별 모델 도입 전략

실무에서는 처음부터 완벽한 시스템을 구축하려 하지 말고, 단계적으로 접근하는 것이 현명하다.

**Phase 1: MVP 단계 (Minimum Viable Produc, 최소 기능 제품)**
```
목표: 빠른 검증과 프로토타입, 핵심 기능만 구현
모델: OpenAI API 또는 Hugging Face 사전 학습 모델
특징: 완벽함보다는 속도, 시장 반응 테스트가 우선
전략: 일단 돌아가는 것을 만든 후 사용자 피드백 수집
기간: 1-2개월
예산: $1,000-5,000

MVP 예시:
- 고객 문의 자동 분류: OpenAI API로 빠른 프로토타입
- 기본 챗봇: Hugging Face ChatBot 모델 + 간단한 인터페이스
- 문서 요약 도구: GPT-3.5 API + 웹 인터페이스
```

**Phase 2: 확장 단계 (Product-Market Fit 달성 후)**
```
목표: 비용 최적화와 성능 개선
모델: 자체 학습한 BERT/T5 + API 하이브리드
특징: 사용량 증가에 따른 비용 압박, 성능 요구사항 명확화
전략: 대부분은 자체 모델, 복잡한 것만 API 활용
기간: 3-6개월  
예산: $5,000-20,000

확장 단계 예시:
- 80% 질문은 자체 BERT 모델로 처리
- 20% 복잡한 질문만 GPT-4 API 사용
- 도메인 특화 데이터로 모델 fine-tuning
```

**Phase 3: 성숙 단계 (스케일업)**
```
목표: 완전한 커스터마이징과 독립성
모델: 도메인 특화 대규모 모델 + 자체 인프라
특징: 대규모 사용자, 차별화된 서비스 필요
전략: 핵심 기술의 내재화, 경쟁 우위 확보
기간: 6개월+
예산: $50,000+

성숙 단계 예시:
- 자체 개발한 도메인 특화 LLM
- 전용 GPU 클러스터 운영
- A/B 테스트 기반 지속적 모델 개선
```

## 의사결정 프레임워크

### 모델 선택 체크리스트

**1. 기술적 요구사항**
- [ ] 정확도 임계값: 90%? 95%? 99%?
- [ ] 응답 속도: 실시간(<100ms)? 준실시간(<1s)? 배치?
- [ ] 동시 사용자 수: 10명? 1,000명? 10,000명?
- [ ] 데이터 민감도: 공개 가능? 제한적? 극비?

**2. 비즈니스 제약사항**
- [ ] 월 예산: $100? $1,000? $10,000?
- [ ] 개발 기간: 1주? 1개월? 6개월?
- [ ] 팀 역량: 연구원 있음? 엔지니어만? 외주?
- [ ] 인프라: 클라우드? 온프레미스? 하이브리드?

**3. 전략적 고려사항**
- [ ] 확장성: 현재만? 향후 10배 성장?
- [ ] 차별화: 경쟁사 대비 핵심 요소?
- [ ] 종속성: 외부 의존 허용? 독립성 필요?
- [ ] 유지보수: 지속적 개선? 일회성 구축?

### 실무진을 위한 가이드라인

**"이럴 때는 이 모델을"**

```
📱 모바일 앱의 실시간 챗봇 (단순)
→ DistilBERT + 사전 정의된 답변 세트
이유: 빠른 응답, 낮은 배터리 소모, 오프라인 가능

🏪 이커머스 상품 검색 (단순)
→ BERT + Elasticsearch
이유: 정확한 의미 검색, 확장성, 비용 효율성

📋 고객 지원 티켓 분류 (단순→복잡)
→ BERT → 복잡한 경우만 GPT-4 API
이유: 대부분은 단순 분류, 어려운 케이스만 고급 모델

📰 뉴스 요약 서비스 (중간)
→ T5 또는 BART
이유: 정형화된 요약 패턴, 일관된 품질, 중간 수준의 이해력

📧 이메일 자동 응답 (중간)
→ T5 + 템플릿 시스템
이유: 기본 구조는 정해져 있고, 내용만 상황에 맞게 생성

🌐 다국어 번역 서비스 (중간)
→ T5 multilingual 또는 mBART
이유: 언어 쌍별 모델보다 효율적, 준수한 품질

✍️ 마케팅 콘텐츠 생성 (복잡)
→ GPT-4 API
이유: 창의성과 품질이 ROI에 직결

🏥 의료 텍스트 분석 (단순)
→ 도메인 특화 BERT (BioBERT)
이유: 전문성, 규제 준수, 설명 가능성

💰 금융 리스크 분석 (단순)
→ 자체 학습 모델 (데이터 보안)
이유: 규제, 보안, 실시간 대량 처리
```

실무에서는 **기술적 완벽함보다 비즈니스 목표 달성**이 우선이다. 최고의 모델이 아니라 **현재 상황에서 최적인 모델**을 선택하는 것이 성공의 열쇠다.

# 결론

* PLM 기술의 발전은 놀랍지만, 실무에서는 **기술적 우수성과 현실적 제약 사이의 균형**을 맞추는 것이 핵심이다. 
* 단순한 분류 문제에 수십억 파라미터의 모델을 사용하는 것은 비효율적이다. 반대로 복잡한 추론이 필요한 곳에 작은 모델만 고집하는 것도 기회 손실이다.
* 중요한 것은 **문제의 본질을 이해하고, 제약 조건을 명확히 하며, 단계적으로 접근하는 것**이다. 오늘은 BERT로 시작해서 내일은 T5로, 필요하다면 GPT-4로 발전시켜 나가는 것이 현실적인 전략이다.
* 결국 가장 좋은 모델은 **가장 비싼 모델이 아니라, 주어진 상황에서 목표를 가장 효과적으로 달성하는 모델**이다. 기술은 수단이지 목적이 아니라는 점을 항상 기억해
 






